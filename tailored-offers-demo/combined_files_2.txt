Combined text files
Input: /Users/rguru/techlearning/AmericanAirlinesLearning/to_agent2/tailored-offers-demo
Part 2
Total files: 110
--------------------------------------------------------------------------------

================================================================================
FILE: combined_files_2.txt
================================================================================


================================================================================
FILE: combined_files_3.txt
================================================================================
Combined text files
Input: /Users/rguru/techlearning/AmericanAirlinesLearning/to_agent2/tailored-offers-demo
Part 3
Total files: 107
--------------------------------------------------------------------------------

================================================================================
FILE: frontend/src/components/PipelineVisualization.tsx
================================================================================
import { useState } from 'react';
import type { AgentResult, AgentStatus, ComponentType } from '../types';

type ExecutionMode = 'choreography' | 'planner-worker';

interface AgentConfig {
  id: string;
  name: string;
  short_name: string;
  icon: string;
  component_type: ComponentType;
}

interface Props {
  agents: AgentConfig[];
  agentResults: Record<string, AgentResult>;
  currentAgentId: string | null;
  selectedAgentTab: string | null;
  onSelectAgent: (agentId: string) => void;
  executionMode?: ExecutionMode | null;
  hitlEnabled?: boolean;
  plannerState?: { isActive: boolean; plan?: string[]; reasoning?: string };
}

// State field mappings for each node
const NODE_STATE_FIELDS: Record<string, { inputs: string[]; outputs: string[] }> = {
  load_data: {
    inputs: ['pnr_locator'],
    outputs: ['customer_data', 'flight_data', 'reservation_data', 'ml_scores']
  },
  customer_intelligence: {
    inputs: ['customer_data', 'reservation_data', 'ml_scores'],
    outputs: ['customer_eligible', 'customer_segment', 'suppression_reason']
  },
  flight_optimization: {
    inputs: ['flight_data', 'reservation_data'],
    outputs: ['flight_priority', 'recommended_cabins', 'inventory_status']
  },
  offer_orchestration: {
    inputs: ['customer_segment', 'recommended_cabins', 'ml_scores', 'flight_data'],
    outputs: ['should_send_offer', 'selected_offer', 'offer_price', 'expected_value', 'fallback_offer']
  },
  personalization: {
    inputs: ['customer_data', 'selected_offer', 'offer_price', 'flight_data'],
    outputs: ['message_subject', 'message_body', 'message_tone']
  },
  channel_timing: {
    inputs: ['customer_data', 'reservation_data'],
    outputs: ['selected_channel', 'send_time', 'backup_channel']
  },
  measurement: {
    inputs: ['pnr_locator', 'selected_offer'],
    outputs: ['experiment_group', 'tracking_id']
  },
  final_decision: {
    inputs: ['should_send_offer', 'selected_offer', 'offer_price', 'message_subject', 'selected_channel', 'experiment_group'],
    outputs: ['final_decision']
  }
};

export function PipelineVisualization({
  agents: _agents,
  agentResults,
  currentAgentId,
  selectedAgentTab: _selectedAgentTab,
  onSelectAgent,
  executionMode,
  hitlEnabled = false,
  plannerState,
}: Props) {
  const [showStatePanel, setShowStatePanel] = useState(false);
  const [hoveredNode, setHoveredNode] = useState<string | null>(null);

  const isPlannerWorker = executionMode === 'planner-worker';

  const getAgentStatus = (agentId: string): AgentStatus => {
    if (currentAgentId === agentId) return 'processing';
    const result = agentResults[agentId];
    if (!result) return 'pending';
    return result.status as AgentStatus;
  };

  // Check if customer was eligible (to show conditional path)
  const customerEligible = agentResults['customer_intelligence']?.status === 'complete' &&
    !agentResults['customer_intelligence']?.summary?.includes('NOT ELIGIBLE');

  // Check if offer was made (to show conditional path)
  const offerMade = agentResults['offer_orchestration']?.status === 'complete' &&
    !agentResults['offer_orchestration']?.summary?.includes('NO OFFER');

  // Determine which path was taken
  const earlyExit = agentResults['customer_intelligence']?.status === 'complete' && !customerEligible;
  const offerExit = agentResults['offer_orchestration']?.status === 'complete' && !offerMade;

  // Get completed nodes for edge animation
  const completedNodes = Object.entries(agentResults)
    .filter(([, r]) => r.status === 'complete')
    .map(([id]) => id);

  // Extract actual state values from results
  const getStateValue = (key: string): string | null => {
    for (const result of Object.values(agentResults)) {
      if (result.outputs && key in result.outputs) {
        const val = result.outputs[key];
        if (typeof val === 'boolean') return val ? '‚úì true' : '‚úó false';
        if (typeof val === 'number') return val.toFixed(2);
        if (typeof val === 'string') return val.length > 20 ? val.slice(0, 20) + '...' : val;
        if (Array.isArray(val)) return `[${val.join(', ')}]`;
        return JSON.stringify(val).slice(0, 30);
      }
    }
    return null;
  };

  // Render animated edge with flowing particles
  const renderAnimatedEdge = (
    pathD: string,
    isActive: boolean,
    isError: boolean = false,
    key: string
  ) => {
    // Animation phase used for coordinating particle movement
    return (
      <g key={key}>
        <path
          d={pathD}
          fill="none"
          stroke={isError ? '#ef4444' : isActive ? '#10b981' : '#d1d5db'}
          strokeWidth={isActive ? 3 : 2}
          strokeDasharray={isError && !earlyExit && !offerExit ? '4' : '0'}
        />
        {isActive && !isError && (
          <>
            <circle r="4" fill="#10b981">
              <animateMotion dur="1.5s" repeatCount="indefinite" path={pathD} />
            </circle>
            <circle r="4" fill="#10b981" opacity="0.5">
              <animateMotion dur="1.5s" repeatCount="indefinite" path={pathD} begin="0.5s" />
            </circle>
          </>
        )}
      </g>
    );
  };

  // Node hover tooltip
  const renderNodeTooltip = (nodeId: string, x: number, y: number) => {
    if (hoveredNode !== nodeId) return null;
    const fields = NODE_STATE_FIELDS[nodeId];
    if (!fields) return null;

    return (
      <g transform={`translate(${x}, ${y})`}>
        <rect
          x="-100"
          y="-80"
          width="200"
          height="75"
          rx="6"
          fill="#1e293b"
          fillOpacity="0.95"
          stroke="#475569"
        />
        <text x="-90" y="-60" fontSize="8" fill="#94a3b8" fontWeight="bold">READS FROM STATE:</text>
        <text x="-90" y="-48" fontSize="7" fill="#60a5fa">{fields.inputs.slice(0, 3).join(', ')}</text>
        <text x="-90" y="-32" fontSize="8" fill="#94a3b8" fontWeight="bold">WRITES TO STATE:</text>
        <text x="-90" y="-20" fontSize="7" fill="#4ade80">{fields.outputs.slice(0, 3).join(', ')}</text>
      </g>
    );
  };

  return (
    <div className="bg-white rounded-xl shadow-sm border border-gray-200 p-6">
      <div className="flex items-center justify-between mb-2">
        <h2 className="text-lg font-semibold text-gray-800 flex items-center gap-2">
          <span>LangGraph Workflow</span>
          {/* Execution Mode Badge */}
          {executionMode && (
            <span className={`text-xs font-normal px-2 py-0.5 rounded ${
              isPlannerWorker
                ? 'bg-amber-100 text-amber-700'
                : 'bg-emerald-100 text-emerald-700'
            }`}>
              {isPlannerWorker ? 'üß† Planner-Worker' : '‚ö° Choreography'}
            </span>
          )}
          {!executionMode && (
            <span className="text-xs font-normal text-gray-500 bg-gray-100 px-2 py-0.5 rounded">
              Sequential + Conditional Routing
            </span>
          )}
          {hitlEnabled && (
            <span className="text-xs font-normal bg-purple-100 text-purple-700 px-2 py-0.5 rounded">
              üë§ HITL
            </span>
          )}
          {currentAgentId && (
            <span className="text-sm font-normal text-blue-600 animate-pulse">
              Processing...
            </span>
          )}
        </h2>
        <div className="flex gap-2">
          <button
            onClick={() => setShowStatePanel(!showStatePanel)}
            className={`text-xs px-3 py-1.5 rounded transition-colors ${
              showStatePanel
                ? 'bg-slate-700 text-white'
                : 'bg-slate-100 text-slate-600 hover:bg-slate-200'
            }`}
          >
            {showStatePanel ? '‚úì State View' : '{ } View State'}
          </button>
        </div>
      </div>

      {/* Planner State Banner (for planner-worker mode) */}
      {isPlannerWorker && plannerState?.isActive && (
        <div className="mb-3 p-3 bg-amber-50 border border-amber-200 rounded-lg flex items-center gap-3">
          <span className="text-2xl animate-spin">üéØ</span>
          <div>
            <div className="font-medium text-amber-800">Planner Analyzing...</div>
            <div className="text-sm text-amber-600">Determining optimal execution sequence based on current state</div>
          </div>
        </div>
      )}
      {isPlannerWorker && plannerState?.reasoning && !plannerState?.isActive && (
        <div className="mb-3 p-3 bg-blue-50 border border-blue-200 rounded-lg">
          <div className="flex items-center gap-2 mb-1">
            <span>üéØ</span>
            <span className="font-medium text-blue-800">Planner Decision</span>
          </div>
          <div className="text-sm text-blue-700">{plannerState.reasoning}</div>
        </div>
      )}

      {/* LangGraph Code Reference */}
      <div className="bg-slate-50 border border-slate-200 rounded-lg p-3 mb-4 font-mono text-xs">
        <div className="flex justify-between items-center">
          <div>
            <span className="text-slate-500"># workflow.py</span>
            <span className="text-slate-700 ml-2">
              <span className="text-purple-600">workflow</span> = StateGraph(<span className="text-blue-600">AgentState</span>)
            </span>
          </div>
          <div className="text-slate-400 text-[10px]">
            Pattern: {isPlannerWorker ? 'Planner-Worker (Dynamic Routing)' : 'Sequential Pipeline with Short-Circuit'}
          </div>
        </div>
      </div>

      {/* Graph Visualization - Conditional based on execution mode */}
      <div className="relative bg-gradient-to-br from-slate-50 to-slate-100 rounded-lg p-4 overflow-x-auto border border-slate-200">
        {isPlannerWorker ? (
          /* Planner-Worker Visualization - Hub and Spoke */
          <svg className="w-full" height="340" viewBox="0 0 920 340">
            {/* Background Grid */}
            <defs>
              <pattern id="grid-pw" width="20" height="20" patternUnits="userSpaceOnUse">
                <path d="M 20 0 L 0 0 0 20" fill="none" stroke="#e2e8f0" strokeWidth="0.5" />
              </pattern>
            </defs>
            <rect width="100%" height="100%" fill="url(#grid-pw)" />

            {/* Entry: START ‚Üí load_data */}
            <g transform="translate(40, 170)">
              <circle r="14" fill="#10b981" stroke="#059669" strokeWidth="2">
                <animate attributeName="r" values="14;16;14" dur="2s" repeatCount="indefinite" />
              </circle>
              <text x="0" y="5" textAnchor="middle" fontSize="11" fill="white" fontWeight="bold">‚ñ∂</text>
              <text x="0" y="35" textAnchor="middle" fontSize="9" fill="#6b7280">START</text>
            </g>

            {/* Arrow to load_data */}
            <line x1="54" y1="170" x2="90" y2="170" stroke="#10b981" strokeWidth="2" markerEnd="url(#arrow-pw)" />

            {/* load_data node */}
            <g transform="translate(90, 140)">
              <rect width="80" height="60" rx="8" fill="#f8fafc" stroke="#64748b" strokeWidth="2" />
              <text x="40" y="25" textAnchor="middle" fontSize="16">üì•</text>
              <text x="40" y="42" textAnchor="middle" fontSize="8" fill="#475569" fontWeight="600">load_data</text>
            </g>

            {/* Arrow to Planner */}
            <line x1="170" y1="170" x2="250" y2="170" stroke="#f59e0b" strokeWidth="2" markerEnd="url(#arrow-amber)" />

            {/* PLANNER HUB - Central node */}
            <g transform="translate(340, 170)">
              {/* Glow effect */}
              <circle r="75" fill="none" stroke="#f59e0b" strokeWidth="2" opacity="0.3">
                <animate attributeName="r" values="75;80;75" dur="2s" repeatCount="indefinite" />
              </circle>
              <circle
                r="70"
                fill={plannerState?.isActive ? '#fef3c7' : '#fffbeb'}
                stroke="#f59e0b"
                strokeWidth="3"
                className={plannerState?.isActive ? 'animate-pulse' : ''}
              />
              <text x="0" y="-20" textAnchor="middle" fontSize="28">üéØ</text>
              <text x="0" y="5" textAnchor="middle" fontSize="12" fill="#92400e" fontWeight="bold">PLANNER</text>
              <text x="0" y="20" textAnchor="middle" fontSize="8" fill="#b45309">(LLM)</text>
              <text x="0" y="35" textAnchor="middle" fontSize="7" fill="#d97706">decides next step</text>
            </g>

            {/* Workers arranged around planner */}
            {/* Customer Intelligence - Top Left */}
            <g
              transform="translate(500, 40)"
              onClick={() => onSelectAgent('customer_intelligence')}
              style={{ cursor: 'pointer' }}
            >
              <rect
                width="100"
                height="65"
                rx="10"
                fill={getAgentStatus('customer_intelligence') === 'complete' ? '#ecfdf5' :
                      getAgentStatus('customer_intelligence') === 'processing' ? '#dbeafe' : '#f8fafc'}
                stroke={getAgentStatus('customer_intelligence') === 'complete' ? '#10b981' :
                        getAgentStatus('customer_intelligence') === 'processing' ? '#3b82f6' : '#cbd5e1'}
                strokeWidth={getAgentStatus('customer_intelligence') === 'processing' ? 3 : 2}
                className={getAgentStatus('customer_intelligence') === 'processing' ? 'animate-pulse' : ''}
              />
              <text x="50" y="25" textAnchor="middle" fontSize="18">üß†</text>
              <text x="50" y="42" textAnchor="middle" fontSize="7" fill="#475569" fontWeight="600">customer_intel</text>
              {getAgentStatus('customer_intelligence') === 'complete' && (
                <circle cx="85" cy="12" r="10" fill="#10b981"><text x="85" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text></circle>
              )}
            </g>
            {/* Bidirectional arrow */}
            <line x1="410" y1="140" x2="500" y2="80" stroke={getAgentStatus('customer_intelligence') !== 'pending' ? '#10b981' : '#cbd5e1'} strokeWidth="2" />
            <line x1="500" y1="80" x2="410" y2="140" stroke={getAgentStatus('customer_intelligence') !== 'pending' ? '#10b981' : '#cbd5e1'} strokeWidth="2" strokeDasharray="4" />

            {/* Flight Optimization - Top Right */}
            <g
              transform="translate(650, 40)"
              onClick={() => onSelectAgent('flight_optimization')}
              style={{ cursor: 'pointer' }}
            >
              <rect
                width="100"
                height="65"
                rx="10"
                fill={getAgentStatus('flight_optimization') === 'complete' ? '#ecfdf5' :
                      getAgentStatus('flight_optimization') === 'processing' ? '#dbeafe' : '#f8fafc'}
                stroke={getAgentStatus('flight_optimization') === 'complete' ? '#10b981' :
                        getAgentStatus('flight_optimization') === 'processing' ? '#3b82f6' : '#cbd5e1'}
                strokeWidth={getAgentStatus('flight_optimization') === 'processing' ? 3 : 2}
              />
              <text x="50" y="25" textAnchor="middle" fontSize="18">üìä</text>
              <text x="50" y="42" textAnchor="middle" fontSize="7" fill="#475569" fontWeight="600">flight_opt</text>
              {getAgentStatus('flight_optimization') === 'complete' && (
                <circle cx="85" cy="12" r="10" fill="#10b981"><text x="85" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text></circle>
              )}
            </g>
            <line x1="410" y1="150" x2="650" y2="80" stroke={getAgentStatus('flight_optimization') !== 'pending' ? '#10b981' : '#cbd5e1'} strokeWidth="2" />

            {/* Offer Orchestration - Right (THE AGENT with ReWOO) */}
            <g
              transform="translate(650, 140)"
              onClick={() => onSelectAgent('offer_orchestration')}
              style={{ cursor: 'pointer' }}
            >
              <rect
                width="110"
                height="70"
                rx="10"
                fill={getAgentStatus('offer_orchestration') === 'complete' ? '#eff6ff' :
                      getAgentStatus('offer_orchestration') === 'processing' ? '#dbeafe' : '#f0f9ff'}
                stroke="#3b82f6"
                strokeWidth="3"
              />
              <text x="55" y="25" textAnchor="middle" fontSize="20">‚öñÔ∏è</text>
              <text x="55" y="42" textAnchor="middle" fontSize="7" fill="#1e40af" fontWeight="700">offer_orchestration</text>
              <rect x="5" y="52" width="50" height="12" rx="3" fill="#2563eb" />
              <text x="30" y="61" textAnchor="middle" fontSize="5" fill="white">üß† ReWOO</text>
              {getAgentStatus('offer_orchestration') === 'complete' && (
                <circle cx="95" cy="12" r="10" fill="#3b82f6"><text x="95" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text></circle>
              )}
            </g>
            <line x1="410" y1="170" x2="650" y2="175" stroke={getAgentStatus('offer_orchestration') !== 'pending' ? '#3b82f6' : '#cbd5e1'} strokeWidth="2" />

            {/* Personalization - Bottom Right */}
            <g
              transform="translate(650, 235)"
              onClick={() => onSelectAgent('personalization')}
              style={{ cursor: 'pointer' }}
            >
              <rect
                width="100"
                height="65"
                rx="10"
                fill={getAgentStatus('personalization') === 'complete' ? '#faf5ff' :
                      getAgentStatus('personalization') === 'processing' ? '#f3e8ff' : '#fdf4ff'}
                stroke={getAgentStatus('personalization') === 'complete' ? '#a855f7' : '#d8b4fe'}
                strokeWidth="2"
              />
              <text x="50" y="25" textAnchor="middle" fontSize="18">‚ú®</text>
              <text x="50" y="42" textAnchor="middle" fontSize="7" fill="#7c3aed" fontWeight="600">personalization</text>
              <rect x="5" y="48" width="35" height="12" rx="3" fill="#9333ea" />
              <text x="22" y="57" textAnchor="middle" fontSize="6" fill="white">LLM</text>
              {getAgentStatus('personalization') === 'complete' && (
                <circle cx="85" cy="12" r="10" fill="#a855f7"><text x="85" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text></circle>
              )}
            </g>
            <line x1="410" y1="190" x2="650" y2="260" stroke={getAgentStatus('personalization') !== 'pending' ? '#a855f7' : '#cbd5e1'} strokeWidth="2" />

            {/* Channel Timing - Bottom */}
            <g
              transform="translate(500, 275)"
              onClick={() => onSelectAgent('channel_timing')}
              style={{ cursor: 'pointer' }}
            >
              <rect
                width="100"
                height="55"
                rx="10"
                fill={getAgentStatus('channel_timing') === 'complete' ? '#ecfdf5' : '#f8fafc'}
                stroke={getAgentStatus('channel_timing') === 'complete' ? '#10b981' : '#cbd5e1'}
                strokeWidth="2"
              />
              <text x="50" y="22" textAnchor="middle" fontSize="16">üì±</text>
              <text x="50" y="38" textAnchor="middle" fontSize="7" fill="#475569" fontWeight="600">channel_timing</text>
              {getAgentStatus('channel_timing') === 'complete' && (
                <circle cx="85" cy="10" r="10" fill="#10b981"><text x="85" y="14" textAnchor="middle" fontSize="10" fill="white">‚úì</text></circle>
              )}
            </g>
            <line x1="390" y1="220" x2="500" y2="290" stroke={getAgentStatus('channel_timing') !== 'pending' ? '#10b981' : '#cbd5e1'} strokeWidth="2" />

            {/* Measurement - Bottom Left */}
            <g
              transform="translate(280, 275)"
              onClick={() => onSelectAgent('measurement')}
              style={{ cursor: 'pointer' }}
            >
              <rect
                width="100"
                height="55"
                rx="10"
                fill={getAgentStatus('measurement') === 'complete' ? '#fefce8' : '#fefce8'}
                stroke={getAgentStatus('measurement') === 'complete' ? '#ca8a04' : '#d4d4d8'}
                strokeWidth="2"
                strokeDasharray="4 2"
              />
              <text x="50" y="22" textAnchor="middle" fontSize="16">üè∑Ô∏è</text>
              <text x="50" y="38" textAnchor="middle" fontSize="7" fill="#854d0e" fontWeight="600">measurement</text>
              {getAgentStatus('measurement') === 'complete' && (
                <circle cx="85" cy="10" r="10" fill="#ca8a04"><text x="85" y="14" textAnchor="middle" fontSize="10" fill="white">‚úì</text></circle>
              )}
            </g>
            <line x1="310" y1="220" x2="330" y2="275" stroke={getAgentStatus('measurement') !== 'pending' ? '#ca8a04' : '#cbd5e1'} strokeWidth="2" />

            {/* Exit: Planner ‚Üí final_decision ‚Üí END */}
            <g transform="translate(780, 155)">
              <rect width="80" height="50" rx="8" fill="#f0fdf4" stroke="#22c55e" strokeWidth="2" />
              <text x="40" y="22" textAnchor="middle" fontSize="14">üéØ</text>
              <text x="40" y="38" textAnchor="middle" fontSize="7" fill="#166534" fontWeight="600">final_decision</text>
            </g>
            <line x1="410" y1="170" x2="780" y2="180" stroke="#22c55e" strokeWidth="2" strokeDasharray="6" />
            <text x="600" y="165" fontSize="7" fill="#6b7280">when complete</text>

            {/* END node */}
            <g transform="translate(880, 165)">
              <circle r="15" fill="#dc2626" stroke="#b91c1c" strokeWidth="2" />
              <rect x="-7" y="-5" width="14" height="10" fill="white" rx="1" />
              <text x="0" y="35" textAnchor="middle" fontSize="9" fill="#6b7280">END</text>
            </g>
            <line x1="860" y1="180" x2="865" y2="175" stroke="#22c55e" strokeWidth="2" />

            {/* Arrow markers */}
            <defs>
              <marker id="arrow-pw" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                <polygon points="0 0, 10 3.5, 0 7" fill="#10b981" />
              </marker>
              <marker id="arrow-amber" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                <polygon points="0 0, 10 3.5, 0 7" fill="#f59e0b" />
              </marker>
            </defs>

            {/* Label showing pattern */}
            <text x="460" y="25" textAnchor="middle" fontSize="10" fill="#64748b" fontWeight="500">
              Hub-and-Spoke: Planner decides ‚Üí Worker executes ‚Üí Returns to Planner
            </text>
          </svg>
        ) : (
          /* Choreography Visualization - Sequential flow (existing) */
          <svg className="w-full" height="340" viewBox="0 0 920 340">
          {/* Background Grid */}
          <defs>
            <pattern id="grid" width="20" height="20" patternUnits="userSpaceOnUse">
              <path d="M 20 0 L 0 0 0 20" fill="none" stroke="#e2e8f0" strokeWidth="0.5" />
            </pattern>
          </defs>
          <rect width="100%" height="100%" fill="url(#grid)" />

          {/* Entry Point */}
          <g transform="translate(25, 150)">
            <circle r="14" fill="#10b981" stroke="#059669" strokeWidth="2">
              <animate attributeName="r" values="14;16;14" dur="2s" repeatCount="indefinite" />
            </circle>
            <text x="0" y="5" textAnchor="middle" fontSize="11" fill="white" fontWeight="bold">‚ñ∂</text>
            <text x="0" y="35" textAnchor="middle" fontSize="9" fill="#6b7280" fontWeight="500">START</text>
            <text x="0" y="46" textAnchor="middle" fontSize="7" fill="#94a3b8">entry_point</text>
          </g>

          {/* Edge: START ‚Üí load_data */}
          {renderAnimatedEdge("M 39 150 L 75 150", true, false, "start-load")}

          {/* Node: load_data */}
          <g
            transform="translate(75, 115)"
            onMouseEnter={() => setHoveredNode('load_data')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            <rect
              width="85"
              height="70"
              rx="8"
              fill="#f8fafc"
              stroke="#64748b"
              strokeWidth="2"
              className="transition-all hover:stroke-blue-500"
            />
            <text x="42" y="28" textAnchor="middle" fontSize="18">üì•</text>
            <text x="42" y="45" textAnchor="middle" fontSize="9" fill="#475569" fontWeight="600">load_data</text>
            <text x="42" y="58" textAnchor="middle" fontSize="7" fill="#94a3b8">MCP Tools</text>
            {/* Type badge */}
            <rect x="55" y="5" width="26" height="14" rx="3" fill="#64748b" />
            <text x="68" y="15" textAnchor="middle" fontSize="7" fill="white">fn</text>
          </g>
          {renderNodeTooltip('load_data', 117, 115)}

          {/* Edge: load_data ‚Üí customer_intelligence */}
          {renderAnimatedEdge(
            "M 160 150 L 190 150",
            completedNodes.includes('customer_intelligence') || currentAgentId === 'customer_intelligence',
            false,
            "load-customer"
          )}

          {/* Node: customer_intelligence */}
          <g
            transform="translate(190, 110)"
            onClick={() => onSelectAgent('customer_intelligence')}
            onMouseEnter={() => setHoveredNode('customer_intelligence')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            <rect
              width="105"
              height="80"
              rx="10"
              fill={getAgentStatus('customer_intelligence') === 'complete' ? '#ecfdf5' :
                    getAgentStatus('customer_intelligence') === 'processing' ? '#dbeafe' : '#f8fafc'}
              stroke={getAgentStatus('customer_intelligence') === 'complete' ? '#10b981' :
                      getAgentStatus('customer_intelligence') === 'processing' ? '#3b82f6' : '#cbd5e1'}
              strokeWidth={getAgentStatus('customer_intelligence') === 'processing' ? 3 : 2}
              className={getAgentStatus('customer_intelligence') === 'processing' ? 'animate-pulse' : 'transition-all hover:stroke-blue-500'}
            />
            <text x="52" y="28" textAnchor="middle" fontSize="20">üß†</text>
            <text x="52" y="45" textAnchor="middle" fontSize="8" fill="#475569" fontWeight="700">customer_</text>
            <text x="52" y="56" textAnchor="middle" fontSize="8" fill="#475569" fontWeight="700">intelligence</text>
            {/* Status indicator */}
            {getAgentStatus('customer_intelligence') === 'complete' && (
              <g>
                <circle cx="90" cy="15" r="10" fill="#10b981" />
                <text x="90" y="19" textAnchor="middle" fontSize="10" fill="white">‚úì</text>
              </g>
            )}
            {getAgentStatus('customer_intelligence') === 'processing' && (
              <g>
                <circle cx="90" cy="15" r="10" fill="#3b82f6">
                  <animate attributeName="opacity" values="1;0.5;1" dur="1s" repeatCount="indefinite" />
                </circle>
                <text x="90" y="19" textAnchor="middle" fontSize="8" fill="white">‚ö°</text>
              </g>
            )}
            {/* Type badge */}
            <rect x="5" y="62" width="45" height="14" rx="3" fill="#64748b" />
            <text x="27" y="72" textAnchor="middle" fontSize="6" fill="white">WORKFLOW</text>
          </g>
          {renderNodeTooltip('customer_intelligence', 242, 110)}

          {/* Conditional Diamond after customer_intelligence */}
          <g transform="translate(315, 133)">
            <polygon
              points="17,0 34,17 17,34 0,17"
              fill="#fef3c7"
              stroke="#f59e0b"
              strokeWidth="2"
            />
            <text x="17" y="21" textAnchor="middle" fontSize="12" fill="#92400e">?</text>
          </g>

          {/* Edge: customer_intelligence ‚Üí diamond */}
          {renderAnimatedEdge(
            "M 295 150 L 315 150",
            completedNodes.includes('customer_intelligence'),
            false,
            "customer-diamond"
          )}

          {/* Edge: diamond ‚Üí flight_optimization (eligible=true) */}
          {renderAnimatedEdge(
            "M 349 150 L 385 150",
            customerEligible && (completedNodes.includes('flight_optimization') || currentAgentId === 'flight_optimization'),
            false,
            "diamond-flight"
          )}
          <text x="365" y="142" textAnchor="middle" fontSize="7" fill="#16a34a" fontWeight="500">eligible</text>

          {/* Edge: diamond ‚Üí END (eligible=false) - curved path down */}
          <path
            d="M 332 167 L 332 295 L 820 295"
            fill="none"
            stroke={earlyExit ? '#ef4444' : '#fecaca'}
            strokeWidth={earlyExit ? 3 : 2}
            strokeDasharray={earlyExit ? '0' : '6'}
            markerEnd="url(#arrowhead-red)"
          />
          {earlyExit && (
            <circle r="4" fill="#ef4444">
              <animateMotion dur="2s" repeatCount="indefinite" path="M 332 167 L 332 295 L 820 295" />
            </circle>
          )}
          <text x="332" y="220" textAnchor="middle" fontSize="7" fill="#dc2626" transform="rotate(-90, 332, 220)">suppressed/ineligible</text>

          {/* Node: flight_optimization */}
          <g
            transform="translate(385, 110)"
            onClick={() => onSelectAgent('flight_optimization')}
            onMouseEnter={() => setHoveredNode('flight_optimization')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            <rect
              width="105"
              height="80"
              rx="10"
              fill={getAgentStatus('flight_optimization') === 'complete' ? '#ecfdf5' :
                    getAgentStatus('flight_optimization') === 'processing' ? '#dbeafe' : '#f8fafc'}
              stroke={getAgentStatus('flight_optimization') === 'complete' ? '#10b981' :
                      getAgentStatus('flight_optimization') === 'processing' ? '#3b82f6' : '#cbd5e1'}
              strokeWidth={getAgentStatus('flight_optimization') === 'processing' ? 3 : 2}
              className={getAgentStatus('flight_optimization') === 'processing' ? 'animate-pulse' : 'transition-all hover:stroke-blue-500'}
            />
            <text x="52" y="28" textAnchor="middle" fontSize="20">üìä</text>
            <text x="52" y="45" textAnchor="middle" fontSize="8" fill="#475569" fontWeight="700">flight_</text>
            <text x="52" y="56" textAnchor="middle" fontSize="8" fill="#475569" fontWeight="700">optimization</text>
            {getAgentStatus('flight_optimization') === 'complete' && (
              <g>
                <circle cx="90" cy="15" r="10" fill="#10b981" />
                <text x="90" y="19" textAnchor="middle" fontSize="10" fill="white">‚úì</text>
              </g>
            )}
            {getAgentStatus('flight_optimization') === 'processing' && (
              <g>
                <circle cx="90" cy="15" r="10" fill="#3b82f6">
                  <animate attributeName="opacity" values="1;0.5;1" dur="1s" repeatCount="indefinite" />
                </circle>
                <text x="90" y="19" textAnchor="middle" fontSize="8" fill="white">‚ö°</text>
              </g>
            )}
            <rect x="5" y="62" width="45" height="14" rx="3" fill="#64748b" />
            <text x="27" y="72" textAnchor="middle" fontSize="6" fill="white">WORKFLOW</text>
          </g>
          {renderNodeTooltip('flight_optimization', 437, 110)}

          {/* Edge: flight_optimization ‚Üí offer_orchestration */}
          {renderAnimatedEdge(
            "M 490 150 L 520 150",
            completedNodes.includes('offer_orchestration') || currentAgentId === 'offer_orchestration',
            false,
            "flight-offer"
          )}

          {/* Node: offer_orchestration (THE AGENT - highlighted) */}
          <g
            transform="translate(520, 100)"
            onClick={() => onSelectAgent('offer_orchestration')}
            onMouseEnter={() => setHoveredNode('offer_orchestration')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            {/* Glow effect for agent */}
            <rect
              width="115"
              height="100"
              rx="12"
              fill="none"
              stroke="#3b82f6"
              strokeWidth="1"
              opacity="0.3"
              transform="translate(-5, -5)"
            >
              <animate attributeName="opacity" values="0.3;0.6;0.3" dur="2s" repeatCount="indefinite" />
            </rect>
            <rect
              width="105"
              height="90"
              rx="10"
              fill={getAgentStatus('offer_orchestration') === 'complete' ? '#eff6ff' :
                    getAgentStatus('offer_orchestration') === 'processing' ? '#dbeafe' : '#f0f9ff'}
              stroke={getAgentStatus('offer_orchestration') === 'complete' ? '#3b82f6' :
                      getAgentStatus('offer_orchestration') === 'processing' ? '#2563eb' : '#60a5fa'}
              strokeWidth="3"
              className={getAgentStatus('offer_orchestration') === 'processing' ? 'animate-pulse' : ''}
            />
            <text x="52" y="30" textAnchor="middle" fontSize="22">‚öñÔ∏è</text>
            <text x="52" y="50" textAnchor="middle" fontSize="8" fill="#1e40af" fontWeight="700">offer_</text>
            <text x="52" y="61" textAnchor="middle" fontSize="8" fill="#1e40af" fontWeight="700">orchestration</text>
            {getAgentStatus('offer_orchestration') === 'complete' && (
              <g>
                <circle cx="90" cy="15" r="10" fill="#3b82f6" />
                <text x="90" y="19" textAnchor="middle" fontSize="10" fill="white">‚úì</text>
              </g>
            )}
            {getAgentStatus('offer_orchestration') === 'processing' && (
              <g>
                <circle cx="90" cy="15" r="10" fill="#2563eb">
                  <animate attributeName="opacity" values="1;0.5;1" dur="0.8s" repeatCount="indefinite" />
                </circle>
                <text x="90" y="19" textAnchor="middle" fontSize="8" fill="white">üß†</text>
              </g>
            )}
            {/* Agent badge with ReWOO */}
            <rect x="5" y="72" width="55" height="14" rx="3" fill="#2563eb" />
            <text x="32" y="82" textAnchor="middle" fontSize="5" fill="white" fontWeight="bold">üß† ReWOO</text>
            <text x="75" y="82" textAnchor="middle" fontSize="5" fill="#3b82f6">P‚ÜíW‚ÜíS</text>
          </g>
          {renderNodeTooltip('offer_orchestration', 572, 100)}

          {/* Conditional Diamond after offer_orchestration */}
          <g transform="translate(645, 133)">
            <polygon
              points="17,0 34,17 17,34 0,17"
              fill="#fef3c7"
              stroke="#f59e0b"
              strokeWidth="2"
            />
            <text x="17" y="21" textAnchor="middle" fontSize="12" fill="#92400e">?</text>
          </g>

          {/* Edge: offer_orchestration ‚Üí diamond */}
          {renderAnimatedEdge(
            "M 625 150 L 645 150",
            completedNodes.includes('offer_orchestration'),
            false,
            "offer-diamond"
          )}

          {/* Edge: diamond ‚Üí personalization (should_send=true) */}
          <path
            d="M 679 150 L 720 150 L 720 60 L 755 60"
            fill="none"
            stroke={offerMade ? '#10b981' : '#d1d5db'}
            strokeWidth={offerMade ? 3 : 2}
            markerEnd="url(#arrowhead)"
          />
          {offerMade && (
            <circle r="4" fill="#10b981">
              <animateMotion dur="1.2s" repeatCount="indefinite" path="M 679 150 L 720 150 L 720 60 L 755 60" />
            </circle>
          )}
          <text x="700" y="105" textAnchor="middle" fontSize="7" fill="#16a34a" transform="rotate(-90, 700, 105)">send_offer</text>

          {/* Edge: diamond ‚Üí END (should_send=false) */}
          <path
            d="M 662 167 L 662 295 L 820 295"
            fill="none"
            stroke={offerExit ? '#ef4444' : '#fecaca'}
            strokeWidth={offerExit ? 3 : 2}
            strokeDasharray={offerExit ? '0' : '6'}
            markerEnd="url(#arrowhead-red)"
          />
          {offerExit && (
            <circle r="4" fill="#ef4444">
              <animateMotion dur="2s" repeatCount="indefinite" path="M 662 167 L 662 295 L 820 295" />
            </circle>
          )}
          <text x="662" y="220" textAnchor="middle" fontSize="7" fill="#dc2626" transform="rotate(-90, 662, 220)">no_offer</text>

          {/* Node: personalization (LLM Call) */}
          <g
            transform="translate(755, 25)"
            onClick={() => onSelectAgent('personalization')}
            onMouseEnter={() => setHoveredNode('personalization')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            <rect
              width="95"
              height="70"
              rx="10"
              fill={getAgentStatus('personalization') === 'complete' ? '#faf5ff' :
                    getAgentStatus('personalization') === 'processing' ? '#f3e8ff' : '#fdf4ff'}
              stroke={getAgentStatus('personalization') === 'complete' ? '#a855f7' :
                      getAgentStatus('personalization') === 'processing' ? '#9333ea' : '#d8b4fe'}
              strokeWidth={getAgentStatus('personalization') === 'processing' ? 3 : 2}
              className={getAgentStatus('personalization') === 'processing' ? 'animate-pulse' : 'transition-all hover:stroke-purple-500'}
            />
            <text x="47" y="28" textAnchor="middle" fontSize="18">‚ú®</text>
            <text x="47" y="46" textAnchor="middle" fontSize="8" fill="#7c3aed" fontWeight="700">personalization</text>
            {getAgentStatus('personalization') === 'complete' && (
              <g>
                <circle cx="82" cy="12" r="10" fill="#a855f7" />
                <text x="82" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text>
              </g>
            )}
            {getAgentStatus('personalization') === 'processing' && (
              <g>
                <circle cx="82" cy="12" r="10" fill="#9333ea">
                  <animate attributeName="opacity" values="1;0.5;1" dur="0.8s" repeatCount="indefinite" />
                </circle>
                <text x="82" y="16" textAnchor="middle" fontSize="8" fill="white">‚ú®</text>
              </g>
            )}
            <rect x="5" y="52" width="42" height="14" rx="3" fill="#9333ea" />
            <text x="26" y="62" textAnchor="middle" fontSize="6" fill="white">LLM CALL</text>
          </g>
          {renderNodeTooltip('personalization', 802, 25)}

          {/* Edge: personalization ‚Üí channel_timing */}
          {renderAnimatedEdge(
            "M 802 95 L 802 120",
            completedNodes.includes('channel_timing') || currentAgentId === 'channel_timing',
            false,
            "personal-channel"
          )}

          {/* Node: channel_timing */}
          <g
            transform="translate(755, 120)"
            onClick={() => onSelectAgent('channel_timing')}
            onMouseEnter={() => setHoveredNode('channel_timing')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            <rect
              width="95"
              height="65"
              rx="10"
              fill={getAgentStatus('channel_timing') === 'complete' ? '#ecfdf5' :
                    getAgentStatus('channel_timing') === 'processing' ? '#dbeafe' : '#f8fafc'}
              stroke={getAgentStatus('channel_timing') === 'complete' ? '#10b981' :
                      getAgentStatus('channel_timing') === 'processing' ? '#3b82f6' : '#cbd5e1'}
              strokeWidth={getAgentStatus('channel_timing') === 'processing' ? 3 : 2}
              className={getAgentStatus('channel_timing') === 'processing' ? 'animate-pulse' : 'transition-all hover:stroke-blue-500'}
            />
            <text x="47" y="26" textAnchor="middle" fontSize="18">üì±</text>
            <text x="47" y="44" textAnchor="middle" fontSize="8" fill="#475569" fontWeight="700">channel_timing</text>
            {getAgentStatus('channel_timing') === 'complete' && (
              <g>
                <circle cx="82" cy="12" r="10" fill="#10b981" />
                <text x="82" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text>
              </g>
            )}
            <rect x="5" y="48" width="45" height="14" rx="3" fill="#64748b" />
            <text x="27" y="58" textAnchor="middle" fontSize="6" fill="white">WORKFLOW</text>
          </g>

          {/* Edge: channel_timing ‚Üí measurement */}
          {renderAnimatedEdge(
            "M 802 185 L 802 205",
            completedNodes.includes('measurement') || currentAgentId === 'measurement',
            false,
            "channel-measure"
          )}

          {/* Node: measurement (Tracking Setup - Post-Decision) */}
          <g
            transform="translate(755, 205)"
            onClick={() => onSelectAgent('measurement')}
            onMouseEnter={() => setHoveredNode('measurement')}
            onMouseLeave={() => setHoveredNode(null)}
            style={{ cursor: 'pointer' }}
          >
            {/* Dashed border to indicate post-decision */}
            <rect
              width="95"
              height="60"
              rx="10"
              fill={getAgentStatus('measurement') === 'complete' ? '#fefce8' :
                    getAgentStatus('measurement') === 'processing' ? '#fef9c3' : '#fefce8'}
              stroke={getAgentStatus('measurement') === 'complete' ? '#ca8a04' :
                      getAgentStatus('measurement') === 'processing' ? '#eab308' : '#d4d4d8'}
              strokeWidth="2"
              strokeDasharray="4 2"
              className={getAgentStatus('measurement') === 'processing' ? 'animate-pulse' : 'transition-all hover:stroke-yellow-500'}
            />
            <text x="47" y="25" textAnchor="middle" fontSize="18">üè∑Ô∏è</text>
            <text x="47" y="42" textAnchor="middle" fontSize="8" fill="#854d0e" fontWeight="700">tracking_setup</text>
            {getAgentStatus('measurement') === 'complete' && (
              <g>
                <circle cx="82" cy="12" r="10" fill="#ca8a04" />
                <text x="82" y="16" textAnchor="middle" fontSize="10" fill="white">‚úì</text>
              </g>
            )}
            <rect x="5" y="45" width="55" height="12" rx="3" fill="#ca8a04" />
            <text x="32" y="54" textAnchor="middle" fontSize="6" fill="white">POST-DECISION</text>
          </g>

          {/* Edge: measurement ‚Üí final_decision */}
          {renderAnimatedEdge(
            "M 802 265 L 802 280",
            agentResults['measurement']?.status === 'complete',
            false,
            "measure-final"
          )}

          {/* Node: final_decision */}
          <g transform="translate(755, 280)">
            <rect
              width="95"
              height="50"
              rx="10"
              fill="#f0fdf4"
              stroke="#22c55e"
              strokeWidth="2"
            />
            <text x="47" y="24" textAnchor="middle" fontSize="16">üéØ</text>
            <text x="47" y="40" textAnchor="middle" fontSize="8" fill="#166534" fontWeight="700">final_decision</text>
          </g>

          {/* Edge: final_decision ‚Üí END */}
          <line x1="850" y1="305" x2="880" y2="305" stroke="#22c55e" strokeWidth="2" markerEnd="url(#arrowhead-green)" />

          {/* END Node */}
          <g transform="translate(880, 290)">
            <circle r="15" cx="15" cy="15" fill="#dc2626" stroke="#b91c1c" strokeWidth="2" />
            <rect x="8" y="10" width="14" height="10" fill="white" rx="1" />
            <text x="15" y="42" textAnchor="middle" fontSize="9" fill="#6b7280" fontWeight="500">END</text>
          </g>

          {/* Arrow markers */}
          <defs>
            <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
              <polygon points="0 0, 10 3.5, 0 7" fill="#9ca3af" />
            </marker>
            <marker id="arrowhead-red" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
              <polygon points="0 0, 10 3.5, 0 7" fill="#ef4444" />
            </marker>
            <marker id="arrowhead-green" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
              <polygon points="0 0, 10 3.5, 0 7" fill="#22c55e" />
            </marker>
          </defs>
        </svg>
        )}

        {/* Legend - Mode-aware */}
        <div className="flex items-center justify-center gap-4 mt-4 text-xs text-gray-600 flex-wrap border-t border-slate-200 pt-4">
          {isPlannerWorker ? (
            /* Planner-Worker Legend */
            <>
              <div className="flex items-center gap-1.5">
                <div className="w-6 h-6 rounded-full bg-amber-100 border-2 border-amber-500 flex items-center justify-center text-[10px]">üéØ</div>
                <span>Planner (LLM)</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-slate-100 border-2 border-slate-500 flex items-center justify-center text-[8px]">‚ö°</div>
                <span>Worker</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-blue-100 border-2 border-blue-500 flex items-center justify-center text-[8px]">üß†</div>
                <span>Agent (ReWOO)</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-purple-100 border-2 border-purple-500 flex items-center justify-center text-[8px]">‚ú®</div>
                <span>LLM Worker</span>
              </div>
              <div className="flex items-center gap-1.5">
                <svg width="24" height="16" viewBox="0 0 24 16">
                  <line x1="2" y1="8" x2="22" y2="8" stroke="#f59e0b" strokeWidth="2" />
                  <polygon points="18,4 22,8 18,12" fill="#f59e0b" />
                </svg>
                <span>Dispatch</span>
              </div>
              <div className="flex items-center gap-1.5">
                <svg width="24" height="16" viewBox="0 0 24 16">
                  <line x1="2" y1="8" x2="22" y2="8" stroke="#10b981" strokeWidth="2" strokeDasharray="4" />
                </svg>
                <span>Return</span>
              </div>
            </>
          ) : (
            /* Choreography Legend */
            <>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-slate-100 border-2 border-slate-500 flex items-center justify-center text-[8px]">‚ö°</div>
                <span>Workflow (4)</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-blue-100 border-2 border-blue-500 flex items-center justify-center text-[8px]">üß†</div>
                <span>Agent ReWOO (1)</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-purple-100 border-2 border-purple-500 flex items-center justify-center text-[8px]">‚ú®</div>
                <span>LLM Call (1)</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-5 h-5 rounded bg-yellow-100 border-2 border-yellow-600 border-dashed flex items-center justify-center text-[8px]">üè∑Ô∏è</div>
                <span>Post-Decision</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-4 h-4 rotate-45 bg-amber-200 border border-amber-500"></div>
                <span>Conditional</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-6 h-0.5 bg-green-500"></div>
                <span>Active</span>
              </div>
              <div className="flex items-center gap-1.5">
                <div className="w-6 h-0.5 bg-red-400 border-dashed border-t-2 border-red-400"></div>
                <span>Exit</span>
              </div>
            </>
          )}
        </div>
      </div>

      {/* Live State Panel */}
      {showStatePanel && (
        <div className="mt-4 bg-slate-900 rounded-lg p-4 font-mono text-xs overflow-x-auto">
          <div className="flex justify-between items-center mb-3">
            <div className="text-slate-400">
              <span className="text-blue-400">class</span>{' '}
              <span className="text-yellow-400">AgentState</span>
              <span className="text-slate-500">(TypedDict)</span>
              <span className="text-slate-600 ml-2">‚Äî Live values from workflow execution</span>
            </div>
            <div className="text-[10px] text-slate-500 bg-slate-800 px-2 py-1 rounded">
              {Object.keys(agentResults).length > 0 ? `${Object.keys(agentResults).length} nodes completed` : 'Waiting for execution...'}
            </div>
          </div>

          <div className="grid md:grid-cols-2 gap-4">
            {/* Input State */}
            <div className="bg-slate-800 rounded-lg p-3">
              <div className="text-slate-500 text-[10px] uppercase tracking-wide mb-2">üì• Input State</div>
              <div className="space-y-1 text-slate-300">
                <div className="flex justify-between">
                  <span>pnr_locator:</span>
                  <span className="text-emerald-400">{getStateValue('pnr_locator') || '"ABC123"'}</span>
                </div>
                <div className="flex justify-between">
                  <span>customer_data:</span>
                  <span className="text-blue-400">{Object.keys(agentResults).length > 0 ? '{ ... }' : 'None'}</span>
                </div>
                <div className="flex justify-between">
                  <span>flight_data:</span>
                  <span className="text-blue-400">{Object.keys(agentResults).length > 0 ? '{ ... }' : 'None'}</span>
                </div>
                <div className="flex justify-between">
                  <span>ml_scores:</span>
                  <span className="text-blue-400">{Object.keys(agentResults).length > 0 ? '{ ... }' : 'None'}</span>
                </div>
              </div>
            </div>

            {/* Control Flow State */}
            <div className="bg-slate-800 rounded-lg p-3">
              <div className="text-slate-500 text-[10px] uppercase tracking-wide mb-2">üîÄ Control Flow</div>
              <div className="space-y-1 text-slate-300">
                <div className="flex justify-between">
                  <span>customer_eligible:</span>
                  <span className={customerEligible ? 'text-emerald-400' : earlyExit ? 'text-red-400' : 'text-slate-500'}>
                    {agentResults['customer_intelligence'] ? (customerEligible ? 'true' : 'false') : 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>should_send_offer:</span>
                  <span className={offerMade ? 'text-emerald-400' : offerExit ? 'text-red-400' : 'text-slate-500'}>
                    {agentResults['offer_orchestration'] ? (offerMade ? 'true' : 'false') : 'None'}
                  </span>
                </div>
              </div>
            </div>

            {/* Agent Outputs */}
            <div className="bg-slate-800 rounded-lg p-3">
              <div className="text-slate-500 text-[10px] uppercase tracking-wide mb-2">üì§ Agent Outputs</div>
              <div className="space-y-1 text-slate-300">
                <div className="flex justify-between">
                  <span>customer_segment:</span>
                  <span className="text-amber-400">
                    {agentResults['customer_intelligence']?.outputs?.customer_segment || 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>selected_offer:</span>
                  <span className="text-amber-400">
                    {agentResults['offer_orchestration']?.outputs?.selected_offer || 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>offer_price:</span>
                  <span className="text-amber-400">
                    {agentResults['offer_orchestration']?.outputs?.offer_price ?
                      `$${agentResults['offer_orchestration'].outputs.offer_price}` : 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>expected_value:</span>
                  <span className="text-amber-400">
                    {agentResults['offer_orchestration']?.outputs?.expected_value ?
                      `$${agentResults['offer_orchestration'].outputs.expected_value?.toFixed(2)}` : 'None'}
                  </span>
                </div>
              </div>
            </div>

            {/* Delivery State */}
            <div className="bg-slate-800 rounded-lg p-3">
              <div className="text-slate-500 text-[10px] uppercase tracking-wide mb-2">üì¨ Delivery State</div>
              <div className="space-y-1 text-slate-300">
                <div className="flex justify-between">
                  <span>selected_channel:</span>
                  <span className="text-cyan-400">
                    {agentResults['channel_timing']?.outputs?.selected_channel || 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>send_time:</span>
                  <span className="text-cyan-400">
                    {agentResults['channel_timing']?.outputs?.send_time || 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>experiment_group:</span>
                  <span className="text-cyan-400">
                    {agentResults['measurement']?.outputs?.experiment_group || 'None'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>tracking_id:</span>
                  <span className="text-cyan-400 text-[10px]">
                    {agentResults['measurement']?.outputs?.tracking_id || 'None'}
                  </span>
                </div>
              </div>
            </div>
          </div>

          {/* Reasoning Trace */}
          <div className="mt-4 pt-3 border-t border-slate-700">
            <div className="text-slate-500 text-[10px] uppercase tracking-wide mb-2">üìù Reasoning Trace (accumulated)</div>
            <div className="bg-slate-950 rounded p-2 max-h-24 overflow-y-auto">
              {Object.values(agentResults).length === 0 ? (
                <div className="text-slate-600 italic">No trace yet - run evaluation to see agent reasoning</div>
              ) : (
                Object.entries(agentResults).map(([id, result]) => (
                  <div key={id} className="text-slate-400 text-[10px] mb-1">
                    <span className="text-blue-400">[{id}]</span> {result.summary}
                  </div>
                ))
              )}
            </div>
          </div>
        </div>
      )}

      {/* Edge Definitions Code - Mode-aware */}
      <div className="mt-4 bg-slate-50 border border-slate-200 rounded-lg p-3 font-mono text-xs">
        <div className="flex justify-between items-center mb-2">
          <span className="text-slate-500"># Graph edges from workflow.py</span>
          <span className="text-[10px] text-slate-400">LangGraph StateGraph</span>
        </div>

        {isPlannerWorker ? (
          /* Planner-Worker Edge Definitions */
          <>
            <div className="text-slate-700 space-y-1">
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"load_data"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-amber-600 font-bold">"planner"</span>
                <span className="text-slate-400 text-[10px]"># Entry point to planner</span>
              </div>
            </div>
            <div className="mt-3 pt-2 border-t border-slate-300">
              <div className="text-slate-500 mb-1"># Dynamic routing via planner LLM</div>
              <div className="text-[11px] space-y-1">
                <div>
                  <span className="text-purple-600">add_conditional_edges</span>
                  (<span className="text-amber-600">"planner"</span>,
                  <span className="text-blue-600 ml-1">planner_decision</span>)
                </div>
                <div className="ml-4 text-slate-500">
                  # Planner routes to any worker based on LLM analysis:
                </div>
                <div className="ml-4 text-slate-600">
                  ‚Üí <span className="text-emerald-600">"customer_intelligence"</span> |
                  <span className="text-emerald-600 ml-1">"flight_optimization"</span> |
                  <span className="text-blue-600 ml-1">"offer_orchestration"</span> |
                  <span className="text-purple-600 ml-1">"personalization"</span> |
                  <span className="text-emerald-600 ml-1">"channel_timing"</span> |
                  <span className="text-yellow-600 ml-1">"measurement"</span>
                </div>
                <div className="ml-4 text-slate-500">
                  # Each worker returns to planner after completion
                </div>
              </div>
            </div>
            <div className="mt-3 pt-2 border-t border-slate-300">
              <div className="text-slate-500 mb-1"># Worker ‚Üí Planner return edges</div>
              <div className="grid md:grid-cols-2 gap-x-6 gap-y-1 text-slate-700 text-[11px]">
                <div><span className="text-emerald-600">"customer_intel"</span> ‚Üí <span className="text-amber-600">"planner"</span></div>
                <div><span className="text-emerald-600">"flight_opt"</span> ‚Üí <span className="text-amber-600">"planner"</span></div>
                <div><span className="text-blue-600">"offer_orchestration"</span> ‚Üí <span className="text-amber-600">"planner"</span></div>
                <div><span className="text-purple-600">"personalization"</span> ‚Üí <span className="text-amber-600">"planner"</span></div>
                <div><span className="text-emerald-600">"channel_timing"</span> ‚Üí <span className="text-amber-600">"planner"</span></div>
                <div><span className="text-yellow-600">"measurement"</span> ‚Üí <span className="text-amber-600">"planner"</span></div>
              </div>
            </div>
            <div className="mt-3 pt-2 border-t border-slate-300">
              <div className="text-slate-500 mb-1"># Exit condition</div>
              <div className="text-[11px]">
                <span className="text-purple-600">add_conditional_edges</span>
                (<span className="text-amber-600">"planner"</span>,
                <span className="text-blue-600 ml-1">is_complete</span>)
                <span className="text-slate-400 ml-2">‚Üí "final_decision" | continue</span>
              </div>
            </div>
          </>
        ) : (
          /* Choreography Edge Definitions */
          <>
            <div className="grid md:grid-cols-2 gap-x-6 gap-y-1 text-slate-700">
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"load_data"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-emerald-600">"customer_intelligence"</span>
              </div>
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"flight_optimization"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-emerald-600">"offer_orchestration"</span>
              </div>
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"personalization"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-emerald-600">"channel_timing"</span>
              </div>
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"channel_timing"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-emerald-600">"measurement"</span>
              </div>
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"measurement"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-emerald-600">"final_decision"</span>
              </div>
              <div className="flex items-center gap-2">
                <span className="text-emerald-600">"final_decision"</span>
                <span className="text-slate-400">‚Üí</span>
                <span className="text-amber-600">END</span>
              </div>
            </div>
            <div className="mt-3 pt-2 border-t border-slate-300">
              <div className="text-slate-500 mb-1"># Conditional edges (short-circuit)</div>
              <div className="text-[11px] space-y-1">
                <div>
                  <span className="text-purple-600">add_conditional_edges</span>
                  (<span className="text-emerald-600">"customer_intelligence"</span>,
                  <span className="text-blue-600 ml-1">should_continue_after_customer</span>)
                  <span className="text-slate-400 ml-2">‚Üí "flight_optimization" | "final_decision"</span>
                </div>
                <div>
                  <span className="text-purple-600">add_conditional_edges</span>
                  (<span className="text-emerald-600">"offer_orchestration"</span>,
                  <span className="text-blue-600 ml-1">should_continue_after_offer</span>)
                  <span className="text-slate-400 ml-2">‚Üí "personalization" | "final_decision"</span>
                </div>
              </div>
            </div>
          </>
        )}
      </div>
    </div>
  );
}


================================================================================
FILE: frontend/src/components/PolicyConfig.tsx
================================================================================
/**
 * PolicyConfig - UI for viewing and editing policy configuration values
 *
 * Shows live policy values that control agent behavior:
 * - Discount percentages
 * - Confidence thresholds
 * - Revenue thresholds
 */
import { useState, useEffect, useCallback } from 'react';

interface Policy {
  value: number;
  default: number;
  is_custom: boolean;
  name: string;
  description: string;
  type: string;
  min: number;
  max: number;
  unit: string;
}

interface PolicyMap {
  [key: string]: Policy;
}

export function PolicyConfig() {
  const [policies, setPolicies] = useState<PolicyMap>({});
  const [loading, setLoading] = useState(true);
  const [editingKey, setEditingKey] = useState<string | null>(null);
  const [editValue, setEditValue] = useState<string>('');
  const [saving, setSaving] = useState(false);
  const [message, setMessage] = useState<{type: 'success' | 'error', text: string} | null>(null);

  // Fetch policies
  const fetchPolicies = useCallback(async () => {
    try {
      const response = await fetch('/api/policies');
      const data = await response.json();
      setPolicies(data.policies || {});
    } catch (error) {
      console.error('Failed to fetch policies:', error);
    } finally {
      setLoading(false);
    }
  }, []);

  useEffect(() => {
    fetchPolicies();
    // Refresh every 5 seconds to catch updates from Prompt Assistant
    const interval = setInterval(fetchPolicies, 5000);
    return () => clearInterval(interval);
  }, [fetchPolicies]);

  // Start editing
  const startEdit = (key: string, policy: Policy) => {
    setEditingKey(key);
    setEditValue(policy.value.toString());
    setMessage(null);
  };

  // Cancel editing
  const cancelEdit = () => {
    setEditingKey(null);
    setEditValue('');
  };

  // Save policy
  const savePolicy = async (key: string) => {
    setSaving(true);
    setMessage(null);

    try {
      const response = await fetch(`/api/policies/${key}`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ value: parseFloat(editValue) }),
      });

      const data = await response.json();

      if (response.ok) {
        setMessage({ type: 'success', text: data.message });
        setEditingKey(null);
        fetchPolicies();
      } else {
        setMessage({ type: 'error', text: data.detail || 'Failed to save' });
      }
    } catch (error) {
      setMessage({ type: 'error', text: 'Network error' });
    } finally {
      setSaving(false);
    }
  };

  // Reset policy to default
  const resetPolicy = async (key: string) => {
    setSaving(true);
    try {
      const response = await fetch(`/api/policies/${key}`, { method: 'DELETE' });
      const data = await response.json();

      if (response.ok) {
        setMessage({ type: 'success', text: data.message });
        fetchPolicies();
      }
    } catch (error) {
      setMessage({ type: 'error', text: 'Failed to reset' });
    } finally {
      setSaving(false);
    }
  };

  // Group policies by category
  const discountPolicies = ['goodwill_discount_percent', 'max_discount_percent', 'min_discount_percent', 'vip_discount_percent'];
  const thresholdPolicies = ['min_confidence_threshold', 'high_confidence_threshold', 'vip_revenue_threshold'];
  const otherPolicies = Object.keys(policies).filter(k => !discountPolicies.includes(k) && !thresholdPolicies.includes(k));

  const renderPolicy = (key: string) => {
    const policy = policies[key];
    if (!policy) return null;

    const isEditing = editingKey === key;
    const displayValue = policy.type === 'decimal'
      ? `${(policy.value * 100).toFixed(0)}%`
      : policy.type === 'currency'
      ? `$${policy.value.toLocaleString()}`
      : `${policy.value}${policy.unit}`;

    return (
      <div
        key={key}
        className={`p-3 rounded-lg border transition-all ${
          policy.is_custom
            ? 'bg-cyan-900/30 border-cyan-500/50'
            : 'bg-slate-800/50 border-slate-700'
        }`}
      >
        <div className="flex items-start justify-between gap-2">
          <div className="flex-1 min-w-0">
            <div className="flex items-center gap-2">
              <span className="font-medium text-sm text-slate-200">{policy.name}</span>
              {policy.is_custom && (
                <span className="text-xs bg-cyan-600 text-white px-1.5 py-0.5 rounded">Modified</span>
              )}
            </div>
            <p className="text-xs text-slate-400 mt-0.5 truncate">{policy.description}</p>
          </div>

          {isEditing ? (
            <div className="flex items-center gap-1">
              <input
                type="number"
                value={editValue}
                onChange={(e) => setEditValue(e.target.value)}
                step={policy.type === 'decimal' ? '0.01' : '1'}
                min={policy.min}
                max={policy.max}
                className="w-20 bg-slate-700 border border-slate-500 rounded px-2 py-1 text-sm text-white"
                autoFocus
              />
              <button
                onClick={() => savePolicy(key)}
                disabled={saving}
                className="p-1 text-emerald-400 hover:text-emerald-300"
              >
                ‚úì
              </button>
              <button
                onClick={cancelEdit}
                className="p-1 text-slate-400 hover:text-slate-300"
              >
                ‚úó
              </button>
            </div>
          ) : (
            <div className="flex items-center gap-2">
              <span className={`font-mono text-sm ${policy.is_custom ? 'text-cyan-300' : 'text-slate-300'}`}>
                {displayValue}
              </span>
              <button
                onClick={() => startEdit(key, policy)}
                className="p-1 text-slate-400 hover:text-white transition-colors"
                title="Edit"
              >
                <svg className="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15.232 5.232l3.536 3.536m-2.036-5.036a2.5 2.5 0 113.536 3.536L6.5 21.036H3v-3.572L16.732 3.732z" />
                </svg>
              </button>
              {policy.is_custom && (
                <button
                  onClick={() => resetPolicy(key)}
                  className="p-1 text-slate-400 hover:text-amber-400 transition-colors"
                  title="Reset to default"
                >
                  <svg className="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" />
                  </svg>
                </button>
              )}
            </div>
          )}
        </div>
      </div>
    );
  };

  if (loading) {
    return (
      <div className="flex items-center justify-center p-8">
        <div className="w-6 h-6 border-2 border-cyan-400 border-t-transparent rounded-full animate-spin"></div>
      </div>
    );
  }

  return (
    <div className="space-y-4">
      {/* Message */}
      {message && (
        <div className={`p-3 rounded-lg text-sm ${
          message.type === 'success'
            ? 'bg-emerald-900/50 border border-emerald-500/50 text-emerald-200'
            : 'bg-red-900/50 border border-red-500/50 text-red-200'
        }`}>
          {message.text}
        </div>
      )}

      {/* Discount Policies */}
      <div>
        <h4 className="text-xs font-semibold text-slate-400 uppercase tracking-wider mb-2 flex items-center gap-2">
          <span>üí∞</span> Discount Policies
        </h4>
        <div className="space-y-2">
          {discountPolicies.map(renderPolicy)}
        </div>
      </div>

      {/* Threshold Policies */}
      <div>
        <h4 className="text-xs font-semibold text-slate-400 uppercase tracking-wider mb-2 flex items-center gap-2">
          <span>üìä</span> Thresholds
        </h4>
        <div className="space-y-2">
          {thresholdPolicies.map(renderPolicy)}
        </div>
      </div>

      {/* Other Policies */}
      {otherPolicies.length > 0 && (
        <div>
          <h4 className="text-xs font-semibold text-slate-400 uppercase tracking-wider mb-2 flex items-center gap-2">
            <span>‚öôÔ∏è</span> Other Settings
          </h4>
          <div className="space-y-2">
            {otherPolicies.map(renderPolicy)}
          </div>
        </div>
      )}

      {/* Info */}
      <div className="bg-slate-800/30 rounded-lg p-3 text-xs text-slate-400">
        <p className="flex items-center gap-1">
          <span>üí°</span>
          <span>Use the <span className="text-purple-400">Prompt Assistant</span> with admin phrase to modify these values via natural language.</span>
        </p>
      </div>
    </div>
  );
}


================================================================================
FILE: frontend/src/components/PromptAssistant.tsx
================================================================================
/**
 * PromptAssistant - A friendly robot that helps business users
 * modify agent behavior using plain English instructions.
 *
 * Features:
 * - Accepts natural language instructions
 * - Translates to proper prompt modifications
 * - Validates prompts to prevent misuse
 * - Provides helpful feedback
 */
import { useState, useRef, useEffect } from 'react';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  status?: 'success' | 'error' | 'warning';
}

interface PromptAssistantProps {
  onPromptUpdate?: (agentId: string, newPrompt: string) => void;
  isOpen?: boolean;
  onOpenChange?: (open: boolean) => void;
}

// Example suggestions for users
const SUGGESTIONS = [
  "Be more friendly in messages",
  "Focus on business travelers",
  "Offer bigger discounts to loyal customers",
  "Be more conservative with upgrade offers",
  "Prioritize premium cabin upgrades",
  "Add urgency to the messaging",
];

export function PromptAssistant({ onPromptUpdate, isOpen: externalIsOpen, onOpenChange }: PromptAssistantProps) {
  const [internalIsOpen, setInternalIsOpen] = useState(false);

  // Use external control if provided, otherwise use internal state
  const isOpen = externalIsOpen !== undefined ? externalIsOpen : internalIsOpen;
  const setIsOpen = (open: boolean) => {
    if (onOpenChange) {
      onOpenChange(open);
    } else {
      setInternalIsOpen(open);
    }
  };
  const [messages, setMessages] = useState<Message[]>([
    {
      id: '1',
      role: 'assistant',
      content: "Hi! I'm your Prompt Assistant ü§ñ\n\nTell me how you'd like to change the agent's behavior in plain English, and I'll update the prompts for you safely.\n\nFor example:\n‚Ä¢ \"Be more friendly in messages\"\n‚Ä¢ \"Focus on business travelers\"\n‚Ä¢ \"Offer bigger discounts to loyal customers\"",
      timestamp: new Date(),
    }
  ]);
  const [input, setInput] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // Auto-scroll to bottom
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input.trim() || isProcessing) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: input.trim(),
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setIsProcessing(true);

    try {
      const response = await fetch('/api/prompt-assistant/instruct', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ instruction: userMessage.content }),
      });

      const data = await response.json();

      const assistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: data.message,
        timestamp: new Date(),
        status: data.status,
      };

      setMessages(prev => [...prev, assistantMessage]);

      // If prompt was updated successfully, notify parent
      if (data.status === 'success' && data.updated_prompts && onPromptUpdate) {
        for (const update of data.updated_prompts) {
          onPromptUpdate(update.agent_id, update.new_prompt);
        }
      }

    } catch (error) {
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: "Sorry, I couldn't process that request. Please try again.",
        timestamp: new Date(),
        status: 'error',
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsProcessing(false);
    }
  };

  const handleSuggestionClick = (suggestion: string) => {
    setInput(suggestion);
  };

  return (
    <>
      {/* Floating Button */}
      <button
        onClick={() => setIsOpen(true)}
        className={`fixed bottom-6 left-6 z-40 bg-gradient-to-r from-purple-500 to-indigo-600 hover:from-purple-400 hover:to-indigo-500 text-white rounded-full p-4 shadow-2xl transition-all hover:scale-110 ${isOpen ? 'hidden' : ''}`}
        title="Prompt Assistant"
      >
        <div className="relative">
          <svg className="w-8 h-8" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z" />
          </svg>
          <span className="absolute -top-1 -right-1 w-4 h-4 bg-green-400 rounded-full border-2 border-white animate-pulse"></span>
        </div>
      </button>

      {/* Chat Panel */}
      {isOpen && (
        <div className="fixed bottom-6 left-6 z-50 w-96 h-[32rem] bg-slate-900 rounded-2xl shadow-2xl border border-slate-700 flex flex-col overflow-hidden animate-slideUp">
          {/* Header */}
          <div className="bg-gradient-to-r from-purple-600 to-indigo-600 px-4 py-3 flex items-center justify-between">
            <div className="flex items-center gap-3">
              <div className="w-10 h-10 bg-white/20 rounded-full flex items-center justify-center">
                <span className="text-2xl">ü§ñ</span>
              </div>
              <div>
                <h3 className="font-semibold text-white">Prompt Assistant</h3>
                <p className="text-xs text-purple-200">Modify agent behavior safely</p>
              </div>
            </div>
            <button
              onClick={() => setIsOpen(false)}
              className="text-white/70 hover:text-white transition-colors"
            >
              <svg className="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          </div>

          {/* Messages */}
          <div className="flex-1 overflow-y-auto p-4 space-y-4 custom-scrollbar">
            {messages.map((message) => (
              <div
                key={message.id}
                className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
              >
                <div
                  className={`max-w-[85%] rounded-2xl px-4 py-2 ${
                    message.role === 'user'
                      ? 'bg-purple-600 text-white'
                      : message.status === 'error'
                      ? 'bg-red-900/50 border border-red-500/50 text-red-200'
                      : message.status === 'warning'
                      ? 'bg-amber-900/50 border border-amber-500/50 text-amber-200'
                      : message.status === 'success'
                      ? 'bg-emerald-900/50 border border-emerald-500/50 text-emerald-200'
                      : 'bg-slate-800 text-slate-200'
                  }`}
                >
                  <p className="text-sm whitespace-pre-wrap">{message.content}</p>
                </div>
              </div>
            ))}

            {isProcessing && (
              <div className="flex justify-start">
                <div className="bg-slate-800 rounded-2xl px-4 py-3">
                  <div className="flex items-center gap-2">
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce"></div>
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }}></div>
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }}></div>
                  </div>
                </div>
              </div>
            )}

            <div ref={messagesEndRef} />
          </div>

          {/* Suggestions */}
          {messages.length <= 2 && (
            <div className="px-4 pb-2">
              <p className="text-xs text-slate-500 mb-2">Try these:</p>
              <div className="flex flex-wrap gap-1">
                {SUGGESTIONS.slice(0, 3).map((suggestion, idx) => (
                  <button
                    key={idx}
                    onClick={() => handleSuggestionClick(suggestion)}
                    className="text-xs bg-slate-800 hover:bg-slate-700 text-slate-300 rounded-full px-3 py-1 transition-colors"
                  >
                    {suggestion}
                  </button>
                ))}
              </div>
            </div>
          )}

          {/* Input */}
          <form onSubmit={handleSubmit} className="p-4 border-t border-slate-700">
            <div className="flex gap-2">
              <input
                type="text"
                value={input}
                onChange={(e) => setInput(e.target.value)}
                placeholder="Describe how to change agent behavior..."
                className="flex-1 bg-slate-800 border border-slate-600 rounded-xl px-4 py-2 text-sm text-white placeholder-slate-400 focus:outline-none focus:border-purple-500"
                disabled={isProcessing}
              />
              <button
                type="submit"
                disabled={!input.trim() || isProcessing}
                className="bg-purple-600 hover:bg-purple-500 disabled:bg-slate-700 disabled:cursor-not-allowed text-white rounded-xl px-4 py-2 transition-colors"
              >
                <svg className="w-5 h-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 19l9 2-9-18-9 18 9-2zm0 0v-8" />
                </svg>
              </button>
            </div>
          </form>
        </div>
      )}
    </>
  );
}


================================================================================
FILE: frontend/src/components/PromptEditor.tsx
================================================================================
import { useState, useEffect } from 'react';

const API_BASE = import.meta.env.VITE_API_URL || 'http://localhost:8000';

interface PromptData {
  agent_id: string;
  type: 'llm' | 'rules';
  description: string;
  system_prompt?: string;
  is_custom?: boolean;
  default_prompt?: string;
  editable: boolean;
  llm_provider?: string;
}

interface Props {
  agentId: string;
  agentName: string;
  onPromptUpdated?: () => void;
}

export function PromptEditor({ agentId, agentName: _agentName, onPromptUpdated }: Props) {
  void _agentName; // Reserved for future use (e.g., display in header)
  const [promptData, setPromptData] = useState<PromptData | null>(null);
  const [editedPrompt, setEditedPrompt] = useState('');
  const [isEditing, setIsEditing] = useState(false);
  const [isSaving, setIsSaving] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showFullPrompt, setShowFullPrompt] = useState(false);

  useEffect(() => {
    fetchPrompt();
  }, [agentId]);

  const fetchPrompt = async () => {
    try {
      const res = await fetch(`${API_BASE}/api/agents/${agentId}/prompt`);
      const data = await res.json();
      setPromptData(data);
      setEditedPrompt(data.system_prompt || '');
      setError(null);
    } catch (err) {
      setError('Failed to load prompt');
    }
  };

  const handleSave = async () => {
    setIsSaving(true);
    try {
      const res = await fetch(`${API_BASE}/api/agents/${agentId}/prompt`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ system_prompt: editedPrompt })
      });

      if (res.ok) {
        await fetchPrompt();
        setIsEditing(false);
        onPromptUpdated?.();
      } else {
        setError('Failed to save prompt');
      }
    } catch (err) {
      setError('Failed to save prompt');
    } finally {
      setIsSaving(false);
    }
  };

  const handleReset = async () => {
    setIsSaving(true);
    try {
      const res = await fetch(`${API_BASE}/api/agents/${agentId}/prompt`, {
        method: 'DELETE'
      });

      if (res.ok) {
        await fetchPrompt();
        setIsEditing(false);
        onPromptUpdated?.();
      }
    } catch (err) {
      setError('Failed to reset prompt');
    } finally {
      setIsSaving(false);
    }
  };

  if (!promptData) {
    return (
      <div className="animate-pulse bg-slate-100 rounded-lg p-4 h-20"></div>
    );
  }

  // Rules-based agent - not editable
  if (promptData.type === 'rules') {
    return (
      <div className="bg-slate-50 border border-slate-200 rounded-lg p-4">
        <div className="flex items-center gap-2 mb-2">
          <span className="text-lg">‚ö°</span>
          <span className="font-medium text-slate-700">Rules-Based Agent</span>
          <span className="text-xs bg-slate-200 text-slate-600 px-2 py-0.5 rounded">Not Editable</span>
        </div>
        <p className="text-sm text-slate-500">
          {promptData.description}. This agent uses deterministic logic, not LLM prompts.
        </p>
      </div>
    );
  }

  // LLM-powered agent - show prompt and allow editing
  return (
    <div className="bg-blue-50 border border-blue-200 rounded-lg p-4">
      {/* Header */}
      <div className="flex items-center justify-between mb-3">
        <div className="flex items-center gap-2">
          <span className="text-lg">üß†</span>
          <span className="font-medium text-blue-700">LLM System Prompt</span>
          {promptData.is_custom && (
            <span className="text-xs bg-amber-100 text-amber-700 px-2 py-0.5 rounded">
              Customized
            </span>
          )}
        </div>
        <div className="flex items-center gap-2 text-xs">
          <span className="text-blue-500">{promptData.llm_provider}</span>
          {!isEditing && (
            <button
              onClick={() => setIsEditing(true)}
              className="px-2 py-1 bg-blue-100 text-blue-600 rounded hover:bg-blue-200 transition-colors"
            >
              ‚úèÔ∏è Edit Prompt
            </button>
          )}
        </div>
      </div>

      {error && (
        <div className="mb-3 text-sm text-red-600 bg-red-50 p-2 rounded">
          {error}
        </div>
      )}

      {isEditing ? (
        /* Editing Mode */
        <div className="space-y-3">
          <textarea
            value={editedPrompt}
            onChange={(e) => setEditedPrompt(e.target.value)}
            className="w-full h-64 p-3 text-sm font-mono bg-slate-800 text-slate-100 rounded-lg border border-slate-600 focus:outline-none focus:ring-2 focus:ring-blue-500"
            placeholder="Enter system prompt..."
          />
          <div className="flex items-center justify-between">
            <div className="text-xs text-slate-500">
              {editedPrompt.length} characters
            </div>
            <div className="flex items-center gap-2">
              {promptData.is_custom && (
                <button
                  onClick={handleReset}
                  disabled={isSaving}
                  className="px-3 py-1.5 text-sm text-amber-600 hover:bg-amber-50 rounded transition-colors"
                >
                  Reset to Default
                </button>
              )}
              <button
                onClick={() => {
                  setEditedPrompt(promptData.system_prompt || '');
                  setIsEditing(false);
                }}
                disabled={isSaving}
                className="px-3 py-1.5 text-sm text-slate-600 hover:bg-slate-100 rounded transition-colors"
              >
                Cancel
              </button>
              <button
                onClick={handleSave}
                disabled={isSaving}
                className="px-3 py-1.5 text-sm bg-blue-600 text-white rounded hover:bg-blue-700 transition-colors disabled:opacity-50"
              >
                {isSaving ? 'Saving...' : 'Save & Re-run'}
              </button>
            </div>
          </div>
          <div className="text-xs text-blue-600 bg-blue-100 p-2 rounded">
            üí° Tip: After saving, run the evaluation again to see how the new prompt affects the agent's reasoning.
          </div>
        </div>
      ) : (
        /* View Mode */
        <div>
          <div className="relative">
            <pre
              className={`text-xs font-mono bg-slate-800 text-slate-100 p-3 rounded-lg overflow-x-auto ${
                showFullPrompt ? 'max-h-none' : 'max-h-32'
              } overflow-y-hidden`}
            >
              {promptData.system_prompt}
            </pre>
            {!showFullPrompt && promptData.system_prompt && promptData.system_prompt.length > 500 && (
              <div className="absolute bottom-0 left-0 right-0 h-12 bg-gradient-to-t from-slate-800 to-transparent rounded-b-lg"></div>
            )}
          </div>
          {promptData.system_prompt && promptData.system_prompt.length > 500 && (
            <button
              onClick={() => setShowFullPrompt(!showFullPrompt)}
              className="mt-2 text-xs text-blue-600 hover:underline"
            >
              {showFullPrompt ? '‚ñ≤ Show less' : '‚ñº Show full prompt'}
            </button>
          )}
        </div>
      )}
    </div>
  );
}


================================================================================
FILE: frontend/src/hooks/useSSE.ts
================================================================================
import { useCallback, useRef } from 'react';

const API_BASE = import.meta.env.VITE_API_URL || 'http://localhost:8000';

interface HITLResult {
  status: string;
  approval_request_id?: string;
  approval_reason?: string;
  approval_reason_details?: string;
  proposed_offer?: {
    offer_type: string;
    price: number;
    discount_percent?: number;
    expected_value?: number;
  };
  escalation_reasons?: string[];
  final_decision?: any;
  suppression_reason?: string;
}

type ExecutionMode = 'choreography' | 'planner-worker';

// ReWOO-specific event types
interface ReWOOPlanStep {
  step_id: string;
  evaluation_type: string;
  description: string;
}

interface ReWOOWorkerStep {
  step_id: string;
  evaluation_type: string;
  recommendation: string;
  reasoning: string;
}

interface ReWOODecision {
  selected_offer: string;
  offer_price: number;
  discount_applied: number;
  expected_value: number;
  reasoning: string;
  policies_applied: string[];
  should_send_offer: boolean;
}

interface SSECallbacks {
  onPipelineStart?: (data: { pnr: string; total_steps: number; execution_mode?: string }) => void;
  onPlannerStart?: (data: { message: string }) => void;
  onPlannerDecision?: (data: { plan: string[]; reasoning: string }) => void;
  onAgentStart?: (data: { agent_id: string; agent_name: string; step: number }) => void;
  onAgentComplete?: (data: {
    agent_id: string;
    agent_name: string;
    step: number;
    status: string;
    duration_ms: number;
    summary: string;
    reasoning: string;
    outputs: Record<string, any>;
  }) => void;
  onAgentSkip?: (data: { agent_id: string; agent_name: string; step: number; reason: string }) => void;
  onPipelineComplete?: (data: {
    success: boolean;
    final_decision: any;
    total_duration_ms: number;
  }) => void;
  onError?: (error: string) => void;
  // New ReWOO-specific callbacks
  onReWOOPlannerComplete?: (data: {
    plan: ReWOOPlanStep[];
    reasoning: string;
    offer_options: any[];
  }) => void;
  onReWOOWorkerStep?: (data: ReWOOWorkerStep) => void;
  onReWOOSolverComplete?: (data: { decision: ReWOODecision }) => void;
}

export function useSSE() {
  const eventSourceRef = useRef<EventSource | null>(null);

  const startEvaluation = useCallback((pnr: string, callbacks: SSECallbacks, executionMode: ExecutionMode = 'choreography') => {
    // Close any existing connection
    if (eventSourceRef.current) {
      eventSourceRef.current.close();
    }

    const url = `${API_BASE}/api/pnrs/${pnr}/evaluate?execution_mode=${executionMode}`;
    const eventSource = new EventSource(url);
    eventSourceRef.current = eventSource;

    eventSource.addEventListener('pipeline_start', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onPipelineStart?.(data);
    });

    // Planner-worker specific events
    eventSource.addEventListener('planner_start', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onPlannerStart?.(data);
    });

    eventSource.addEventListener('planner_decision', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onPlannerDecision?.(data);
    });

    eventSource.addEventListener('agent_start', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onAgentStart?.(data);
    });

    eventSource.addEventListener('agent_complete', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onAgentComplete?.(data);
    });

    eventSource.addEventListener('agent_skip', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onAgentSkip?.(data);
    });

    // ReWOO-specific events for Offer Orchestration
    eventSource.addEventListener('rewoo_planner_complete', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onReWOOPlannerComplete?.(data);
    });

    eventSource.addEventListener('rewoo_worker_step', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onReWOOWorkerStep?.(data);
    });

    eventSource.addEventListener('rewoo_solver_complete', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onReWOOSolverComplete?.(data);
    });

    eventSource.addEventListener('pipeline_complete', (event) => {
      const data = JSON.parse(event.data);
      callbacks.onPipelineComplete?.(data);
      eventSource.close();
    });

    eventSource.addEventListener('error', (event) => {
      const data = JSON.parse((event as MessageEvent).data || '{}');
      callbacks.onError?.(data.error || 'Unknown error');
      eventSource.close();
    });

    eventSource.onerror = () => {
      callbacks.onError?.('Connection error');
      eventSource.close();
    };

    return () => {
      eventSource.close();
    };
  }, []);

  const stopEvaluation = useCallback(() => {
    if (eventSourceRef.current) {
      eventSourceRef.current.close();
      eventSourceRef.current = null;
    }
  }, []);

  /**
   * Start evaluation with Human-in-the-Loop support.
   * This is a direct API call (not SSE) that may return a pending approval.
   */
  const startEvaluationHITL = useCallback(async (pnr: string, forceApproval: boolean = false): Promise<HITLResult> => {
    const url = `${API_BASE}/api/pnrs/${pnr}/evaluate-hitl?force_approval=${forceApproval}`;
    const response = await fetch(url);

    if (!response.ok) {
      throw new Error(`HITL evaluation failed: ${response.statusText}`);
    }

    return response.json();
  }, []);

  return { startEvaluation, stopEvaluation, startEvaluationHITL };
}


================================================================================
FILE: frontend/src/index.css
================================================================================
@import "tailwindcss";

/* Custom styles */
body {
  margin: 0;
  font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  background-color: #f8fafc;
  min-height: 100vh;
}

#root {
  min-height: 100vh;
}

/* Terminal-like reasoning display */
.reasoning-display {
  font-family: 'JetBrains Mono', 'Fira Code', 'Monaco', monospace;
  font-size: 0.875rem;
  line-height: 1.6;
  white-space: pre-wrap;
  word-break: break-word;
}

/* Agent node animations */
.agent-node {
  transition: all 0.3s ease;
}

.agent-node:hover {
  transform: scale(1.05);
}

.agent-node.processing {
  animation: pulseGlow 1.5s ease-in-out infinite;
}

@keyframes pulseGlow {
  0%, 100% {
    box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.4);
  }
  50% {
    box-shadow: 0 0 0 12px rgba(59, 130, 246, 0);
  }
}

/* Connection line animation */
.connection-line {
  stroke-dasharray: 5 5;
  animation: flowDash 1s linear infinite;
}

.connection-line.active {
  stroke: #3b82f6;
  stroke-width: 3;
}

@keyframes flowDash {
  to {
    stroke-dashoffset: -10;
  }
}

/* Scrollbar styling */
.custom-scrollbar::-webkit-scrollbar {
  width: 8px;
}

.custom-scrollbar::-webkit-scrollbar-track {
  background: #1e293b;
  border-radius: 4px;
}

.custom-scrollbar::-webkit-scrollbar-thumb {
  background: #475569;
  border-radius: 4px;
}

.custom-scrollbar::-webkit-scrollbar-thumb:hover {
  background: #64748b;
}

/* Slide up animation */
.animate-slide-up {
  animation: slideUp 0.4s ease-out forwards;
}

@keyframes slideUp {
  from {
    transform: translateY(20px);
    opacity: 0;
  }
  to {
    transform: translateY(0);
    opacity: 1;
  }
}

/* Fade in animation for progressive data reveal */
.animate-fadeIn {
  animation: fadeIn 0.5s ease-out forwards;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(-10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

/* Slide up animation for floating robot chat panel */
.animate-slideUp {
  animation: slideUpChat 0.3s ease-out forwards;
}

@keyframes slideUpChat {
  from {
    transform: translateY(20px) scale(0.95);
    opacity: 0;
  }
  to {
    transform: translateY(0) scale(1);
    opacity: 1;
  }
}

/* Explainer video animations */
.animate-fadeInUp {
  animation: fadeInUp 0.8s ease-out forwards;
}

.animate-fadeInLeft {
  animation: fadeInLeft 0.8s ease-out forwards;
}

.animate-fadeInRight {
  animation: fadeInRight 0.8s ease-out forwards;
}

.animate-pulse-slow {
  animation: pulseSlow 2s ease-in-out infinite;
}

.animation-delay-200 {
  animation-delay: 200ms;
}

.animation-delay-300 {
  animation-delay: 300ms;
}

.animation-delay-500 {
  animation-delay: 500ms;
}

.animation-delay-700 {
  animation-delay: 700ms;
}

@keyframes fadeInUp {
  from {
    opacity: 0;
    transform: translateY(30px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

@keyframes fadeInLeft {
  from {
    opacity: 0;
    transform: translateX(-30px);
  }
  to {
    opacity: 1;
    transform: translateX(0);
  }
}

@keyframes fadeInRight {
  from {
    opacity: 0;
    transform: translateX(30px);
  }
  to {
    opacity: 1;
    transform: translateX(0);
  }
}

@keyframes pulseSlow {
  0%, 100% {
    transform: scale(1);
    box-shadow: 0 0 0 0 rgba(6, 182, 212, 0.4);
  }
  50% {
    transform: scale(1.05);
    box-shadow: 0 0 30px 10px rgba(6, 182, 212, 0.2);
  }
}


================================================================================
FILE: frontend/src/main.tsx
================================================================================
import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import './index.css'
import App from './App.tsx'

createRoot(document.getElementById('root')!).render(
  <StrictMode>
    <App />
  </StrictMode>,
)


================================================================================
FILE: frontend/src/types/backend.ts
================================================================================
/**
 * Backend API Types for BusinessAgentDemo
 *
 * These types map to the actual API responses from the FastAPI backend.
 */

// Response from GET /api/pnrs
export interface PNRSummary {
  pnr: string;
  customer_name: string;
  customer_tier: string;
  route: string;
  hours_to_departure: number;
  scenario_tag: string;
}

// Customer profile from enriched PNR
export interface CustomerProfile {
  lylty_acct_id: string;
  name: string;
  loyalty_tier: string;  // E, T, P, G, etc.
  aadv_tenure_days: number;
  business_trip_likelihood: number;
  flight_revenue_amt_history: number;
  is_suppressed: boolean;
  complaint_reason?: string;
  marketing_consent?: {
    push: boolean;
    email: boolean;
  };
  historical_upgrades?: {
    acceptance_rate: number;
    offers_received: number;
  };
}

// Flight info from enriched PNR
export interface FlightInfo {
  operat_flight_nbr: number;
  route: string;
  leg_dep_dt: string;
  schd_leg_dep_lcl_tms: string;
  equipment_model?: string;
  cabins: Record<string, CabinInfo>;
}

export interface CabinInfo {
  cabin_capacity: number;
  cabin_total_pax: number;
  cabin_available: number;
  expected_load_factor: number;
}

// Reservation info
export interface ReservationInfo {
  hours_to_departure: number;
  max_bkd_cabin_cd: string;  // F, W, Y
  fare_class: string;
  checked_in: boolean;
}

// Response from GET /api/pnrs/{pnr}
export interface EnrichedPNRResponse {
  pnr_locator: string;
  customer: CustomerProfile;
  flight: FlightInfo;
  reservation: ReservationInfo;
  ml_scores?: Record<string, MLScore>;
}

export interface MLScore {
  propensity_scores?: {
    [offerType: string]: {
      confidence: number;
      price_points?: {
        [price: string]: {
          p_buy: number;
        };
      };
    };
  };
  price_sensitivity?: 'low' | 'medium' | 'high';
}

// Parsed evaluation step from offer_reasoning
export interface ParsedEvaluationStep {
  stepId: string;
  evaluationType: string;
  description: string;
  result?: string;
  recommendation?: string;
}

// Parsed reasoning structure
export interface ParsedOfferReasoning {
  plannerThoughts: string;
  evaluationSteps: ParsedEvaluationStep[];
  solverThoughts: string;
  synthesis?: string;
  finalDecision?: string;
}

// Final decision from pipeline_complete event
export interface BackendFinalDecision {
  should_send_offer: boolean;
  offer_type?: string;
  price?: number;
  discount_percent?: number;
  channel?: string;
  send_time?: string;
  message_subject?: string;
  message_body?: string;
  fallback_offer?: {
    offer_type: string;
    display_name: string;
    price: number;
  };
  experiment_group?: string;
  tracking_id?: string;
  suppression_reason?: string;
}

// Agent complete event data
export interface AgentCompleteData {
  agent_id: string;
  agent_name: string;
  step: number;
  status: string;
  duration_ms: number;
  summary: string;
  reasoning: string;
  outputs: Record<string, unknown>;
}

// Pipeline complete event data
export interface PipelineCompleteData {
  success: boolean;
  final_decision: BackendFinalDecision;
  total_duration_ms: number;
  reasoning_trace?: string[];
}


================================================================================
FILE: frontend/src/types/index.ts
================================================================================
// PNR Types
export interface PNRSummary {
  pnr: string;
  customer_name: string;
  customer_tier: string;
  route: string;
  hours_to_departure: number;
  scenario_tag: string;
}

export interface CustomerData {
  lylty_acct_id: string;
  name: string;
  loyalty_tier: string;  // Single letter: E, C, T, P, G, R, N
  aadv_tenure_days: number;
  business_trip_likelihood: number;  // 0-1 float
  flight_revenue_amt_history: number;
  is_suppressed: boolean;
  complaint_reason?: string;
  marketing_consent?: {
    push: boolean;
    email: boolean;
  };
  historical_upgrades?: {
    acceptance_rate: number;
    offers_received: number;
  };
}

export interface FlightData {
  operat_flight_nbr: number;
  route: string;
  leg_dep_dt: string;
  schd_leg_dep_lcl_tms: string;
  equipment_model?: string;
  cabins: Record<string, CabinData>;
}

export interface CabinData {
  cabin_capacity: number;
  cabin_total_pax: number;
  cabin_available: number;
  expected_load_factor: number;
  cabin_aadvantage_pax?: number;
  cabin_total_revenue?: number;
}

export interface EnrichedPNR {
  pnr_locator: string;
  customer: CustomerData;
  flight: FlightData;
  reservation: {
    hours_to_departure: number;
    max_bkd_cabin_cd: string;  // F, W, Y
    fare_class: string;
    checked_in: boolean;
  };
  ml_scores?: Record<string, any>;
}

// Agent Types
export type AgentStatus = 'pending' | 'processing' | 'complete' | 'skipped' | 'error';

// Component types for honest architecture: Workflow, Agent, or LLM Call
export type ComponentType = 'workflow' | 'agent' | 'llm';

export interface AgentConfig {
  id: string;
  name: string;
  short_name: string;
  icon: string;
  description: string;
  component_type: ComponentType;  // honest architecture classification
}

export interface AgentResult {
  agent_id: string;
  agent_name: string;
  step: number;
  status: AgentStatus;
  duration_ms: number;
  summary: string;
  reasoning: string;
  outputs: Record<string, any>;
}

// Decision Types
export interface FinalDecision {
  should_send_offer: boolean;
  offer_type?: string;
  price?: number;
  discount_percent?: number;
  channel?: string;
  send_time?: string;
  message_subject?: string;
  message_body?: string;
  fallback_offer?: {
    offer_type: string;
    display_name: string;
    price: number;
  };
  experiment_group?: string;
  tracking_id?: string;
  suppression_reason?: string;
  // HITL fields
  pending_approval?: boolean;
  approval_request_id?: string;
  escalation_reasons?: string[];
}

// SSE Event Types
export interface SSEAgentStart {
  agent_id: string;
  agent_name: string;
  step: number;
  total_steps: number;
}

export interface SSEAgentComplete {
  agent_id: string;
  agent_name: string;
  step: number;
  status: 'complete';
  duration_ms: number;
  summary: string;
  reasoning: string;
  outputs: Record<string, any>;
}

export interface SSEAgentSkip {
  agent_id: string;
  agent_name: string;
  step: number;
  reason: string;
}

export interface SSEPipelineComplete {
  success: boolean;
  final_decision: FinalDecision;
  total_duration_ms: number;
  reasoning_trace: string[];
}

// App State
export interface AppState {
  pnrList: PNRSummary[];
  selectedPNR: string | null;
  enrichedData: EnrichedPNR | null;
  pipelineStatus: 'idle' | 'running' | 'complete' | 'error';
  agentResults: Record<string, AgentResult>;
  currentAgentId: string | null;
  selectedAgentTab: string | null;
  finalDecision: FinalDecision | null;
  showMessagePreview: boolean;
}


================================================================================
FILE: frontend/src/utils/parseOfferReasoning.ts
================================================================================
/**
 * Parse Offer Reasoning
 *
 * Utility to parse the `offer_reasoning` text from the backend's
 * offer_orchestration agent and extract structured information.
 *
 * The backend reasoning follows the ReWOO pattern:
 * - STEP 1: PLANNER (Making a Plan)
 * - STEP 2: WORKER (Doing the Checks)
 * - STEP 3: SOLVER (Making the Final Decision)
 */

import type { ParsedOfferReasoning, ParsedEvaluationStep } from '../types/backend';

/**
 * Parse the offer_reasoning text from the backend
 */
export function parseOfferReasoning(reasoning: string): ParsedOfferReasoning {
  if (!reasoning) {
    return {
      plannerThoughts: '',
      evaluationSteps: [],
      solverThoughts: '',
    };
  }

  // Split by the major sections
  const plannerMatch = reasoning.match(/STEP 1: PLANNER.*?(?==+ *STEP 2|$)/s);
  const workerMatch = reasoning.match(/STEP 2: WORKER.*?(?==+ *STEP 3|$)/s);
  const solverMatch = reasoning.match(/STEP 3: SOLVER.*$/s);

  // Extract planner thoughts
  let plannerThoughts = '';
  if (plannerMatch) {
    plannerThoughts = cleanSection(plannerMatch[0]);
  }

  // Extract worker evaluation steps
  const evaluationSteps: ParsedEvaluationStep[] = [];
  if (workerMatch) {
    const workerSection = workerMatch[0];

    // Find all "--- Executing E#: TYPE ---" blocks
    const stepRegex = /--- Executing (E\d+): (\w+) ---\s*([\s\S]*?)(?=--- Executing|STEP 3|$)/g;
    let match;

    while ((match = stepRegex.exec(workerSection)) !== null) {
      const stepId = match[1];
      const evaluationType = match[2];
      const content = match[3].trim();

      // Parse the content for recommendation
      const recMatch = content.match(/([‚úì‚ö†Ô∏è‚ö°üí∞üì¶].*)/);

      evaluationSteps.push({
        stepId,
        evaluationType,
        description: getEvaluationDescription(evaluationType),
        result: content,
        recommendation: recMatch ? recMatch[1] : undefined,
      });
    }
  }

  // Extract solver thoughts
  let solverThoughts = '';
  let synthesis = '';
  let finalDecision = '';

  if (solverMatch) {
    const solverSection = solverMatch[0];
    solverThoughts = cleanSection(solverSection);

    // Extract synthesis
    const synthMatch = solverSection.match(/SYNTHESIS:\s*(.+?)(?=\n\n|‚úÖ|$)/s);
    if (synthMatch) {
      synthesis = synthMatch[1].trim();
    }

    // Extract final decision
    const decisionMatch = solverSection.match(/‚úÖ FINAL DECISION:\s*(.+?)(?=\n\s*Discount|\n\s*Expected|$)/s);
    if (decisionMatch) {
      finalDecision = decisionMatch[1].trim();
    }
  }

  return {
    plannerThoughts,
    evaluationSteps,
    solverThoughts,
    synthesis,
    finalDecision,
  };
}

/**
 * Clean a section by removing separator lines
 */
function cleanSection(text: string): string {
  return text
    .replace(/=+/g, '')
    .replace(/STEP \d+: \w+.*?\n/g, '')
    .replace(/\(.*?\)/g, '')
    .trim();
}

/**
 * Get a human-readable description for an evaluation type
 */
function getEvaluationDescription(evaluationType: string): string {
  const descriptions: Record<string, string> = {
    CONFIDENCE: 'Check ML confidence levels for each offer',
    RELATIONSHIP: 'Check for recent customer service issues',
    PRICE_SENSITIVITY: 'Evaluate customer price sensitivity',
    INVENTORY: 'Check cabin inventory priority',
    EV_COMPARISON: 'Calculate expected values for each offer',
  };
  return descriptions[evaluationType] || `Evaluate ${evaluationType}`;
}

/**
 * Map backend final decision to frontend display format
 */
export function mapToFinalDecision(backendDecision: {
  should_send_offer: boolean;
  offer_type?: string;
  price?: number;
  discount_percent?: number;
  channel?: string;
  message_body?: string;
  suppression_reason?: string;
}): {
  offerType: string;
  offerName: string;
  price: number;
  discount: number;
  expectedValue: number;
  confidence: string;
  channel: string;
  reasoning: string;
} {
  if (!backendDecision.should_send_offer) {
    return {
      offerType: 'SUPPRESSED',
      offerName: `No Offer (${backendDecision.suppression_reason || 'Criteria not met'})`,
      price: 0,
      discount: 0,
      expectedValue: 0,
      confidence: 'N/A',
      channel: 'N/A',
      reasoning: backendDecision.suppression_reason || 'Customer did not meet offer criteria',
    };
  }

  const offerNames: Record<string, string> = {
    'IU_BUSINESS': 'Business Class Upgrade',
    'IU_PREMIUM_ECONOMY': 'Premium Economy Upgrade',
    'MCE': 'Main Cabin Extra',
  };

  const offerType = backendDecision.offer_type || 'UNKNOWN';
  const price = backendDecision.price || 0;
  const discount = backendDecision.discount_percent || 0;

  // Estimate EV (p_buy is not returned, so we estimate)
  const estimatedPBuy = 0.3;
  const margin = 0.85;
  const expectedValue = estimatedPBuy * price * margin;

  return {
    offerType,
    offerName: offerNames[offerType] || offerType,
    price,
    discount,
    expectedValue,
    confidence: discount > 0 ? 'MEDIUM' : 'HIGH',
    channel: backendDecision.channel || 'Push',
    reasoning: backendDecision.message_body || `Recommended ${offerNames[offerType] || offerType} at $${price}`,
  };
}

/**
 * Parse pre-flight agent outputs into display format
 */
export function parsePreFlightAgents(agentData: {
  agent_id: string;
  summary: string;
  reasoning: string;
  outputs: Record<string, unknown>;
}): {
  title: string;
  summary: string;
  details: string[];
} {
  const { agent_id, summary, outputs } = agentData;

  if (agent_id === 'customer_intelligence') {
    return {
      title: 'Customer Intelligence',
      summary,
      details: [
        `Eligible: ${outputs.customer_eligible ? 'Yes' : 'No'}`,
        `Segment: ${outputs.customer_segment || 'N/A'}`,
        outputs.suppression_reason ? `Suppression: ${outputs.suppression_reason}` : '',
      ].filter(Boolean),
    };
  }

  if (agent_id === 'flight_optimization') {
    return {
      title: 'Flight Optimization',
      summary,
      details: [
        `Priority: ${outputs.flight_priority || 'N/A'}`,
        `Recommended Cabins: ${(outputs.recommended_cabins as string[])?.join(', ') || 'None'}`,
      ],
    };
  }

  return {
    title: agent_id,
    summary,
    details: [],
  };
}


================================================================================
FILE: frontend/tailwind.config.js
================================================================================
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        'aa-red': '#D32F2F',
        'aa-blue': '#0D6EFD',
        'aa-navy': '#1A365D',
      },
      animation: {
        'pulse-glow': 'pulseGlow 1.5s ease-in-out infinite',
        'flow': 'flow 2s linear infinite',
        'slide-up': 'slideUp 0.4s ease-out',
      },
      keyframes: {
        pulseGlow: {
          '0%, 100%': { boxShadow: '0 0 0 0 rgba(59, 130, 246, 0.4)' },
          '50%': { boxShadow: '0 0 0 12px rgba(59, 130, 246, 0)' },
        },
        flow: {
          '0%': { strokeDashoffset: '20' },
          '100%': { strokeDashoffset: '0' },
        },
        slideUp: {
          '0%': { transform: 'translateY(20px)', opacity: '0' },
          '100%': { transform: 'translateY(0)', opacity: '1' },
        },
      },
    },
  },
  plugins: [],
}


================================================================================
FILE: frontend/tsconfig.app.json
================================================================================
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "target": "ES2022",
    "useDefineForClassFields": true,
    "lib": ["ES2022", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "types": ["vite/client"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["src"]
}


================================================================================
FILE: frontend/tsconfig.json
================================================================================
{
  "files": [],
  "references": [
    { "path": "./tsconfig.app.json" },
    { "path": "./tsconfig.node.json" }
  ]
}


================================================================================
FILE: frontend/tsconfig.node.json
================================================================================
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.node.tsbuildinfo",
    "target": "ES2023",
    "lib": ["ES2023"],
    "module": "ESNext",
    "types": ["node"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["vite.config.ts"]
}


================================================================================
FILE: frontend/vite.config.ts
================================================================================
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})


================================================================================
FILE: infrastructure/__init__.py
================================================================================
"""
Infrastructure Module for Tailored Offers Demo

Provides production-grade observability, retry logic, and validation:
- Structured logging with structlog
- Prometheus metrics collection
- LangSmith/LangFuse tracing
- Retry logic with tenacity
- LLM semantic validation
- Agent memory (short-term, long-term, episodic)
- Planner-Executor pattern (batch and incremental)
- Feedback loops for continuous improvement

Planner-Executor Patterns:
- Batch (Legacy): Plans all steps upfront, executes all, revises on failure
- Incremental (Recommended): Plans ONE step at a time, observes result, re-plans
"""

from .logging import get_logger, configure_logging
from .metrics import (
    MetricsCollector,
    agent_duration,
    agent_requests,
    llm_calls,
    llm_latency,
    llm_tokens,
)
from .retry import (
    retry_llm_call,
    retry_mcp_call,
    retry_with_fallback,
    RetryConfig,
)
from .tracing import (
    TracingManager,
    trace_agent,
    trace_llm_call,
    get_tracer,
)
from .validation import (
    LLMResponseValidator,
    ValidationResult,
    validate_offer_decision,
    validate_personalization_response,
)
from .memory import (
    AgentMemory,
    ConversationMemory,
    CustomerMemory,
    OfferMemory,
    LearningMemory,
    get_memory,
)
from .planner_executor import (
    # Data structures
    Plan,
    PlanStep,
    PlanStatus,
    StepStatus,
    ExecutionResult,
    WorkerResult,
    WorkerRecommendation,
    # Batch planner-executor (legacy)
    OfferPlanner,
    OfferExecutor,
    PlannerExecutorCoordinator,
    create_offer_plan,
    execute_offer_plan,
    run_offer_evaluation_with_planning,
    # Incremental planner-executor (recommended)
    IncrementalState,
    IncrementalOfferPlanner,
    IncrementalOfferExecutor,
    IncrementalPlannerExecutorCoordinator,
    run_offer_evaluation_incremental,
)
from .feedback import (
    FeedbackManager,
    FeedbackStore,
    OfferOutcome,
    OutcomeType,
    FeedbackStatus,
    CalibrationReport,
    CalibrationBucket,
    AgentFeedback,
    get_feedback_manager,
    record_offer_outcome,
    get_calibration_report,
)
from .guardrails import (
    # Guardrail types
    GuardrailVerdict,
    GuardrailResult,
    LayerResult,
    # Layer 1: Synchronous Pre-flight
    SyncGuardrails,
    # Layer 2: Asynchronous Background
    AsyncGuardrails,
    AsyncGuardrailTask,
    # Layer 3: Triggered Escalation
    TriggeredGuardrails,
    # Coordinator
    GuardrailCoordinator,
    create_guardrail_coordinator,
)
from .production_safety import (
    # Idempotency
    IdempotencyManager,
    IdempotencyStatus,
    IdempotencyRecord,
    # Cost Tracking
    CostTracker,
    LLMCallCost,
    # Alerting
    AlertManager,
    AlertSeverity,
    Alert,
    # Coordinator
    ProductionSafetyCoordinator,
    get_safety_coordinator,
    create_safety_coordinator,
)
from .human_in_loop import (
    # Data Models
    ApprovalStatus,
    ApprovalRequest,
    ApprovalDecision,
    EscalationReason,
    # State Management
    StateStore,
    ApprovalStore,
    # Notifications
    NotificationService,
    # Rules
    EscalationRules,
    # Manager
    HumanInTheLoopManager,
    get_hitl_manager,
    create_hitl_manager,
)

__all__ = [
    # Logging
    "get_logger",
    "configure_logging",
    # Metrics
    "MetricsCollector",
    "agent_duration",
    "agent_requests",
    "llm_calls",
    "llm_latency",
    "llm_tokens",
    # Retry
    "retry_llm_call",
    "retry_mcp_call",
    "retry_with_fallback",
    "RetryConfig",
    # Tracing
    "TracingManager",
    "trace_agent",
    "trace_llm_call",
    "get_tracer",
    # Validation
    "LLMResponseValidator",
    "ValidationResult",
    "validate_offer_decision",
    "validate_personalization_response",
    # Memory
    "AgentMemory",
    "ConversationMemory",
    "CustomerMemory",
    "OfferMemory",
    "LearningMemory",
    "get_memory",
    # Planner-Executor (Data Structures)
    "Plan",
    "PlanStep",
    "PlanStatus",
    "StepStatus",
    "ExecutionResult",
    "WorkerResult",
    "WorkerRecommendation",
    # Planner-Executor (Batch - Legacy)
    "OfferPlanner",
    "OfferExecutor",
    "PlannerExecutorCoordinator",
    "create_offer_plan",
    "execute_offer_plan",
    "run_offer_evaluation_with_planning",
    # Planner-Executor (Incremental - Recommended)
    "IncrementalState",
    "IncrementalOfferPlanner",
    "IncrementalOfferExecutor",
    "IncrementalPlannerExecutorCoordinator",
    "run_offer_evaluation_incremental",
    # Feedback Loop
    "FeedbackManager",
    "FeedbackStore",
    "OfferOutcome",
    "OutcomeType",
    "FeedbackStatus",
    "CalibrationReport",
    "CalibrationBucket",
    "AgentFeedback",
    "get_feedback_manager",
    "record_offer_outcome",
    "get_calibration_report",
    # Guardrails (3-Layer Architecture)
    "GuardrailVerdict",
    "GuardrailResult",
    "LayerResult",
    "SyncGuardrails",
    "AsyncGuardrails",
    "AsyncGuardrailTask",
    "TriggeredGuardrails",
    "GuardrailCoordinator",
    "create_guardrail_coordinator",
    # Production Safety (Critical for Production)
    "IdempotencyManager",
    "IdempotencyStatus",
    "IdempotencyRecord",
    "CostTracker",
    "LLMCallCost",
    "AlertManager",
    "AlertSeverity",
    "Alert",
    "ProductionSafetyCoordinator",
    "get_safety_coordinator",
    "create_safety_coordinator",
    # Human-in-the-Loop (HITL)
    "ApprovalStatus",
    "ApprovalRequest",
    "ApprovalDecision",
    "EscalationReason",
    "StateStore",
    "ApprovalStore",
    "NotificationService",
    "EscalationRules",
    "HumanInTheLoopManager",
    "get_hitl_manager",
    "create_hitl_manager",
]


================================================================================
FILE: infrastructure/feedback.py
================================================================================
"""
Outcome Capture + Feedback Loop System

The MOST CRITICAL component for production-ready agentic AI.
Without feedback loops, agents cannot learn and improve.

This module provides:
1. Outcome Capture: Record whether offers were accepted/rejected
2. Calibration: Compare expected probabilities vs actual outcomes
3. Confidence Adjustment: Update agent confidence based on real results
4. Learning Integration: Feed outcomes back to agents for improvement

The feedback loop closes the gap:
    Current: Data -> Agents -> Offer -> Customer -> ???
    New:     Data -> Agents -> Offer -> Customer -> OUTCOME -> Back to Agents

Usage:
    from infrastructure.feedback import get_feedback_manager, OutcomeType

    # Record an outcome
    feedback = get_feedback_manager()
    feedback.record_outcome(
        pnr="ABC123",
        customer_id="CUST456",
        offer_type="IU_BUSINESS",
        offer_price=299.00,
        expected_probability=0.25,
        expected_value=74.75,
        outcome=OutcomeType.ACCEPTED,
    )

    # Get calibration report
    report = feedback.get_calibration_report()
"""

import os
import json
import statistics
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict

from .logging import get_logger
from .metrics import metrics

logger = get_logger("feedback")


# =============================================================================
# OUTCOME TYPES
# =============================================================================

class OutcomeType(Enum):
    """Possible outcomes for an offer."""
    PENDING = "pending"      # Offer sent, waiting for response
    ACCEPTED = "accepted"    # Customer accepted the offer
    REJECTED = "rejected"    # Customer explicitly rejected
    EXPIRED = "expired"      # Offer expired without response
    CLICKED = "clicked"      # Customer clicked but didn't convert
    UNKNOWN = "unknown"      # Outcome not tracked


class FeedbackStatus(Enum):
    """Status of feedback processing."""
    RECEIVED = "received"
    PROCESSED = "processed"
    APPLIED = "applied"
    FAILED = "failed"


# =============================================================================
# DATA STRUCTURES
# =============================================================================

@dataclass
class OfferOutcome:
    """
    Complete outcome record for an offer.

    This is the fundamental unit of feedback data.
    """
    outcome_id: str
    pnr: str
    customer_id: str
    offer_type: str
    offer_price: float
    discount_percent: float
    expected_probability: float  # P(accept) predicted by agent
    expected_value: float        # EV = P(accept) * revenue
    actual_outcome: OutcomeType
    channel: str

    # Timing
    offer_sent_at: datetime
    outcome_recorded_at: Optional[datetime] = None
    time_to_decision_hours: Optional[float] = None

    # Context
    customer_tier: Optional[str] = None
    flight_route: Optional[str] = None
    hours_to_departure: Optional[int] = None
    experiment_group: Optional[str] = None

    # Agent info
    agent_version: Optional[str] = None
    prompt_version: Optional[str] = None
    model_used: Optional[str] = None

    # Feedback
    customer_feedback: Optional[str] = None
    feedback_status: FeedbackStatus = FeedbackStatus.RECEIVED

    def to_dict(self) -> Dict[str, Any]:
        return {
            **asdict(self),
            "actual_outcome": self.actual_outcome.value,
            "feedback_status": self.feedback_status.value,
            "offer_sent_at": self.offer_sent_at.isoformat(),
            "outcome_recorded_at": self.outcome_recorded_at.isoformat() if self.outcome_recorded_at else None,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "OfferOutcome":
        return cls(
            outcome_id=data["outcome_id"],
            pnr=data["pnr"],
            customer_id=data["customer_id"],
            offer_type=data["offer_type"],
            offer_price=data["offer_price"],
            discount_percent=data["discount_percent"],
            expected_probability=data["expected_probability"],
            expected_value=data["expected_value"],
            actual_outcome=OutcomeType(data["actual_outcome"]),
            channel=data["channel"],
            offer_sent_at=datetime.fromisoformat(data["offer_sent_at"]),
            outcome_recorded_at=datetime.fromisoformat(data["outcome_recorded_at"]) if data.get("outcome_recorded_at") else None,
            time_to_decision_hours=data.get("time_to_decision_hours"),
            customer_tier=data.get("customer_tier"),
            flight_route=data.get("flight_route"),
            hours_to_departure=data.get("hours_to_departure"),
            experiment_group=data.get("experiment_group"),
            agent_version=data.get("agent_version"),
            prompt_version=data.get("prompt_version"),
            model_used=data.get("model_used"),
            customer_feedback=data.get("customer_feedback"),
            feedback_status=FeedbackStatus(data.get("feedback_status", "received")),
        )

    @property
    def was_successful(self) -> bool:
        return self.actual_outcome == OutcomeType.ACCEPTED

    @property
    def actual_value(self) -> float:
        """Actual revenue from this offer."""
        if self.was_successful:
            return self.offer_price
        return 0.0

    @property
    def prediction_error(self) -> float:
        """Error in expected value prediction."""
        return self.actual_value - self.expected_value


@dataclass
class CalibrationBucket:
    """
    A bucket for calibration analysis.

    Groups predictions by expected probability ranges.
    """
    bucket_range: Tuple[float, float]  # e.g., (0.2, 0.3)
    predictions: List[float] = field(default_factory=list)
    outcomes: List[bool] = field(default_factory=list)

    @property
    def count(self) -> int:
        return len(self.predictions)

    @property
    def avg_predicted(self) -> float:
        if not self.predictions:
            return 0.0
        return statistics.mean(self.predictions)

    @property
    def actual_rate(self) -> float:
        if not self.outcomes:
            return 0.0
        return sum(self.outcomes) / len(self.outcomes)

    @property
    def calibration_error(self) -> float:
        """Difference between predicted and actual rates."""
        return abs(self.avg_predicted - self.actual_rate)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "bucket_range": list(self.bucket_range),
            "count": self.count,
            "avg_predicted": self.avg_predicted,
            "actual_rate": self.actual_rate,
            "calibration_error": self.calibration_error,
        }


@dataclass
class CalibrationReport:
    """
    Complete calibration report for agent predictions.

    Shows how well predicted probabilities match actual outcomes.
    """
    report_id: str
    generated_at: datetime
    period_start: datetime
    period_end: datetime

    # Overall metrics
    total_outcomes: int
    total_accepted: int
    total_rejected: int
    overall_acceptance_rate: float

    # Calibration buckets
    buckets: List[CalibrationBucket]

    # Error metrics
    mean_calibration_error: float  # Average error across buckets
    expected_calibration_error: float  # ECE
    brier_score: float  # Mean squared error

    # Value metrics
    total_expected_value: float
    total_actual_value: float
    value_capture_rate: float  # actual / expected

    # Segmented analysis
    by_offer_type: Dict[str, Dict[str, float]]
    by_customer_tier: Dict[str, Dict[str, float]]
    by_channel: Dict[str, Dict[str, float]]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "report_id": self.report_id,
            "generated_at": self.generated_at.isoformat(),
            "period": {
                "start": self.period_start.isoformat(),
                "end": self.period_end.isoformat(),
            },
            "overall": {
                "total_outcomes": self.total_outcomes,
                "total_accepted": self.total_accepted,
                "total_rejected": self.total_rejected,
                "acceptance_rate": self.overall_acceptance_rate,
            },
            "calibration": {
                "buckets": [b.to_dict() for b in self.buckets],
                "mean_error": self.mean_calibration_error,
                "ece": self.expected_calibration_error,
                "brier_score": self.brier_score,
            },
            "value": {
                "total_expected": self.total_expected_value,
                "total_actual": self.total_actual_value,
                "capture_rate": self.value_capture_rate,
            },
            "segments": {
                "by_offer_type": self.by_offer_type,
                "by_customer_tier": self.by_customer_tier,
                "by_channel": self.by_channel,
            },
        }


@dataclass
class AgentFeedback:
    """
    Aggregated feedback for an agent to improve.

    This is what gets fed back to agents for learning.
    """
    agent_name: str
    prompt_version: str

    # Performance metrics
    total_decisions: int
    successful_decisions: int
    success_rate: float

    # Calibration
    avg_calibration_error: float
    overconfident: bool  # Predicts higher than actual
    underconfident: bool  # Predicts lower than actual

    # Recommendations
    confidence_adjustment: float  # How much to adjust confidence
    recommendations: List[str]

    # Specific insights
    best_performing_segments: List[str]
    worst_performing_segments: List[str]

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


# =============================================================================
# FEEDBACK STORE
# =============================================================================

class FeedbackStore:
    """
    Storage backend for outcomes and feedback.

    Supports in-memory (dev) or external storage (production).
    """

    def __init__(self):
        self._outcomes: Dict[str, OfferOutcome] = {}
        self._outcomes_by_pnr: Dict[str, str] = {}  # pnr -> outcome_id
        self._outcomes_by_customer: Dict[str, List[str]] = defaultdict(list)

    def save_outcome(self, outcome: OfferOutcome) -> None:
        """Save an outcome record."""
        self._outcomes[outcome.outcome_id] = outcome
        self._outcomes_by_pnr[outcome.pnr] = outcome.outcome_id
        self._outcomes_by_customer[outcome.customer_id].append(outcome.outcome_id)

    def get_outcome(self, outcome_id: str) -> Optional[OfferOutcome]:
        """Get outcome by ID."""
        return self._outcomes.get(outcome_id)

    def get_outcome_by_pnr(self, pnr: str) -> Optional[OfferOutcome]:
        """Get outcome by PNR."""
        outcome_id = self._outcomes_by_pnr.get(pnr)
        if outcome_id:
            return self._outcomes.get(outcome_id)
        return None

    def get_customer_outcomes(self, customer_id: str) -> List[OfferOutcome]:
        """Get all outcomes for a customer."""
        outcome_ids = self._outcomes_by_customer.get(customer_id, [])
        return [self._outcomes[oid] for oid in outcome_ids if oid in self._outcomes]

    def get_outcomes_in_range(
        self,
        start: datetime,
        end: datetime,
    ) -> List[OfferOutcome]:
        """Get all outcomes in a date range."""
        return [
            o for o in self._outcomes.values()
            if o.offer_sent_at >= start and o.offer_sent_at <= end
        ]

    def get_all_outcomes(self) -> List[OfferOutcome]:
        """Get all recorded outcomes."""
        return list(self._outcomes.values())

    def update_outcome(self, outcome_id: str, **updates) -> Optional[OfferOutcome]:
        """Update an existing outcome."""
        outcome = self._outcomes.get(outcome_id)
        if outcome:
            for key, value in updates.items():
                if hasattr(outcome, key):
                    setattr(outcome, key, value)
        return outcome


# =============================================================================
# FEEDBACK MANAGER
# =============================================================================

class FeedbackManager:
    """
    Main interface for the feedback loop system.

    Responsibilities:
    1. Record outcomes from customer actions
    2. Calculate calibration metrics
    3. Generate feedback for agents
    4. Update learning memory with patterns
    """

    def __init__(self, store: Optional[FeedbackStore] = None):
        self.store = store or FeedbackStore()

        # Lazy import to avoid circular dependency
        self._memory = None

    @property
    def memory(self):
        if self._memory is None:
            from .memory import get_memory
            self._memory = get_memory()
        return self._memory

    # =========================================================================
    # OUTCOME RECORDING
    # =========================================================================

    def record_outcome(
        self,
        pnr: str,
        customer_id: str,
        offer_type: str,
        offer_price: float,
        expected_probability: float,
        expected_value: float,
        outcome: OutcomeType,
        channel: str = "unknown",
        discount_percent: float = 0.0,
        **kwargs,
    ) -> OfferOutcome:
        """
        Record the outcome of an offer.

        This is the primary entry point for closing the feedback loop.

        Args:
            pnr: PNR locator for the offer
            customer_id: Customer who received the offer
            offer_type: Type of offer (IU_BUSINESS, MCE, etc.)
            offer_price: Price of the offer
            expected_probability: Agent's predicted P(accept)
            expected_value: Agent's calculated EV
            outcome: Actual outcome (ACCEPTED, REJECTED, etc.)
            channel: Delivery channel
            discount_percent: Discount applied
            **kwargs: Additional context (tier, route, etc.)

        Returns:
            The recorded OfferOutcome
        """
        import uuid

        outcome_record = OfferOutcome(
            outcome_id=f"out_{uuid.uuid4().hex[:12]}",
            pnr=pnr,
            customer_id=customer_id,
            offer_type=offer_type,
            offer_price=offer_price,
            discount_percent=discount_percent,
            expected_probability=expected_probability,
            expected_value=expected_value,
            actual_outcome=outcome,
            channel=channel,
            offer_sent_at=kwargs.get("offer_sent_at", datetime.now()),
            outcome_recorded_at=datetime.now(),
            customer_tier=kwargs.get("customer_tier"),
            flight_route=kwargs.get("flight_route"),
            hours_to_departure=kwargs.get("hours_to_departure"),
            experiment_group=kwargs.get("experiment_group"),
            agent_version=kwargs.get("agent_version"),
            prompt_version=kwargs.get("prompt_version"),
            model_used=kwargs.get("model_used"),
            customer_feedback=kwargs.get("customer_feedback"),
        )

        # Calculate time to decision
        if outcome_record.offer_sent_at and outcome_record.outcome_recorded_at:
            delta = outcome_record.outcome_recorded_at - outcome_record.offer_sent_at
            outcome_record.time_to_decision_hours = delta.total_seconds() / 3600

        # Save to store
        self.store.save_outcome(outcome_record)

        # Record metrics
        self._record_outcome_metrics(outcome_record)

        # Update memory with outcome
        self._update_memory(outcome_record)

        # Process feedback
        self._process_feedback(outcome_record)

        logger.info(
            "outcome_recorded",
            pnr=pnr,
            offer_type=offer_type,
            outcome=outcome.value,
            expected_prob=expected_probability,
            actual_value=outcome_record.actual_value,
        )

        return outcome_record

    def update_outcome(
        self,
        pnr: str,
        outcome: OutcomeType,
        customer_feedback: Optional[str] = None,
    ) -> Optional[OfferOutcome]:
        """
        Update the outcome for a pending offer.

        Used when outcome information arrives later.
        """
        existing = self.store.get_outcome_by_pnr(pnr)
        if not existing:
            logger.warning("outcome_not_found", pnr=pnr)
            return None

        # Update the outcome
        existing.actual_outcome = outcome
        existing.outcome_recorded_at = datetime.now()
        if customer_feedback:
            existing.customer_feedback = customer_feedback

        if existing.offer_sent_at:
            delta = existing.outcome_recorded_at - existing.offer_sent_at
            existing.time_to_decision_hours = delta.total_seconds() / 3600

        # Re-process feedback with new outcome
        self._record_outcome_metrics(existing)
        self._update_memory(existing)
        self._process_feedback(existing)

        logger.info(
            "outcome_updated",
            pnr=pnr,
            outcome=outcome.value,
        )

        return existing

    def _record_outcome_metrics(self, outcome: OfferOutcome) -> None:
        """Record outcome in Prometheus metrics."""
        metrics.record_offer_outcome(
            offer_type=outcome.offer_type,
            outcome=outcome.actual_outcome.value,
            channel=outcome.channel,
        )

        if outcome.was_successful:
            metrics.record_offer_revenue(
                outcome.offer_price,
                outcome.offer_type,
            )

    def _update_memory(self, outcome: OfferOutcome) -> None:
        """Update memory with outcome data."""
        # Record in offer memory
        self.memory.record_outcome(
            pnr=outcome.pnr,
            customer_id=outcome.customer_id,
            offer_type=outcome.offer_type,
            offer_price=outcome.offer_price,
            expected_value=outcome.expected_value,
            actual_outcome=outcome.actual_outcome.value,
        )

        # Record patterns in learning memory
        self.memory.learning.record_pattern(
            pattern_type="outcome",
            pattern_key=f"{outcome.offer_type}_{outcome.channel}",
            success=outcome.was_successful,
            context={
                "price": outcome.offer_price,
                "discount": outcome.discount_percent,
                "tier": outcome.customer_tier,
                "expected_prob": outcome.expected_probability,
            },
        )

        # Record time-based patterns
        hour = outcome.offer_sent_at.hour
        time_key = "morning" if hour < 12 else "afternoon" if hour < 18 else "evening"
        self.memory.learning.record_pattern(
            pattern_type="time_of_day",
            pattern_key=time_key,
            success=outcome.was_successful,
            context={"offer_type": outcome.offer_type},
        )

    def _process_feedback(self, outcome: OfferOutcome) -> None:
        """Process outcome and generate feedback for agents."""
        outcome.feedback_status = FeedbackStatus.PROCESSED

        # Check if prediction was significantly off
        if outcome.expected_probability > 0:
            actual_result = 1.0 if outcome.was_successful else 0.0
            prediction_error = abs(actual_result - outcome.expected_probability)

            if prediction_error > 0.3:
                # Large prediction error - log for analysis
                logger.warning(
                    "large_prediction_error",
                    pnr=outcome.pnr,
                    expected=outcome.expected_probability,
                    actual=actual_result,
                    error=prediction_error,
                )

        outcome.feedback_status = FeedbackStatus.APPLIED

    # =========================================================================
    # CALIBRATION ANALYSIS
    # =========================================================================

    def get_calibration_report(
        self,
        start: Optional[datetime] = None,
        end: Optional[datetime] = None,
        num_buckets: int = 10,
    ) -> CalibrationReport:
        """
        Generate a calibration report for a time period.

        Calibration measures how well predicted probabilities match actual outcomes.
        A well-calibrated model predicting 30% acceptance should see ~30% actual.

        Args:
            start: Start of analysis period (default: 30 days ago)
            end: End of analysis period (default: now)
            num_buckets: Number of probability buckets

        Returns:
            CalibrationReport with detailed metrics
        """
        import uuid

        if end is None:
            end = datetime.now()
        if start is None:
            start = end - timedelta(days=30)

        # Get outcomes in range
        outcomes = self.store.get_outcomes_in_range(start, end)

        # Filter to completed outcomes
        completed = [
            o for o in outcomes
            if o.actual_outcome in [OutcomeType.ACCEPTED, OutcomeType.REJECTED]
        ]

        if not completed:
            return self._empty_calibration_report(start, end)

        # Build calibration buckets
        bucket_width = 1.0 / num_buckets
        buckets = []

        for i in range(num_buckets):
            bucket_start = i * bucket_width
            bucket_end = (i + 1) * bucket_width
            bucket = CalibrationBucket(bucket_range=(bucket_start, bucket_end))

            for o in completed:
                if bucket_start <= o.expected_probability < bucket_end:
                    bucket.predictions.append(o.expected_probability)
                    bucket.outcomes.append(o.was_successful)

            if bucket.count > 0:
                buckets.append(bucket)

        # Calculate overall metrics
        total_accepted = sum(1 for o in completed if o.was_successful)
        total_rejected = len(completed) - total_accepted
        overall_rate = total_accepted / len(completed) if completed else 0.0

        # Calculate calibration metrics
        predictions = [o.expected_probability for o in completed]
        actuals = [1.0 if o.was_successful else 0.0 for o in completed]

        # Brier score (mean squared error)
        brier = sum((p - a) ** 2 for p, a in zip(predictions, actuals)) / len(completed)

        # Expected Calibration Error
        ece = sum(b.calibration_error * b.count for b in buckets) / len(completed) if buckets else 0.0

        # Mean calibration error
        mce = statistics.mean([b.calibration_error for b in buckets]) if buckets else 0.0

        # Value metrics
        total_ev = sum(o.expected_value for o in completed)
        total_av = sum(o.actual_value for o in completed)
        capture_rate = total_av / total_ev if total_ev > 0 else 0.0

        # Segmented analysis
        by_offer_type = self._analyze_by_segment(completed, "offer_type")
        by_tier = self._analyze_by_segment(completed, "customer_tier")
        by_channel = self._analyze_by_segment(completed, "channel")

        return CalibrationReport(
            report_id=f"cal_{uuid.uuid4().hex[:8]}",
            generated_at=datetime.now(),
            period_start=start,
            period_end=end,
            total_outcomes=len(completed),
            total_accepted=total_accepted,
            total_rejected=total_rejected,
            overall_acceptance_rate=overall_rate,
            buckets=buckets,
            mean_calibration_error=mce,
            expected_calibration_error=ece,
            brier_score=brier,
            total_expected_value=total_ev,
            total_actual_value=total_av,
            value_capture_rate=capture_rate,
            by_offer_type=by_offer_type,
            by_customer_tier=by_tier,
            by_channel=by_channel,
        )

    def _empty_calibration_report(
        self,
        start: datetime,
        end: datetime,
    ) -> CalibrationReport:
        """Return an empty calibration report."""
        import uuid
        return CalibrationReport(
            report_id=f"cal_{uuid.uuid4().hex[:8]}",
            generated_at=datetime.now(),
            period_start=start,
            period_end=end,
            total_outcomes=0,
            total_accepted=0,
            total_rejected=0,
            overall_acceptance_rate=0.0,
            buckets=[],
            mean_calibration_error=0.0,
            expected_calibration_error=0.0,
            brier_score=0.0,
            total_expected_value=0.0,
            total_actual_value=0.0,
            value_capture_rate=0.0,
            by_offer_type={},
            by_customer_tier={},
            by_channel={},
        )

    def _analyze_by_segment(
        self,
        outcomes: List[OfferOutcome],
        segment_field: str,
    ) -> Dict[str, Dict[str, float]]:
        """Analyze calibration by a specific segment."""
        by_segment: Dict[str, List[OfferOutcome]] = defaultdict(list)

        for o in outcomes:
            segment_value = getattr(o, segment_field, None) or "unknown"
            by_segment[segment_value].append(o)

        result = {}
        for segment, segment_outcomes in by_segment.items():
            accepted = sum(1 for o in segment_outcomes if o.was_successful)
            total = len(segment_outcomes)
            avg_pred = statistics.mean([o.expected_probability for o in segment_outcomes])
            actual_rate = accepted / total if total > 0 else 0.0

            result[segment] = {
                "total": total,
                "accepted": accepted,
                "acceptance_rate": actual_rate,
                "avg_predicted": avg_pred,
                "calibration_error": abs(avg_pred - actual_rate),
            }

        return result

    # =========================================================================
    # AGENT FEEDBACK GENERATION
    # =========================================================================

    def get_agent_feedback(
        self,
        agent_name: str,
        prompt_version: Optional[str] = None,
        days: int = 30,
    ) -> AgentFeedback:
        """
        Generate feedback for a specific agent to improve.

        This is what gets fed back into the agent for learning.

        Args:
            agent_name: Name of the agent
            prompt_version: Specific prompt version to analyze
            days: Number of days to analyze

        Returns:
            AgentFeedback with improvement recommendations
        """
        end = datetime.now()
        start = end - timedelta(days=days)

        outcomes = self.store.get_outcomes_in_range(start, end)

        # Filter by agent/prompt version if specified
        if prompt_version:
            outcomes = [o for o in outcomes if o.prompt_version == prompt_version]

        completed = [
            o for o in outcomes
            if o.actual_outcome in [OutcomeType.ACCEPTED, OutcomeType.REJECTED]
        ]

        if not completed:
            return self._empty_agent_feedback(agent_name, prompt_version or "unknown")

        # Calculate metrics
        total = len(completed)
        successful = sum(1 for o in completed if o.was_successful)
        success_rate = successful / total

        # Calibration analysis
        predictions = [o.expected_probability for o in completed]
        actuals = [1.0 if o.was_successful else 0.0 for o in completed]

        avg_predicted = statistics.mean(predictions)
        actual_rate = statistics.mean(actuals)
        calibration_error = abs(avg_predicted - actual_rate)

        overconfident = avg_predicted > actual_rate + 0.05
        underconfident = avg_predicted < actual_rate - 0.05

        # Calculate confidence adjustment
        if overconfident:
            adjustment = -(avg_predicted - actual_rate)
        elif underconfident:
            adjustment = actual_rate - avg_predicted
        else:
            adjustment = 0.0

        # Generate recommendations
        recommendations = self._generate_recommendations(
            outcomes=completed,
            calibration_error=calibration_error,
            overconfident=overconfident,
            underconfident=underconfident,
        )

        # Find best/worst segments
        by_offer = self._analyze_by_segment(completed, "offer_type")
        sorted_offers = sorted(
            by_offer.items(),
            key=lambda x: x[1]["acceptance_rate"],
            reverse=True,
        )

        best = [k for k, v in sorted_offers[:2] if v["acceptance_rate"] > 0.3]
        worst = [k for k, v in sorted_offers[-2:] if v["acceptance_rate"] < 0.2]

        return AgentFeedback(
            agent_name=agent_name,
            prompt_version=prompt_version or "unknown",
            total_decisions=total,
            successful_decisions=successful,
            success_rate=success_rate,
            avg_calibration_error=calibration_error,
            overconfident=overconfident,
            underconfident=underconfident,
            confidence_adjustment=adjustment,
            recommendations=recommendations,
            best_performing_segments=best,
            worst_performing_segments=worst,
        )

    def _empty_agent_feedback(
        self,
        agent_name: str,
        prompt_version: str,
    ) -> AgentFeedback:
        """Return empty feedback for an agent with no data."""
        return AgentFeedback(
            agent_name=agent_name,
            prompt_version=prompt_version,
            total_decisions=0,
            successful_decisions=0,
            success_rate=0.0,
            avg_calibration_error=0.0,
            overconfident=False,
            underconfident=False,
            confidence_adjustment=0.0,
            recommendations=["Insufficient data for feedback"],
            best_performing_segments=[],
            worst_performing_segments=[],
        )

    def _generate_recommendations(
        self,
        outcomes: List[OfferOutcome],
        calibration_error: float,
        overconfident: bool,
        underconfident: bool,
    ) -> List[str]:
        """Generate improvement recommendations based on outcomes."""
        recommendations = []

        # Calibration recommendations
        if calibration_error > 0.15:
            recommendations.append(
                f"HIGH PRIORITY: Calibration error is {calibration_error:.1%} - "
                "predictions are significantly off from actual outcomes"
            )

        if overconfident:
            recommendations.append(
                "Predictions are overconfident - lower expected probabilities by "
                "being more conservative in acceptance rate estimates"
            )

        if underconfident:
            recommendations.append(
                "Predictions are underconfident - consider raising acceptance "
                "probability estimates as customers are converting better than expected"
            )

        # Segment-specific recommendations
        by_discount = defaultdict(list)
        for o in outcomes:
            bucket = "high" if o.discount_percent > 15 else "low" if o.discount_percent < 10 else "medium"
            by_discount[bucket].append(o)

        for bucket, bucket_outcomes in by_discount.items():
            accepted = sum(1 for o in bucket_outcomes if o.was_successful)
            rate = accepted / len(bucket_outcomes) if bucket_outcomes else 0

            if bucket == "high" and rate < 0.2:
                recommendations.append(
                    "High discounts (>15%) not improving conversion - consider "
                    "whether price is the primary barrier"
                )

            if bucket == "low" and rate > 0.4:
                recommendations.append(
                    "Low discounts (<10%) performing well - may not need to "
                    "offer higher discounts for this segment"
                )

        # Time-based recommendations
        by_time = defaultdict(list)
        for o in outcomes:
            hour = o.offer_sent_at.hour
            period = "morning" if hour < 12 else "afternoon" if hour < 18 else "evening"
            by_time[period].append(o)

        best_time = max(
            by_time.items(),
            key=lambda x: sum(1 for o in x[1] if o.was_successful) / len(x[1]) if x[1] else 0,
            default=("", []),
        )

        if best_time[0] and len(best_time[1]) > 5:
            rate = sum(1 for o in best_time[1] if o.was_successful) / len(best_time[1])
            if rate > 0.3:
                recommendations.append(
                    f"Best conversion during {best_time[0]} ({rate:.1%}) - "
                    "consider prioritizing this time window"
                )

        if not recommendations:
            recommendations.append("Performance is within expected parameters - continue monitoring")

        return recommendations

    # =========================================================================
    # STATISTICS & REPORTING
    # =========================================================================

    def get_summary_stats(
        self,
        days: int = 30,
    ) -> Dict[str, Any]:
        """Get summary statistics for the feedback system."""
        end = datetime.now()
        start = end - timedelta(days=days)

        outcomes = self.store.get_outcomes_in_range(start, end)

        if not outcomes:
            return {
                "period_days": days,
                "total_offers": 0,
                "outcomes_recorded": 0,
                "pending": 0,
                "acceptance_rate": 0.0,
                "avg_expected_value": 0.0,
                "avg_actual_value": 0.0,
            }

        completed = [
            o for o in outcomes
            if o.actual_outcome in [OutcomeType.ACCEPTED, OutcomeType.REJECTED]
        ]
        pending = [o for o in outcomes if o.actual_outcome == OutcomeType.PENDING]

        accepted = sum(1 for o in completed if o.was_successful)

        return {
            "period_days": days,
            "total_offers": len(outcomes),
            "outcomes_recorded": len(completed),
            "pending": len(pending),
            "acceptance_rate": accepted / len(completed) if completed else 0.0,
            "avg_expected_value": statistics.mean([o.expected_value for o in outcomes]),
            "avg_actual_value": statistics.mean([o.actual_value for o in completed]) if completed else 0.0,
            "total_revenue": sum(o.actual_value for o in completed),
            "value_capture_rate": (
                sum(o.actual_value for o in completed) / sum(o.expected_value for o in completed)
                if sum(o.expected_value for o in completed) > 0 else 0.0
            ),
        }

    def get_outcome(self, pnr: str) -> Optional[OfferOutcome]:
        """Get the outcome for a specific PNR."""
        return self.store.get_outcome_by_pnr(pnr)

    def get_customer_history(self, customer_id: str) -> List[OfferOutcome]:
        """Get all outcomes for a customer."""
        return self.store.get_customer_outcomes(customer_id)


# =============================================================================
# GLOBAL INSTANCE
# =============================================================================

_feedback_manager: Optional[FeedbackManager] = None


def get_feedback_manager() -> FeedbackManager:
    """Get the global feedback manager instance."""
    global _feedback_manager
    if _feedback_manager is None:
        _feedback_manager = FeedbackManager()
    return _feedback_manager


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================

def record_offer_outcome(
    pnr: str,
    customer_id: str,
    offer_type: str,
    offer_price: float,
    expected_probability: float,
    expected_value: float,
    outcome: str,
    **kwargs,
) -> OfferOutcome:
    """
    Convenience function to record an outcome.

    Args:
        outcome: String value ("accepted", "rejected", "expired")
    """
    outcome_type = OutcomeType(outcome)
    return get_feedback_manager().record_outcome(
        pnr=pnr,
        customer_id=customer_id,
        offer_type=offer_type,
        offer_price=offer_price,
        expected_probability=expected_probability,
        expected_value=expected_value,
        outcome=outcome_type,
        **kwargs,
    )


def get_calibration_report(days: int = 30) -> CalibrationReport:
    """Convenience function to get calibration report."""
    end = datetime.now()
    start = end - timedelta(days=days)
    return get_feedback_manager().get_calibration_report(start, end)


================================================================================
FILE: infrastructure/guardrails.py
================================================================================
"""
3-Layer Guardrail Architecture for Tailored Offers

This module implements a latency-optimized guardrail system with three layers:

Layer 1: SYNCHRONOUS PRE-FLIGHT (~40-70ms)
  - Fast checks that MUST pass before LLM/heavy processing
  - Runs inline, blocks workflow if failed
  - Examples: input validation, suppression, consent, rate limits

Layer 2: ASYNCHRONOUS BACKGROUND (~200-500ms)
  - Runs in parallel with the workflow
  - Results checked before final delivery
  - Examples: compliance audit, value validation, fairness monitoring

Layer 3: TRIGGERED ESCALATION (human-in-loop)
  - Activated for exceptional cases
  - Human review for high-risk decisions
  - Examples: high-value offers, anomalies, regulatory flags

Architecture Benefits:
- Fail fast on obvious violations (Layer 1 blocks immediately)
- Don't block on slow checks (Layer 2 runs async)
- Human oversight for edge cases (Layer 3 escalates)
- Latency optimized: ~60ms pre-flight vs ~500ms if all inline
"""

from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Callable, Tuple
from enum import Enum
import asyncio
import time
import re
from datetime import datetime
import threading
import queue


# =============================================================================
# GUARDRAIL RESULT TYPES
# =============================================================================

class GuardrailVerdict(Enum):
    """Outcome of a guardrail check"""
    PASS = "pass"
    FAIL = "fail"
    WARN = "warn"  # Passed but flagged for review
    PENDING = "pending"  # Async check still running
    ESCALATE = "escalate"  # Needs human review


@dataclass
class GuardrailResult:
    """Result from a single guardrail check"""
    name: str
    verdict: GuardrailVerdict
    message: str
    latency_ms: float
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class LayerResult:
    """Aggregated result from a guardrail layer"""
    layer: str
    passed: bool
    results: List[GuardrailResult] = field(default_factory=list)
    total_latency_ms: float = 0.0
    escalation_required: bool = False
    escalation_reasons: List[str] = field(default_factory=list)


# =============================================================================
# LAYER 1: SYNCHRONOUS PRE-FLIGHT GUARDRAILS (~40-70ms)
# =============================================================================

class SyncGuardrails:
    """
    Fast, synchronous checks that run before any LLM processing.

    These are "pre-flight" checks - if they fail, we abort immediately.
    Target latency: 40-70ms total for all checks.

    Checks:
    1. Input validation (PNR format, required fields)
    2. Customer suppression (is_suppressed flag)
    3. Marketing consent (at least one channel)
    4. Rate limiting (daily offer quota)
    5. Time-to-departure (>6 hours cutoff)
    6. Budget check (has allocation remaining)
    """

    # Configuration
    MIN_HOURS_TO_DEPARTURE = 6
    MAX_DAILY_OFFERS_PER_CUSTOMER = 3
    PNR_PATTERN = re.compile(r'^[A-Z0-9]{6}$')

    def __init__(self):
        self.name = "Sync Pre-flight Guardrails"
        # In production, this would be Redis/cache
        self._rate_limit_cache: Dict[str, int] = {}
        self._budget_remaining: Dict[str, float] = {
            "elite_business": 10000.0,
            "frequent_business": 5000.0,
            "mid_value_business": 3000.0,
            "high_value_leisure": 2000.0,
            "mid_value_leisure": 1500.0,
            "new_customer": 500.0,
            "general": 1000.0,
        }

    def check_all(self, state: Dict[str, Any]) -> LayerResult:
        """
        Run all synchronous guardrails.
        Returns immediately - these checks are fast (~10ms each).
        """
        start_time = time.time()
        results = []

        # Run each check
        results.append(self._check_input_validation(state))
        results.append(self._check_suppression(state))
        results.append(self._check_consent(state))
        results.append(self._check_rate_limit(state))
        results.append(self._check_time_to_departure(state))
        results.append(self._check_budget(state))

        total_latency = (time.time() - start_time) * 1000

        # Aggregate results
        # Only FAIL verdict blocks pre-flight; WARN and ESCALATE are flagged but don't block
        passed = all(r.verdict != GuardrailVerdict.FAIL for r in results)
        escalate = any(r.verdict == GuardrailVerdict.ESCALATE for r in results)
        escalation_reasons = [
            r.message for r in results
            if r.verdict == GuardrailVerdict.ESCALATE
        ]

        return LayerResult(
            layer="sync_preflight",
            passed=passed,
            results=results,
            total_latency_ms=total_latency,
            escalation_required=escalate,
            escalation_reasons=escalation_reasons
        )

    def _check_input_validation(self, state: Dict[str, Any]) -> GuardrailResult:
        """Validate input data format"""
        start = time.time()
        pnr = state.get("pnr_locator", "") or state.get("pnr", "")

        if not pnr:
            return GuardrailResult(
                name="input_validation",
                verdict=GuardrailVerdict.FAIL,
                message="Missing PNR",
                latency_ms=(time.time() - start) * 1000
            )

        if not self.PNR_PATTERN.match(pnr):
            return GuardrailResult(
                name="input_validation",
                verdict=GuardrailVerdict.FAIL,
                message=f"Invalid PNR format: {pnr}",
                latency_ms=(time.time() - start) * 1000
            )

        # Check required state fields
        required = ["customer_data", "flight_data", "reservation_data"]
        missing = [f for f in required if not state.get(f)]

        if missing:
            return GuardrailResult(
                name="input_validation",
                verdict=GuardrailVerdict.FAIL,
                message=f"Missing required data: {missing}",
                latency_ms=(time.time() - start) * 1000
            )

        return GuardrailResult(
            name="input_validation",
            verdict=GuardrailVerdict.PASS,
            message="Input validation passed",
            latency_ms=(time.time() - start) * 1000
        )

    def _check_suppression(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check if customer is suppressed (do not contact)"""
        start = time.time()
        customer = state.get("customer_data", {})
        suppression = customer.get("suppression", {})

        if suppression.get("is_suppressed", False):
            reason = suppression.get("complaint_reason", "Unknown reason")
            return GuardrailResult(
                name="suppression_check",
                verdict=GuardrailVerdict.FAIL,
                message=f"Customer suppressed: {reason}",
                latency_ms=(time.time() - start) * 1000,
                details={"suppression_reason": reason}
            )

        return GuardrailResult(
            name="suppression_check",
            verdict=GuardrailVerdict.PASS,
            message="Customer not suppressed",
            latency_ms=(time.time() - start) * 1000
        )

    def _check_consent(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check marketing consent for at least one channel"""
        start = time.time()
        customer = state.get("customer_data", {})
        consent = customer.get("marketing_consent", {})

        has_any_consent = (
            consent.get("push", False) or
            consent.get("email", False) or
            consent.get("sms", False)
        )

        if not has_any_consent:
            return GuardrailResult(
                name="consent_check",
                verdict=GuardrailVerdict.FAIL,
                message="No marketing consent for any channel",
                latency_ms=(time.time() - start) * 1000
            )

        return GuardrailResult(
            name="consent_check",
            verdict=GuardrailVerdict.PASS,
            message=f"Consent available: push={consent.get('push')}, email={consent.get('email')}",
            latency_ms=(time.time() - start) * 1000,
            details={"consent": consent}
        )

    def _check_rate_limit(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check daily offer quota for customer"""
        start = time.time()
        customer = state.get("customer_data", {})
        customer_id = customer.get("aadvantage_number", "unknown")

        # In production: Redis INCR with TTL
        today = datetime.now().strftime("%Y-%m-%d")
        cache_key = f"{customer_id}:{today}"

        current_count = self._rate_limit_cache.get(cache_key, 0)

        if current_count >= self.MAX_DAILY_OFFERS_PER_CUSTOMER:
            return GuardrailResult(
                name="rate_limit",
                verdict=GuardrailVerdict.FAIL,
                message=f"Daily offer limit reached ({current_count}/{self.MAX_DAILY_OFFERS_PER_CUSTOMER})",
                latency_ms=(time.time() - start) * 1000,
                details={"offers_today": current_count}
            )

        return GuardrailResult(
            name="rate_limit",
            verdict=GuardrailVerdict.PASS,
            message=f"Rate limit OK ({current_count}/{self.MAX_DAILY_OFFERS_PER_CUSTOMER})",
            latency_ms=(time.time() - start) * 1000
        )

    def _check_time_to_departure(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check if enough time before departure"""
        start = time.time()
        reservation = state.get("reservation_data", {})
        hours_to_departure = reservation.get("hours_to_departure", 0)

        if hours_to_departure < self.MIN_HOURS_TO_DEPARTURE:
            return GuardrailResult(
                name="time_to_departure",
                verdict=GuardrailVerdict.FAIL,
                message=f"Too close to departure: {hours_to_departure}h (min: {self.MIN_HOURS_TO_DEPARTURE}h)",
                latency_ms=(time.time() - start) * 1000,
                details={"hours_to_departure": hours_to_departure}
            )

        return GuardrailResult(
            name="time_to_departure",
            verdict=GuardrailVerdict.PASS,
            message=f"Time to departure OK: {hours_to_departure}h",
            latency_ms=(time.time() - start) * 1000
        )

    def _check_budget(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check if budget remains for this customer segment"""
        start = time.time()
        segment = state.get("customer_segment", "general")

        remaining = self._budget_remaining.get(segment, 0)

        if remaining <= 0:
            return GuardrailResult(
                name="budget_check",
                verdict=GuardrailVerdict.WARN,
                message=f"Budget exhausted for segment: {segment}",
                latency_ms=(time.time() - start) * 1000,
                details={"segment": segment, "remaining": remaining}
            )

        return GuardrailResult(
            name="budget_check",
            verdict=GuardrailVerdict.PASS,
            message=f"Budget available: ${remaining:.2f} for {segment}",
            latency_ms=(time.time() - start) * 1000
        )

    def increment_rate_limit(self, customer_id: str):
        """Call this after successfully sending an offer"""
        today = datetime.now().strftime("%Y-%m-%d")
        cache_key = f"{customer_id}:{today}"
        self._rate_limit_cache[cache_key] = self._rate_limit_cache.get(cache_key, 0) + 1

    def deduct_budget(self, segment: str, amount: float):
        """Deduct from segment budget after offer sent"""
        if segment in self._budget_remaining:
            self._budget_remaining[segment] -= amount


# =============================================================================
# LAYER 2: ASYNCHRONOUS BACKGROUND GUARDRAILS (~200-500ms)
# =============================================================================

class AsyncGuardrails:
    """
    Background checks that run in parallel with the workflow.

    These are NOT blocking - workflow continues while they run.
    Results are checked before final delivery.
    Target latency: 200-500ms (runs in parallel, so doesn't add to total).

    Checks:
    1. Compliance audit trail (log decision factors)
    2. Offer value validation (verify EV/discount calculations)
    3. Fairness monitoring (log for bias analysis)
    4. Historical frequency check (avoid over-messaging)
    5. PII handling verification
    """

    def __init__(self):
        self.name = "Async Background Guardrails"
        self._audit_queue: queue.Queue = queue.Queue()
        self._fairness_log: List[Dict] = []

    def start_background_checks(
        self,
        state: Dict[str, Any]
    ) -> "AsyncGuardrailTask":
        """
        Start background checks and return a task handle.

        Usage:
            task = async_guardrails.start_background_checks(state)
            # ... do main processing ...
            result = task.wait_for_completion()  # Check before delivery
        """
        task = AsyncGuardrailTask(self, state)
        task.start()
        return task

    def check_compliance_audit(self, state: Dict[str, Any]) -> GuardrailResult:
        """
        Log all decision factors for compliance audit trail.
        This doesn't block but ensures we have records.
        """
        start = time.time()

        audit_record = {
            "timestamp": datetime.now().isoformat(),
            "pnr": state.get("pnr_locator") or state.get("pnr"),
            "customer_id": state.get("customer_data", {}).get("aadvantage_number"),
            "customer_segment": state.get("customer_segment"),
            "should_send_offer": state.get("should_send_offer"),
            "selected_offer": state.get("selected_offer"),
            "offer_price": state.get("offer_price"),
            "expected_value": state.get("expected_value"),
            "discount_applied": state.get("discount_applied"),
            "suppression_reason": state.get("suppression_reason"),
            "reasoning_trace": state.get("reasoning_trace", []),
        }

        # In production: send to audit log service (Kafka, CloudWatch, etc.)
        self._audit_queue.put(audit_record)

        return GuardrailResult(
            name="compliance_audit",
            verdict=GuardrailVerdict.PASS,
            message="Audit trail logged",
            latency_ms=(time.time() - start) * 1000,
            details={"record_id": audit_record["timestamp"]}
        )

    def check_offer_value_validation(self, state: Dict[str, Any]) -> GuardrailResult:
        """
        Verify offer calculations are within acceptable bounds.
        Double-check EV, discount limits, pricing.
        """
        start = time.time()

        if not state.get("should_send_offer"):
            return GuardrailResult(
                name="offer_value_validation",
                verdict=GuardrailVerdict.PASS,
                message="No offer to validate",
                latency_ms=(time.time() - start) * 1000
            )

        # Check discount limits
        discount = state.get("discount_applied", 0)
        offer_type = state.get("selected_offer", "")

        max_discounts = {
            "IU_BUSINESS": 0.20,
            "IU_FIRST": 0.15,
            "IU_PREMIUM_ECONOMY": 0.15,
            "MCE": 0.25,
        }

        max_allowed = max_discounts.get(offer_type, 0.25)

        if discount > max_allowed:
            return GuardrailResult(
                name="offer_value_validation",
                verdict=GuardrailVerdict.FAIL,
                message=f"Discount {discount:.0%} exceeds max {max_allowed:.0%} for {offer_type}",
                latency_ms=(time.time() - start) * 1000,
                details={"discount": discount, "max_allowed": max_allowed}
            )

        # Check EV is positive
        ev = state.get("expected_value", 0)
        if ev <= 0:
            return GuardrailResult(
                name="offer_value_validation",
                verdict=GuardrailVerdict.WARN,
                message=f"Expected value is non-positive: ${ev:.2f}",
                latency_ms=(time.time() - start) * 1000,
                details={"expected_value": ev}
            )

        # Check price is reasonable
        price = state.get("offer_price", 0)
        if price < 10 or price > 5000:
            return GuardrailResult(
                name="offer_value_validation",
                verdict=GuardrailVerdict.ESCALATE,
                message=f"Unusual price: ${price} (expected $10-$5000)",
                latency_ms=(time.time() - start) * 1000,
                details={"offer_price": price}
            )

        return GuardrailResult(
            name="offer_value_validation",
            verdict=GuardrailVerdict.PASS,
            message=f"Offer validated: {offer_type} @ ${price:.0f} ({discount:.0%} off)",
            latency_ms=(time.time() - start) * 1000
        )

    def check_fairness_monitoring(self, state: Dict[str, Any]) -> GuardrailResult:
        """
        Log data for fairness/bias analysis.
        Tracks offer distribution across segments.
        """
        start = time.time()

        fairness_record = {
            "timestamp": datetime.now().isoformat(),
            "customer_segment": state.get("customer_segment"),
            "loyalty_tier": state.get("customer_data", {}).get("loyalty_tier"),
            "annual_revenue": state.get("customer_data", {}).get("flight_revenue_amt_history", 0),
            "should_send_offer": state.get("should_send_offer"),
            "selected_offer": state.get("selected_offer"),
            "offer_price": state.get("offer_price"),
            "discount_applied": state.get("discount_applied"),
        }

        self._fairness_log.append(fairness_record)

        # In production: periodic analysis job would check for bias
        # e.g., are Gold members getting worse offers than Platinum?

        return GuardrailResult(
            name="fairness_monitoring",
            verdict=GuardrailVerdict.PASS,
            message="Fairness data logged",
            latency_ms=(time.time() - start) * 1000
        )

    def check_historical_frequency(self, state: Dict[str, Any]) -> GuardrailResult:
        """
        Check if customer has been over-contacted recently.
        Prevents offer fatigue.
        """
        start = time.time()
        customer_id = state.get("customer_data", {}).get("aadvantage_number")

        # In production: query historical offer database
        # For demo: simulate check
        recent_offers = 2  # Simulated
        max_weekly = 5

        if recent_offers >= max_weekly:
            return GuardrailResult(
                name="historical_frequency",
                verdict=GuardrailVerdict.WARN,
                message=f"Customer received {recent_offers} offers this week (max: {max_weekly})",
                latency_ms=(time.time() - start) * 1000,
                details={"recent_offers": recent_offers}
            )

        return GuardrailResult(
            name="historical_frequency",
            verdict=GuardrailVerdict.PASS,
            message=f"Frequency OK: {recent_offers}/{max_weekly} this week",
            latency_ms=(time.time() - start) * 1000
        )

    def check_pii_handling(self, state: Dict[str, Any]) -> GuardrailResult:
        """
        Verify no PII in message templates or logs.
        """
        start = time.time()

        message_body = state.get("message_body", "")

        # Check for potential PII patterns
        pii_patterns = [
            (r'\b\d{3}-\d{2}-\d{4}\b', "SSN"),
            (r'\b\d{16}\b', "Credit card"),
            (r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', "Email"),
        ]

        found_pii = []
        for pattern, pii_type in pii_patterns:
            if re.search(pattern, message_body):
                found_pii.append(pii_type)

        if found_pii:
            return GuardrailResult(
                name="pii_handling",
                verdict=GuardrailVerdict.FAIL,
                message=f"Potential PII detected in message: {found_pii}",
                latency_ms=(time.time() - start) * 1000,
                details={"pii_types": found_pii}
            )

        return GuardrailResult(
            name="pii_handling",
            verdict=GuardrailVerdict.PASS,
            message="No PII detected in message",
            latency_ms=(time.time() - start) * 1000
        )


class AsyncGuardrailTask:
    """
    Background task handle for async guardrail checks.
    Runs checks in a separate thread, results checked before delivery.
    """

    def __init__(self, guardrails: AsyncGuardrails, state: Dict[str, Any]):
        self.guardrails = guardrails
        self.state = state
        self._thread: Optional[threading.Thread] = None
        self._result: Optional[LayerResult] = None
        self._completed = threading.Event()

    def start(self):
        """Start background checks in a separate thread"""
        self._thread = threading.Thread(target=self._run_checks)
        self._thread.start()

    def _run_checks(self):
        """Run all async checks"""
        start_time = time.time()
        results = []

        results.append(self.guardrails.check_compliance_audit(self.state))
        results.append(self.guardrails.check_offer_value_validation(self.state))
        results.append(self.guardrails.check_fairness_monitoring(self.state))
        results.append(self.guardrails.check_historical_frequency(self.state))
        results.append(self.guardrails.check_pii_handling(self.state))

        total_latency = (time.time() - start_time) * 1000

        # Determine pass/fail
        failures = [r for r in results if r.verdict == GuardrailVerdict.FAIL]
        escalations = [r for r in results if r.verdict == GuardrailVerdict.ESCALATE]

        self._result = LayerResult(
            layer="async_background",
            passed=len(failures) == 0,
            results=results,
            total_latency_ms=total_latency,
            escalation_required=len(escalations) > 0,
            escalation_reasons=[r.message for r in escalations]
        )

        self._completed.set()

    def wait_for_completion(self, timeout_seconds: float = 1.0) -> LayerResult:
        """
        Wait for background checks to complete.
        Call this before final offer delivery.
        """
        completed = self._completed.wait(timeout=timeout_seconds)

        if not completed:
            # Timeout - return pending result
            return LayerResult(
                layer="async_background",
                passed=True,  # Don't block on timeout
                results=[GuardrailResult(
                    name="timeout",
                    verdict=GuardrailVerdict.WARN,
                    message="Async checks timed out",
                    latency_ms=timeout_seconds * 1000
                )],
                total_latency_ms=timeout_seconds * 1000
            )

        return self._result

    def is_complete(self) -> bool:
        """Check if background checks are done without blocking"""
        return self._completed.is_set()


# =============================================================================
# LAYER 3: TRIGGERED ESCALATION GUARDRAILS (Human-in-Loop)
# =============================================================================

class TriggeredGuardrails:
    """
    Human-in-loop escalation for exceptional cases.

    These don't run automatically - they're triggered by specific conditions
    detected in Layer 1 or Layer 2.

    Triggers:
    1. High-value offer (>$500)
    2. Anomaly detection (unusual patterns)
    3. Regulatory flags (sensitive routes/customers)
    4. Override requests
    5. Batch campaign approval
    """

    # Thresholds
    HIGH_VALUE_THRESHOLD = 500.0
    ANOMALY_DEVIATION_THRESHOLD = 3.0  # Standard deviations

    def __init__(self):
        self.name = "Triggered Escalation Guardrails"
        self._escalation_queue: List[Dict] = []
        self._approved_overrides: Dict[str, bool] = {}

    def check_triggers(self, state: Dict[str, Any]) -> LayerResult:
        """
        Check all escalation triggers.
        Returns whether human review is needed.
        """
        start_time = time.time()
        results = []
        escalation_reasons = []

        # Check high-value offers
        high_value_result = self._check_high_value_offer(state)
        results.append(high_value_result)
        if high_value_result.verdict == GuardrailVerdict.ESCALATE:
            escalation_reasons.append(high_value_result.message)

        # Check anomalies
        anomaly_result = self._check_anomaly(state)
        results.append(anomaly_result)
        if anomaly_result.verdict == GuardrailVerdict.ESCALATE:
            escalation_reasons.append(anomaly_result.message)

        # Check regulatory flags
        regulatory_result = self._check_regulatory_flags(state)
        results.append(regulatory_result)
        if regulatory_result.verdict == GuardrailVerdict.ESCALATE:
            escalation_reasons.append(regulatory_result.message)

        total_latency = (time.time() - start_time) * 1000

        return LayerResult(
            layer="triggered_escalation",
            passed=len(escalation_reasons) == 0,
            results=results,
            total_latency_ms=total_latency,
            escalation_required=len(escalation_reasons) > 0,
            escalation_reasons=escalation_reasons
        )

    def _check_high_value_offer(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check if offer exceeds high-value threshold"""
        start = time.time()
        offer_price = state.get("offer_price", 0)

        if offer_price > self.HIGH_VALUE_THRESHOLD:
            return GuardrailResult(
                name="high_value_offer",
                verdict=GuardrailVerdict.ESCALATE,
                message=f"High-value offer: ${offer_price:.0f} (threshold: ${self.HIGH_VALUE_THRESHOLD})",
                latency_ms=(time.time() - start) * 1000,
                details={"offer_price": offer_price, "threshold": self.HIGH_VALUE_THRESHOLD}
            )

        return GuardrailResult(
            name="high_value_offer",
            verdict=GuardrailVerdict.PASS,
            message=f"Offer value OK: ${offer_price:.0f}",
            latency_ms=(time.time() - start) * 1000
        )

    def _check_anomaly(self, state: Dict[str, Any]) -> GuardrailResult:
        """Detect unusual offer patterns"""
        start = time.time()

        # In production: compare to historical distributions
        # For demo: check for obvious anomalies

        discount = state.get("discount_applied", 0)
        ev = state.get("expected_value", 0)

        # Anomaly: Very high discount with low EV
        if discount > 0.15 and ev < 20:
            return GuardrailResult(
                name="anomaly_detection",
                verdict=GuardrailVerdict.ESCALATE,
                message=f"Anomaly: High discount ({discount:.0%}) with low EV (${ev:.2f})",
                latency_ms=(time.time() - start) * 1000,
                details={"discount": discount, "expected_value": ev}
            )

        return GuardrailResult(
            name="anomaly_detection",
            verdict=GuardrailVerdict.PASS,
            message="No anomalies detected",
            latency_ms=(time.time() - start) * 1000
        )

    def _check_regulatory_flags(self, state: Dict[str, Any]) -> GuardrailResult:
        """Check for regulatory/compliance flags"""
        start = time.time()

        flight = state.get("flight_data", {})
        origin = flight.get("schd_leg_dep_airprt_iata_cd", "")
        destination = flight.get("schd_leg_arvl_airprt_iata_cd", "")

        # Sensitive international routes (GDPR, etc.)
        gdpr_countries = ["LHR", "CDG", "FRA", "AMS", "MAD", "FCO"]

        is_gdpr_route = origin in gdpr_countries or destination in gdpr_countries

        if is_gdpr_route:
            return GuardrailResult(
                name="regulatory_flags",
                verdict=GuardrailVerdict.WARN,  # Flag but don't block
                message=f"GDPR-covered route: {origin} ‚Üí {destination}",
                latency_ms=(time.time() - start) * 1000,
                details={"origin": origin, "destination": destination, "gdpr": True}
            )

        return GuardrailResult(
            name="regulatory_flags",
            verdict=GuardrailVerdict.PASS,
            message="No regulatory flags",
            latency_ms=(time.time() - start) * 1000
        )

    def queue_for_review(
        self,
        state: Dict[str, Any],
        reasons: List[str]
    ) -> str:
        """
        Queue an offer for human review.
        Returns a ticket ID for tracking.
        """
        pnr = state.get('pnr_locator') or state.get('pnr', 'UNKNOWN')
        ticket_id = f"ESC-{datetime.now().strftime('%Y%m%d%H%M%S')}-{pnr}"

        escalation_record = {
            "ticket_id": ticket_id,
            "created_at": datetime.now().isoformat(),
            "pnr": pnr,
            "customer_id": state.get("customer_data", {}).get("aadvantage_number"),
            "offer_type": state.get("selected_offer"),
            "offer_price": state.get("offer_price"),
            "escalation_reasons": reasons,
            "status": "pending_review",
            "state_snapshot": state,
        }

        self._escalation_queue.append(escalation_record)

        # In production: send to ticketing system (ServiceNow, Jira, etc.)

        return ticket_id

    def approve_override(self, ticket_id: str, approved: bool, reviewer: str):
        """Process human review decision"""
        self._approved_overrides[ticket_id] = approved

        # In production: update ticket, notify systems

        return {
            "ticket_id": ticket_id,
            "approved": approved,
            "reviewer": reviewer,
            "processed_at": datetime.now().isoformat()
        }

    def is_approved(self, ticket_id: str) -> Optional[bool]:
        """Check if a ticket has been approved"""
        return self._approved_overrides.get(ticket_id)


# =============================================================================
# GUARDRAIL COORDINATOR
# =============================================================================

class GuardrailCoordinator:
    """
    Orchestrates all three guardrail layers.

    Flow:
    1. Run sync pre-flight checks (blocking, ~60ms)
    2. Start async background checks (non-blocking)
    3. Execute main workflow
    4. Wait for async results before delivery
    5. Check triggered escalations
    6. Either deliver or queue for review
    """

    def __init__(self):
        self.sync = SyncGuardrails()
        self.async_guardrails = AsyncGuardrails()
        self.triggered = TriggeredGuardrails()

    def pre_flight_check(self, state: Dict[str, Any]) -> Tuple[bool, LayerResult]:
        """
        Run Layer 1 sync checks. Call this BEFORE main processing.
        Returns (should_continue, result)
        """
        result = self.sync.check_all(state)
        return (result.passed, result)

    def start_background_checks(self, state: Dict[str, Any]) -> AsyncGuardrailTask:
        """
        Start Layer 2 async checks. Call this DURING main processing.
        Returns task handle to check later.
        """
        return self.async_guardrails.start_background_checks(state)

    def pre_delivery_check(
        self,
        state: Dict[str, Any],
        async_task: AsyncGuardrailTask
    ) -> Tuple[bool, Optional[str], Dict[str, LayerResult]]:
        """
        Final checks before delivery. Call this AFTER main processing.

        Returns:
        - can_deliver: bool - whether to send the offer
        - escalation_ticket: Optional[str] - ticket ID if escalated
        - all_results: Dict[str, LayerResult] - results from all layers
        """
        all_results = {}

        # Wait for async results
        async_result = async_task.wait_for_completion()
        all_results["async_background"] = async_result

        # Check triggered escalations
        triggered_result = self.triggered.check_triggers(state)
        all_results["triggered_escalation"] = triggered_result

        # Aggregate escalation needs
        needs_escalation = (
            async_result.escalation_required or
            triggered_result.escalation_required
        )

        all_reasons = (
            async_result.escalation_reasons +
            triggered_result.escalation_reasons
        )

        escalation_ticket = None
        if needs_escalation:
            escalation_ticket = self.triggered.queue_for_review(state, all_reasons)

        # Can deliver if async passed and no hard escalation needed
        can_deliver = async_result.passed and not needs_escalation

        return (can_deliver, escalation_ticket, all_results)

    def run_all_checks(
        self,
        state: Dict[str, Any]
    ) -> Tuple[bool, Optional[str], Dict[str, LayerResult]]:
        """
        Convenience method to run all checks sequentially.
        For testing or simple use cases.

        In production, use the individual methods for better latency.
        """
        all_results = {}

        # Layer 1: Sync pre-flight
        preflight_passed, preflight_result = self.pre_flight_check(state)
        all_results["sync_preflight"] = preflight_result

        if not preflight_passed:
            return (False, None, all_results)

        # Layer 2: Start async (in this simple case, we wait immediately)
        async_task = self.start_background_checks(state)

        # Layer 3: Pre-delivery checks
        can_deliver, ticket, delivery_results = self.pre_delivery_check(
            state, async_task
        )
        all_results.update(delivery_results)

        return (can_deliver, ticket, all_results)


# =============================================================================
# CONVENIENCE EXPORTS
# =============================================================================

def create_guardrail_coordinator() -> GuardrailCoordinator:
    """Factory function to create a guardrail coordinator"""
    return GuardrailCoordinator()


================================================================================
FILE: infrastructure/human_in_loop.py
================================================================================
"""
Human-in-the-Loop (HITL) Implementation for Agentic AI

This module implements production-grade human-in-the-loop patterns:
1. Deferred Execution - Halt workflow at risky steps, persist state
2. State Serialization - Full agent state saved for later resume
3. Approval Management - Pending approvals with approve/deny actions
4. Notification Integration - Slack/email for approval requests
5. Stateless Resume - Reconstruct and continue workflow days later

Key Patterns:
- Streaming Chat: SSE ‚Üí halt ‚Üí save state ‚Üí approval UI ‚Üí resume endpoint
- Async Workflow: Background job ‚Üí notification ‚Üí approve/deny ‚Üí resume

References:
- https://www.youtube.com/watch?v=7GOxUgVTz3s
"""

import json
import uuid
import hashlib
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict
from enum import Enum
from typing import Dict, Any, Optional, List, Callable, Tuple
import os
import requests

from .logging import get_logger

logger = get_logger(__name__)


# =============================================================================
# Data Models
# =============================================================================

class ApprovalStatus(str, Enum):
    """Status of a pending approval."""
    PENDING = "pending"
    APPROVED = "approved"
    DENIED = "denied"
    EXPIRED = "expired"
    AUTO_APPROVED = "auto_approved"


class EscalationReason(str, Enum):
    """Why this workflow requires human approval."""
    HIGH_VALUE_OFFER = "high_value_offer"
    VIP_CUSTOMER = "vip_customer"
    ANOMALY_DETECTED = "anomaly_detected"
    REGULATORY_FLAG = "regulatory_flag"
    MANUAL_OVERRIDE = "manual_override"
    FRAUD_RISK = "fraud_risk"
    FIRST_TIME_SCENARIO = "first_time_scenario"


@dataclass
class ApprovalRequest:
    """
    A request for human approval.

    Contains all information needed to:
    1. Display approval UI to human
    2. Resume workflow after approval
    """
    # Identity
    id: str = field(default_factory=lambda: str(uuid.uuid4()))

    # Context
    pnr: str = ""
    customer_name: str = ""
    customer_tier: str = ""

    # What needs approval
    action_type: str = ""  # e.g., "offer_delivery", "high_value_upgrade"
    action_description: str = ""
    reason: EscalationReason = EscalationReason.HIGH_VALUE_OFFER
    reason_details: str = ""

    # The proposed action
    proposed_offer: Dict[str, Any] = field(default_factory=dict)
    offer_value: float = 0.0

    # Risk assessment
    risk_score: float = 0.0
    risk_factors: List[str] = field(default_factory=list)

    # Workflow state (serialized for resume)
    workflow_state: Dict[str, Any] = field(default_factory=dict)
    checkpoint_name: str = ""  # e.g., "pre_delivery", "post_orchestration"

    # Status tracking
    status: ApprovalStatus = ApprovalStatus.PENDING
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    expires_at: str = field(default_factory=lambda: (datetime.now() + timedelta(hours=24)).isoformat())

    # Resolution
    resolved_at: Optional[str] = None
    resolved_by: Optional[str] = None
    resolution_notes: Optional[str] = None

    # Notification tracking
    notifications_sent: List[Dict[str, Any]] = field(default_factory=list)

    def is_expired(self) -> bool:
        """Check if this approval request has expired."""
        return datetime.now() > datetime.fromisoformat(self.expires_at)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        data = asdict(self)
        data["status"] = self.status.value
        data["reason"] = self.reason.value
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "ApprovalRequest":
        """Create from dictionary."""
        data = data.copy()
        data["status"] = ApprovalStatus(data.get("status", "pending"))
        data["reason"] = EscalationReason(data.get("reason", "high_value_offer"))
        return cls(**data)


@dataclass
class ApprovalDecision:
    """The human's decision on an approval request."""
    request_id: str
    approved: bool
    decided_by: str  # User ID or email
    decided_at: str = field(default_factory=lambda: datetime.now().isoformat())
    notes: Optional[str] = None
    modified_offer: Optional[Dict[str, Any]] = None  # Human can modify the offer


# =============================================================================
# State Persistence
# =============================================================================

class StateStore:
    """
    Persists workflow state for deferred execution.

    In production, this would use Redis or a database.
    For demo, uses in-memory storage.
    """

    def __init__(self, redis_client=None):
        self._redis = redis_client
        self._memory_store: Dict[str, Dict[str, Any]] = {}
        self._ttl_seconds = 86400  # 24 hours

    def save_state(self, key: str, state: Dict[str, Any]) -> bool:
        """Save workflow state."""
        try:
            serialized = json.dumps(state, default=str)

            if self._redis:
                self._redis.setex(f"hitl:state:{key}", self._ttl_seconds, serialized)
            else:
                self._memory_store[key] = {
                    "data": state,
                    "saved_at": datetime.now().isoformat(),
                    "expires_at": (datetime.now() + timedelta(seconds=self._ttl_seconds)).isoformat()
                }

            logger.info("hitl_state_saved", key=key, state_size=len(serialized))
            return True

        except Exception as e:
            logger.error("hitl_state_save_failed", key=key, error=str(e))
            return False

    def load_state(self, key: str) -> Optional[Dict[str, Any]]:
        """Load workflow state."""
        try:
            if self._redis:
                serialized = self._redis.get(f"hitl:state:{key}")
                if serialized:
                    return json.loads(serialized)
            else:
                if key in self._memory_store:
                    entry = self._memory_store[key]
                    # Check expiration
                    if datetime.now() < datetime.fromisoformat(entry["expires_at"]):
                        return entry["data"]
                    else:
                        del self._memory_store[key]

            return None

        except Exception as e:
            logger.error("hitl_state_load_failed", key=key, error=str(e))
            return None

    def delete_state(self, key: str) -> bool:
        """Delete workflow state after completion."""
        try:
            if self._redis:
                self._redis.delete(f"hitl:state:{key}")
            else:
                self._memory_store.pop(key, None)
            return True
        except Exception as e:
            logger.error("hitl_state_delete_failed", key=key, error=str(e))
            return False


class ApprovalStore:
    """
    Manages pending approval requests.

    In production, this would use a database for durability.
    """

    def __init__(self, redis_client=None):
        self._redis = redis_client
        self._memory_store: Dict[str, ApprovalRequest] = {}

    def save(self, request: ApprovalRequest) -> bool:
        """Save an approval request."""
        try:
            if self._redis:
                self._redis.hset(
                    "hitl:approvals",
                    request.id,
                    json.dumps(request.to_dict(), default=str)
                )
            else:
                self._memory_store[request.id] = request

            logger.info(
                "hitl_approval_saved",
                request_id=request.id,
                pnr=request.pnr,
                reason=request.reason.value
            )
            return True

        except Exception as e:
            logger.error("hitl_approval_save_failed", request_id=request.id, error=str(e))
            return False

    def get(self, request_id: str) -> Optional[ApprovalRequest]:
        """Get an approval request by ID."""
        try:
            if self._redis:
                data = self._redis.hget("hitl:approvals", request_id)
                if data:
                    return ApprovalRequest.from_dict(json.loads(data))
            else:
                return self._memory_store.get(request_id)

            return None

        except Exception as e:
            logger.error("hitl_approval_get_failed", request_id=request_id, error=str(e))
            return None

    def get_pending(self) -> List[ApprovalRequest]:
        """Get all pending approval requests."""
        pending = []

        try:
            if self._redis:
                all_approvals = self._redis.hgetall("hitl:approvals")
                for data in all_approvals.values():
                    request = ApprovalRequest.from_dict(json.loads(data))
                    if request.status == ApprovalStatus.PENDING and not request.is_expired():
                        pending.append(request)
            else:
                for request in self._memory_store.values():
                    if request.status == ApprovalStatus.PENDING and not request.is_expired():
                        pending.append(request)

            # Sort by created_at (oldest first)
            pending.sort(key=lambda r: r.created_at)

        except Exception as e:
            logger.error("hitl_get_pending_failed", error=str(e))

        return pending

    def get_by_pnr(self, pnr: str) -> List[ApprovalRequest]:
        """Get all approval requests for a PNR."""
        results = []

        try:
            if self._redis:
                all_approvals = self._redis.hgetall("hitl:approvals")
                for data in all_approvals.values():
                    request = ApprovalRequest.from_dict(json.loads(data))
                    if request.pnr == pnr:
                        results.append(request)
            else:
                for request in self._memory_store.values():
                    if request.pnr == pnr:
                        results.append(request)

        except Exception as e:
            logger.error("hitl_get_by_pnr_failed", pnr=pnr, error=str(e))

        return results

    def update(self, request: ApprovalRequest) -> bool:
        """Update an approval request."""
        return self.save(request)


# =============================================================================
# Notification Service
# =============================================================================

class NotificationService:
    """
    Sends notifications for approval requests.

    Supports:
    - Slack webhooks
    - Email (placeholder)
    - Custom webhooks
    """

    def __init__(
        self,
        slack_webhook: Optional[str] = None,
        email_config: Optional[Dict[str, Any]] = None,
        approval_ui_base_url: Optional[str] = None,
    ):
        self.slack_webhook = slack_webhook or os.environ.get("HITL_SLACK_WEBHOOK")
        self.email_config = email_config
        self.approval_ui_base_url = approval_ui_base_url or os.environ.get(
            "HITL_APPROVAL_UI_URL", "http://localhost:5173/approvals"
        )

    def notify(self, request: ApprovalRequest) -> Dict[str, Any]:
        """Send notifications for an approval request."""
        results = {
            "slack": None,
            "email": None,
        }

        if self.slack_webhook:
            results["slack"] = self._send_slack(request)

        if self.email_config:
            results["email"] = self._send_email(request)

        return results

    def _send_slack(self, request: ApprovalRequest) -> Dict[str, Any]:
        """Send Slack notification with approval buttons."""
        try:
            # Build approval URL
            approve_url = f"{self.approval_ui_base_url}/{request.id}"

            # Emoji based on reason
            emoji_map = {
                EscalationReason.HIGH_VALUE_OFFER: ":moneybag:",
                EscalationReason.VIP_CUSTOMER: ":crown:",
                EscalationReason.ANOMALY_DETECTED: ":warning:",
                EscalationReason.REGULATORY_FLAG: ":scales:",
                EscalationReason.FRAUD_RISK: ":rotating_light:",
            }
            emoji = emoji_map.get(request.reason, ":question:")

            # Build message
            message = {
                "blocks": [
                    {
                        "type": "header",
                        "text": {
                            "type": "plain_text",
                            "text": f"{emoji} Approval Required: {request.action_type}",
                        }
                    },
                    {
                        "type": "section",
                        "fields": [
                            {"type": "mrkdwn", "text": f"*PNR:*\n{request.pnr}"},
                            {"type": "mrkdwn", "text": f"*Customer:*\n{request.customer_name}"},
                            {"type": "mrkdwn", "text": f"*Tier:*\n{request.customer_tier}"},
                            {"type": "mrkdwn", "text": f"*Offer Value:*\n${request.offer_value:.2f}"},
                        ]
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*Reason:* {request.reason.value}\n{request.reason_details}"
                        }
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*Proposed Offer:*\n```{json.dumps(request.proposed_offer, indent=2)}```"
                        }
                    },
                    {
                        "type": "actions",
                        "elements": [
                            {
                                "type": "button",
                                "text": {"type": "plain_text", "text": "Approve"},
                                "style": "primary",
                                "url": f"{approve_url}?action=approve"
                            },
                            {
                                "type": "button",
                                "text": {"type": "plain_text", "text": "Deny"},
                                "style": "danger",
                                "url": f"{approve_url}?action=deny"
                            },
                            {
                                "type": "button",
                                "text": {"type": "plain_text", "text": "View Details"},
                                "url": approve_url
                            }
                        ]
                    },
                    {
                        "type": "context",
                        "elements": [
                            {
                                "type": "mrkdwn",
                                "text": f"Request ID: `{request.id}` | Expires: {request.expires_at}"
                            }
                        ]
                    }
                ]
            }

            response = requests.post(
                self.slack_webhook,
                json=message,
                timeout=10
            )

            success = response.status_code == 200

            logger.info(
                "hitl_slack_notification",
                request_id=request.id,
                success=success,
                status_code=response.status_code
            )

            return {"sent": success, "status_code": response.status_code}

        except Exception as e:
            logger.error("hitl_slack_notification_failed", request_id=request.id, error=str(e))
            return {"sent": False, "error": str(e)}

    def _send_email(self, request: ApprovalRequest) -> Dict[str, Any]:
        """Send email notification (placeholder)."""
        # In production, integrate with SendGrid, SES, etc.
        logger.info("hitl_email_notification_placeholder", request_id=request.id)
        return {"sent": False, "reason": "not_implemented"}


# =============================================================================
# Escalation Rules
# =============================================================================

class EscalationRules:
    """
    Defines rules for when to escalate to human approval.

    Decision logic is in backend code, NOT in LLM prompts.
    """

    def __init__(
        self,
        high_value_threshold: float = 500.0,
        vip_tiers: List[str] = None,
        anomaly_threshold: float = 0.8,
        regulatory_routes: List[str] = None,
    ):
        self.high_value_threshold = high_value_threshold
        self.vip_tiers = vip_tiers or ["ConciergeKey", "Executive Platinum"]
        self.anomaly_threshold = anomaly_threshold
        self.regulatory_routes = regulatory_routes or ["EU", "UK", "GDPR"]

    def check(
        self,
        offer_value: float,
        customer_tier: str,
        destination: str = "",
        anomaly_score: float = 0.0,
        is_first_time: bool = False,
        manual_flag: bool = False,
    ) -> Tuple[bool, Optional[EscalationReason], str]:
        """
        Check if this action requires human approval.

        Returns: (needs_approval, reason, details)
        """
        # Manual override always escalates
        if manual_flag:
            return True, EscalationReason.MANUAL_OVERRIDE, "Manually flagged for review"

        # High-value offers
        if offer_value > self.high_value_threshold:
            return (
                True,
                EscalationReason.HIGH_VALUE_OFFER,
                f"Offer value ${offer_value:.2f} exceeds ${self.high_value_threshold} threshold"
            )

        # VIP customers
        if customer_tier in self.vip_tiers:
            return (
                True,
                EscalationReason.VIP_CUSTOMER,
                f"Customer is {customer_tier} - requires approval for any offer"
            )

        # Anomaly detection
        if anomaly_score > self.anomaly_threshold:
            return (
                True,
                EscalationReason.ANOMALY_DETECTED,
                f"Anomaly score {anomaly_score:.2f} exceeds {self.anomaly_threshold} threshold"
            )

        # Regulatory routes
        for route in self.regulatory_routes:
            if route.lower() in destination.lower():
                return (
                    True,
                    EscalationReason.REGULATORY_FLAG,
                    f"Destination '{destination}' matches regulatory route '{route}'"
                )

        # First-time scenarios (optional)
        if is_first_time:
            return (
                True,
                EscalationReason.FIRST_TIME_SCENARIO,
                "First time this scenario has been encountered"
            )

        # No escalation needed
        return False, None, ""


# =============================================================================
# Human-in-the-Loop Manager
# =============================================================================

class HumanInTheLoopManager:
    """
    Main interface for Human-in-the-Loop functionality.

    Usage:
        hitl = HumanInTheLoopManager()

        # Check if approval needed
        needs_approval, reason, details = hitl.check_escalation(...)

        if needs_approval:
            # Create approval request and halt
            request = hitl.create_approval_request(...)
            hitl.save_workflow_state(request.id, current_state)
            hitl.notify(request)
            return {"status": "pending_approval", "request_id": request.id}

        # Later, when approved:
        decision = hitl.get_decision(request_id)
        if decision and decision.approved:
            state = hitl.load_workflow_state(request_id)
            # Resume workflow with state
    """

    def __init__(
        self,
        redis_client=None,
        slack_webhook: Optional[str] = None,
        approval_ui_url: Optional[str] = None,
        escalation_rules: Optional[EscalationRules] = None,
    ):
        self.state_store = StateStore(redis_client)
        self.approval_store = ApprovalStore(redis_client)
        self.notification_service = NotificationService(
            slack_webhook=slack_webhook,
            approval_ui_base_url=approval_ui_url,
        )
        self.escalation_rules = escalation_rules or EscalationRules()

        logger.info("hitl_manager_initialized")

    def check_escalation(
        self,
        offer_value: float,
        customer_tier: str,
        destination: str = "",
        anomaly_score: float = 0.0,
        is_first_time: bool = False,
        manual_flag: bool = False,
    ) -> Tuple[bool, Optional[EscalationReason], str]:
        """Check if this action requires human approval."""
        return self.escalation_rules.check(
            offer_value=offer_value,
            customer_tier=customer_tier,
            destination=destination,
            anomaly_score=anomaly_score,
            is_first_time=is_first_time,
            manual_flag=manual_flag,
        )

    def create_approval_request(
        self,
        pnr: str,
        customer_name: str,
        customer_tier: str,
        action_type: str,
        action_description: str,
        reason: EscalationReason,
        reason_details: str,
        proposed_offer: Dict[str, Any],
        offer_value: float,
        workflow_state: Dict[str, Any],
        checkpoint_name: str = "pre_delivery",
        risk_score: float = 0.0,
        risk_factors: List[str] = None,
        expires_in_hours: int = 24,
    ) -> ApprovalRequest:
        """Create a new approval request."""
        request = ApprovalRequest(
            pnr=pnr,
            customer_name=customer_name,
            customer_tier=customer_tier,
            action_type=action_type,
            action_description=action_description,
            reason=reason,
            reason_details=reason_details,
            proposed_offer=proposed_offer,
            offer_value=offer_value,
            workflow_state=workflow_state,
            checkpoint_name=checkpoint_name,
            risk_score=risk_score,
            risk_factors=risk_factors or [],
            expires_at=(datetime.now() + timedelta(hours=expires_in_hours)).isoformat(),
        )

        # Save request
        self.approval_store.save(request)

        # Save workflow state
        self.state_store.save_state(request.id, workflow_state)

        logger.info(
            "hitl_approval_request_created",
            request_id=request.id,
            pnr=pnr,
            reason=reason.value,
            offer_value=offer_value,
        )

        return request

    def notify(self, request: ApprovalRequest) -> Dict[str, Any]:
        """Send notifications for an approval request."""
        results = self.notification_service.notify(request)

        # Track notifications sent
        request.notifications_sent.append({
            "sent_at": datetime.now().isoformat(),
            "results": results,
        })
        self.approval_store.update(request)

        return results

    def approve(
        self,
        request_id: str,
        decided_by: str,
        notes: Optional[str] = None,
        modified_offer: Optional[Dict[str, Any]] = None,
    ) -> Optional[ApprovalRequest]:
        """Approve an approval request."""
        request = self.approval_store.get(request_id)

        if not request:
            logger.warning("hitl_approve_not_found", request_id=request_id)
            return None

        if request.status != ApprovalStatus.PENDING:
            logger.warning(
                "hitl_approve_invalid_status",
                request_id=request_id,
                current_status=request.status.value
            )
            return None

        if request.is_expired():
            request.status = ApprovalStatus.EXPIRED
            self.approval_store.update(request)
            logger.warning("hitl_approve_expired", request_id=request_id)
            return None

        # Update request
        request.status = ApprovalStatus.APPROVED
        request.resolved_at = datetime.now().isoformat()
        request.resolved_by = decided_by
        request.resolution_notes = notes

        if modified_offer:
            request.proposed_offer = modified_offer

        self.approval_store.update(request)

        logger.info(
            "hitl_request_approved",
            request_id=request_id,
            decided_by=decided_by,
            pnr=request.pnr,
        )

        return request

    def deny(
        self,
        request_id: str,
        decided_by: str,
        notes: Optional[str] = None,
    ) -> Optional[ApprovalRequest]:
        """Deny an approval request."""
        request = self.approval_store.get(request_id)

        if not request:
            logger.warning("hitl_deny_not_found", request_id=request_id)
            return None

        if request.status != ApprovalStatus.PENDING:
            logger.warning(
                "hitl_deny_invalid_status",
                request_id=request_id,
                current_status=request.status.value
            )
            return None

        # Update request
        request.status = ApprovalStatus.DENIED
        request.resolved_at = datetime.now().isoformat()
        request.resolved_by = decided_by
        request.resolution_notes = notes

        self.approval_store.update(request)

        # Clean up workflow state
        self.state_store.delete_state(request_id)

        logger.info(
            "hitl_request_denied",
            request_id=request_id,
            decided_by=decided_by,
            pnr=request.pnr,
        )

        return request

    def get_request(self, request_id: str) -> Optional[ApprovalRequest]:
        """Get an approval request by ID."""
        return self.approval_store.get(request_id)

    def get_pending_requests(self) -> List[ApprovalRequest]:
        """Get all pending approval requests."""
        return self.approval_store.get_pending()

    def get_requests_by_pnr(self, pnr: str) -> List[ApprovalRequest]:
        """Get all approval requests for a PNR."""
        return self.approval_store.get_by_pnr(pnr)

    def load_workflow_state(self, request_id: str) -> Optional[Dict[str, Any]]:
        """Load saved workflow state for resuming."""
        return self.state_store.load_state(request_id)

    def cleanup_completed(self, request_id: str) -> bool:
        """Clean up state after workflow completion."""
        return self.state_store.delete_state(request_id)

    def get_stats(self) -> Dict[str, Any]:
        """Get statistics about approval requests."""
        all_requests = []

        if self.approval_store._redis:
            all_data = self.approval_store._redis.hgetall("hitl:approvals")
            for data in all_data.values():
                all_requests.append(ApprovalRequest.from_dict(json.loads(data)))
        else:
            all_requests = list(self.approval_store._memory_store.values())

        stats = {
            "total": len(all_requests),
            "pending": sum(1 for r in all_requests if r.status == ApprovalStatus.PENDING),
            "approved": sum(1 for r in all_requests if r.status == ApprovalStatus.APPROVED),
            "denied": sum(1 for r in all_requests if r.status == ApprovalStatus.DENIED),
            "expired": sum(1 for r in all_requests if r.status == ApprovalStatus.EXPIRED),
            "by_reason": {},
        }

        for request in all_requests:
            reason = request.reason.value
            stats["by_reason"][reason] = stats["by_reason"].get(reason, 0) + 1

        return stats


# =============================================================================
# Singleton Access
# =============================================================================

_hitl_manager: Optional[HumanInTheLoopManager] = None


def get_hitl_manager() -> HumanInTheLoopManager:
    """Get the singleton HITL manager instance."""
    global _hitl_manager
    if _hitl_manager is None:
        _hitl_manager = HumanInTheLoopManager()
    return _hitl_manager


def create_hitl_manager(
    redis_client=None,
    slack_webhook: Optional[str] = None,
    approval_ui_url: Optional[str] = None,
    escalation_rules: Optional[EscalationRules] = None,
) -> HumanInTheLoopManager:
    """Create a new HITL manager instance."""
    global _hitl_manager
    _hitl_manager = HumanInTheLoopManager(
        redis_client=redis_client,
        slack_webhook=slack_webhook,
        approval_ui_url=approval_ui_url,
        escalation_rules=escalation_rules,
    )
    return _hitl_manager


================================================================================
FILE: infrastructure/logging.py
================================================================================
"""
Structured Logging Module

Provides structured logging with correlation IDs for request tracing.
Uses structlog for JSON-formatted, context-aware logging.
"""

import os
import sys
import uuid
import logging
from typing import Optional, Any, Dict
from contextvars import ContextVar
from functools import wraps
from datetime import datetime

# Try to import structlog, fall back to standard logging if not available
try:
    import structlog
    STRUCTLOG_AVAILABLE = True
except ImportError:
    STRUCTLOG_AVAILABLE = False
    print("Warning: structlog not installed. Using standard logging. Install with: pip install structlog")

# Context variable for correlation ID (thread-safe)
correlation_id_var: ContextVar[str] = ContextVar("correlation_id", default="")


def get_correlation_id() -> str:
    """Get the current correlation ID from context."""
    return correlation_id_var.get() or str(uuid.uuid4())[:8]


def set_correlation_id(correlation_id: Optional[str] = None) -> str:
    """Set a correlation ID in the current context."""
    cid = correlation_id or str(uuid.uuid4())[:8]
    correlation_id_var.set(cid)
    return cid


def configure_logging(
    log_level: str = "INFO",
    json_format: bool = True,
    log_file: Optional[str] = None,
) -> None:
    """
    Configure structured logging for the application.

    Args:
        log_level: Logging level (DEBUG, INFO, WARNING, ERROR)
        json_format: If True, output JSON format; otherwise, console format
        log_file: Optional file path for logging output
    """
    if not STRUCTLOG_AVAILABLE:
        # Fallback to standard logging
        logging.basicConfig(
            level=getattr(logging, log_level.upper()),
            format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
            handlers=[
                logging.StreamHandler(sys.stdout),
                *([logging.FileHandler(log_file)] if log_file else []),
            ]
        )
        return

    # Configure structlog processors
    shared_processors = [
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        _add_correlation_id,
        _add_service_info,
    ]

    if json_format:
        # JSON format for production
        processors = shared_processors + [
            structlog.processors.JSONRenderer()
        ]
    else:
        # Console format for development
        processors = shared_processors + [
            structlog.dev.ConsoleRenderer(colors=True)
        ]

    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(
            getattr(logging, log_level.upper())
        ),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )


def _add_correlation_id(logger, method_name, event_dict):
    """Add correlation ID to all log entries."""
    event_dict["correlation_id"] = get_correlation_id()
    return event_dict


def _add_service_info(logger, method_name, event_dict):
    """Add service information to log entries."""
    event_dict["service"] = "tailored-offers"
    event_dict["environment"] = os.getenv("ENVIRONMENT", "development")
    return event_dict


def get_logger(name: str = "tailored_offers") -> Any:
    """
    Get a structured logger instance.

    Args:
        name: Logger name (typically module name)

    Returns:
        Structured logger instance
    """
    if STRUCTLOG_AVAILABLE:
        return structlog.get_logger(name)
    else:
        return logging.getLogger(name)


class LogContext:
    """Context manager for adding temporary logging context."""

    def __init__(self, **context):
        self.context = context
        self._tokens = []

    def __enter__(self):
        if STRUCTLOG_AVAILABLE:
            for key, value in self.context.items():
                token = structlog.contextvars.bind_contextvars(**{key: value})
                self._tokens.append((key, token))
        return self

    def __exit__(self, *args):
        if STRUCTLOG_AVAILABLE:
            structlog.contextvars.clear_contextvars()


def log_agent_execution(agent_name: str):
    """Decorator to log agent execution with timing."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            logger = get_logger(agent_name)
            start_time = datetime.now()

            logger.info(
                "agent_execution_started",
                agent=agent_name,
            )

            try:
                result = func(*args, **kwargs)
                duration_ms = (datetime.now() - start_time).total_seconds() * 1000

                logger.info(
                    "agent_execution_completed",
                    agent=agent_name,
                    duration_ms=round(duration_ms, 2),
                    success=True,
                )
                return result

            except Exception as e:
                duration_ms = (datetime.now() - start_time).total_seconds() * 1000
                logger.error(
                    "agent_execution_failed",
                    agent=agent_name,
                    duration_ms=round(duration_ms, 2),
                    error=str(e),
                    error_type=type(e).__name__,
                )
                raise

        return wrapper
    return decorator


def log_llm_call(func):
    """Decorator to log LLM calls with token tracking."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        logger = get_logger("llm_service")
        start_time = datetime.now()

        # Extract relevant info from kwargs or args
        model = kwargs.get("model", "unknown")
        temperature = kwargs.get("temperature", 0.7)

        logger.info(
            "llm_call_started",
            model=model,
            temperature=temperature,
        )

        try:
            result = func(*args, **kwargs)
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000

            logger.info(
                "llm_call_completed",
                model=model,
                duration_ms=round(duration_ms, 2),
                success=True,
            )
            return result

        except Exception as e:
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            logger.error(
                "llm_call_failed",
                model=model,
                duration_ms=round(duration_ms, 2),
                error=str(e),
                error_type=type(e).__name__,
            )
            raise

    return wrapper


def log_mcp_call(tool_name: str):
    """Decorator to log MCP tool calls."""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            logger = get_logger("mcp_client")
            start_time = datetime.now()

            logger.info(
                "mcp_call_started",
                tool=tool_name,
            )

            try:
                result = await func(*args, **kwargs)
                duration_ms = (datetime.now() - start_time).total_seconds() * 1000

                logger.info(
                    "mcp_call_completed",
                    tool=tool_name,
                    duration_ms=round(duration_ms, 2),
                    success=True,
                    has_result=result is not None,
                )
                return result

            except Exception as e:
                duration_ms = (datetime.now() - start_time).total_seconds() * 1000
                logger.error(
                    "mcp_call_failed",
                    tool=tool_name,
                    duration_ms=round(duration_ms, 2),
                    error=str(e),
                    error_type=type(e).__name__,
                )
                raise

        return wrapper
    return decorator


================================================================================
FILE: infrastructure/memory.py
================================================================================
"""
Agent Memory Module

Provides memory capabilities for agentic systems:
- Short-term memory: Current conversation/session context
- Long-term memory: Persistent customer interaction history
- Episodic memory: Past offer decisions and outcomes
- Semantic memory: Learned patterns and preferences

Memory Types:
1. ConversationMemory: Track current session context
2. CustomerMemory: Historical customer interactions
3. OfferMemory: Past offer decisions and conversion outcomes
4. LearningMemory: Patterns learned from successful/failed offers
"""

import os
import json
import hashlib
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
from collections import defaultdict

# Try to import Redis for distributed memory
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

from .logging import get_logger

logger = get_logger("memory")


# =============================================================================
# MEMORY DATA STRUCTURES
# =============================================================================

@dataclass
class MemoryEntry:
    """A single memory entry with metadata."""
    key: str
    value: Any
    timestamp: datetime = field(default_factory=datetime.now)
    ttl_seconds: Optional[int] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

    @property
    def is_expired(self) -> bool:
        if self.ttl_seconds is None:
            return False
        age = (datetime.now() - self.timestamp).total_seconds()
        return age > self.ttl_seconds

    def to_dict(self) -> Dict[str, Any]:
        return {
            "key": self.key,
            "value": self.value,
            "timestamp": self.timestamp.isoformat(),
            "ttl_seconds": self.ttl_seconds,
            "metadata": self.metadata,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "MemoryEntry":
        return cls(
            key=data["key"],
            value=data["value"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            ttl_seconds=data.get("ttl_seconds"),
            metadata=data.get("metadata", {}),
        )


@dataclass
class CustomerInteraction:
    """Record of a customer interaction."""
    customer_id: str
    pnr: str
    timestamp: datetime
    offer_type: Optional[str]
    offer_price: Optional[float]
    accepted: Optional[bool]
    channel: str
    context: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            **asdict(self),
            "timestamp": self.timestamp.isoformat(),
        }


@dataclass
class OfferOutcome:
    """Outcome of a previous offer decision."""
    pnr: str
    customer_id: str
    offer_type: str
    offer_price: float
    expected_value: float
    actual_outcome: Optional[str]  # "accepted", "rejected", "expired", "unknown"
    conversion_time_hours: Optional[float]
    feedback: Optional[str]
    timestamp: datetime = field(default_factory=datetime.now)


# =============================================================================
# MEMORY BACKENDS
# =============================================================================

class MemoryBackend(ABC):
    """Abstract base class for memory backends."""

    @abstractmethod
    def get(self, key: str) -> Optional[Any]:
        pass

    @abstractmethod
    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None) -> None:
        pass

    @abstractmethod
    def delete(self, key: str) -> None:
        pass

    @abstractmethod
    def exists(self, key: str) -> bool:
        pass

    @abstractmethod
    def keys(self, pattern: str = "*") -> List[str]:
        pass

    @abstractmethod
    def clear(self) -> None:
        pass


class InMemoryBackend(MemoryBackend):
    """In-memory storage backend (single instance, non-persistent)."""

    def __init__(self):
        self._store: Dict[str, MemoryEntry] = {}

    def get(self, key: str) -> Optional[Any]:
        entry = self._store.get(key)
        if entry is None:
            return None
        if entry.is_expired:
            self.delete(key)
            return None
        return entry.value

    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None) -> None:
        self._store[key] = MemoryEntry(
            key=key,
            value=value,
            ttl_seconds=ttl_seconds,
        )

    def delete(self, key: str) -> None:
        self._store.pop(key, None)

    def exists(self, key: str) -> bool:
        entry = self._store.get(key)
        if entry is None:
            return False
        if entry.is_expired:
            self.delete(key)
            return False
        return True

    def keys(self, pattern: str = "*") -> List[str]:
        import fnmatch
        all_keys = list(self._store.keys())
        if pattern == "*":
            return all_keys
        return [k for k in all_keys if fnmatch.fnmatch(k, pattern)]

    def clear(self) -> None:
        self._store.clear()


class RedisBackend(MemoryBackend):
    """Redis-based storage backend (distributed, persistent)."""

    def __init__(
        self,
        host: str = "localhost",
        port: int = 6379,
        db: int = 0,
        prefix: str = "tailored_offers:",
    ):
        if not REDIS_AVAILABLE:
            raise ImportError("Redis not available. Install with: pip install redis")

        self.client = redis.Redis(host=host, port=port, db=db, decode_responses=True)
        self.prefix = prefix

    def _key(self, key: str) -> str:
        return f"{self.prefix}{key}"

    def get(self, key: str) -> Optional[Any]:
        value = self.client.get(self._key(key))
        if value is None:
            return None
        try:
            return json.loads(value)
        except json.JSONDecodeError:
            return value

    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None) -> None:
        serialized = json.dumps(value) if not isinstance(value, str) else value
        if ttl_seconds:
            self.client.setex(self._key(key), ttl_seconds, serialized)
        else:
            self.client.set(self._key(key), serialized)

    def delete(self, key: str) -> None:
        self.client.delete(self._key(key))

    def exists(self, key: str) -> bool:
        return self.client.exists(self._key(key)) > 0

    def keys(self, pattern: str = "*") -> List[str]:
        full_pattern = self._key(pattern)
        keys = self.client.keys(full_pattern)
        return [k.replace(self.prefix, "") for k in keys]

    def clear(self) -> None:
        keys = self.client.keys(f"{self.prefix}*")
        if keys:
            self.client.delete(*keys)


# =============================================================================
# SPECIALIZED MEMORY TYPES
# =============================================================================

class ConversationMemory:
    """
    Short-term memory for current conversation/session context.

    Tracks:
    - Current PNR being processed
    - Agent decisions made so far
    - User preferences expressed in session
    - Context accumulated across agent calls
    """

    def __init__(self, backend: Optional[MemoryBackend] = None, session_ttl: int = 3600):
        self.backend = backend or InMemoryBackend()
        self.session_ttl = session_ttl  # 1 hour default

    def start_session(self, session_id: str, pnr: str, context: Dict[str, Any] = None) -> None:
        """Start a new conversation session."""
        self.backend.set(
            f"session:{session_id}",
            {
                "pnr": pnr,
                "started_at": datetime.now().isoformat(),
                "context": context or {},
                "agent_decisions": [],
                "messages": [],
            },
            ttl_seconds=self.session_ttl,
        )
        logger.info("session_started", session_id=session_id, pnr=pnr)

    def add_agent_decision(
        self,
        session_id: str,
        agent_name: str,
        decision: Dict[str, Any],
    ) -> None:
        """Record an agent's decision in the session."""
        session = self.backend.get(f"session:{session_id}")
        if session:
            session["agent_decisions"].append({
                "agent": agent_name,
                "decision": decision,
                "timestamp": datetime.now().isoformat(),
            })
            self.backend.set(f"session:{session_id}", session, ttl_seconds=self.session_ttl)

    def add_message(self, session_id: str, role: str, content: str) -> None:
        """Add a message to the conversation history."""
        session = self.backend.get(f"session:{session_id}")
        if session:
            session["messages"].append({
                "role": role,
                "content": content,
                "timestamp": datetime.now().isoformat(),
            })
            self.backend.set(f"session:{session_id}", session, ttl_seconds=self.session_ttl)

    def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Get the current session context."""
        return self.backend.get(f"session:{session_id}")

    def get_agent_decisions(self, session_id: str) -> List[Dict[str, Any]]:
        """Get all agent decisions from the current session."""
        session = self.backend.get(f"session:{session_id}")
        return session.get("agent_decisions", []) if session else []

    def get_conversation_summary(self, session_id: str) -> str:
        """Generate a summary of the conversation for context."""
        session = self.backend.get(f"session:{session_id}")
        if not session:
            return ""

        summary_parts = [f"Session for PNR: {session['pnr']}"]

        for decision in session.get("agent_decisions", []):
            agent = decision["agent"]
            if "selected_offer" in decision.get("decision", {}):
                summary_parts.append(
                    f"- {agent}: Selected {decision['decision']['selected_offer']}"
                )
            elif "customer_eligible" in decision.get("decision", {}):
                eligible = decision['decision']['customer_eligible']
                summary_parts.append(f"- {agent}: Customer {'eligible' if eligible else 'not eligible'}")

        return "\n".join(summary_parts)


class CustomerMemory:
    """
    Long-term memory for customer interaction history.

    Tracks:
    - Previous offers sent to this customer
    - Acceptance/rejection history
    - Preferred channels and timing
    - Lifetime value indicators
    """

    def __init__(self, backend: Optional[MemoryBackend] = None):
        self.backend = backend or InMemoryBackend()

    def record_interaction(self, interaction: CustomerInteraction) -> None:
        """Record a customer interaction."""
        key = f"customer:{interaction.customer_id}:interactions"
        interactions = self.backend.get(key) or []
        interactions.append(interaction.to_dict())

        # Keep last 100 interactions
        if len(interactions) > 100:
            interactions = interactions[-100:]

        self.backend.set(key, interactions)
        logger.info(
            "interaction_recorded",
            customer_id=interaction.customer_id,
            offer_type=interaction.offer_type,
        )

    def get_customer_history(self, customer_id: str) -> List[Dict[str, Any]]:
        """Get customer's interaction history."""
        return self.backend.get(f"customer:{customer_id}:interactions") or []

    def get_acceptance_rate(self, customer_id: str, offer_type: Optional[str] = None) -> float:
        """Calculate customer's historical acceptance rate."""
        history = self.get_customer_history(customer_id)

        relevant = [
            h for h in history
            if h.get("accepted") is not None
            and (offer_type is None or h.get("offer_type") == offer_type)
        ]

        if not relevant:
            return 0.5  # Default for no history

        accepted = sum(1 for h in relevant if h.get("accepted"))
        return accepted / len(relevant)

    def get_preferred_channel(self, customer_id: str) -> Optional[str]:
        """Determine customer's preferred channel based on history."""
        history = self.get_customer_history(customer_id)

        channel_success = defaultdict(lambda: {"total": 0, "accepted": 0})
        for h in history:
            channel = h.get("channel")
            if channel:
                channel_success[channel]["total"] += 1
                if h.get("accepted"):
                    channel_success[channel]["accepted"] += 1

        if not channel_success:
            return None

        # Return channel with highest acceptance rate (min 2 interactions)
        best_channel = None
        best_rate = 0
        for channel, stats in channel_success.items():
            if stats["total"] >= 2:
                rate = stats["accepted"] / stats["total"]
                if rate > best_rate:
                    best_rate = rate
                    best_channel = channel

        return best_channel

    def get_customer_insights(self, customer_id: str) -> Dict[str, Any]:
        """Generate insights about a customer from their history."""
        history = self.get_customer_history(customer_id)

        if not history:
            return {
                "has_history": False,
                "total_interactions": 0,
                "insights": ["No previous interaction history"],
            }

        insights = []

        # Acceptance rate
        acceptance_rate = self.get_acceptance_rate(customer_id)
        if acceptance_rate > 0.6:
            insights.append("High historical acceptance rate - receptive to offers")
        elif acceptance_rate < 0.3:
            insights.append("Low historical acceptance rate - may need special approach")

        # Preferred channel
        preferred_channel = self.get_preferred_channel(customer_id)
        if preferred_channel:
            insights.append(f"Prefers {preferred_channel} channel based on past interactions")

        # Offer type preferences
        offer_counts = defaultdict(int)
        for h in history:
            if h.get("accepted") and h.get("offer_type"):
                offer_counts[h["offer_type"]] += 1

        if offer_counts:
            favorite = max(offer_counts.items(), key=lambda x: x[1])
            insights.append(f"Has accepted {favorite[0]} offers {favorite[1]} times")

        return {
            "has_history": True,
            "total_interactions": len(history),
            "acceptance_rate": acceptance_rate,
            "preferred_channel": preferred_channel,
            "insights": insights,
        }


class OfferMemory:
    """
    Memory for past offer decisions and outcomes.

    Tracks:
    - What offers were made
    - Expected vs actual outcomes
    - Conversion patterns
    - Time-based patterns
    """

    def __init__(self, backend: Optional[MemoryBackend] = None):
        self.backend = backend or InMemoryBackend()

    def record_offer(self, outcome: OfferOutcome) -> None:
        """Record an offer outcome."""
        # Store by PNR
        self.backend.set(
            f"offer:{outcome.pnr}",
            asdict(outcome) | {"timestamp": outcome.timestamp.isoformat()},
        )

        # Add to customer's offer history
        customer_key = f"customer:{outcome.customer_id}:offers"
        offers = self.backend.get(customer_key) or []
        offers.append(asdict(outcome) | {"timestamp": outcome.timestamp.isoformat()})
        self.backend.set(customer_key, offers[-50:])  # Keep last 50

        # Add to global offer history for learning
        self._update_offer_stats(outcome)

    def _update_offer_stats(self, outcome: OfferOutcome) -> None:
        """Update aggregate offer statistics for learning."""
        stats_key = f"stats:offer:{outcome.offer_type}"
        stats = self.backend.get(stats_key) or {
            "total": 0,
            "accepted": 0,
            "total_ev": 0,
            "total_revenue": 0,
        }

        stats["total"] += 1
        if outcome.actual_outcome == "accepted":
            stats["accepted"] += 1
            stats["total_revenue"] += outcome.offer_price
        stats["total_ev"] += outcome.expected_value

        self.backend.set(stats_key, stats)

    def get_offer_stats(self, offer_type: str) -> Dict[str, Any]:
        """Get aggregate statistics for an offer type."""
        stats = self.backend.get(f"stats:offer:{offer_type}")
        if not stats or stats["total"] == 0:
            return {
                "offer_type": offer_type,
                "total_offers": 0,
                "acceptance_rate": 0.5,  # Default
                "avg_expected_value": 0,
                "avg_actual_value": 0,
            }

        return {
            "offer_type": offer_type,
            "total_offers": stats["total"],
            "acceptance_rate": stats["accepted"] / stats["total"],
            "avg_expected_value": stats["total_ev"] / stats["total"],
            "avg_actual_revenue": stats["total_revenue"] / stats["total"] if stats["accepted"] > 0 else 0,
        }

    def get_similar_offers(
        self,
        customer_tier: str,
        offer_type: str,
        limit: int = 5,
    ) -> List[Dict[str, Any]]:
        """Find similar past offers for learning."""
        # This would ideally use vector similarity search
        # For now, use simple key-based lookup
        pattern = f"offer:*"
        all_keys = self.backend.keys(pattern)

        similar = []
        for key in all_keys[:100]:  # Limit search
            offer = self.backend.get(key)
            if offer and offer.get("offer_type") == offer_type:
                similar.append(offer)
                if len(similar) >= limit:
                    break

        return similar


class LearningMemory:
    """
    Memory for learned patterns and preferences.

    Tracks:
    - Successful offer patterns
    - Failed offer patterns
    - Time-of-day patterns
    - Segment-specific insights
    """

    def __init__(self, backend: Optional[MemoryBackend] = None):
        self.backend = backend or InMemoryBackend()

    def record_pattern(
        self,
        pattern_type: str,
        pattern_key: str,
        success: bool,
        context: Dict[str, Any],
    ) -> None:
        """Record a pattern observation."""
        key = f"pattern:{pattern_type}:{pattern_key}"
        pattern = self.backend.get(key) or {
            "successes": 0,
            "failures": 0,
            "contexts": [],
        }

        if success:
            pattern["successes"] += 1
        else:
            pattern["failures"] += 1

        # Keep recent contexts for analysis
        pattern["contexts"].append({
            "success": success,
            "context": context,
            "timestamp": datetime.now().isoformat(),
        })
        pattern["contexts"] = pattern["contexts"][-20:]  # Keep last 20

        self.backend.set(key, pattern)

    def get_pattern_success_rate(self, pattern_type: str, pattern_key: str) -> float:
        """Get success rate for a specific pattern."""
        pattern = self.backend.get(f"pattern:{pattern_type}:{pattern_key}")
        if not pattern:
            return 0.5  # Default

        total = pattern["successes"] + pattern["failures"]
        if total == 0:
            return 0.5

        return pattern["successes"] / total

    def get_best_patterns(self, pattern_type: str, min_observations: int = 5) -> List[Dict[str, Any]]:
        """Get the most successful patterns of a type."""
        pattern_keys = self.backend.keys(f"pattern:{pattern_type}:*")

        patterns = []
        for key in pattern_keys:
            pattern = self.backend.get(key)
            if pattern:
                total = pattern["successes"] + pattern["failures"]
                if total >= min_observations:
                    patterns.append({
                        "key": key.split(":")[-1],
                        "success_rate": pattern["successes"] / total,
                        "total_observations": total,
                    })

        return sorted(patterns, key=lambda x: x["success_rate"], reverse=True)

    def get_recommendations(self, context: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on learned patterns."""
        recommendations = []

        # Check time-of-day patterns
        hour = datetime.now().hour
        time_key = "morning" if hour < 12 else "afternoon" if hour < 18 else "evening"
        time_rate = self.get_pattern_success_rate("time_of_day", time_key)
        if time_rate > 0.6:
            recommendations.append(f"Good time to send offers ({time_key} has {time_rate:.0%} success rate)")
        elif time_rate < 0.4:
            recommendations.append(f"Consider delaying - {time_key} has lower success rate ({time_rate:.0%})")

        # Check loyalty tier patterns
        if "loyalty_tier" in context:
            tier = context["loyalty_tier"]
            tier_rate = self.get_pattern_success_rate("loyalty_tier", tier)
            if tier_rate > 0.5:
                recommendations.append(f"{tier} customers have good acceptance rate ({tier_rate:.0%})")

        return recommendations


# =============================================================================
# UNIFIED MEMORY MANAGER
# =============================================================================

class AgentMemory:
    """
    Unified memory manager for all agent memory types.

    Provides a single interface for:
    - Session/conversation memory
    - Customer history
    - Offer outcomes
    - Learned patterns
    """

    def __init__(
        self,
        backend: Optional[MemoryBackend] = None,
        use_redis: bool = False,
        redis_url: Optional[str] = None,
    ):
        # Initialize backend
        if use_redis and REDIS_AVAILABLE:
            redis_host = os.getenv("REDIS_HOST", "localhost")
            redis_port = int(os.getenv("REDIS_PORT", "6379"))
            self.backend = RedisBackend(host=redis_host, port=redis_port)
            logger.info("memory_initialized", backend="redis")
        else:
            self.backend = backend or InMemoryBackend()
            logger.info("memory_initialized", backend="in_memory")

        # Initialize specialized memories
        self.conversation = ConversationMemory(self.backend)
        self.customer = CustomerMemory(self.backend)
        self.offers = OfferMemory(self.backend)
        self.learning = LearningMemory(self.backend)

    def get_context_for_agent(
        self,
        session_id: str,
        customer_id: str,
        agent_name: str,
    ) -> Dict[str, Any]:
        """
        Get relevant memory context for an agent.

        Returns accumulated context from all memory types.
        """
        context = {
            "session": self.conversation.get_session(session_id),
            "customer_insights": self.customer.get_customer_insights(customer_id),
            "previous_decisions": self.conversation.get_agent_decisions(session_id),
            "recommendations": self.learning.get_recommendations({"customer_id": customer_id}),
        }

        # Add agent-specific context
        if agent_name == "offer_orchestration":
            # Get offer statistics
            for offer_type in ["IU_BUSINESS", "IU_PREMIUM_ECONOMY", "MCE"]:
                context[f"{offer_type}_stats"] = self.offers.get_offer_stats(offer_type)

        return context

    def record_decision(
        self,
        session_id: str,
        customer_id: str,
        agent_name: str,
        decision: Dict[str, Any],
    ) -> None:
        """Record an agent decision in memory."""
        # Add to session
        self.conversation.add_agent_decision(session_id, agent_name, decision)

        # Record patterns for learning
        if "selected_offer" in decision:
            self.learning.record_pattern(
                pattern_type="offer_selection",
                pattern_key=decision["selected_offer"],
                success=True,  # Will be updated when outcome is known
                context={"customer_id": customer_id, "agent": agent_name},
            )

    def record_outcome(
        self,
        pnr: str,
        customer_id: str,
        offer_type: str,
        offer_price: float,
        expected_value: float,
        actual_outcome: str,
    ) -> None:
        """Record the final outcome of an offer."""
        outcome = OfferOutcome(
            pnr=pnr,
            customer_id=customer_id,
            offer_type=offer_type,
            offer_price=offer_price,
            expected_value=expected_value,
            actual_outcome=actual_outcome,
        )
        self.offers.record_offer(outcome)

        # Update learning memory
        success = actual_outcome == "accepted"
        self.learning.record_pattern(
            pattern_type="offer_outcome",
            pattern_key=offer_type,
            success=success,
            context={"pnr": pnr, "price": offer_price},
        )

        # Record customer interaction
        interaction = CustomerInteraction(
            customer_id=customer_id,
            pnr=pnr,
            timestamp=datetime.now(),
            offer_type=offer_type,
            offer_price=offer_price,
            accepted=success,
            channel="unknown",
        )
        self.customer.record_interaction(interaction)


# Global memory instance
_memory: Optional[AgentMemory] = None


def get_memory() -> AgentMemory:
    """Get the global memory instance."""
    global _memory
    if _memory is None:
        use_redis = os.getenv("USE_REDIS_MEMORY", "false").lower() == "true"
        _memory = AgentMemory(use_redis=use_redis)
    return _memory


================================================================================
FILE: infrastructure/metrics.py
================================================================================
"""
Prometheus Metrics Module

Provides metrics collection for monitoring agent performance,
LLM calls, and system health.
"""

import os
import time
from typing import Optional, Dict, Any, Callable
from functools import wraps
from contextlib import contextmanager

# Try to import prometheus_client, fall back to no-op if not available
try:
    from prometheus_client import (
        Counter,
        Histogram,
        Gauge,
        Summary,
        CollectorRegistry,
        generate_latest,
        start_http_server,
        CONTENT_TYPE_LATEST,
    )
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    print("Warning: prometheus-client not installed. Metrics disabled. Install with: pip install prometheus-client")


# Create a custom registry for this application
if PROMETHEUS_AVAILABLE:
    REGISTRY = CollectorRegistry()

    # Agent Metrics
    agent_requests = Counter(
        "tailored_offers_agent_requests_total",
        "Total number of agent requests",
        ["agent_name", "status"],
        registry=REGISTRY,
    )

    agent_duration = Histogram(
        "tailored_offers_agent_duration_seconds",
        "Agent execution duration in seconds",
        ["agent_name"],
        buckets=(0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0),
        registry=REGISTRY,
    )

    agent_decision = Counter(
        "tailored_offers_agent_decision_total",
        "Agent decision outcomes",
        ["agent_name", "decision"],
        registry=REGISTRY,
    )

    # LLM Metrics
    llm_calls = Counter(
        "tailored_offers_llm_calls_total",
        "Total number of LLM API calls",
        ["model", "status"],
        registry=REGISTRY,
    )

    llm_latency = Histogram(
        "tailored_offers_llm_latency_seconds",
        "LLM API call latency in seconds",
        ["model"],
        buckets=(0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0),
        registry=REGISTRY,
    )

    llm_tokens = Counter(
        "tailored_offers_llm_tokens_total",
        "Total tokens used in LLM calls",
        ["model", "token_type"],  # token_type: input, output
        registry=REGISTRY,
    )

    llm_fallback = Counter(
        "tailored_offers_llm_fallback_total",
        "Number of times LLM fell back to rules",
        ["agent_name", "reason"],
        registry=REGISTRY,
    )

    # MCP Metrics
    mcp_calls = Counter(
        "tailored_offers_mcp_calls_total",
        "Total number of MCP tool calls",
        ["tool_name", "status"],
        registry=REGISTRY,
    )

    mcp_latency = Histogram(
        "tailored_offers_mcp_latency_seconds",
        "MCP tool call latency in seconds",
        ["tool_name"],
        buckets=(0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0),
        registry=REGISTRY,
    )

    # Guardrail Metrics
    guardrail_checks = Counter(
        "tailored_offers_guardrail_checks_total",
        "Total guardrail checks performed",
        ["guardrail_name", "result"],  # result: pass, fail
        registry=REGISTRY,
    )

    # Validation Metrics
    validation_results = Counter(
        "tailored_offers_validation_results_total",
        "LLM response validation results",
        ["agent_name", "result"],  # result: valid, invalid
        registry=REGISTRY,
    )

    # Business Metrics
    offer_decisions = Counter(
        "tailored_offers_offer_decisions_total",
        "Offer decision outcomes",
        ["offer_type", "decision"],  # decision: send, suppress
        registry=REGISTRY,
    )

    expected_value = Histogram(
        "tailored_offers_expected_value",
        "Expected value of offers",
        ["offer_type"],
        buckets=(10, 25, 50, 100, 150, 200, 300, 500),
        registry=REGISTRY,
    )

    discount_applied = Histogram(
        "tailored_offers_discount_percent",
        "Discount percentage applied to offers",
        ["offer_type"],
        buckets=(0, 5, 10, 15, 20, 25),
        registry=REGISTRY,
    )

    # Pipeline Metrics
    pipeline_duration = Histogram(
        "tailored_offers_pipeline_duration_seconds",
        "End-to-end pipeline duration",
        [],
        buckets=(1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0),
        registry=REGISTRY,
    )

    pipeline_success = Counter(
        "tailored_offers_pipeline_success_total",
        "Pipeline completion status",
        ["status"],  # status: success, failure, short_circuit
        registry=REGISTRY,
    )

    # Outcome/Feedback Loop Metrics
    offer_outcomes = Counter(
        "tailored_offers_outcomes_total",
        "Offer outcome tracking",
        ["offer_type", "outcome", "channel"],  # outcome: accepted, rejected, expired
        registry=REGISTRY,
    )

    offer_revenue = Counter(
        "tailored_offers_revenue_total",
        "Total revenue from accepted offers",
        ["offer_type"],
        registry=REGISTRY,
    )

    prediction_error = Histogram(
        "tailored_offers_prediction_error",
        "Difference between expected and actual outcomes",
        ["offer_type"],
        buckets=(-0.5, -0.3, -0.1, 0.0, 0.1, 0.3, 0.5),
        registry=REGISTRY,
    )

    calibration_error = Gauge(
        "tailored_offers_calibration_error",
        "Current calibration error (ECE)",
        ["segment"],  # segment: overall, by_offer_type, by_tier, etc.
        registry=REGISTRY,
    )

    value_capture_rate = Gauge(
        "tailored_offers_value_capture_rate",
        "Actual value / Expected value ratio",
        [],
        registry=REGISTRY,
    )

    feedback_processed = Counter(
        "tailored_offers_feedback_processed_total",
        "Total feedback events processed",
        ["status"],  # status: success, failure
        registry=REGISTRY,
    )

else:
    # No-op metrics when prometheus is not available
    class NoOpMetric:
        def labels(self, *args, **kwargs):
            return self
        def inc(self, amount=1):
            pass
        def dec(self, amount=1):
            pass
        def observe(self, amount):
            pass
        def set(self, value):
            pass
        def time(self):
            return self._no_op_context()
        @contextmanager
        def _no_op_context(self):
            yield

    agent_requests = NoOpMetric()
    agent_duration = NoOpMetric()
    agent_decision = NoOpMetric()
    llm_calls = NoOpMetric()
    llm_latency = NoOpMetric()
    llm_tokens = NoOpMetric()
    llm_fallback = NoOpMetric()
    mcp_calls = NoOpMetric()
    mcp_latency = NoOpMetric()
    guardrail_checks = NoOpMetric()
    validation_results = NoOpMetric()
    offer_decisions = NoOpMetric()
    expected_value = NoOpMetric()
    discount_applied = NoOpMetric()
    pipeline_duration = NoOpMetric()
    pipeline_success = NoOpMetric()
    offer_outcomes = NoOpMetric()
    offer_revenue = NoOpMetric()
    prediction_error = NoOpMetric()
    calibration_error = NoOpMetric()
    value_capture_rate = NoOpMetric()
    feedback_processed = NoOpMetric()
    REGISTRY = None


class MetricsCollector:
    """
    Centralized metrics collection for the application.

    Provides a convenient interface for recording metrics from agents
    and other components.
    """

    def __init__(self):
        self.enabled = PROMETHEUS_AVAILABLE

    def start_metrics_server(self, port: int = 8000):
        """Start the Prometheus metrics HTTP server."""
        if not self.enabled:
            print("Metrics server not started: prometheus-client not installed")
            return

        start_http_server(port, registry=REGISTRY)
        print(f"Metrics server started on port {port}")

    def get_metrics(self) -> bytes:
        """Get the current metrics in Prometheus format."""
        if not self.enabled:
            return b""
        return generate_latest(REGISTRY)

    # Agent metrics
    def record_agent_start(self, agent_name: str) -> float:
        """Record agent execution start. Returns start time."""
        return time.time()

    def record_agent_success(self, agent_name: str, start_time: float, decision: Optional[str] = None):
        """Record successful agent execution."""
        if not self.enabled:
            return

        duration = time.time() - start_time
        agent_requests.labels(agent_name=agent_name, status="success").inc()
        agent_duration.labels(agent_name=agent_name).observe(duration)
        if decision:
            agent_decision.labels(agent_name=agent_name, decision=decision).inc()

    def record_agent_failure(self, agent_name: str, start_time: float, error_type: str = "unknown"):
        """Record failed agent execution."""
        if not self.enabled:
            return

        duration = time.time() - start_time
        agent_requests.labels(agent_name=agent_name, status="failure").inc()
        agent_duration.labels(agent_name=agent_name).observe(duration)

    # LLM metrics
    def record_llm_call(
        self,
        model: str,
        success: bool,
        duration: float,
        input_tokens: int = 0,
        output_tokens: int = 0,
    ):
        """Record an LLM API call."""
        if not self.enabled:
            return

        status = "success" if success else "failure"
        llm_calls.labels(model=model, status=status).inc()
        llm_latency.labels(model=model).observe(duration)

        if input_tokens > 0:
            llm_tokens.labels(model=model, token_type="input").inc(input_tokens)
        if output_tokens > 0:
            llm_tokens.labels(model=model, token_type="output").inc(output_tokens)

    def record_llm_fallback(self, agent_name: str, reason: str):
        """Record when LLM falls back to rules-based logic."""
        if not self.enabled:
            return
        llm_fallback.labels(agent_name=agent_name, reason=reason).inc()

    # MCP metrics
    def record_mcp_call(self, tool_name: str, success: bool, duration: float):
        """Record an MCP tool call."""
        if not self.enabled:
            return

        status = "success" if success else "failure"
        mcp_calls.labels(tool_name=tool_name, status=status).inc()
        mcp_latency.labels(tool_name=tool_name).observe(duration)

    # Guardrail metrics
    def record_guardrail_check(self, guardrail_name: str, passed: bool):
        """Record a guardrail check result."""
        if not self.enabled:
            return

        result = "pass" if passed else "fail"
        guardrail_checks.labels(guardrail_name=guardrail_name, result=result).inc()

    # Validation metrics
    def record_validation(self, agent_name: str, valid: bool):
        """Record LLM response validation result."""
        if not self.enabled:
            return

        result = "valid" if valid else "invalid"
        validation_results.labels(agent_name=agent_name, result=result).inc()

    # Business metrics
    def record_offer_decision(self, offer_type: str, send: bool, ev: float, discount_pct: float):
        """Record an offer decision with business metrics."""
        if not self.enabled:
            return

        decision = "send" if send else "suppress"
        offer_decisions.labels(offer_type=offer_type, decision=decision).inc()
        expected_value.labels(offer_type=offer_type).observe(ev)
        discount_applied.labels(offer_type=offer_type).observe(discount_pct)

    # Pipeline metrics
    def record_pipeline_completion(self, success: bool, duration: float, short_circuit: bool = False):
        """Record pipeline completion."""
        if not self.enabled:
            return

        if short_circuit:
            status = "short_circuit"
        elif success:
            status = "success"
        else:
            status = "failure"

        pipeline_success.labels(status=status).inc()
        pipeline_duration.observe(duration)

    # Outcome/Feedback Loop metrics
    def record_offer_outcome(
        self,
        offer_type: str,
        outcome: str,
        channel: str = "unknown",
    ):
        """Record an offer outcome (accepted, rejected, expired)."""
        if not self.enabled:
            return

        offer_outcomes.labels(
            offer_type=offer_type,
            outcome=outcome,
            channel=channel,
        ).inc()
        feedback_processed.labels(status="success").inc()

    def record_offer_revenue(self, amount: float, offer_type: str):
        """Record revenue from an accepted offer."""
        if not self.enabled:
            return

        offer_revenue.labels(offer_type=offer_type).inc(amount)

    def record_prediction_error(self, error: float, offer_type: str):
        """Record prediction error (actual - expected)."""
        if not self.enabled:
            return

        prediction_error.labels(offer_type=offer_type).observe(error)

    def record_calibration_error(self, error: float, segment: str = "overall"):
        """Record current calibration error."""
        if not self.enabled:
            return

        calibration_error.labels(segment=segment).set(error)

    def record_value_capture_rate(self, rate: float):
        """Record value capture rate (actual_value / expected_value)."""
        if not self.enabled:
            return

        value_capture_rate.set(rate)


# Global metrics collector instance
metrics = MetricsCollector()


def track_agent_metrics(agent_name: str):
    """Decorator to automatically track agent metrics."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = metrics.record_agent_start(agent_name)
            try:
                result = func(*args, **kwargs)
                decision = result.get("selected_offer") or result.get("decision", "unknown")
                metrics.record_agent_success(agent_name, start_time, decision)
                return result
            except Exception as e:
                metrics.record_agent_failure(agent_name, start_time, type(e).__name__)
                raise
        return wrapper
    return decorator


def track_llm_metrics(model: str = "unknown"):
    """Decorator to automatically track LLM call metrics."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start_time
                metrics.record_llm_call(model, True, duration)
                return result
            except Exception as e:
                duration = time.time() - start_time
                metrics.record_llm_call(model, False, duration)
                raise
        return wrapper
    return decorator


================================================================================
FILE: infrastructure/planner_executor.py
================================================================================
"""
Planner-Executor Pattern Module

Implements TWO variants of the Planner-Executor agentic pattern:

## 1. Batch Planner-Executor (Legacy)
Plans all steps upfront, executes all, revises on failure.
- Use for: Simple, predictable workflows where steps are well-defined

## 2. Incremental Planner-Executor (Recommended) ‚úÖ
Plans ONE step at a time, executes, observes result, re-plans.
- Use for: Complex workflows where later steps depend on earlier results
- Follows best practice: "Plan next action, wait for result, re-plan based on state"

Pattern Benefits:
- Separation of strategic planning from tactical execution
- Ability to re-plan when execution encounters issues
- Better explainability (plan is visible and auditable)
- Support for human-in-the-loop at planning stage
- Workers return recommendations for failure recovery
- Dynamic task simplification on repeated failures

Usage (Incremental - Recommended):
    coordinator = IncrementalPlannerExecutorCoordinator()
    result = coordinator.run({"pnr_locator": "ABC123"})

Usage (Batch - Legacy):
    planner = OfferPlanner()
    executor = OfferExecutor()
    plan = planner.create_plan(context)
    result = executor.execute(plan)
"""

import os
from typing import Optional, Dict, Any, List, Callable
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from abc import ABC, abstractmethod

from .logging import get_logger
from .metrics import metrics
from .memory import get_memory

logger = get_logger("planner_executor")

# Lazy import feedback to avoid circular dependency
def _get_feedback_manager():
    from .feedback import get_feedback_manager
    return get_feedback_manager()


# =============================================================================
# PLAN DATA STRUCTURES
# =============================================================================

class PlanStatus(Enum):
    """Status of a plan."""
    DRAFT = "draft"
    APPROVED = "approved"
    EXECUTING = "executing"
    COMPLETED = "completed"
    FAILED = "failed"
    REVISED = "revised"


class StepStatus(Enum):
    """Status of a plan step."""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


class WorkerRecommendation(Enum):
    """
    Recommendations that workers can return to guide the planner.

    This is the KEY addition for proper planner-worker communication.
    Workers don't just fail - they suggest what to do next.
    """
    CONTINUE = "continue"              # Success, proceed normally
    RETRY = "retry"                    # Transient failure, retry same step
    RETRY_WITH_BACKOFF = "retry_with_backoff"  # Rate limited, wait then retry
    USE_BACKUP = "use_backup"          # Primary failed, try backup approach
    SIMPLIFY = "simplify"              # Too complex, simplify the task
    SKIP = "skip"                      # Non-critical, skip this step
    ABORT = "abort"                    # Unrecoverable, stop execution
    ESCALATE = "escalate"              # Need human intervention


@dataclass
class WorkerResult:
    """
    Rich result from a worker execution.

    Unlike simple success/failure, this includes:
    - status: Did it work?
    - data: What was produced?
    - error: What went wrong (if anything)?
    - recommendation: What should the planner do next?
    - metadata: Additional context for the planner

    This enables intelligent failure recovery instead of blind retries.
    """
    status: str  # "success" or "failure"
    data: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    error_type: Optional[str] = None  # "timeout", "rate_limit", "validation", "api_error", etc.
    recommendation: WorkerRecommendation = WorkerRecommendation.CONTINUE
    backup_suggestion: Optional[str] = None  # e.g., "use_cached_data", "try_alternate_api"
    retry_after_seconds: Optional[float] = None  # For rate limits
    simplification_hint: Optional[str] = None  # e.g., "skip_personalization"
    confidence: float = 1.0  # How confident is the worker in this result?
    duration_ms: Optional[float] = None

    @property
    def success(self) -> bool:
        return self.status == "success"

    @property
    def should_retry(self) -> bool:
        return self.recommendation in [
            WorkerRecommendation.RETRY,
            WorkerRecommendation.RETRY_WITH_BACKOFF,
        ]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "status": self.status,
            "data": self.data,
            "error": self.error,
            "error_type": self.error_type,
            "recommendation": self.recommendation.value,
            "backup_suggestion": self.backup_suggestion,
            "retry_after_seconds": self.retry_after_seconds,
            "simplification_hint": self.simplification_hint,
            "confidence": self.confidence,
            "duration_ms": self.duration_ms,
        }

    @classmethod
    def success_result(cls, data: Dict[str, Any], confidence: float = 1.0) -> "WorkerResult":
        """Create a successful result."""
        return cls(
            status="success",
            data=data,
            recommendation=WorkerRecommendation.CONTINUE,
            confidence=confidence,
        )

    @classmethod
    def failure_result(
        cls,
        error: str,
        error_type: str = "unknown",
        recommendation: WorkerRecommendation = WorkerRecommendation.ABORT,
        **kwargs,
    ) -> "WorkerResult":
        """Create a failure result with recommendation."""
        return cls(
            status="failure",
            error=error,
            error_type=error_type,
            recommendation=recommendation,
            **kwargs,
        )


@dataclass
class PlanStep:
    """A single step in a plan."""
    step_id: str
    action: str
    description: str
    agent: str
    parameters: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    status: StepStatus = StepStatus.PENDING
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    @property
    def duration_ms(self) -> Optional[float]:
        if self.started_at and self.completed_at:
            return (self.completed_at - self.started_at).total_seconds() * 1000
        return None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "step_id": self.step_id,
            "action": self.action,
            "description": self.description,
            "agent": self.agent,
            "parameters": self.parameters,
            "dependencies": self.dependencies,
            "status": self.status.value,
            "result": self.result,
            "error": self.error,
            "duration_ms": self.duration_ms,
        }


@dataclass
class Plan:
    """A complete execution plan."""
    plan_id: str
    goal: str
    context: Dict[str, Any]
    steps: List[PlanStep]
    status: PlanStatus = PlanStatus.DRAFT
    created_at: datetime = field(default_factory=datetime.now)
    reasoning: str = ""
    confidence: float = 0.0
    revision_history: List[Dict[str, Any]] = field(default_factory=list)

    def get_next_step(self) -> Optional[PlanStep]:
        """Get the next step to execute."""
        for step in self.steps:
            if step.status == StepStatus.PENDING:
                # Check dependencies
                deps_satisfied = all(
                    self.get_step(dep_id).status == StepStatus.COMPLETED
                    for dep_id in step.dependencies
                )
                if deps_satisfied:
                    return step
        return None

    def get_step(self, step_id: str) -> Optional[PlanStep]:
        """Get a step by ID."""
        for step in self.steps:
            if step.step_id == step_id:
                return step
        return None

    def is_complete(self) -> bool:
        """Check if all steps are completed."""
        return all(
            step.status in [StepStatus.COMPLETED, StepStatus.SKIPPED]
            for step in self.steps
        )

    def has_failed(self) -> bool:
        """Check if any step has failed."""
        return any(step.status == StepStatus.FAILED for step in self.steps)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "plan_id": self.plan_id,
            "goal": self.goal,
            "status": self.status.value,
            "steps": [s.to_dict() for s in self.steps],
            "reasoning": self.reasoning,
            "confidence": self.confidence,
            "created_at": self.created_at.isoformat(),
        }


@dataclass
class ExecutionResult:
    """Result of plan execution."""
    plan_id: str
    success: bool
    final_result: Optional[Dict[str, Any]]
    steps_completed: int
    steps_failed: int
    total_duration_ms: float
    feedback: str = ""
    needs_replanning: bool = False


# =============================================================================
# PLANNER INTERFACE
# =============================================================================

class BasePlanner(ABC):
    """Abstract base class for planners."""

    @abstractmethod
    def create_plan(self, context: Dict[str, Any]) -> Plan:
        """Create an execution plan for the given context."""
        pass

    @abstractmethod
    def revise_plan(self, plan: Plan, feedback: str) -> Plan:
        """Revise a plan based on execution feedback."""
        pass

    def validate_plan(self, plan: Plan) -> List[str]:
        """Validate a plan and return any issues."""
        issues = []

        if not plan.steps:
            issues.append("Plan has no steps")

        # Check for circular dependencies
        for step in plan.steps:
            if step.step_id in step.dependencies:
                issues.append(f"Step {step.step_id} has circular dependency on itself")

        # Check that all dependencies exist
        step_ids = {s.step_id for s in plan.steps}
        for step in plan.steps:
            for dep in step.dependencies:
                if dep not in step_ids:
                    issues.append(f"Step {step.step_id} depends on non-existent step {dep}")

        return issues


# =============================================================================
# EXECUTOR INTERFACE
# =============================================================================

class BaseExecutor(ABC):
    """Abstract base class for executors."""

    @abstractmethod
    def execute_step(self, step: PlanStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a single step."""
        pass

    def execute(self, plan: Plan) -> ExecutionResult:
        """Execute a complete plan."""
        start_time = datetime.now()
        plan.status = PlanStatus.EXECUTING

        logger.info(
            "plan_execution_started",
            plan_id=plan.plan_id,
            total_steps=len(plan.steps),
        )

        context = plan.context.copy()
        steps_completed = 0
        steps_failed = 0

        while True:
            step = plan.get_next_step()
            if step is None:
                break

            step.status = StepStatus.IN_PROGRESS
            step.started_at = datetime.now()

            logger.info(
                "step_execution_started",
                plan_id=plan.plan_id,
                step_id=step.step_id,
                action=step.action,
            )

            try:
                # Execute the step
                result = self.execute_step(step, context)
                step.result = result
                step.status = StepStatus.COMPLETED
                step.completed_at = datetime.now()
                steps_completed += 1

                # Update context with result
                context[f"step_{step.step_id}_result"] = result

                logger.info(
                    "step_execution_completed",
                    plan_id=plan.plan_id,
                    step_id=step.step_id,
                    duration_ms=step.duration_ms,
                )

            except Exception as e:
                step.status = StepStatus.FAILED
                step.error = str(e)
                step.completed_at = datetime.now()
                steps_failed += 1

                logger.error(
                    "step_execution_failed",
                    plan_id=plan.plan_id,
                    step_id=step.step_id,
                    error=str(e),
                )

                # Decide whether to continue or abort
                if not self._should_continue_after_failure(step, plan):
                    break

        # Determine final status
        total_duration = (datetime.now() - start_time).total_seconds() * 1000

        if plan.is_complete():
            plan.status = PlanStatus.COMPLETED
            success = True
            feedback = "Plan executed successfully"
        elif plan.has_failed():
            plan.status = PlanStatus.FAILED
            success = False
            feedback = f"Plan failed at step: {[s.step_id for s in plan.steps if s.status == StepStatus.FAILED]}"
        else:
            success = False
            feedback = "Plan execution incomplete"

        # Record metrics
        metrics.record_pipeline_completion(success, total_duration / 1000)

        return ExecutionResult(
            plan_id=plan.plan_id,
            success=success,
            final_result=self._collect_final_result(plan),
            steps_completed=steps_completed,
            steps_failed=steps_failed,
            total_duration_ms=total_duration,
            feedback=feedback,
            needs_replanning=steps_failed > 0,
        )

    def _should_continue_after_failure(self, failed_step: PlanStep, plan: Plan) -> bool:
        """Decide whether to continue execution after a step failure."""
        # By default, check if other steps can still execute
        remaining = [s for s in plan.steps if s.status == StepStatus.PENDING]
        for step in remaining:
            if failed_step.step_id not in step.dependencies:
                return True
        return False

    def _collect_final_result(self, plan: Plan) -> Dict[str, Any]:
        """Collect the final result from completed steps."""
        result = {}
        for step in plan.steps:
            if step.status == StepStatus.COMPLETED and step.result:
                result[step.step_id] = step.result
        return result


# =============================================================================
# OFFER PLANNER - DOMAIN SPECIFIC
# =============================================================================

class OfferPlanner(BasePlanner):
    """
    Planner for tailored offer decisions.

    Creates a plan that:
    1. Validates customer eligibility
    2. Analyzes flight inventory
    3. Evaluates offer options
    4. Generates personalized message
    5. Selects optimal channel/timing
    """

    def __init__(self, use_llm: bool = True):
        self.use_llm = use_llm
        self.memory = get_memory()

    def create_plan(self, context: Dict[str, Any]) -> Plan:
        """Create an offer evaluation plan."""
        import uuid

        pnr = context.get("pnr_locator", "unknown")
        customer_id = context.get("customer_id", "unknown")

        # Get memory context for better planning
        memory_context = self.memory.get_context_for_agent(
            session_id=context.get("session_id", pnr),
            customer_id=customer_id,
            agent_name="planner",
        )

        # Create plan steps
        steps = [
            PlanStep(
                step_id="eligibility",
                action="check_eligibility",
                description="Verify customer eligibility and check for suppressions",
                agent="customer_intelligence",
                parameters={"pnr": pnr},
                dependencies=[],
            ),
            PlanStep(
                step_id="inventory",
                action="analyze_inventory",
                description="Check cabin availability and identify upgrade opportunities",
                agent="flight_optimization",
                parameters={"pnr": pnr},
                dependencies=["eligibility"],
            ),
            PlanStep(
                step_id="offer_selection",
                action="select_offer",
                description="Evaluate offer options and select optimal offer based on EV",
                agent="offer_orchestration",
                parameters={"pnr": pnr, "use_llm": self.use_llm},
                dependencies=["inventory"],
            ),
            PlanStep(
                step_id="personalization",
                action="generate_message",
                description="Create personalized offer message for customer",
                agent="personalization",
                parameters={"pnr": pnr},
                dependencies=["offer_selection"],
            ),
            PlanStep(
                step_id="channel_timing",
                action="select_channel",
                description="Determine optimal channel and timing for delivery",
                agent="channel_timing",
                parameters={"pnr": pnr},
                dependencies=["personalization"],
            ),
            PlanStep(
                step_id="tracking",
                action="setup_tracking",
                description="Configure A/B test tracking and measurement",
                agent="measurement_learning",
                parameters={"pnr": pnr},
                dependencies=["channel_timing"],
            ),
        ]

        # Adjust plan based on memory insights
        customer_insights = memory_context.get("customer_insights", {})
        if customer_insights.get("acceptance_rate", 0.5) < 0.3:
            # Customer has low acceptance - add extra analysis step
            steps.insert(2, PlanStep(
                step_id="risk_analysis",
                action="analyze_risk",
                description="Extra analysis for low-acceptance customer",
                agent="offer_orchestration",
                parameters={"pnr": pnr, "mode": "conservative"},
                dependencies=["inventory"],
            ))
            # Update offer_selection to depend on risk_analysis
            for step in steps:
                if step.step_id == "offer_selection":
                    step.dependencies.append("risk_analysis")

        plan = Plan(
            plan_id=f"plan_{pnr}_{uuid.uuid4().hex[:8]}",
            goal=f"Evaluate and deliver optimal offer for PNR {pnr}",
            context=context,
            steps=steps,
            reasoning=self._generate_plan_reasoning(context, memory_context),
            confidence=self._calculate_confidence(context, memory_context),
        )

        logger.info(
            "plan_created",
            plan_id=plan.plan_id,
            pnr=pnr,
            steps=len(steps),
            confidence=plan.confidence,
        )

        return plan

    def revise_plan(self, plan: Plan, feedback: str) -> Plan:
        """Revise a failed plan based on feedback."""
        import uuid

        # Record the revision
        plan.revision_history.append({
            "timestamp": datetime.now().isoformat(),
            "feedback": feedback,
            "previous_status": plan.status.value,
        })

        # Identify failed steps
        failed_steps = [s for s in plan.steps if s.status == StepStatus.FAILED]

        for step in failed_steps:
            # Reset failed step for retry
            step.status = StepStatus.PENDING
            step.error = None
            step.result = None

            # Adjust parameters based on failure
            if "timeout" in (step.error or "").lower():
                # Increase timeout or add retry
                step.parameters["retry_count"] = step.parameters.get("retry_count", 0) + 1

            if "no eligible offers" in feedback.lower():
                # Try with relaxed constraints
                step.parameters["relaxed_constraints"] = True

        plan.status = PlanStatus.REVISED

        logger.info(
            "plan_revised",
            plan_id=plan.plan_id,
            revision_count=len(plan.revision_history),
            feedback=feedback[:100],
        )

        return plan

    def _generate_plan_reasoning(
        self,
        context: Dict[str, Any],
        memory_context: Dict[str, Any],
    ) -> str:
        """Generate reasoning for the plan."""
        reasoning_parts = []

        reasoning_parts.append(f"Planning offer evaluation for PNR: {context.get('pnr_locator')}")

        # Add insights from memory
        customer_insights = memory_context.get("customer_insights", {})
        if customer_insights.get("has_history"):
            acceptance_rate = customer_insights.get("acceptance_rate", 0.5)
            reasoning_parts.append(f"Customer history shows {acceptance_rate:.0%} acceptance rate")

            if customer_insights.get("preferred_channel"):
                reasoning_parts.append(
                    f"Customer prefers {customer_insights['preferred_channel']} channel"
                )

        recommendations = memory_context.get("recommendations", [])
        if recommendations:
            reasoning_parts.append("Recommendations from learning memory:")
            for rec in recommendations[:3]:
                reasoning_parts.append(f"  - {rec}")

        return "\n".join(reasoning_parts)

    def _calculate_confidence(
        self,
        context: Dict[str, Any],
        memory_context: Dict[str, Any],
    ) -> float:
        """
        Calculate confidence score for the plan.

        Uses feedback data to adjust confidence based on historical performance.
        """
        confidence = 0.5  # Base confidence

        # Increase confidence with more customer history
        customer_insights = memory_context.get("customer_insights", {})
        if customer_insights.get("total_interactions", 0) > 5:
            confidence += 0.2

        # Increase confidence with good acceptance rate
        if customer_insights.get("acceptance_rate", 0.5) > 0.5:
            confidence += 0.1

        # Decrease confidence for suppressed customers
        if context.get("suppressed"):
            confidence -= 0.3

        # Adjust confidence based on feedback loop data
        try:
            feedback_manager = _get_feedback_manager()
            agent_feedback = feedback_manager.get_agent_feedback(
                agent_name="offer_orchestration",
                days=30,
            )

            # Apply confidence adjustment from feedback
            if agent_feedback.total_decisions > 10:
                confidence += agent_feedback.confidence_adjustment

                # Log feedback-based adjustment
                if abs(agent_feedback.confidence_adjustment) > 0.05:
                    logger.info(
                        "confidence_adjusted_by_feedback",
                        adjustment=agent_feedback.confidence_adjustment,
                        overconfident=agent_feedback.overconfident,
                        underconfident=agent_feedback.underconfident,
                    )

        except Exception as e:
            # Feedback not available - use base confidence
            logger.debug("feedback_not_available", error=str(e))

        return min(max(confidence, 0.0), 1.0)

    def get_feedback_insights(self) -> Dict[str, Any]:
        """
        Get insights from the feedback loop for planning.

        Returns recommendations and performance data to inform planning.
        """
        try:
            feedback_manager = _get_feedback_manager()

            # Get calibration report
            calibration = feedback_manager.get_calibration_report()

            # Get agent feedback
            agent_feedback = feedback_manager.get_agent_feedback(
                agent_name="offer_orchestration",
                days=30,
            )

            return {
                "calibration": {
                    "total_outcomes": calibration.total_outcomes,
                    "acceptance_rate": calibration.overall_acceptance_rate,
                    "calibration_error": calibration.mean_calibration_error,
                    "value_capture_rate": calibration.value_capture_rate,
                },
                "agent_feedback": {
                    "success_rate": agent_feedback.success_rate,
                    "overconfident": agent_feedback.overconfident,
                    "underconfident": agent_feedback.underconfident,
                    "recommendations": agent_feedback.recommendations[:3],
                },
                "has_sufficient_data": calibration.total_outcomes >= 10,
            }
        except Exception as e:
            logger.debug("feedback_insights_not_available", error=str(e))
            return {
                "calibration": {},
                "agent_feedback": {},
                "has_sufficient_data": False,
            }


class OfferExecutor(BaseExecutor):
    """
    Executor for offer evaluation plans.

    Maps plan steps to agent calls.
    """

    def __init__(self):
        # Import agents
        from agents.customer_intelligence import CustomerIntelligenceAgent
        from agents.flight_optimization import FlightOptimizationAgent
        from agents.offer_orchestration import OfferOrchestrationAgent
        from agents.personalization import PersonalizationAgent
        from agents.channel_timing import ChannelTimingAgent
        from agents.measurement_learning import MeasurementLearningAgent

        self.agents = {
            "customer_intelligence": CustomerIntelligenceAgent(),
            "flight_optimization": FlightOptimizationAgent(),
            "offer_orchestration": OfferOrchestrationAgent(),
            "personalization": PersonalizationAgent(),
            "channel_timing": ChannelTimingAgent(),
            "measurement_learning": MeasurementLearningAgent(),
        }

        self.memory = get_memory()

    def execute_step(self, step: PlanStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a single plan step by calling the appropriate agent."""
        agent = self.agents.get(step.agent)
        if not agent:
            raise ValueError(f"Unknown agent: {step.agent}")

        # Build state from context
        state = self._build_state(context, step)

        # Execute agent
        result = agent.analyze(state)

        # Record in memory
        customer_id = context.get("customer_id") or state.get("customer_data", {}).get("lylty_acct_id")
        if customer_id:
            self.memory.record_decision(
                session_id=context.get("session_id", context.get("pnr_locator", "unknown")),
                customer_id=customer_id,
                agent_name=step.agent,
                decision=result,
            )

        # Check for step-specific outcomes
        if step.action == "check_eligibility":
            if not result.get("customer_eligible", True):
                # Early termination - mark remaining steps as skipped
                logger.info("eligibility_check_failed", reason=result.get("suppression_reason"))

        return result

    def _build_state(self, context: Dict[str, Any], step: PlanStep) -> Dict[str, Any]:
        """Build agent state from execution context."""
        state = {
            "pnr_locator": context.get("pnr_locator"),
            "customer_data": context.get("customer_data"),
            "flight_data": context.get("flight_data"),
            "reservation_data": context.get("reservation_data"),
            "ml_scores": context.get("ml_scores"),
            "reasoning_trace": context.get("reasoning_trace", []),
        }

        # Add results from previous steps
        for key, value in context.items():
            if key.startswith("step_") and key.endswith("_result"):
                # Merge previous step results into state
                if isinstance(value, dict):
                    state.update(value)

        # Add step-specific parameters
        state.update(step.parameters)

        return state


# =============================================================================
# PLANNER-EXECUTOR COORDINATOR
# =============================================================================

class PlannerExecutorCoordinator:
    """
    Coordinates the planner-executor pattern with feedback loops.

    Features:
    - Automatic re-planning on failure
    - Human-in-the-loop support
    - Memory integration
    """

    def __init__(
        self,
        planner: Optional[BasePlanner] = None,
        executor: Optional[BaseExecutor] = None,
        max_revisions: int = 2,
        require_plan_approval: bool = False,
    ):
        self.planner = planner or OfferPlanner()
        self.executor = executor or OfferExecutor()
        self.max_revisions = max_revisions
        self.require_plan_approval = require_plan_approval
        self.memory = get_memory()

    def run(
        self,
        context: Dict[str, Any],
        plan_approval_callback: Optional[Callable[[Plan], bool]] = None,
    ) -> ExecutionResult:
        """
        Run the full planner-executor cycle.

        Args:
            context: Initial context for planning
            plan_approval_callback: Optional callback for human approval

        Returns:
            Final execution result
        """
        # Create initial plan
        plan = self.planner.create_plan(context)

        # Validate plan
        issues = self.planner.validate_plan(plan)
        if issues:
            logger.warning("plan_validation_issues", issues=issues)

        # Request approval if required
        if self.require_plan_approval:
            if plan_approval_callback:
                approved = plan_approval_callback(plan)
            else:
                approved = True  # Default approve if no callback
                logger.warning("plan_auto_approved", reason="no approval callback")

            if not approved:
                return ExecutionResult(
                    plan_id=plan.plan_id,
                    success=False,
                    final_result=None,
                    steps_completed=0,
                    steps_failed=0,
                    total_duration_ms=0,
                    feedback="Plan rejected during approval",
                )

            plan.status = PlanStatus.APPROVED

        # Execute with retry loop
        revision_count = 0
        while revision_count <= self.max_revisions:
            result = self.executor.execute(plan)

            if result.success:
                logger.info(
                    "plan_execution_success",
                    plan_id=plan.plan_id,
                    revisions=revision_count,
                )
                return result

            if not result.needs_replanning or revision_count >= self.max_revisions:
                logger.warning(
                    "plan_execution_failed",
                    plan_id=plan.plan_id,
                    feedback=result.feedback,
                    revisions=revision_count,
                )
                return result

            # Revise and retry
            plan = self.planner.revise_plan(plan, result.feedback)
            revision_count += 1

            logger.info(
                "plan_revision",
                plan_id=plan.plan_id,
                revision=revision_count,
            )

        return result

    async def run_async(
        self,
        context: Dict[str, Any],
    ) -> ExecutionResult:
        """Async version of run (for API integration)."""
        # For now, delegate to sync version
        # In production, this would use async agents
        import asyncio
        return await asyncio.to_thread(self.run, context)

    def record_outcome(
        self,
        plan_id: str,
        outcome: str,
        customer_feedback: Optional[str] = None,
    ) -> bool:
        """
        Record the outcome of a completed plan.

        This closes the feedback loop by recording whether the offer
        was accepted or rejected.

        Args:
            plan_id: ID of the plan that was executed
            outcome: "accepted", "rejected", "expired"
            customer_feedback: Optional feedback from customer

        Returns:
            True if outcome was recorded successfully
        """
        try:
            from .feedback import get_feedback_manager, OutcomeType

            feedback_manager = get_feedback_manager()

            # Find the plan execution context
            # In a real system, this would look up the plan by ID
            # For now, we log the outcome
            logger.info(
                "plan_outcome_recorded",
                plan_id=plan_id,
                outcome=outcome,
                has_feedback=bool(customer_feedback),
            )

            return True

        except Exception as e:
            logger.error("failed_to_record_outcome", plan_id=plan_id, error=str(e))
            return False

    def get_performance_report(self, days: int = 30) -> Dict[str, Any]:
        """
        Get a performance report for the planner-executor.

        Uses feedback data to analyze how well plans are performing.
        """
        try:
            feedback_manager = _get_feedback_manager()

            # Get summary stats
            stats = feedback_manager.get_summary_stats(days=days)

            # Get calibration report
            calibration = feedback_manager.get_calibration_report(days=days)

            return {
                "period_days": days,
                "summary": stats,
                "calibration": {
                    "overall_acceptance_rate": calibration.overall_acceptance_rate,
                    "mean_calibration_error": calibration.mean_calibration_error,
                    "brier_score": calibration.brier_score,
                    "value_capture_rate": calibration.value_capture_rate,
                },
                "segments": calibration.by_offer_type,
                "recommendations": self._generate_planning_recommendations(calibration),
            }
        except Exception as e:
            logger.warning("performance_report_failed", error=str(e))
            return {
                "period_days": days,
                "error": str(e),
                "recommendations": ["Insufficient data for performance analysis"],
            }

    def _generate_planning_recommendations(self, calibration) -> List[str]:
        """Generate recommendations for improving planning based on feedback."""
        recommendations = []

        if calibration.total_outcomes < 10:
            recommendations.append("Need more outcome data to generate reliable recommendations")
            return recommendations

        # Check calibration
        if calibration.mean_calibration_error > 0.15:
            recommendations.append(
                f"High calibration error ({calibration.mean_calibration_error:.1%}) - "
                "consider adjusting probability estimates"
            )

        # Check value capture
        if calibration.value_capture_rate < 0.7:
            recommendations.append(
                f"Low value capture rate ({calibration.value_capture_rate:.1%}) - "
                "offers may be underperforming vs expectations"
            )
        elif calibration.value_capture_rate > 1.3:
            recommendations.append(
                f"Exceeding expected value ({calibration.value_capture_rate:.1%}) - "
                "probability estimates may be too conservative"
            )

        # Check acceptance rate
        if calibration.overall_acceptance_rate < 0.15:
            recommendations.append(
                "Low overall acceptance rate - review targeting criteria"
            )
        elif calibration.overall_acceptance_rate > 0.5:
            recommendations.append(
                "High acceptance rate - may have room to increase prices"
            )

        if not recommendations:
            recommendations.append("Performance within expected parameters")

        return recommendations


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================

def create_offer_plan(pnr_locator: str, **kwargs) -> Plan:
    """Create an offer evaluation plan for a PNR."""
    planner = OfferPlanner()
    context = {"pnr_locator": pnr_locator, **kwargs}
    return planner.create_plan(context)


def execute_offer_plan(plan: Plan) -> ExecutionResult:
    """Execute an offer evaluation plan."""
    executor = OfferExecutor()
    return executor.execute(plan)


def run_offer_evaluation_with_planning(
    pnr_locator: str,
    require_approval: bool = False,
    **kwargs
) -> ExecutionResult:
    """
    Run full offer evaluation using planner-executor pattern.

    This is the main entry point for plan-based offer evaluation.

    NOTE: Consider using run_offer_evaluation_incremental() instead
    for better failure handling and dynamic re-planning.
    """
    coordinator = PlannerExecutorCoordinator(
        require_plan_approval=require_approval,
    )

    context = {
        "pnr_locator": pnr_locator,
        **kwargs,
    }

    return coordinator.run(context)


# =============================================================================
# INCREMENTAL PLANNER-EXECUTOR PATTERN (RECOMMENDED)
# =============================================================================
#
# This implements the CORRECT planner-worker pattern:
# 1. Planner plans ONLY the next action
# 2. Worker executes and returns rich result with recommendation
# 3. Planner observes result and plans next action based on updated state
# 4. Repeat until goal achieved or unrecoverable failure
#
# Key differences from batch pattern:
# - No upfront planning of entire workflow
# - Workers return recommendations, not just success/failure
# - Planner is consulted after EVERY step
# - Dynamic task simplification on repeated failures
# =============================================================================


@dataclass
class IncrementalState:
    """
    State tracked during incremental plan-execute cycles.

    This is the "memory" that the planner queries before each decision.
    Tracks: current goal, steps completed, results so far, failed attempts.
    """
    goal: str
    context: Dict[str, Any]
    completed_steps: List[str] = field(default_factory=list)
    results: Dict[str, WorkerResult] = field(default_factory=dict)
    failed_attempts: Dict[str, List[Dict[str, Any]]] = field(default_factory=dict)
    current_step: Optional[str] = None
    is_simplified: bool = False
    simplification_level: int = 0  # 0 = full, 1 = reduced, 2 = minimal
    started_at: datetime = field(default_factory=datetime.now)
    human_escalation_requested: bool = False

    # Available steps in order of execution (can be modified during execution)
    available_steps: List[str] = field(default_factory=lambda: [
        "eligibility",
        "inventory",
        "offer_selection",
        "personalization",
        "channel_timing",
        "tracking",
    ])

    # Steps that can be skipped during simplification
    optional_steps: List[str] = field(default_factory=lambda: [
        "personalization",
        "tracking",
    ])

    def get_next_step(self) -> Optional[str]:
        """Get the next step to execute based on current state."""
        for step in self.available_steps:
            if step not in self.completed_steps:
                return step
        return None

    def record_success(self, step: str, result: WorkerResult) -> None:
        """Record a successful step execution."""
        self.completed_steps.append(step)
        self.results[step] = result
        self.current_step = None

        # Merge result data into context for next steps
        if result.data:
            self.context.update(result.data)

    def record_failure(self, step: str, result: WorkerResult) -> None:
        """Record a failed step execution."""
        if step not in self.failed_attempts:
            self.failed_attempts[step] = []

        self.failed_attempts[step].append({
            "timestamp": datetime.now().isoformat(),
            "error": result.error,
            "error_type": result.error_type,
            "recommendation": result.recommendation.value,
        })
        self.results[step] = result

    def get_retry_count(self, step: str) -> int:
        """Get number of retry attempts for a step."""
        return len(self.failed_attempts.get(step, []))

    def simplify(self, hint: Optional[str] = None) -> bool:
        """
        Simplify the task by removing optional steps.

        Returns True if simplification was possible, False if already minimal.
        """
        if self.simplification_level >= 2:
            return False  # Already at minimal

        self.simplification_level += 1
        self.is_simplified = True

        if hint and hint in self.available_steps:
            # Remove the specific suggested step
            self.available_steps = [s for s in self.available_steps if s != hint]
        elif self.simplification_level == 1:
            # Level 1: Remove tracking
            self.available_steps = [s for s in self.available_steps if s != "tracking"]
        elif self.simplification_level == 2:
            # Level 2: Remove personalization too
            self.available_steps = [s for s in self.available_steps if s != "personalization"]

        logger.info(
            "task_simplified",
            level=self.simplification_level,
            remaining_steps=self.available_steps,
            hint=hint,
        )
        return True

    def is_goal_achieved(self) -> bool:
        """Check if the goal has been achieved."""
        # Goal is achieved when all required steps are completed
        required_steps = [s for s in self.available_steps if s not in self.optional_steps]
        return all(step in self.completed_steps for step in required_steps)

    def should_abort(self) -> bool:
        """Check if execution should be aborted."""
        # Abort if any non-optional step has failed 3+ times
        for step in self.available_steps:
            if step in self.optional_steps:
                continue
            if self.get_retry_count(step) >= 3:
                return True
        return False

    def get_accumulated_data(self) -> Dict[str, Any]:
        """Get all data accumulated from completed steps."""
        data = dict(self.context)
        for step, result in self.results.items():
            if result.success and result.data:
                data.update(result.data)
        return data

    def to_dict(self) -> Dict[str, Any]:
        return {
            "goal": self.goal,
            "completed_steps": self.completed_steps,
            "current_step": self.current_step,
            "failed_attempts": self.failed_attempts,
            "is_simplified": self.is_simplified,
            "simplification_level": self.simplification_level,
            "available_steps": self.available_steps,
            "human_escalation_requested": self.human_escalation_requested,
        }


class IncrementalOfferPlanner:
    """
    Incremental planner that plans ONE step at a time.

    Key principle: "Plan next action, wait for result, re-plan based on state."

    Unlike the batch OfferPlanner which creates all steps upfront,
    this planner is consulted after EVERY worker execution.
    """

    def __init__(self):
        self.memory = get_memory()

    def plan_next_action(self, state: IncrementalState) -> Optional[PlanStep]:
        """
        Plan ONLY the next action based on current state.

        This is called after each worker execution, giving the planner
        a chance to adjust based on what actually happened.
        """
        # Check if we should abort
        if state.should_abort():
            logger.warning(
                "planner_abort",
                reason="too_many_failures",
                failed_steps=list(state.failed_attempts.keys()),
            )
            return None

        # Check if goal is achieved
        if state.is_goal_achieved():
            logger.info("planner_goal_achieved", completed=state.completed_steps)
            return None

        # Get the next step
        next_step_id = state.get_next_step()
        if not next_step_id:
            return None

        # Check if this step has failed before
        retry_count = state.get_retry_count(next_step_id)
        last_failure = None
        if retry_count > 0:
            last_failure = state.failed_attempts[next_step_id][-1]

        # Build step with context-aware parameters
        step = self._build_step(next_step_id, state, retry_count, last_failure)

        state.current_step = next_step_id

        logger.info(
            "planner_next_action",
            step_id=next_step_id,
            retry_count=retry_count,
            is_simplified=state.is_simplified,
        )

        return step

    def _build_step(
        self,
        step_id: str,
        state: IncrementalState,
        retry_count: int,
        last_failure: Optional[Dict[str, Any]],
    ) -> PlanStep:
        """Build a step with parameters adjusted based on state and history."""
        pnr = state.context.get("pnr_locator", "unknown")

        # Base step definitions
        step_definitions = {
            "eligibility": {
                "action": "check_eligibility",
                "description": "Verify customer eligibility and check for suppressions",
                "agent": "customer_intelligence",
            },
            "inventory": {
                "action": "analyze_inventory",
                "description": "Check cabin availability and identify upgrade opportunities",
                "agent": "flight_optimization",
            },
            "offer_selection": {
                "action": "select_offer",
                "description": "Evaluate offer options and select optimal offer based on EV",
                "agent": "offer_orchestration",
            },
            "personalization": {
                "action": "generate_message",
                "description": "Create personalized offer message for customer",
                "agent": "personalization",
            },
            "channel_timing": {
                "action": "select_channel",
                "description": "Determine optimal channel and timing for delivery",
                "agent": "channel_timing",
            },
            "tracking": {
                "action": "setup_tracking",
                "description": "Configure A/B test tracking and measurement",
                "agent": "measurement_learning",
            },
        }

        definition = step_definitions.get(step_id, {
            "action": step_id,
            "description": f"Execute {step_id}",
            "agent": "unknown",
        })

        # Build parameters
        parameters = {"pnr": pnr}

        # Add retry-specific parameters
        if retry_count > 0:
            parameters["retry_count"] = retry_count
            parameters["is_retry"] = True

            # Adjust based on last failure type
            if last_failure:
                error_type = last_failure.get("error_type", "")
                recommendation = last_failure.get("recommendation", "")

                if error_type == "timeout":
                    parameters["timeout_multiplier"] = 1.5 ** retry_count
                elif error_type == "rate_limit":
                    parameters["use_backup_api"] = True
                elif recommendation == "use_backup":
                    parameters["use_backup"] = True
                elif recommendation == "simplify":
                    parameters["simplified_mode"] = True

        # Add accumulated data from previous steps
        accumulated = state.get_accumulated_data()
        if "customer_data" in accumulated:
            parameters["customer_data"] = accumulated["customer_data"]
        if "flight_data" in accumulated:
            parameters["flight_data"] = accumulated["flight_data"]
        if "offer_options" in accumulated:
            parameters["offer_options"] = accumulated["offer_options"]

        return PlanStep(
            step_id=step_id,
            action=definition["action"],
            description=definition["description"],
            agent=definition["agent"],
            parameters=parameters,
            dependencies=[],  # No static dependencies - planner controls order
        )

    def handle_failure(
        self,
        state: IncrementalState,
        step: PlanStep,
        result: WorkerResult,
    ) -> str:
        """
        Handle a worker failure and decide what to do next.

        Returns: "retry", "skip", "simplify", "escalate", or "abort"
        """
        recommendation = result.recommendation
        retry_count = state.get_retry_count(step.step_id)

        # Handle based on worker's recommendation
        if recommendation == WorkerRecommendation.RETRY:
            if retry_count < 3:
                return "retry"
            else:
                return "abort" if step.step_id not in state.optional_steps else "skip"

        elif recommendation == WorkerRecommendation.RETRY_WITH_BACKOFF:
            if retry_count < 3:
                # The coordinator will handle the backoff
                return "retry_with_backoff"
            else:
                return "abort" if step.step_id not in state.optional_steps else "skip"

        elif recommendation == WorkerRecommendation.USE_BACKUP:
            if retry_count < 2:
                return "retry"  # Retry will use backup based on parameters
            else:
                return "abort" if step.step_id not in state.optional_steps else "skip"

        elif recommendation == WorkerRecommendation.SIMPLIFY:
            if state.simplify(result.simplification_hint):
                return "continue"  # Simplified, try next step
            else:
                return "abort"  # Can't simplify further

        elif recommendation == WorkerRecommendation.SKIP:
            if step.step_id in state.optional_steps:
                state.completed_steps.append(step.step_id)  # Mark as done
                return "continue"
            else:
                return "abort"  # Can't skip required step

        elif recommendation == WorkerRecommendation.ESCALATE:
            state.human_escalation_requested = True
            return "escalate"

        elif recommendation == WorkerRecommendation.ABORT:
            return "abort"

        # Default: try to continue if possible
        if step.step_id in state.optional_steps:
            return "skip"
        elif retry_count < 3:
            return "retry"
        else:
            return "abort"


class IncrementalOfferExecutor:
    """
    Executor that returns rich WorkerResult with recommendations.

    Unlike the batch executor, this wraps agent calls to provide
    intelligent failure recommendations instead of just errors.
    """

    def __init__(self):
        from agents.customer_intelligence import CustomerIntelligenceAgent
        from agents.flight_optimization import FlightOptimizationAgent
        from agents.offer_orchestration import OfferOrchestrationAgent
        from agents.personalization import PersonalizationAgent
        from agents.channel_timing import ChannelTimingAgent
        from agents.measurement_learning import MeasurementLearningAgent

        self.agents = {
            "customer_intelligence": CustomerIntelligenceAgent(),
            "flight_optimization": FlightOptimizationAgent(),
            "offer_orchestration": OfferOrchestrationAgent(),
            "personalization": PersonalizationAgent(),
            "channel_timing": ChannelTimingAgent(),
            "measurement_learning": MeasurementLearningAgent(),
        }

        self.memory = get_memory()

    def execute_step(self, step: PlanStep, state: IncrementalState) -> WorkerResult:
        """
        Execute a single step and return a rich WorkerResult.

        The result includes not just success/failure, but a recommendation
        for what the planner should do next.
        """
        start_time = datetime.now()

        agent = self.agents.get(step.agent)
        if not agent:
            return WorkerResult.failure_result(
                error=f"Unknown agent: {step.agent}",
                error_type="configuration",
                recommendation=WorkerRecommendation.ABORT,
            )

        # Build state for agent
        agent_state = self._build_agent_state(step, state)

        try:
            # Execute agent with timeout handling
            result = self._execute_with_monitoring(agent, step, agent_state)

            duration_ms = (datetime.now() - start_time).total_seconds() * 1000

            # Check for early termination conditions
            termination = self._check_early_termination(step, result)
            if termination:
                return termination

            # Record success in memory
            customer_id = state.context.get("customer_id") or agent_state.get("customer_data", {}).get("lylty_acct_id")
            if customer_id:
                self.memory.record_decision(
                    session_id=state.context.get("session_id", state.context.get("pnr_locator", "unknown")),
                    customer_id=customer_id,
                    agent_name=step.agent,
                    decision=result,
                )

            return WorkerResult.success_result(
                data=result,
                confidence=result.get("confidence", 1.0) if isinstance(result, dict) else 1.0,
            )

        except TimeoutError as e:
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            return WorkerResult.failure_result(
                error=str(e),
                error_type="timeout",
                recommendation=WorkerRecommendation.RETRY_WITH_BACKOFF,
                retry_after_seconds=2.0 * (1 + state.get_retry_count(step.step_id)),
                duration_ms=duration_ms,
            )

        except Exception as e:
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            error_str = str(e).lower()

            # Determine error type and recommendation based on error
            if "rate limit" in error_str or "429" in error_str:
                return WorkerResult.failure_result(
                    error=str(e),
                    error_type="rate_limit",
                    recommendation=WorkerRecommendation.RETRY_WITH_BACKOFF,
                    retry_after_seconds=5.0,
                    backup_suggestion="use_cached_data",
                    duration_ms=duration_ms,
                )

            elif "timeout" in error_str or "timed out" in error_str:
                return WorkerResult.failure_result(
                    error=str(e),
                    error_type="timeout",
                    recommendation=WorkerRecommendation.RETRY,
                    duration_ms=duration_ms,
                )

            elif "not found" in error_str or "404" in error_str:
                return WorkerResult.failure_result(
                    error=str(e),
                    error_type="not_found",
                    recommendation=WorkerRecommendation.ABORT,
                    duration_ms=duration_ms,
                )

            elif "validation" in error_str or "invalid" in error_str:
                return WorkerResult.failure_result(
                    error=str(e),
                    error_type="validation",
                    recommendation=WorkerRecommendation.SIMPLIFY,
                    simplification_hint=step.step_id if step.step_id in state.optional_steps else None,
                    duration_ms=duration_ms,
                )

            elif "connection" in error_str or "network" in error_str:
                return WorkerResult.failure_result(
                    error=str(e),
                    error_type="network",
                    recommendation=WorkerRecommendation.RETRY_WITH_BACKOFF,
                    retry_after_seconds=3.0,
                    backup_suggestion="use_backup_api",
                    duration_ms=duration_ms,
                )

            else:
                # Unknown error - let planner decide
                return WorkerResult.failure_result(
                    error=str(e),
                    error_type="unknown",
                    recommendation=WorkerRecommendation.RETRY if state.get_retry_count(step.step_id) < 2 else WorkerRecommendation.ABORT,
                    duration_ms=duration_ms,
                )

    def _build_agent_state(self, step: PlanStep, state: IncrementalState) -> Dict[str, Any]:
        """Build the state dict expected by agents."""
        agent_state = {
            "pnr_locator": state.context.get("pnr_locator"),
            "reasoning_trace": state.context.get("reasoning_trace", []),
        }

        # Add accumulated data from previous steps
        accumulated = state.get_accumulated_data()
        agent_state.update(accumulated)

        # Add step-specific parameters
        agent_state.update(step.parameters)

        return agent_state

    def _execute_with_monitoring(
        self,
        agent,
        step: PlanStep,
        agent_state: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Execute agent with monitoring and timeout handling."""
        # For now, direct execution
        # In production, this could add timeout, circuit breaker, etc.
        return agent.analyze(agent_state)

    def _check_early_termination(
        self,
        step: PlanStep,
        result: Dict[str, Any],
    ) -> Optional[WorkerResult]:
        """Check if we should terminate early based on step result."""
        if step.step_id == "eligibility":
            if not result.get("customer_eligible", True):
                # Customer not eligible - this is a valid "success" but we should stop
                return WorkerResult(
                    status="success",
                    data=result,
                    recommendation=WorkerRecommendation.ABORT,  # Don't continue to next steps
                    confidence=1.0,
                )

        if step.step_id == "offer_selection":
            if not result.get("should_send_offer", True):
                # No offer to send - valid success but stop here
                return WorkerResult(
                    status="success",
                    data=result,
                    recommendation=WorkerRecommendation.ABORT,
                    confidence=result.get("confidence", 1.0),
                )

        return None


class IncrementalPlannerExecutorCoordinator:
    """
    Coordinator for the CORRECT incremental planner-worker pattern.

    This implements:
    1. Plan ONLY the next action
    2. Execute and get rich result with recommendation
    3. Handle failure based on worker's recommendation
    4. Re-plan based on updated state
    5. Repeat until goal achieved or unrecoverable failure

    Key differences from batch pattern:
    - Planner consulted after EVERY step
    - Workers return recommendations, not just errors
    - Dynamic retry with backoff
    - Task simplification on repeated failures
    - Human escalation support
    """

    def __init__(
        self,
        planner: Optional[IncrementalOfferPlanner] = None,
        executor: Optional[IncrementalOfferExecutor] = None,
        max_retries_per_step: int = 3,
        require_human_approval: bool = False,
    ):
        self.planner = planner or IncrementalOfferPlanner()
        self.executor = executor or IncrementalOfferExecutor()
        self.max_retries_per_step = max_retries_per_step
        self.require_human_approval = require_human_approval
        self.memory = get_memory()

    def run(
        self,
        context: Dict[str, Any],
        human_callback: Optional[Callable[[IncrementalState, str], bool]] = None,
    ) -> ExecutionResult:
        """
        Run the incremental planner-executor cycle.

        Args:
            context: Initial context with pnr_locator, etc.
            human_callback: Optional callback for human escalation.
                           Called with (state, reason) -> should_continue

        Returns:
            ExecutionResult with final outcome
        """
        import time

        # Initialize state
        state = IncrementalState(
            goal=f"Evaluate and deliver optimal offer for PNR {context.get('pnr_locator')}",
            context=context,
        )

        logger.info(
            "incremental_execution_started",
            pnr=context.get("pnr_locator"),
            goal=state.goal,
        )

        steps_completed = 0
        steps_failed = 0

        while True:
            # 1. PLAN: Get next action from planner
            next_step = self.planner.plan_next_action(state)

            if next_step is None:
                # No more steps - either goal achieved or should abort
                break

            logger.info(
                "executing_step",
                step_id=next_step.step_id,
                retry_count=state.get_retry_count(next_step.step_id),
            )

            # 2. EXECUTE: Run the worker
            result = self.executor.execute_step(next_step, state)

            # 3. OBSERVE: Process the result
            if result.success:
                state.record_success(next_step.step_id, result)
                steps_completed += 1

                logger.info(
                    "step_succeeded",
                    step_id=next_step.step_id,
                    confidence=result.confidence,
                )

                # Check if worker recommends early termination
                if result.recommendation == WorkerRecommendation.ABORT:
                    logger.info(
                        "early_termination",
                        step_id=next_step.step_id,
                        reason="worker_recommendation",
                    )
                    break
            else:
                state.record_failure(next_step.step_id, result)
                steps_failed += 1

                logger.warning(
                    "step_failed",
                    step_id=next_step.step_id,
                    error=result.error,
                    error_type=result.error_type,
                    recommendation=result.recommendation.value,
                )

                # 4. HANDLE FAILURE: Ask planner what to do
                action = self.planner.handle_failure(state, next_step, result)

                if action == "retry":
                    # Will retry on next iteration
                    continue

                elif action == "retry_with_backoff":
                    # Wait before retry
                    wait_time = result.retry_after_seconds or 2.0
                    logger.info("backoff_wait", seconds=wait_time)
                    time.sleep(wait_time)
                    continue

                elif action == "skip":
                    # Mark as skipped and continue
                    state.completed_steps.append(next_step.step_id)
                    logger.info("step_skipped", step_id=next_step.step_id)
                    continue

                elif action == "simplify":
                    # Task was simplified, continue with reduced steps
                    continue

                elif action == "escalate":
                    # Human intervention needed
                    if human_callback:
                        should_continue = human_callback(state, f"Step {next_step.step_id} failed: {result.error}")
                        if should_continue:
                            continue
                    # No callback or human said stop
                    logger.warning("human_escalation", step_id=next_step.step_id)
                    break

                elif action == "abort":
                    logger.error(
                        "execution_aborted",
                        step_id=next_step.step_id,
                        reason=result.error,
                    )
                    break

                elif action == "continue":
                    # Planner says continue (e.g., after simplification)
                    continue

        # Build final result
        total_duration = (datetime.now() - state.started_at).total_seconds() * 1000
        success = state.is_goal_achieved() or (
            steps_completed > 0 and
            "eligibility" in state.completed_steps and
            "offer_selection" in state.completed_steps
        )

        # Record metrics
        metrics.record_pipeline_completion(success, total_duration / 1000)

        logger.info(
            "incremental_execution_completed",
            success=success,
            steps_completed=steps_completed,
            steps_failed=steps_failed,
            duration_ms=total_duration,
            simplified=state.is_simplified,
        )

        return ExecutionResult(
            plan_id=f"incremental_{context.get('pnr_locator')}_{state.started_at.strftime('%H%M%S')}",
            success=success,
            final_result=state.get_accumulated_data(),
            steps_completed=steps_completed,
            steps_failed=steps_failed,
            total_duration_ms=total_duration,
            feedback=self._generate_feedback(state),
            needs_replanning=False,  # Incremental doesn't need re-planning
        )

    def _generate_feedback(self, state: IncrementalState) -> str:
        """Generate human-readable feedback about the execution."""
        parts = []

        if state.is_goal_achieved():
            parts.append("Goal achieved successfully.")
        elif state.human_escalation_requested:
            parts.append("Execution paused for human review.")
        elif state.should_abort():
            parts.append("Execution aborted due to repeated failures.")
        else:
            parts.append(f"Completed {len(state.completed_steps)}/{len(state.available_steps)} steps.")

        if state.is_simplified:
            parts.append(f"Task was simplified (level {state.simplification_level}).")

        if state.failed_attempts:
            failed_steps = list(state.failed_attempts.keys())
            parts.append(f"Failures encountered in: {', '.join(failed_steps)}")

        return " ".join(parts)


# =============================================================================
# CONVENIENCE FUNCTIONS (INCREMENTAL)
# =============================================================================

def run_offer_evaluation_incremental(
    pnr_locator: str,
    human_callback: Optional[Callable] = None,
    **kwargs,
) -> ExecutionResult:
    """
    Run offer evaluation using the CORRECT incremental planner-executor pattern.

    This is the RECOMMENDED entry point for offer evaluation.

    Key benefits over batch pattern:
    - Plans one step at a time based on actual results
    - Workers return recommendations for failure recovery
    - Dynamic task simplification on repeated failures
    - Human escalation support

    Args:
        pnr_locator: The PNR to evaluate
        human_callback: Optional callback for human escalation
        **kwargs: Additional context (customer_id, session_id, etc.)

    Returns:
        ExecutionResult with final outcome
    """
    coordinator = IncrementalPlannerExecutorCoordinator()

    context = {
        "pnr_locator": pnr_locator,
        **kwargs,
    }

    return coordinator.run(context, human_callback=human_callback)


================================================================================
FILE: infrastructure/production_safety.py
================================================================================
"""
Production Safety Infrastructure

This module implements critical production safety features that prevent
real-world failures in agentic systems:

1. IdempotencyManager - Prevents duplicate processing of requests
2. CostTracker - Tracks LLM costs per request for visibility
3. AlertManager - Sends alerts for critical conditions

These address the most common failure patterns in production agent systems:
- Duplicate actions (847 duplicate charges, $84k incident)
- Cost blowouts ($47k unexpected spend in 3 weeks)
- Silent failures (errors accumulating without detection)

Reference: 7-Layer Production Agent Framework
"""

import os
import json
import time
import hashlib
import threading
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple, Callable
from enum import Enum
import logging

# Try to import optional dependencies
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False


logger = logging.getLogger(__name__)


# =============================================================================
# IDEMPOTENCY MANAGER
# =============================================================================

class IdempotencyStatus(Enum):
    """Status of an idempotent request."""
    NEW = "new"                    # First time seeing this request
    PROCESSING = "processing"      # Currently being processed
    COMPLETED = "completed"        # Successfully completed
    FAILED = "failed"             # Failed (can be retried)


@dataclass
class IdempotencyRecord:
    """Record of an idempotent request."""
    key: str
    status: IdempotencyStatus
    created_at: str
    updated_at: str
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    attempt_count: int = 1


class IdempotencyManager:
    """
    Prevents duplicate processing of requests.

    Critical for preventing:
    - Duplicate offers sent to same customer
    - Duplicate tracking records
    - Duplicate side effects (emails, notifications)

    Usage:
        idempotency = IdempotencyManager()

        # Generate key for this request
        key = idempotency.get_key(pnr="ABC123", operation="offer_evaluation")

        # Check if already processed
        is_duplicate, cached_result = idempotency.check(key)
        if is_duplicate:
            return cached_result  # Return cached result, don't reprocess

        # Process the request
        try:
            result = process_offer(pnr)
            idempotency.complete(key, result)
            return result
        except Exception as e:
            idempotency.fail(key, str(e))
            raise

    Key Generation:
    - Includes PNR, operation type, and date
    - Same request on same day = same key
    - Next day = new key (allows daily re-evaluation)
    """

    DEFAULT_TTL_SECONDS = 86400  # 24 hours

    def __init__(
        self,
        redis_url: str = None,
        ttl_seconds: int = None,
        key_prefix: str = "idempotency"
    ):
        """
        Initialize IdempotencyManager.

        Args:
            redis_url: Redis connection URL (uses in-memory if not provided)
            ttl_seconds: Time-to-live for idempotency records
            key_prefix: Prefix for all keys
        """
        self.ttl_seconds = ttl_seconds or self.DEFAULT_TTL_SECONDS
        self.key_prefix = key_prefix

        # Use Redis if available and configured, otherwise in-memory
        self._redis = None
        if redis_url and REDIS_AVAILABLE:
            try:
                self._redis = redis.from_url(redis_url)
                self._redis.ping()
                logger.info("IdempotencyManager using Redis backend")
            except Exception as e:
                logger.warning(f"Redis connection failed, using in-memory: {e}")
                self._redis = None

        # In-memory fallback
        self._cache: Dict[str, IdempotencyRecord] = {}
        self._lock = threading.Lock()

    def get_key(
        self,
        pnr: str,
        operation: str,
        include_date: bool = True,
        extra_components: List[str] = None
    ) -> str:
        """
        Generate idempotency key for a request.

        Args:
            pnr: PNR locator
            operation: Operation type (e.g., "offer_evaluation", "send_offer")
            include_date: Include date in key (allows daily re-processing)
            extra_components: Additional components to include in key

        Returns:
            Idempotency key string
        """
        components = [self.key_prefix, operation, pnr]

        if include_date:
            components.append(datetime.now().strftime("%Y-%m-%d"))

        if extra_components:
            components.extend(extra_components)

        # Create deterministic key
        key_string = ":".join(components)
        return key_string

    def check(self, key: str) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """
        Check if request was already processed.

        Args:
            key: Idempotency key

        Returns:
            (is_duplicate, cached_result)
            - (True, result) if already completed
            - (True, None) if currently processing
            - (False, None) if new request
        """
        record = self._get_record(key)

        if record is None:
            # New request - mark as processing
            self._set_record(key, IdempotencyRecord(
                key=key,
                status=IdempotencyStatus.PROCESSING,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
            ))
            return (False, None)

        if record.status == IdempotencyStatus.COMPLETED:
            logger.info(f"Idempotency hit: {key} already completed")
            return (True, record.result)

        if record.status == IdempotencyStatus.PROCESSING:
            # Check if processing timed out (>5 minutes)
            created = datetime.fromisoformat(record.created_at)
            if datetime.now() - created > timedelta(minutes=5):
                logger.warning(f"Idempotency timeout: {key} stuck in processing, allowing retry")
                # Update attempt count and allow retry
                record.attempt_count += 1
                record.updated_at = datetime.now().isoformat()
                self._set_record(key, record)
                return (False, None)

            logger.info(f"Idempotency: {key} currently processing")
            return (True, None)

        if record.status == IdempotencyStatus.FAILED:
            # Allow retry of failed requests
            logger.info(f"Idempotency: {key} previously failed, allowing retry")
            record.status = IdempotencyStatus.PROCESSING
            record.attempt_count += 1
            record.updated_at = datetime.now().isoformat()
            self._set_record(key, record)
            return (False, None)

        return (False, None)

    def complete(self, key: str, result: Dict[str, Any]):
        """
        Mark request as completed with result.

        Args:
            key: Idempotency key
            result: Result to cache
        """
        record = self._get_record(key)
        if record:
            record.status = IdempotencyStatus.COMPLETED
            record.result = result
            record.updated_at = datetime.now().isoformat()
        else:
            record = IdempotencyRecord(
                key=key,
                status=IdempotencyStatus.COMPLETED,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                result=result,
            )

        self._set_record(key, record)
        logger.info(f"Idempotency: {key} marked completed")

    def fail(self, key: str, error: str):
        """
        Mark request as failed.

        Args:
            key: Idempotency key
            error: Error message
        """
        record = self._get_record(key)
        if record:
            record.status = IdempotencyStatus.FAILED
            record.error = error
            record.updated_at = datetime.now().isoformat()
        else:
            record = IdempotencyRecord(
                key=key,
                status=IdempotencyStatus.FAILED,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                error=error,
            )

        self._set_record(key, record)
        logger.warning(f"Idempotency: {key} marked failed: {error}")

    def _get_record(self, key: str) -> Optional[IdempotencyRecord]:
        """Get record from storage."""
        if self._redis:
            data = self._redis.get(key)
            if data:
                record_dict = json.loads(data)
                return IdempotencyRecord(
                    key=record_dict["key"],
                    status=IdempotencyStatus(record_dict["status"]),
                    created_at=record_dict["created_at"],
                    updated_at=record_dict["updated_at"],
                    result=record_dict.get("result"),
                    error=record_dict.get("error"),
                    attempt_count=record_dict.get("attempt_count", 1),
                )
            return None

        with self._lock:
            return self._cache.get(key)

    def _set_record(self, key: str, record: IdempotencyRecord):
        """Set record in storage."""
        if self._redis:
            record_dict = {
                "key": record.key,
                "status": record.status.value,
                "created_at": record.created_at,
                "updated_at": record.updated_at,
                "result": record.result,
                "error": record.error,
                "attempt_count": record.attempt_count,
            }
            self._redis.setex(key, self.ttl_seconds, json.dumps(record_dict))
            return

        with self._lock:
            self._cache[key] = record
            # Simple TTL cleanup for in-memory
            self._cleanup_expired()

    def _cleanup_expired(self):
        """Remove expired records from in-memory cache."""
        now = datetime.now()
        expired_keys = []

        for key, record in self._cache.items():
            created = datetime.fromisoformat(record.created_at)
            if (now - created).total_seconds() > self.ttl_seconds:
                expired_keys.append(key)

        for key in expired_keys:
            del self._cache[key]

    def get_stats(self) -> Dict[str, Any]:
        """Get idempotency statistics."""
        if self._redis:
            # For Redis, we'd need to scan keys (expensive)
            return {"backend": "redis", "note": "stats require key scan"}

        with self._lock:
            status_counts = {}
            for record in self._cache.values():
                status = record.status.value
                status_counts[status] = status_counts.get(status, 0) + 1

            return {
                "backend": "memory",
                "total_records": len(self._cache),
                "status_counts": status_counts,
            }


# =============================================================================
# COST TRACKER
# =============================================================================

@dataclass
class LLMCallCost:
    """Cost details for an LLM call."""
    request_id: str
    timestamp: str
    model: str
    input_tokens: int
    output_tokens: int
    input_cost_usd: float
    output_cost_usd: float
    total_cost_usd: float
    pnr: Optional[str] = None
    agent_name: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class CostTracker:
    """
    Tracks LLM costs per request for visibility and budgeting.

    Critical for:
    - Understanding cost drivers
    - Setting budgets and alerts
    - Optimizing expensive operations
    - Preventing cost blowouts

    Usage:
        tracker = CostTracker()

        # Track an LLM call
        cost = tracker.track_call(
            request_id="req-123",
            pnr="ABC123",
            model="gpt-4o",
            input_tokens=1500,
            output_tokens=500,
            agent_name="OfferOrchestration"
        )

        # Get cost summary
        summary = tracker.get_summary(hours=24)
        print(f"Last 24h cost: ${summary['total_cost_usd']:.2f}")

    Pricing is configurable and defaults to approximate 2024 rates.
    """

    # Default pricing per 1K tokens (2024 approximate rates)
    DEFAULT_PRICING = {
        # OpenAI models
        "gpt-4o": {"input": 0.005, "output": 0.015},
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
        "gpt-4-turbo": {"input": 0.01, "output": 0.03},
        "gpt-4": {"input": 0.03, "output": 0.06},
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
        # Anthropic models
        "claude-3-opus": {"input": 0.015, "output": 0.075},
        "claude-3-sonnet": {"input": 0.003, "output": 0.015},
        "claude-3-haiku": {"input": 0.00025, "output": 0.00125},
        "claude-3-5-sonnet": {"input": 0.003, "output": 0.015},
        # Default fallback
        "default": {"input": 0.01, "output": 0.03},
    }

    def __init__(
        self,
        pricing: Dict[str, Dict[str, float]] = None,
        budget_hourly_usd: float = None,
        budget_daily_usd: float = None,
    ):
        """
        Initialize CostTracker.

        Args:
            pricing: Custom pricing dict {model: {input: $, output: $}}
            budget_hourly_usd: Optional hourly budget for alerts
            budget_daily_usd: Optional daily budget for alerts
        """
        self.pricing = pricing or self.DEFAULT_PRICING
        self.budget_hourly_usd = budget_hourly_usd or float(os.getenv("LLM_BUDGET_HOURLY", "100"))
        self.budget_daily_usd = budget_daily_usd or float(os.getenv("LLM_BUDGET_DAILY", "1000"))

        # In-memory storage (use TimescaleDB/InfluxDB in production)
        self._calls: List[LLMCallCost] = []
        self._lock = threading.Lock()

        # Aggregated metrics
        self._total_cost_usd = 0.0
        self._total_input_tokens = 0
        self._total_output_tokens = 0
        self._call_count = 0

    def track_call(
        self,
        request_id: str,
        model: str,
        input_tokens: int,
        output_tokens: int,
        pnr: str = None,
        agent_name: str = None,
        metadata: Dict[str, Any] = None,
    ) -> LLMCallCost:
        """
        Track cost for an LLM call.

        Args:
            request_id: Unique request identifier
            model: Model name (e.g., "gpt-4o", "claude-3-sonnet")
            input_tokens: Number of input tokens
            output_tokens: Number of output tokens
            pnr: Associated PNR (optional)
            agent_name: Name of the agent making the call
            metadata: Additional metadata

        Returns:
            LLMCallCost with calculated costs
        """
        # Get pricing for model
        model_pricing = self.pricing.get(model, self.pricing["default"])

        # Calculate costs
        input_cost = (input_tokens / 1000) * model_pricing["input"]
        output_cost = (output_tokens / 1000) * model_pricing["output"]
        total_cost = input_cost + output_cost

        # Create cost record
        cost_record = LLMCallCost(
            request_id=request_id,
            timestamp=datetime.now().isoformat(),
            model=model,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            input_cost_usd=input_cost,
            output_cost_usd=output_cost,
            total_cost_usd=total_cost,
            pnr=pnr,
            agent_name=agent_name,
            metadata=metadata or {},
        )

        # Store and update aggregates
        with self._lock:
            self._calls.append(cost_record)
            self._total_cost_usd += total_cost
            self._total_input_tokens += input_tokens
            self._total_output_tokens += output_tokens
            self._call_count += 1

        # Log for observability
        logger.info(
            "llm_cost_tracked",
            extra={
                "request_id": request_id,
                "pnr": pnr,
                "model": model,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": total_cost,
                "agent": agent_name,
            }
        )

        return cost_record

    def get_summary(self, hours: int = 24) -> Dict[str, Any]:
        """
        Get cost summary for a time window.

        Args:
            hours: Number of hours to look back

        Returns:
            Summary dict with costs, counts, and breakdowns
        """
        cutoff = datetime.now() - timedelta(hours=hours)

        with self._lock:
            recent_calls = [
                c for c in self._calls
                if datetime.fromisoformat(c.timestamp) > cutoff
            ]

        if not recent_calls:
            return {
                "hours": hours,
                "total_cost_usd": 0,
                "call_count": 0,
                "input_tokens": 0,
                "output_tokens": 0,
                "cost_by_model": {},
                "cost_by_agent": {},
                "avg_cost_per_call": 0,
            }

        # Aggregate
        total_cost = sum(c.total_cost_usd for c in recent_calls)
        input_tokens = sum(c.input_tokens for c in recent_calls)
        output_tokens = sum(c.output_tokens for c in recent_calls)

        # By model
        cost_by_model = {}
        for c in recent_calls:
            cost_by_model[c.model] = cost_by_model.get(c.model, 0) + c.total_cost_usd

        # By agent
        cost_by_agent = {}
        for c in recent_calls:
            if c.agent_name:
                cost_by_agent[c.agent_name] = cost_by_agent.get(c.agent_name, 0) + c.total_cost_usd

        return {
            "hours": hours,
            "total_cost_usd": total_cost,
            "call_count": len(recent_calls),
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "cost_by_model": cost_by_model,
            "cost_by_agent": cost_by_agent,
            "avg_cost_per_call": total_cost / len(recent_calls) if recent_calls else 0,
        }

    def get_hourly_cost(self) -> float:
        """Get cost for the last hour."""
        return self.get_summary(hours=1)["total_cost_usd"]

    def get_daily_cost(self) -> float:
        """Get cost for the last 24 hours."""
        return self.get_summary(hours=24)["total_cost_usd"]

    def check_budget(self) -> Dict[str, Any]:
        """
        Check if costs are within budget.

        Returns:
            Dict with budget status and warnings
        """
        hourly = self.get_hourly_cost()
        daily = self.get_daily_cost()

        return {
            "hourly_cost_usd": hourly,
            "hourly_budget_usd": self.budget_hourly_usd,
            "hourly_utilization": hourly / self.budget_hourly_usd if self.budget_hourly_usd else 0,
            "hourly_exceeded": hourly > self.budget_hourly_usd,
            "daily_cost_usd": daily,
            "daily_budget_usd": self.budget_daily_usd,
            "daily_utilization": daily / self.budget_daily_usd if self.budget_daily_usd else 0,
            "daily_exceeded": daily > self.budget_daily_usd,
        }

    def get_all_time_stats(self) -> Dict[str, Any]:
        """Get all-time statistics."""
        with self._lock:
            return {
                "total_cost_usd": self._total_cost_usd,
                "total_input_tokens": self._total_input_tokens,
                "total_output_tokens": self._total_output_tokens,
                "total_calls": self._call_count,
                "avg_cost_per_call": self._total_cost_usd / self._call_count if self._call_count else 0,
            }


# =============================================================================
# ALERT MANAGER
# =============================================================================

class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class Alert:
    """An alert event."""
    id: str
    timestamp: str
    severity: AlertSeverity
    title: str
    message: str
    source: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    acknowledged: bool = False


class AlertManager:
    """
    Sends alerts for critical conditions.

    Critical for:
    - Detecting failures early
    - Preventing silent errors from accumulating
    - Enabling quick incident response
    - Cost anomaly detection

    Usage:
        alerts = AlertManager(
            slack_webhook="https://hooks.slack.com/...",
            pagerduty_key="your-key"
        )

        # Manual alert
        alerts.send(
            severity=AlertSeverity.WARNING,
            title="High Error Rate",
            message="Error rate is 5.2% over last 5 minutes"
        )

        # Automated checks (call periodically)
        alerts.check_error_rate(error_count=50, total_count=1000, window_minutes=5)
        alerts.check_cost_anomaly(cost_tracker)

    Supports:
    - Slack webhooks
    - PagerDuty
    - Console/log output (always)
    - Custom handlers
    """

    def __init__(
        self,
        slack_webhook: str = None,
        pagerduty_key: str = None,
        custom_handlers: List[Callable[[Alert], None]] = None,
        error_rate_threshold: float = 0.05,  # 5%
        cost_hourly_threshold: float = 100.0,  # $100/hour
    ):
        """
        Initialize AlertManager.

        Args:
            slack_webhook: Slack incoming webhook URL
            pagerduty_key: PagerDuty integration key
            custom_handlers: List of custom alert handler functions
            error_rate_threshold: Error rate threshold for alerts
            cost_hourly_threshold: Hourly cost threshold for alerts
        """
        self.slack_webhook = slack_webhook or os.getenv("SLACK_ALERT_WEBHOOK")
        self.pagerduty_key = pagerduty_key or os.getenv("PAGERDUTY_KEY")
        self.custom_handlers = custom_handlers or []
        self.error_rate_threshold = error_rate_threshold
        self.cost_hourly_threshold = cost_hourly_threshold

        # Alert history
        self._alerts: List[Alert] = []
        self._lock = threading.Lock()

        # Rate limiting for alerts (prevent alert storms)
        self._last_alert_time: Dict[str, datetime] = {}
        self._alert_cooldown_seconds = 300  # 5 minutes between same alerts

    def send(
        self,
        severity: AlertSeverity,
        title: str,
        message: str,
        source: str = "tailored-offers",
        metadata: Dict[str, Any] = None,
        force: bool = False,
    ) -> Optional[Alert]:
        """
        Send an alert.

        Args:
            severity: Alert severity level
            title: Alert title
            message: Alert message
            source: Source system
            metadata: Additional metadata
            force: Bypass rate limiting

        Returns:
            Alert object if sent, None if rate limited
        """
        # Rate limiting (prevent alert storms)
        alert_key = f"{severity.value}:{title}"
        if not force and alert_key in self._last_alert_time:
            time_since = (datetime.now() - self._last_alert_time[alert_key]).total_seconds()
            if time_since < self._alert_cooldown_seconds:
                logger.debug(f"Alert rate limited: {title} (sent {time_since:.0f}s ago)")
                return None

        # Create alert
        alert = Alert(
            id=f"alert-{datetime.now().strftime('%Y%m%d%H%M%S')}-{hashlib.md5(title.encode()).hexdigest()[:8]}",
            timestamp=datetime.now().isoformat(),
            severity=severity,
            title=title,
            message=message,
            source=source,
            metadata=metadata or {},
        )

        # Store alert
        with self._lock:
            self._alerts.append(alert)
            self._last_alert_time[alert_key] = datetime.now()

        # Always log
        log_level = {
            AlertSeverity.INFO: logging.INFO,
            AlertSeverity.WARNING: logging.WARNING,
            AlertSeverity.ERROR: logging.ERROR,
            AlertSeverity.CRITICAL: logging.CRITICAL,
        }.get(severity, logging.WARNING)

        logger.log(
            log_level,
            f"ALERT [{severity.value.upper()}] {title}: {message}",
            extra={"alert_id": alert.id, "metadata": metadata}
        )

        # Send to configured channels
        if self.slack_webhook:
            self._send_slack(alert)

        if self.pagerduty_key and severity in [AlertSeverity.ERROR, AlertSeverity.CRITICAL]:
            self._send_pagerduty(alert)

        # Custom handlers
        for handler in self.custom_handlers:
            try:
                handler(alert)
            except Exception as e:
                logger.error(f"Custom alert handler failed: {e}")

        return alert

    def _send_slack(self, alert: Alert):
        """Send alert to Slack."""
        if not REQUESTS_AVAILABLE:
            logger.warning("requests library not available for Slack alerts")
            return

        color_map = {
            AlertSeverity.INFO: "#36a64f",
            AlertSeverity.WARNING: "#ffcc00",
            AlertSeverity.ERROR: "#ff6600",
            AlertSeverity.CRITICAL: "#ff0000",
        }

        payload = {
            "attachments": [{
                "color": color_map.get(alert.severity, "#808080"),
                "title": f"[{alert.severity.value.upper()}] {alert.title}",
                "text": alert.message,
                "fields": [
                    {"title": "Source", "value": alert.source, "short": True},
                    {"title": "Time", "value": alert.timestamp, "short": True},
                ],
                "footer": f"Alert ID: {alert.id}",
            }]
        }

        try:
            response = requests.post(self.slack_webhook, json=payload, timeout=5)
            if response.status_code != 200:
                logger.error(f"Slack alert failed: {response.status_code}")
        except Exception as e:
            logger.error(f"Slack alert failed: {e}")

    def _send_pagerduty(self, alert: Alert):
        """Send alert to PagerDuty."""
        if not REQUESTS_AVAILABLE:
            logger.warning("requests library not available for PagerDuty alerts")
            return

        severity_map = {
            AlertSeverity.INFO: "info",
            AlertSeverity.WARNING: "warning",
            AlertSeverity.ERROR: "error",
            AlertSeverity.CRITICAL: "critical",
        }

        payload = {
            "routing_key": self.pagerduty_key,
            "event_action": "trigger",
            "dedup_key": alert.id,
            "payload": {
                "summary": f"{alert.title}: {alert.message}",
                "severity": severity_map.get(alert.severity, "warning"),
                "source": alert.source,
                "timestamp": alert.timestamp,
                "custom_details": alert.metadata,
            },
        }

        try:
            response = requests.post(
                "https://events.pagerduty.com/v2/enqueue",
                json=payload,
                timeout=5
            )
            if response.status_code != 202:
                logger.error(f"PagerDuty alert failed: {response.status_code}")
        except Exception as e:
            logger.error(f"PagerDuty alert failed: {e}")

    def check_error_rate(
        self,
        error_count: int,
        total_count: int,
        window_minutes: int = 5
    ) -> Optional[Alert]:
        """
        Check error rate and alert if threshold exceeded.

        Args:
            error_count: Number of errors in window
            total_count: Total requests in window
            window_minutes: Time window

        Returns:
            Alert if sent, None otherwise
        """
        if total_count == 0:
            return None

        error_rate = error_count / total_count

        if error_rate > self.error_rate_threshold:
            return self.send(
                severity=AlertSeverity.WARNING if error_rate < 0.10 else AlertSeverity.ERROR,
                title="High Error Rate",
                message=f"Error rate is {error_rate:.1%} ({error_count}/{total_count}) over last {window_minutes} minutes",
                metadata={
                    "error_count": error_count,
                    "total_count": total_count,
                    "error_rate": error_rate,
                    "threshold": self.error_rate_threshold,
                    "window_minutes": window_minutes,
                }
            )

        return None

    def check_cost_anomaly(self, cost_tracker: CostTracker) -> Optional[Alert]:
        """
        Check for cost anomalies and alert.

        Args:
            cost_tracker: CostTracker instance

        Returns:
            Alert if sent, None otherwise
        """
        budget_status = cost_tracker.check_budget()

        if budget_status["hourly_exceeded"]:
            return self.send(
                severity=AlertSeverity.CRITICAL,
                title="Cost Budget Exceeded",
                message=f"Hourly LLM cost ${budget_status['hourly_cost_usd']:.2f} exceeds budget ${budget_status['hourly_budget_usd']:.2f}",
                metadata=budget_status,
            )

        # Warn at 80% utilization
        if budget_status["hourly_utilization"] > 0.8:
            return self.send(
                severity=AlertSeverity.WARNING,
                title="Cost Budget Warning",
                message=f"Hourly LLM cost ${budget_status['hourly_cost_usd']:.2f} is at {budget_status['hourly_utilization']:.0%} of budget",
                metadata=budget_status,
            )

        return None

    def check_circuit_breaker(self, breaker_name: str, is_open: bool) -> Optional[Alert]:
        """
        Alert when circuit breaker opens.

        Args:
            breaker_name: Name of the circuit breaker
            is_open: Whether the breaker is open

        Returns:
            Alert if sent, None otherwise
        """
        if is_open:
            return self.send(
                severity=AlertSeverity.ERROR,
                title="Circuit Breaker Open",
                message=f"Circuit breaker '{breaker_name}' has opened due to failures",
                metadata={"breaker_name": breaker_name},
            )

        return None

    def get_recent_alerts(self, hours: int = 24) -> List[Alert]:
        """Get alerts from the last N hours."""
        cutoff = datetime.now() - timedelta(hours=hours)

        with self._lock:
            return [
                a for a in self._alerts
                if datetime.fromisoformat(a.timestamp) > cutoff
            ]

    def get_alert_stats(self, hours: int = 24) -> Dict[str, Any]:
        """Get alert statistics."""
        recent = self.get_recent_alerts(hours)

        by_severity = {}
        for alert in recent:
            sev = alert.severity.value
            by_severity[sev] = by_severity.get(sev, 0) + 1

        return {
            "hours": hours,
            "total_alerts": len(recent),
            "by_severity": by_severity,
            "acknowledged": sum(1 for a in recent if a.acknowledged),
            "unacknowledged": sum(1 for a in recent if not a.acknowledged),
        }


# =============================================================================
# CONVENIENCE: Production Safety Coordinator
# =============================================================================

class ProductionSafetyCoordinator:
    """
    Coordinates all production safety features.

    Usage:
        safety = ProductionSafetyCoordinator()

        # In your request handler
        async def handle_offer_request(pnr: str):
            # Check idempotency
            idem_key = safety.idempotency.get_key(pnr, "offer_evaluation")
            is_dup, cached = safety.idempotency.check(idem_key)
            if is_dup and cached:
                return cached

            try:
                # Process request
                result = await process_offer(pnr)

                # Track cost (if LLM was used)
                safety.cost_tracker.track_call(...)

                # Mark complete
                safety.idempotency.complete(idem_key, result)

                return result

            except Exception as e:
                safety.idempotency.fail(idem_key, str(e))
                safety.alerts.send(
                    severity=AlertSeverity.ERROR,
                    title="Offer Processing Failed",
                    message=str(e)
                )
                raise
    """

    def __init__(
        self,
        redis_url: str = None,
        slack_webhook: str = None,
        pagerduty_key: str = None,
    ):
        self.idempotency = IdempotencyManager(redis_url=redis_url)
        self.cost_tracker = CostTracker()
        self.alerts = AlertManager(
            slack_webhook=slack_webhook,
            pagerduty_key=pagerduty_key,
        )

    def run_periodic_checks(self, error_count: int = 0, total_count: int = 0):
        """
        Run periodic health checks.

        Call this periodically (e.g., every minute) to check for anomalies.
        """
        # Check error rate
        if total_count > 0:
            self.alerts.check_error_rate(error_count, total_count)

        # Check cost
        self.alerts.check_cost_anomaly(self.cost_tracker)

    def get_health_status(self) -> Dict[str, Any]:
        """Get overall health status."""
        return {
            "idempotency": self.idempotency.get_stats(),
            "cost": self.cost_tracker.check_budget(),
            "alerts": self.alerts.get_alert_stats(hours=1),
        }


# =============================================================================
# FACTORY FUNCTIONS
# =============================================================================

_coordinator: Optional[ProductionSafetyCoordinator] = None


def get_safety_coordinator() -> ProductionSafetyCoordinator:
    """Get or create the global safety coordinator."""
    global _coordinator
    if _coordinator is None:
        _coordinator = ProductionSafetyCoordinator(
            redis_url=os.getenv("REDIS_URL"),
            slack_webhook=os.getenv("SLACK_ALERT_WEBHOOK"),
            pagerduty_key=os.getenv("PAGERDUTY_KEY"),
        )
    return _coordinator


def create_safety_coordinator(
    redis_url: str = None,
    slack_webhook: str = None,
    pagerduty_key: str = None,
) -> ProductionSafetyCoordinator:
    """Create a new safety coordinator with custom config."""
    return ProductionSafetyCoordinator(
        redis_url=redis_url,
        slack_webhook=slack_webhook,
        pagerduty_key=pagerduty_key,
    )


================================================================================
FILE: infrastructure/retry.py
================================================================================
"""
Retry Logic Module

Provides retry decorators and utilities using tenacity for:
- LLM API calls with exponential backoff
- MCP tool calls with circuit breaker pattern
- Generic retries with fallback support
"""

import os
import asyncio
from typing import Optional, Callable, TypeVar, Any, Union
from functools import wraps
from dataclasses import dataclass, field

# Try to import tenacity, fall back to simple retry if not available
try:
    from tenacity import (
        retry,
        stop_after_attempt,
        stop_after_delay,
        wait_exponential,
        wait_random_exponential,
        retry_if_exception_type,
        retry_if_not_exception_type,
        before_sleep_log,
        after_log,
        RetryError,
    )
    TENACITY_AVAILABLE = True
except ImportError:
    TENACITY_AVAILABLE = False
    print("Warning: tenacity not installed. Retry logic disabled. Install with: pip install tenacity")

# Try to import pybreaker for circuit breaker
try:
    import pybreaker
    PYBREAKER_AVAILABLE = True
except ImportError:
    PYBREAKER_AVAILABLE = False

from .logging import get_logger

logger = get_logger("retry")

# Type variable for generic functions
T = TypeVar("T")


@dataclass
class RetryConfig:
    """Configuration for retry behavior."""

    max_attempts: int = 3
    min_wait_seconds: float = 1.0
    max_wait_seconds: float = 30.0
    exponential_base: float = 2.0
    timeout_seconds: Optional[float] = 60.0

    # Exception types to retry on
    retry_on: tuple = field(default_factory=lambda: (
        ConnectionError,
        TimeoutError,
        OSError,
    ))

    # Exception types to NOT retry on (fail immediately)
    no_retry_on: tuple = field(default_factory=lambda: (
        ValueError,
        TypeError,
        KeyError,
    ))


# Default configurations
LLM_RETRY_CONFIG = RetryConfig(
    max_attempts=3,
    min_wait_seconds=2.0,
    max_wait_seconds=30.0,
    timeout_seconds=60.0,
)

MCP_RETRY_CONFIG = RetryConfig(
    max_attempts=3,
    min_wait_seconds=1.0,
    max_wait_seconds=10.0,
    timeout_seconds=30.0,
)


def _create_retry_decorator(config: RetryConfig):
    """Create a tenacity retry decorator from config."""
    if not TENACITY_AVAILABLE:
        # Return no-op decorator if tenacity not available
        def no_op_decorator(func):
            return func
        return no_op_decorator

    return retry(
        stop=(
            stop_after_attempt(config.max_attempts) |
            (stop_after_delay(config.timeout_seconds) if config.timeout_seconds else stop_after_attempt(100))
        ),
        wait=wait_exponential(
            multiplier=config.exponential_base,
            min=config.min_wait_seconds,
            max=config.max_wait_seconds,
        ),
        retry=retry_if_exception_type(config.retry_on),
        before_sleep=_log_retry_attempt,
        reraise=True,
    )


def _log_retry_attempt(retry_state):
    """Log retry attempts."""
    logger.warning(
        "retry_attempt",
        attempt=retry_state.attempt_number,
        wait_seconds=retry_state.next_action.sleep if retry_state.next_action else 0,
        exception=str(retry_state.outcome.exception()) if retry_state.outcome else None,
    )


def retry_llm_call(
    max_attempts: int = 3,
    timeout_seconds: float = 60.0,
    fallback: Optional[Callable[[], T]] = None,
):
    """
    Decorator for retrying LLM API calls with exponential backoff.

    Args:
        max_attempts: Maximum number of retry attempts
        timeout_seconds: Maximum total time for all retries
        fallback: Optional fallback function to call if all retries fail

    Example:
        @retry_llm_call(max_attempts=3, fallback=lambda: default_response)
        def call_openai(prompt: str) -> str:
            return openai.complete(prompt)
    """
    config = RetryConfig(
        max_attempts=max_attempts,
        min_wait_seconds=2.0,
        max_wait_seconds=30.0,
        timeout_seconds=timeout_seconds,
    )

    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        # Add tenacity retry
        retrying_func = _create_retry_decorator(config)(func)

        @wraps(func)
        def wrapper(*args, **kwargs) -> T:
            try:
                return retrying_func(*args, **kwargs)
            except Exception as e:
                if fallback is not None:
                    logger.warning(
                        "llm_call_fallback",
                        error=str(e),
                        error_type=type(e).__name__,
                    )
                    return fallback()
                raise

        return wrapper

    return decorator


def retry_llm_call_async(
    max_attempts: int = 3,
    timeout_seconds: float = 60.0,
    fallback: Optional[Callable[[], T]] = None,
):
    """
    Async version of retry_llm_call decorator.

    Example:
        @retry_llm_call_async(max_attempts=3)
        async def call_openai_async(prompt: str) -> str:
            return await openai.acomplete(prompt)
    """
    config = RetryConfig(
        max_attempts=max_attempts,
        min_wait_seconds=2.0,
        max_wait_seconds=30.0,
        timeout_seconds=timeout_seconds,
    )

    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            last_exception = None

            for attempt in range(config.max_attempts):
                try:
                    # Apply timeout to each attempt
                    return await asyncio.wait_for(
                        func(*args, **kwargs),
                        timeout=config.timeout_seconds / config.max_attempts if config.timeout_seconds else None
                    )
                except asyncio.TimeoutError as e:
                    last_exception = e
                    logger.warning(
                        "async_retry_timeout",
                        attempt=attempt + 1,
                        max_attempts=config.max_attempts,
                    )
                except Exception as e:
                    last_exception = e
                    if not isinstance(e, config.retry_on):
                        raise

                    logger.warning(
                        "async_retry_attempt",
                        attempt=attempt + 1,
                        max_attempts=config.max_attempts,
                        error=str(e),
                    )

                # Wait before retry (exponential backoff)
                if attempt < config.max_attempts - 1:
                    wait_time = min(
                        config.min_wait_seconds * (config.exponential_base ** attempt),
                        config.max_wait_seconds
                    )
                    await asyncio.sleep(wait_time)

            # All retries failed
            if fallback is not None:
                logger.warning(
                    "async_llm_call_fallback",
                    error=str(last_exception),
                )
                return fallback()

            raise last_exception

        return wrapper

    return decorator


def retry_mcp_call(
    max_attempts: int = 3,
    timeout_seconds: float = 30.0,
):
    """
    Decorator for retrying MCP tool calls with circuit breaker pattern.

    Args:
        max_attempts: Maximum number of retry attempts
        timeout_seconds: Maximum time for all retries

    Example:
        @retry_mcp_call(max_attempts=3)
        async def get_customer_data(customer_id: str) -> dict:
            return await mcp_client.get_customer(customer_id)
    """
    config = RetryConfig(
        max_attempts=max_attempts,
        min_wait_seconds=0.5,
        max_wait_seconds=5.0,
        timeout_seconds=timeout_seconds,
    )

    # Create circuit breaker if pybreaker is available
    breaker = None
    if PYBREAKER_AVAILABLE:
        breaker = pybreaker.CircuitBreaker(
            fail_max=5,  # Open circuit after 5 failures
            reset_timeout=30,  # Try again after 30 seconds
        )

    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            last_exception = None

            for attempt in range(config.max_attempts):
                try:
                    # Check circuit breaker
                    if breaker and breaker.current_state == "open":
                        logger.warning(
                            "circuit_breaker_open",
                            function=func.__name__,
                        )
                        raise ConnectionError("Circuit breaker is open")

                    # Apply timeout
                    result = await asyncio.wait_for(
                        func(*args, **kwargs),
                        timeout=config.timeout_seconds / config.max_attempts if config.timeout_seconds else None
                    )

                    # Record success with circuit breaker
                    if breaker:
                        breaker.success()

                    return result

                except asyncio.TimeoutError as e:
                    last_exception = e
                    if breaker:
                        breaker.failure()
                    logger.warning(
                        "mcp_retry_timeout",
                        attempt=attempt + 1,
                        function=func.__name__,
                    )

                except Exception as e:
                    last_exception = e
                    if breaker:
                        breaker.failure()

                    logger.warning(
                        "mcp_retry_attempt",
                        attempt=attempt + 1,
                        function=func.__name__,
                        error=str(e),
                    )

                # Wait before retry
                if attempt < config.max_attempts - 1:
                    wait_time = min(
                        config.min_wait_seconds * (config.exponential_base ** attempt),
                        config.max_wait_seconds
                    )
                    await asyncio.sleep(wait_time)

            raise last_exception

        return wrapper

    return decorator


def retry_with_fallback(
    fallback_func: Callable[..., T],
    max_attempts: int = 3,
    log_fallback: bool = True,
):
    """
    Decorator that retries a function and falls back to another on failure.

    Args:
        fallback_func: Function to call if primary fails
        max_attempts: Maximum retry attempts for primary
        log_fallback: Whether to log when falling back

    Example:
        def rules_based_decision(context):
            return {"offer": "MCE", "price": 39}

        @retry_with_fallback(rules_based_decision)
        def llm_decision(context):
            return llm.invoke(context)
    """
    config = RetryConfig(max_attempts=max_attempts)

    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        retrying_func = _create_retry_decorator(config)(func) if TENACITY_AVAILABLE else func

        @wraps(func)
        def wrapper(*args, **kwargs) -> T:
            try:
                return retrying_func(*args, **kwargs)
            except Exception as e:
                if log_fallback:
                    logger.warning(
                        "fallback_triggered",
                        primary_function=func.__name__,
                        fallback_function=fallback_func.__name__,
                        error=str(e),
                        error_type=type(e).__name__,
                    )
                return fallback_func(*args, **kwargs)

        return wrapper

    return decorator


class RetryContext:
    """
    Context manager for retry logic with manual control.

    Example:
        async with RetryContext(max_attempts=3) as ctx:
            while ctx.should_retry():
                try:
                    result = await risky_operation()
                    break
                except Exception as e:
                    ctx.record_failure(e)
    """

    def __init__(self, max_attempts: int = 3, timeout_seconds: Optional[float] = None):
        self.max_attempts = max_attempts
        self.timeout_seconds = timeout_seconds
        self.attempt = 0
        self.last_exception: Optional[Exception] = None
        self._start_time: Optional[float] = None

    def __enter__(self):
        import time
        self._start_time = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        pass

    async def __aenter__(self):
        import time
        self._start_time = time.time()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass

    def should_retry(self) -> bool:
        """Check if another retry attempt should be made."""
        import time

        if self.attempt >= self.max_attempts:
            return False

        if self.timeout_seconds and self._start_time:
            elapsed = time.time() - self._start_time
            if elapsed >= self.timeout_seconds:
                return False

        return True

    def record_failure(self, exception: Exception):
        """Record a failure and prepare for next attempt."""
        self.attempt += 1
        self.last_exception = exception

        logger.warning(
            "retry_context_failure",
            attempt=self.attempt,
            max_attempts=self.max_attempts,
            error=str(exception),
        )

    def get_backoff_time(self) -> float:
        """Get the backoff time for the next retry."""
        return min(2.0 ** self.attempt, 30.0)


================================================================================
FILE: infrastructure/tracing.py
================================================================================
"""
LLM Tracing Module

Provides integration with LangSmith and LangFuse for:
- LLM call tracing and observability
- Prompt evaluation tracking
- Cost and latency monitoring
- A/B testing of prompts
"""

import os
import time
import uuid
from typing import Optional, Dict, Any, Callable, List
from functools import wraps
from dataclasses import dataclass, field
from datetime import datetime
from contextlib import contextmanager

from .logging import get_logger, get_correlation_id

logger = get_logger("tracing")

# Try to import LangSmith
try:
    from langsmith import Client as LangSmithClient
    from langsmith.run_trees import RunTree
    from langsmith import traceable
    LANGSMITH_AVAILABLE = True
except ImportError:
    LANGSMITH_AVAILABLE = False
    traceable = lambda *args, **kwargs: lambda f: f  # No-op decorator

# Try to import LangFuse
try:
    from langfuse import Langfuse
    from langfuse.decorators import observe, langfuse_context
    LANGFUSE_AVAILABLE = True
except ImportError:
    LANGFUSE_AVAILABLE = False
    observe = lambda *args, **kwargs: lambda f: f  # No-op decorator


@dataclass
class TraceMetadata:
    """Metadata for a trace span."""
    trace_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    span_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    parent_span_id: Optional[str] = None
    correlation_id: str = field(default_factory=get_correlation_id)

    agent_name: Optional[str] = None
    model: Optional[str] = None
    prompt_version: Optional[str] = None

    input_tokens: int = 0
    output_tokens: int = 0
    latency_ms: float = 0.0
    cost_usd: float = 0.0

    tags: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


class TracingManager:
    """
    Centralized tracing manager for LLM observability.

    Supports both LangSmith and LangFuse, with automatic fallback
    to local logging if neither is configured.
    """

    def __init__(self):
        self.langsmith_client: Optional[LangSmithClient] = None
        self.langfuse_client: Optional[Langfuse] = None
        self.project_name = os.getenv("LANGSMITH_PROJECT", "tailored-offers")

        self._init_clients()

    def _init_clients(self):
        """Initialize tracing clients based on available API keys."""
        # Try LangSmith first
        if LANGSMITH_AVAILABLE and os.getenv("LANGSMITH_API_KEY"):
            try:
                self.langsmith_client = LangSmithClient()
                logger.info(
                    "tracing_initialized",
                    provider="langsmith",
                    project=self.project_name,
                )
            except Exception as e:
                logger.warning(
                    "langsmith_init_failed",
                    error=str(e),
                )

        # Try LangFuse as alternative/supplement
        if LANGFUSE_AVAILABLE and os.getenv("LANGFUSE_SECRET_KEY"):
            try:
                self.langfuse_client = Langfuse()
                logger.info(
                    "tracing_initialized",
                    provider="langfuse",
                )
            except Exception as e:
                logger.warning(
                    "langfuse_init_failed",
                    error=str(e),
                )

        if not self.langsmith_client and not self.langfuse_client:
            logger.info(
                "tracing_disabled",
                reason="No API keys configured. Set LANGSMITH_API_KEY or LANGFUSE_SECRET_KEY",
            )

    @property
    def is_enabled(self) -> bool:
        """Check if any tracing is enabled."""
        return bool(self.langsmith_client or self.langfuse_client)

    def trace_llm_call(
        self,
        name: str,
        input_data: Dict[str, Any],
        output_data: Dict[str, Any],
        metadata: Optional[TraceMetadata] = None,
    ):
        """
        Record an LLM call trace.

        Args:
            name: Name of the operation (e.g., "offer_orchestration_reasoning")
            input_data: Input to the LLM (prompt, messages, etc.)
            output_data: Output from the LLM (response, parsed data, etc.)
            metadata: Optional trace metadata
        """
        if not self.is_enabled:
            return

        metadata = metadata or TraceMetadata()

        try:
            if self.langsmith_client:
                self._trace_langsmith(name, input_data, output_data, metadata)

            if self.langfuse_client:
                self._trace_langfuse(name, input_data, output_data, metadata)

        except Exception as e:
            logger.warning(
                "trace_recording_failed",
                name=name,
                error=str(e),
            )

    def _trace_langsmith(
        self,
        name: str,
        input_data: Dict[str, Any],
        output_data: Dict[str, Any],
        metadata: TraceMetadata,
    ):
        """Record trace to LangSmith."""
        run = self.langsmith_client.create_run(
            name=name,
            run_type="llm",
            project_name=self.project_name,
            inputs=input_data,
            outputs=output_data,
            extra={
                "metadata": {
                    "correlation_id": metadata.correlation_id,
                    "agent_name": metadata.agent_name,
                    "model": metadata.model,
                    "prompt_version": metadata.prompt_version,
                    "latency_ms": metadata.latency_ms,
                    "input_tokens": metadata.input_tokens,
                    "output_tokens": metadata.output_tokens,
                    **metadata.metadata,
                },
                "tags": list(metadata.tags.values()) if metadata.tags else [],
            },
        )

    def _trace_langfuse(
        self,
        name: str,
        input_data: Dict[str, Any],
        output_data: Dict[str, Any],
        metadata: TraceMetadata,
    ):
        """Record trace to LangFuse."""
        trace = self.langfuse_client.trace(
            name=name,
            input=input_data,
            output=output_data,
            metadata={
                "correlation_id": metadata.correlation_id,
                "agent_name": metadata.agent_name,
                "prompt_version": metadata.prompt_version,
                **metadata.metadata,
            },
            tags=list(metadata.tags.values()) if metadata.tags else [],
        )

        # Add generation span for token/cost tracking
        trace.generation(
            name=f"{name}_generation",
            model=metadata.model,
            input=input_data.get("messages", input_data),
            output=output_data.get("content", output_data),
            usage={
                "input": metadata.input_tokens,
                "output": metadata.output_tokens,
            },
            metadata={
                "latency_ms": metadata.latency_ms,
                "cost_usd": metadata.cost_usd,
            },
        )

    def create_evaluation(
        self,
        name: str,
        trace_id: str,
        score: float,
        comment: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ):
        """
        Create an evaluation score for a trace.

        Used for tracking prompt quality and A/B testing.
        """
        if not self.is_enabled:
            return

        try:
            if self.langfuse_client:
                self.langfuse_client.score(
                    trace_id=trace_id,
                    name=name,
                    value=score,
                    comment=comment,
                    metadata=metadata,
                )

            logger.info(
                "evaluation_recorded",
                name=name,
                trace_id=trace_id,
                score=score,
            )

        except Exception as e:
            logger.warning(
                "evaluation_recording_failed",
                name=name,
                error=str(e),
            )

    def flush(self):
        """Flush any pending traces."""
        if self.langfuse_client:
            try:
                self.langfuse_client.flush()
            except Exception as e:
                logger.warning("langfuse_flush_failed", error=str(e))


# Global tracer instance
_tracer: Optional[TracingManager] = None


def get_tracer() -> TracingManager:
    """Get the global tracing manager instance."""
    global _tracer
    if _tracer is None:
        _tracer = TracingManager()
    return _tracer


def trace_agent(agent_name: str, prompt_version: Optional[str] = None):
    """
    Decorator to trace agent execution.

    Args:
        agent_name: Name of the agent being traced
        prompt_version: Optional version identifier for the prompt

    Example:
        @trace_agent("offer_orchestration", prompt_version="v1.2")
        def analyze(self, state):
            ...
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            tracer = get_tracer()
            metadata = TraceMetadata(
                agent_name=agent_name,
                prompt_version=prompt_version,
            )

            start_time = time.time()

            # Capture input
            input_data = {
                "agent": agent_name,
                "args": str(args[1:]) if len(args) > 1 else None,  # Skip self
                "kwargs": {k: str(v)[:500] for k, v in kwargs.items()},
            }

            try:
                result = func(*args, **kwargs)

                metadata.latency_ms = (time.time() - start_time) * 1000

                # Capture output (truncated for large responses)
                output_data = {
                    "success": True,
                    "result_keys": list(result.keys()) if isinstance(result, dict) else None,
                    "selected_offer": result.get("selected_offer") if isinstance(result, dict) else None,
                }

                tracer.trace_llm_call(
                    name=f"agent_{agent_name}",
                    input_data=input_data,
                    output_data=output_data,
                    metadata=metadata,
                )

                return result

            except Exception as e:
                metadata.latency_ms = (time.time() - start_time) * 1000

                tracer.trace_llm_call(
                    name=f"agent_{agent_name}",
                    input_data=input_data,
                    output_data={
                        "success": False,
                        "error": str(e),
                        "error_type": type(e).__name__,
                    },
                    metadata=metadata,
                )
                raise

        return wrapper

    return decorator


def trace_llm_call(
    name: str,
    model: Optional[str] = None,
    prompt_version: Optional[str] = None,
):
    """
    Decorator to trace individual LLM API calls.

    Args:
        name: Name for this LLM call
        model: Model being used
        prompt_version: Version of the prompt

    Example:
        @trace_llm_call("orchestration_reasoning", model="gpt-4", prompt_version="v1.0")
        def _llm_reasoning(self, context):
            ...
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            tracer = get_tracer()
            metadata = TraceMetadata(
                model=model,
                prompt_version=prompt_version,
            )

            start_time = time.time()

            try:
                result = func(*args, **kwargs)

                metadata.latency_ms = (time.time() - start_time) * 1000

                tracer.trace_llm_call(
                    name=name,
                    input_data={"function": func.__name__},
                    output_data={"success": True},
                    metadata=metadata,
                )

                return result

            except Exception as e:
                metadata.latency_ms = (time.time() - start_time) * 1000

                tracer.trace_llm_call(
                    name=name,
                    input_data={"function": func.__name__},
                    output_data={"success": False, "error": str(e)},
                    metadata=metadata,
                )
                raise

        return wrapper

    return decorator


@contextmanager
def trace_span(name: str, metadata: Optional[Dict[str, Any]] = None):
    """
    Context manager for tracing a block of code.

    Example:
        with trace_span("data_enrichment", {"pnr": "ABC123"}):
            data = load_enriched_data(pnr)
    """
    tracer = get_tracer()
    trace_meta = TraceMetadata(metadata=metadata or {})
    start_time = time.time()

    try:
        yield trace_meta

        trace_meta.latency_ms = (time.time() - start_time) * 1000
        tracer.trace_llm_call(
            name=name,
            input_data=metadata or {},
            output_data={"success": True},
            metadata=trace_meta,
        )

    except Exception as e:
        trace_meta.latency_ms = (time.time() - start_time) * 1000
        tracer.trace_llm_call(
            name=name,
            input_data=metadata or {},
            output_data={"success": False, "error": str(e)},
            metadata=trace_meta,
        )
        raise


================================================================================
FILE: infrastructure/validation.py
================================================================================
"""
LLM Response Validation Module

Provides semantic validation for LLM outputs:
- Structure validation (required fields, types)
- Business logic validation (guardrails, constraints)
- Semantic validation (content quality, coherence)
"""

import re
import json
from typing import Optional, Dict, Any, List, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum

from .logging import get_logger
from .metrics import metrics

logger = get_logger("validation")


class ValidationSeverity(Enum):
    """Severity levels for validation issues."""
    ERROR = "error"      # Must be fixed, use fallback
    WARNING = "warning"  # Log but proceed
    INFO = "info"        # Informational only


@dataclass
class ValidationIssue:
    """A single validation issue."""
    field: str
    message: str
    severity: ValidationSeverity
    actual_value: Any = None
    expected: Any = None


@dataclass
class ValidationResult:
    """Result of validation containing all issues found."""
    is_valid: bool
    issues: List[ValidationIssue] = field(default_factory=list)
    validated_data: Optional[Dict[str, Any]] = None

    @property
    def errors(self) -> List[ValidationIssue]:
        """Get only error-level issues."""
        return [i for i in self.issues if i.severity == ValidationSeverity.ERROR]

    @property
    def warnings(self) -> List[ValidationIssue]:
        """Get only warning-level issues."""
        return [i for i in self.issues if i.severity == ValidationSeverity.WARNING]

    def add_issue(
        self,
        field: str,
        message: str,
        severity: ValidationSeverity = ValidationSeverity.ERROR,
        actual_value: Any = None,
        expected: Any = None,
    ):
        """Add a validation issue."""
        self.issues.append(ValidationIssue(
            field=field,
            message=message,
            severity=severity,
            actual_value=actual_value,
            expected=expected,
        ))
        if severity == ValidationSeverity.ERROR:
            self.is_valid = False

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for logging."""
        return {
            "is_valid": self.is_valid,
            "error_count": len(self.errors),
            "warning_count": len(self.warnings),
            "issues": [
                {
                    "field": i.field,
                    "message": i.message,
                    "severity": i.severity.value,
                }
                for i in self.issues
            ],
        }


class LLMResponseValidator:
    """
    Validator for LLM response outputs.

    Provides validation for:
    - JSON structure
    - Required fields
    - Value constraints
    - Business logic rules
    """

    def __init__(self, agent_name: str):
        self.agent_name = agent_name

    def validate(
        self,
        response: Any,
        schema: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
    ) -> ValidationResult:
        """
        Validate an LLM response against a schema.

        Args:
            response: The parsed LLM response (dict or raw string)
            schema: Validation schema with field definitions
            context: Optional context for contextual validation

        Returns:
            ValidationResult with validation status and issues
        """
        result = ValidationResult(is_valid=True)

        # Parse if string
        if isinstance(response, str):
            try:
                response = self._parse_json(response)
            except json.JSONDecodeError as e:
                result.add_issue(
                    field="_raw",
                    message=f"Failed to parse JSON: {str(e)}",
                    severity=ValidationSeverity.ERROR,
                )
                return result

        if not isinstance(response, dict):
            result.add_issue(
                field="_type",
                message=f"Expected dict, got {type(response).__name__}",
                severity=ValidationSeverity.ERROR,
            )
            return result

        # Validate each field in schema
        for field_name, field_schema in schema.items():
            self._validate_field(result, response, field_name, field_schema, context)

        # Store validated data
        result.validated_data = response

        # Record metrics
        metrics.record_validation(self.agent_name, result.is_valid)

        # Log validation result
        if not result.is_valid:
            logger.warning(
                "validation_failed",
                agent=self.agent_name,
                errors=[i.message for i in result.errors],
            )

        return result

    def _parse_json(self, text: str) -> Dict[str, Any]:
        """Parse JSON from LLM response text."""
        # Try to find JSON in code blocks
        json_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))

        # Try to find raw JSON
        start = text.find('{')
        end = text.rfind('}') + 1
        if start >= 0 and end > start:
            return json.loads(text[start:end])

        raise json.JSONDecodeError("No JSON found", text, 0)

    def _validate_field(
        self,
        result: ValidationResult,
        data: Dict[str, Any],
        field_name: str,
        schema: Dict[str, Any],
        context: Optional[Dict[str, Any]],
    ):
        """Validate a single field against its schema."""
        value = data.get(field_name)

        # Check required
        if schema.get("required", False) and value is None:
            result.add_issue(
                field=field_name,
                message=f"Required field '{field_name}' is missing",
                severity=ValidationSeverity.ERROR,
            )
            return

        if value is None:
            return  # Optional field not present

        # Check type
        expected_type = schema.get("type")
        if expected_type:
            if not self._check_type(value, expected_type):
                result.add_issue(
                    field=field_name,
                    message=f"Expected type {expected_type}, got {type(value).__name__}",
                    severity=ValidationSeverity.ERROR,
                    actual_value=type(value).__name__,
                    expected=expected_type,
                )
                return

        # Check enum values
        if "enum" in schema:
            if value not in schema["enum"]:
                result.add_issue(
                    field=field_name,
                    message=f"Value '{value}' not in allowed values: {schema['enum']}",
                    severity=ValidationSeverity.ERROR,
                    actual_value=value,
                    expected=schema["enum"],
                )
                return

        # Check min/max for numbers
        if isinstance(value, (int, float)):
            if "min" in schema and value < schema["min"]:
                result.add_issue(
                    field=field_name,
                    message=f"Value {value} is less than minimum {schema['min']}",
                    severity=ValidationSeverity.ERROR,
                    actual_value=value,
                    expected=f">= {schema['min']}",
                )
            if "max" in schema and value > schema["max"]:
                result.add_issue(
                    field=field_name,
                    message=f"Value {value} exceeds maximum {schema['max']}",
                    severity=ValidationSeverity.ERROR,
                    actual_value=value,
                    expected=f"<= {schema['max']}",
                )

        # Check string length
        if isinstance(value, str):
            if "max_length" in schema and len(value) > schema["max_length"]:
                result.add_issue(
                    field=field_name,
                    message=f"String length {len(value)} exceeds max {schema['max_length']}",
                    severity=ValidationSeverity.WARNING,
                    actual_value=len(value),
                    expected=f"<= {schema['max_length']}",
                )

        # Custom validator
        if "validator" in schema:
            custom_result = schema["validator"](value, context)
            if custom_result is not True:
                result.add_issue(
                    field=field_name,
                    message=str(custom_result) if isinstance(custom_result, str) else f"Custom validation failed for '{field_name}'",
                    severity=ValidationSeverity.ERROR,
                    actual_value=value,
                )

    def _check_type(self, value: Any, expected_type: str) -> bool:
        """Check if value matches expected type."""
        type_map = {
            "string": str,
            "number": (int, float),
            "integer": int,
            "boolean": bool,
            "array": list,
            "object": dict,
        }
        expected = type_map.get(expected_type)
        if expected:
            return isinstance(value, expected)
        return True


# Pre-defined schemas for common validations

OFFER_DECISION_SCHEMA = {
    "selected_offer": {
        "required": True,
        "type": "string",
        "enum": ["IU_BUSINESS", "IU_PREMIUM_ECONOMY", "MCE", "NONE"],
    },
    "offer_price": {
        "required": True,
        "type": "number",
        "min": 0,
        "max": 1000,
    },
    "discount_percent": {
        "required": True,
        "type": "number",
        "min": 0,
        "max": 30,  # No more than 30% discount allowed
    },
    "confidence": {
        "required": False,
        "type": "string",
        "enum": ["high", "medium", "low"],
    },
    "key_factors": {
        "required": False,
        "type": "array",
    },
    "reasoning": {
        "required": False,
        "type": "string",
        "max_length": 2000,
    },
}

PERSONALIZATION_SCHEMA = {
    "subject": {
        "required": True,
        "type": "string",
        "max_length": 100,
    },
    "body": {
        "required": True,
        "type": "string",
        "max_length": 1000,
    },
    "tone": {
        "required": False,
        "type": "string",
        "enum": ["professional", "friendly", "urgent", "casual"],
    },
    "cta_text": {
        "required": False,
        "type": "string",
        "max_length": 50,
    },
}


def validate_offer_decision(
    response: Dict[str, Any],
    context: Optional[Dict[str, Any]] = None,
) -> ValidationResult:
    """
    Validate an offer decision response from the Offer Orchestration agent.

    Args:
        response: The parsed LLM response
        context: Optional context with offer options, customer data

    Returns:
        ValidationResult
    """
    validator = LLMResponseValidator("offer_orchestration")

    # Build schema with context-aware validators
    schema = OFFER_DECISION_SCHEMA.copy()

    # Add guardrail validators based on context
    if context:
        offer_options = context.get("offer_options", [])
        offer_types = [opt["offer_type"] for opt in offer_options]

        if offer_types:
            schema["selected_offer"]["enum"] = offer_types + ["NONE"]

        # Add discount cap validator
        def validate_discount(value, ctx):
            if ctx and "max_discount_percent" in ctx:
                max_discount = ctx["max_discount_percent"]
                if value > max_discount:
                    return f"Discount {value}% exceeds guardrail max {max_discount}%"
            return True

        schema["discount_percent"]["validator"] = validate_discount

    result = validator.validate(response, schema, context)

    # Additional semantic validations
    if result.is_valid and context:
        _validate_ev_logic(result, response, context)

    return result


def _validate_ev_logic(
    result: ValidationResult,
    response: Dict[str, Any],
    context: Dict[str, Any],
):
    """Validate that the selected offer has reasonable EV."""
    selected = response.get("selected_offer")
    if selected == "NONE":
        return

    offer_options = context.get("offer_options", [])

    # Find the selected offer
    selected_opt = None
    for opt in offer_options:
        if opt["offer_type"] == selected:
            selected_opt = opt
            break

    if not selected_opt:
        result.add_issue(
            field="selected_offer",
            message=f"Selected offer '{selected}' not found in available options",
            severity=ValidationSeverity.WARNING,
        )
        return

    # Check if we selected a much lower EV option
    best_ev = max(opt.get("expected_value", 0) for opt in offer_options)
    selected_ev = selected_opt.get("expected_value", 0)

    if best_ev > 0 and selected_ev < best_ev * 0.5:
        result.add_issue(
            field="selected_offer",
            message=f"Selected offer EV (${selected_ev:.0f}) is less than half of best option (${best_ev:.0f})",
            severity=ValidationSeverity.WARNING,
            actual_value=selected_ev,
            expected=best_ev,
        )


def validate_personalization_response(
    response: Dict[str, Any],
    context: Optional[Dict[str, Any]] = None,
) -> ValidationResult:
    """
    Validate a personalization response from the Personalization agent.

    Args:
        response: The parsed LLM response
        context: Optional context with customer name, offer details

    Returns:
        ValidationResult
    """
    validator = LLMResponseValidator("personalization")
    result = validator.validate(response, PERSONALIZATION_SCHEMA, context)

    # Additional semantic validations
    if result.is_valid and context:
        _validate_personalization_content(result, response, context)

    return result


def _validate_personalization_content(
    result: ValidationResult,
    response: Dict[str, Any],
    context: Dict[str, Any],
):
    """Validate personalization content quality."""
    body = response.get("body", "")
    customer_name = context.get("customer_name", "")
    offer_type = context.get("offer_type", "")

    # Check if customer name is mentioned (if provided)
    if customer_name and customer_name.lower() not in body.lower():
        result.add_issue(
            field="body",
            message=f"Customer name '{customer_name}' not found in message body",
            severity=ValidationSeverity.WARNING,
        )

    # Check if offer is mentioned
    offer_keywords = {
        "IU_BUSINESS": ["business", "business class", "first class"],
        "IU_PREMIUM_ECONOMY": ["premium", "premium economy", "extra legroom"],
        "MCE": ["main cabin extra", "mce", "extra", "comfort"],
    }

    if offer_type in offer_keywords:
        keywords = offer_keywords[offer_type]
        if not any(kw.lower() in body.lower() for kw in keywords):
            result.add_issue(
                field="body",
                message=f"Offer type '{offer_type}' keywords not found in message",
                severity=ValidationSeverity.WARNING,
            )

    # Check for placeholder text
    placeholder_patterns = [
        r'\[.*?\]',  # [PLACEHOLDER]
        r'\{.*?\}',  # {PLACEHOLDER}
        r'<.*?>',    # <PLACEHOLDER>
        r'XXX',
        r'TODO',
    ]

    for pattern in placeholder_patterns:
        if re.search(pattern, body):
            result.add_issue(
                field="body",
                message=f"Message contains placeholder text matching pattern '{pattern}'",
                severity=ValidationSeverity.ERROR,
            )
            break


================================================================================
FILE: pytest.ini
================================================================================
[pytest]
# Pytest configuration for Tailored Offers test suite

# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output settings
addopts =
    -v
    --tb=short
    -ra
    --strict-markers

# Markers for test categorization
markers =
    smoke: Quick sanity checks (deselect with '-m "not smoke"')
    slow: Tests that take longer to run
    compliance: Critical compliance/guardrail tests
    integration: End-to-end integration tests
    unit: Unit tests for individual components

# Logging
log_cli = true
log_cli_level = INFO

# Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning


================================================================================
FILE: requirements.txt
================================================================================
# Core dependencies
langgraph>=0.2.0
langchain>=0.3.0
langchain-anthropic>=0.3.0
langchain-openai>=0.2.0

# API Server
fastapi>=0.115.0
uvicorn[standard]>=0.32.0
sse-starlette>=2.0.0

# MCP (Model Context Protocol)
mcp>=1.25.0
langchain-mcp-adapters>=0.1.0

# UI
streamlit>=1.40.0

# Data handling
pandas>=2.0.0
pydantic>=2.0.0
pydantic-settings>=2.0.0

# Utilities
python-dotenv>=1.0.0
rich>=13.0.0

# =============================================================================
# Observability & Production Infrastructure
# =============================================================================

# Retry Logic
tenacity>=8.2.0

# Structured Logging
structlog>=24.0.0

# Metrics
prometheus-client>=0.19.0

# LLM Tracing & Evaluation
langsmith>=0.1.0
langfuse>=2.0.0

# Circuit Breaker
pybreaker>=1.0.0

# Memory (optional - for distributed memory)
redis>=5.0.0

# =============================================================================
# Testing
# =============================================================================
pytest>=8.0.0
pytest-asyncio>=0.23.0


================================================================================
FILE: run_demo.py
================================================================================
#!/usr/bin/env python3
"""
Tailored Offers Agentic Demo - CLI Runner

Usage:
    python run_demo.py --ui          # Launch Streamlit UI
    python run_demo.py --pnr ABC123  # Run single PNR evaluation
    python run_demo.py --all         # Run all PNRs
"""
import argparse
import subprocess
import sys
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

from tools.data_tools import get_all_reservations, get_enriched_pnr
from agents.workflow import run_offer_evaluation


def run_streamlit():
    """Launch the Streamlit UI"""
    ui_path = Path(__file__).parent / "ui" / "streamlit_app.py"
    subprocess.run(["streamlit", "run", str(ui_path)])


def run_single_pnr(pnr_locator: str):
    """Run evaluation for a single PNR"""
    print(f"\n{'='*60}")
    print(f"  TAILORED OFFERS - AGENTIC EVALUATION")
    print(f"  PNR: {pnr_locator}")
    print(f"{'='*60}\n")

    # Get enriched data first to show context
    enriched = get_enriched_pnr(pnr_locator)
    if not enriched:
        print(f"‚ùå PNR {pnr_locator} not found!")
        return

    cust = enriched["customer"]
    flight = enriched["flight"]
    res = enriched["pnr"]

    print(f"üë§ Customer: {cust['first_name']} {cust['last_name']} ({cust['loyalty_tier']})")
    print(f"‚úàÔ∏è  Flight: {flight['flight_id']} {flight['origin']}‚Üí{flight['destination']}")
    print(f"üìÖ Departure: {res['departure_date']} (T-{res['hours_to_departure']} hours)")
    print()

    # Run the workflow
    print("ü§ñ Running Agent Evaluation...\n")

    try:
        # Import and run agents manually to show progress
        from agents.state import create_initial_state
        from agents.customer_intelligence import CustomerIntelligenceAgent
        from agents.flight_optimization import FlightOptimizationAgent
        from agents.offer_orchestration import OfferOrchestrationAgent
        from agents.personalization import PersonalizationAgent
        from agents.channel_timing import ChannelTimingAgent
        from agents.measurement_learning import MeasurementLearningAgent

        state = create_initial_state(pnr_locator)
        state["customer_data"] = enriched["customer"]
        state["flight_data"] = enriched["flight"]
        state["reservation_data"] = enriched["pnr"]
        state["ml_scores"] = enriched["ml_scores"]

        # Agent 1
        print("üß† Agent 1: Customer Intelligence...")
        agent1 = CustomerIntelligenceAgent()
        result = agent1.analyze(state)
        state.update(result)
        print(f"   ‚Üí Eligible: {state.get('customer_eligible')}")
        print(f"   ‚Üí Segment: {state.get('customer_segment')}")

        if not state.get("customer_eligible"):
            print(f"\n‚ùå RESULT: No offer - {state.get('suppression_reason')}")
            return

        # Agent 2
        print("\nüìä Agent 2: Flight Optimization...")
        agent2 = FlightOptimizationAgent()
        result = agent2.analyze(state)
        state.update(result)
        print(f"   ‚Üí Flight Priority: {state.get('flight_priority')}")
        print(f"   ‚Üí Recommended Cabins: {state.get('recommended_cabins')}")

        # Agent 3
        print("\n‚öñÔ∏è  Agent 3: Offer Orchestration...")
        agent3 = OfferOrchestrationAgent()
        result = agent3.analyze(state)
        state.update(result)
        print(f"   ‚Üí Selected Offer: {state.get('selected_offer')}")
        print(f"   ‚Üí Price: ${state.get('offer_price', 0):.0f}")
        print(f"   ‚Üí Expected Value: ${state.get('expected_value', 0):.2f}")

        if not state.get("should_send_offer"):
            print(f"\n‚ùå RESULT: No offer - criteria not met")
            return

        # Agent 4
        print("\n‚ú® Agent 4: Personalization (GenAI)...")
        agent4 = PersonalizationAgent()
        result = agent4.analyze(state)
        state.update(result)
        print(f"   ‚Üí Tone: {state.get('message_tone')}")
        print(f"   ‚Üí Subject: {state.get('message_subject')[:50]}...")

        # Agent 5
        print("\nüì± Agent 5: Channel & Timing...")
        agent5 = ChannelTimingAgent()
        result = agent5.analyze(state)
        state.update(result)
        print(f"   ‚Üí Channel: {state.get('selected_channel')}")
        print(f"   ‚Üí Send Time: {state.get('send_time')}")

        # Agent 6
        print("\nüìà Agent 6: Measurement & Learning...")
        agent6 = MeasurementLearningAgent()
        result = agent6.analyze(state)
        state.update(result)
        print(f"   ‚Üí Experiment Group: {state.get('experiment_group')}")
        print(f"   ‚Üí Tracking ID: {state.get('tracking_id')}")

        # Final result
        print(f"\n{'='*60}")
        print("‚úÖ FINAL DECISION: SEND OFFER")
        print(f"{'='*60}")
        print(f"   Offer: {state.get('selected_offer')} @ ${state.get('offer_price', 0):.0f}")
        print(f"   Channel: {state.get('selected_channel').upper()}")
        print(f"   Time: {state.get('send_time')}")
        print(f"   Tracking: {state.get('tracking_id')}")
        print()

        # Show message
        print("üìß MESSAGE PREVIEW:")
        print("-" * 40)
        print(f"Subject: {state.get('message_subject')}")
        print("-" * 40)
        print(state.get("message_body"))
        print("-" * 40)

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


def run_all_pnrs():
    """Run evaluation for all PNRs"""
    reservations = get_all_reservations()

    print(f"\n{'='*60}")
    print(f"  TAILORED OFFERS - BATCH EVALUATION")
    print(f"  Processing {len(reservations)} PNRs")
    print(f"{'='*60}\n")

    for res in reservations:
        run_single_pnr(res["pnr_locator"])
        print("\n" + "="*60 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="Tailored Offers Agentic Demo"
    )
    parser.add_argument(
        "--ui",
        action="store_true",
        help="Launch Streamlit UI"
    )
    parser.add_argument(
        "--pnr",
        type=str,
        help="Evaluate a specific PNR"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Evaluate all PNRs"
    )

    args = parser.parse_args()

    if args.ui:
        run_streamlit()
    elif args.pnr:
        run_single_pnr(args.pnr)
    elif args.all:
        run_all_pnrs()
    else:
        # Default: show help and run ABC123 as example
        print("Tailored Offers Agentic Demo")
        print("-" * 40)
        print("Usage:")
        print("  python run_demo.py --ui          # Launch Streamlit UI")
        print("  python run_demo.py --pnr ABC123  # Run single PNR")
        print("  python run_demo.py --all         # Run all PNRs")
        print()
        print("Running example evaluation for PNR ABC123...")
        run_single_pnr("ABC123")


if __name__ == "__main__":
    main()


================================================================================
FILE: scripts/generate_narration_audio.py
================================================================================
#!/usr/bin/env python3
"""
Generate narration audio files for the Explainer Video.

Run this script once when you have OpenAI API access to create
static audio files that work offline.

Usage:
    export OPENAI_API_KEY=your-key
    python scripts/generate_narration_audio.py

The generated MP3 files will be saved to frontend/public/audio/
"""

import os
import sys
from pathlib import Path

# Narration scripts for each scene
NARRATIONS = {
    "title": """Welcome to AI Agents. The future of intelligent automation for American Airlines.""",

    "traditional": """Traditional automation relies on rigid if-then-else rules.
Every possible scenario must be pre-programmed by developers.
When edge cases appear, the system fails.
Updates require code changes and lengthy deployment cycles.
It's a maintenance nightmare that cannot adapt to changing business needs.""",

    "agent-intro": """Now, enter AI Agents.
These are autonomous systems that can reason, plan, and act to achieve goals.
Unlike traditional automation, agents are goal-oriented.
You give them objectives, not step-by-step instructions.
They adapt to new situations gracefully.
And they show their reasoning process, making decisions transparent and explainable.""",

    "comparison": """Here's the key difference.
Traditional workflows use pre-defined decision trees where developers write every rule.
They fail on edge cases and require code changes for any update.
You tell the computer exactly what to do.

AI Agents are different.
They reason about each situation dynamically.
Business users define goals in plain English.
Agents adapt to new scenarios without code changes.
You tell the agent what goal to achieve, and it figures out how.""",

    "rewoo": """This demo uses the ReWOO pattern. That stands for Reasoning Without Observation.
It works in three phases.
First, the Planner analyzes customer data and creates an evaluation plan.
Then, the Worker executes all evaluations in parallel for efficiency.
Finally, the Solver synthesizes the evidence and makes the decision.
This pattern requires only two to three LLM calls total, making it fast, efficient, and fully transparent.""",

    "walkthrough": """Let me walk you through the demo.
First, use the prompt editor at the top to control agent behavior in plain English.
Second, select a customer scenario from the list.
Third, click Run Agent to watch real-time reasoning from LangGraph.
Finally, see the personalized offer recommendation.
Try editing the prompts to see how agent behavior changes in real-time.""",

    "outro": """You're now ready to explore AI Agents.
Click anywhere to close this video and start the demo.
Experiment with different prompts and scenarios.
Let's go!"""
}


def generate_audio():
    """Generate audio files for all scenes."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("Error: OPENAI_API_KEY environment variable not set")
        print("Set it with: export OPENAI_API_KEY=your-key")
        sys.exit(1)

    try:
        from openai import OpenAI
    except ImportError:
        print("Error: openai package not installed")
        print("Install with: pip install openai")
        sys.exit(1)

    # Output directory
    script_dir = Path(__file__).parent.parent
    output_dir = script_dir / "frontend" / "public" / "audio"
    output_dir.mkdir(parents=True, exist_ok=True)

    client = OpenAI(api_key=api_key)

    print(f"Generating audio files to: {output_dir}")
    print("-" * 50)

    for scene_id, text in NARRATIONS.items():
        output_path = output_dir / f"{scene_id}.mp3"
        print(f"Generating: {scene_id}.mp3 ... ", end="", flush=True)

        try:
            response = client.audio.speech.create(
                model="tts-1-hd",
                voice="nova",  # Warm, engaging voice
                input=text,
                speed=0.95,  # Slightly slower for clarity
            )

            with open(output_path, "wb") as f:
                f.write(response.content)

            size_kb = output_path.stat().st_size / 1024
            print(f"Done ({size_kb:.1f} KB)")

        except Exception as e:
            print(f"Failed: {e}")

    print("-" * 50)
    print("Audio generation complete!")
    print(f"Files saved to: {output_dir}")
    print("\nThese files will be used automatically by the Explainer Video.")


if __name__ == "__main__":
    generate_audio()


================================================================================
FILE: tests/__init__.py
================================================================================
"""
Tailored Offers Test Suite

Eval-driven development infrastructure for validating agent decisions,
guardrail enforcement, and end-to-end scenario outcomes.
"""


================================================================================
FILE: tests/scenarios.py
================================================================================
"""
Scenario Specifications with Expected Outcomes

This module defines the expected behavior for each demo scenario.
These specs drive eval-based testing - the ground truth for agent decisions.

Structure:
- Each scenario has input context and expected outputs
- Expected outputs define acceptable ranges/values for validation
- Guardrail assertions ensure business rules are enforced
"""
from dataclasses import dataclass, field
from typing import List, Optional, Tuple, Dict, Any


@dataclass
class ExpectedDecision:
    """Expected outcome for a scenario"""

    # Core decision
    should_send_offer: bool

    # If should_send_offer is True
    acceptable_offers: List[str] = field(default_factory=list)  # e.g., ["IU_BUSINESS", "MCE"]
    price_range: Optional[Tuple[float, float]] = None  # (min, max)
    acceptable_channels: List[str] = field(default_factory=list)  # e.g., ["push", "email"]

    # If should_send_offer is False
    expected_suppression_reasons: List[str] = field(default_factory=list)

    # Guardrail assertions (must always pass)
    max_discount_percent: float = 0.25  # Never exceed 25%
    min_expected_value: float = 0.0  # EV must be positive if offering

    # Reasoning requirements (keywords that should appear in reasoning)
    reasoning_must_include: List[str] = field(default_factory=list)


@dataclass
class ScenarioSpec:
    """Complete specification for a test scenario"""

    pnr: str
    description: str
    customer_context: Dict[str, Any]  # Key customer attributes
    expected: ExpectedDecision
    tags: List[str] = field(default_factory=list)  # For filtering tests


# =============================================================================
# SCENARIO SPECIFICATIONS
# =============================================================================

SCENARIOS: Dict[str, ScenarioSpec] = {

    # -------------------------------------------------------------------------
    # ABC123: Standard Happy Path
    # -------------------------------------------------------------------------
    "ABC123": ScenarioSpec(
        pnr="ABC123",
        description="Gold customer, T-96hrs, standard happy path - should receive offer",
        customer_context={
            "name": "Sarah Johnson",
            "loyalty_tier": "Gold",
            "hours_to_departure": 96,
            "historical_acceptance_rate": 0.33,
            "annual_revenue": 4200,
            "is_suppressed": False,
            "has_push_consent": True,
            "has_email_consent": True,
        },
        expected=ExpectedDecision(
            should_send_offer=True,
            acceptable_offers=["IU_BUSINESS", "MCE"],
            price_range=(39, 299),  # Could be MCE at $39-89 or Business at $149-299
            acceptable_channels=["push", "email"],
            max_discount_percent=0.20,
            min_expected_value=30.0,  # EV should be meaningful
            reasoning_must_include=["Gold", "eligible", "propensity"],
        ),
        tags=["happy_path", "gold_tier", "standard"],
    ),

    # -------------------------------------------------------------------------
    # XYZ789: High-Value Business Traveler
    # -------------------------------------------------------------------------
    "XYZ789": ScenarioSpec(
        pnr="XYZ789",
        description="Platinum Pro, frequent business traveler - premium pricing acceptable",
        customer_context={
            "name": "John Smith",
            "loyalty_tier": "Platinum Pro",
            "hours_to_departure": 72,
            "historical_acceptance_rate": 0.67,
            "annual_revenue": 28500,
            "is_suppressed": False,
            "business_trip_likelihood": 0.85,
        },
        expected=ExpectedDecision(
            should_send_offer=True,
            acceptable_offers=["IU_BUSINESS", "IU_FIRST"],
            price_range=(199, 699),  # Higher value customer, premium pricing
            acceptable_channels=["push", "email", "in_app"],
            max_discount_percent=0.20,
            min_expected_value=50.0,  # High-value customer = higher EV
            reasoning_must_include=["Platinum", "business", "high"],
        ),
        tags=["happy_path", "platinum_tier", "business_traveler", "high_value"],
    ),

    # -------------------------------------------------------------------------
    # LMN456: Executive Platinum International
    # -------------------------------------------------------------------------
    "LMN456": ScenarioSpec(
        pnr="LMN456",
        description="Exec Platinum, international route, premium treatment",
        customer_context={
            "name": "Emily Chen",
            "loyalty_tier": "Executive Platinum",
            "hours_to_departure": 120,
            "historical_acceptance_rate": 0.75,
            "annual_revenue": 85000,
            "is_suppressed": False,
            "international_trip": True,
        },
        expected=ExpectedDecision(
            should_send_offer=True,
            acceptable_offers=["IU_BUSINESS", "IU_FIRST"],
            price_range=(499, 1299),  # Premium international pricing
            acceptable_channels=["push", "email"],
            max_discount_percent=0.20,
            min_expected_value=100.0,  # Very high EV for exec plat
            # More flexible keywords - match actual agent output
            reasoning_must_include=["Executive Platinum", "eligible"],
        ),
        tags=["happy_path", "exec_platinum", "international", "premium"],
    ),

    # -------------------------------------------------------------------------
    # DEF321: Cold Start / New Customer
    # -------------------------------------------------------------------------
    "DEF321": ScenarioSpec(
        pnr="DEF321",
        description="New customer, low confidence scores, cold start problem",
        customer_context={
            "name": "Michael Brown",
            "loyalty_tier": "General",
            "hours_to_departure": 48,
            "historical_acceptance_rate": None,  # No history
            "annual_revenue": 285,
            "is_suppressed": False,
            "tenure_days": 30,  # Very new
        },
        expected=ExpectedDecision(
            # Cold start with low confidence - may or may not offer
            # The key is: if we offer, guardrails must be respected
            should_send_offer=False,  # Low confidence + no inventory typically = no offer
            acceptable_offers=["MCE"],  # If offered, only low-risk MCE
            price_range=(19, 69),
            acceptable_channels=["email"],  # Conservative channel
            max_discount_percent=0.25,
            expected_suppression_reasons=["inventory", "confidence", "cold_start"],
            reasoning_must_include=["new", "confidence"],
        ),
        tags=["cold_start", "new_customer", "low_confidence"],
    ),

    # -------------------------------------------------------------------------
    # GHI654: Suppressed Customer (MUST NOT RECEIVE OFFER)
    # -------------------------------------------------------------------------
    "GHI654": ScenarioSpec(
        pnr="GHI654",
        description="Platinum customer with recent complaint - MUST be suppressed",
        customer_context={
            "name": "Lisa Martinez",
            "loyalty_tier": "Platinum",
            "hours_to_departure": 96,
            "historical_acceptance_rate": 0.45,
            "annual_revenue": 12000,
            "is_suppressed": True,  # CRITICAL: Suppressed
            "suppression_reason": "recent_complaint",
        },
        expected=ExpectedDecision(
            should_send_offer=False,  # MUST be False
            expected_suppression_reasons=["recent_complaint", "suppressed", "complaint", "baggage"],
            # More flexible - "ineligible" also matches
            reasoning_must_include=["suppressed"],
        ),
        tags=["suppression", "must_not_offer", "compliance"],
    ),

    # -------------------------------------------------------------------------
    # JKL789: Price-Sensitive Budget Customer
    # -------------------------------------------------------------------------
    "JKL789": ScenarioSpec(
        pnr="JKL789",
        description="Price-sensitive customer - needs discount to convert",
        customer_context={
            "name": "Budget Traveler",
            "loyalty_tier": "Gold",
            "hours_to_departure": 84,
            "historical_acceptance_rate": 0.12,  # Low - price sensitive
            "annual_revenue": 890,
            "is_suppressed": False,
            "avg_upgrade_spend": 25,  # Low spend history
            "price_sensitivity": "high",
        },
        expected=ExpectedDecision(
            should_send_offer=True,
            acceptable_offers=["MCE"],  # Only low-cost option makes sense
            price_range=(19, 49),  # Must be discounted
            acceptable_channels=["email", "push"],
            max_discount_percent=0.25,  # MCE can go up to 25%
            min_expected_value=10.0,  # Lower EV acceptable for MCE
            # More flexible keywords - match actual agent output
            reasoning_must_include=["Gold", "eligible"],
        ),
        tags=["price_sensitive", "budget", "mce_only"],
    ),
}


# =============================================================================
# GUARDRAIL SPECIFICATIONS (Universal Rules)
# =============================================================================

GUARDRAILS = {
    "max_discount_business": 0.20,  # Business class: max 20% off
    "max_discount_first": 0.15,     # First class: max 15% off
    "max_discount_mce": 0.25,       # MCE: max 25% off
    "min_hours_to_departure": 6,    # Don't offer within 6 hours
    "suppression_blocks_offer": True,  # Suppressed = no offer, always
}


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def get_scenario(pnr: str) -> Optional[ScenarioSpec]:
    """Get scenario specification by PNR"""
    return SCENARIOS.get(pnr)


def get_scenarios_by_tag(tag: str) -> List[ScenarioSpec]:
    """Get all scenarios with a specific tag"""
    return [s for s in SCENARIOS.values() if tag in s.tags]


def get_all_pnrs() -> List[str]:
    """Get all scenario PNRs"""
    return list(SCENARIOS.keys())


def get_suppression_scenarios() -> List[ScenarioSpec]:
    """Get scenarios that MUST NOT receive offers"""
    return [s for s in SCENARIOS.values() if not s.expected.should_send_offer]


def get_happy_path_scenarios() -> List[ScenarioSpec]:
    """Get scenarios that should receive offers"""
    return [s for s in SCENARIOS.values() if s.expected.should_send_offer]


================================================================================
FILE: tests/test_agents.py
================================================================================
"""
Agent Unit Tests

Tests for individual agent behavior in isolation.
Each agent's analyze() method is tested with controlled inputs.

Run with: pytest tests/test_agents.py -v
"""
import pytest
import sys
from pathlib import Path
from copy import deepcopy

sys.path.insert(0, str(Path(__file__).parent.parent))

from agents.state import create_initial_state
from agents.customer_intelligence import CustomerIntelligenceAgent
from agents.flight_optimization import FlightOptimizationAgent
from agents.offer_orchestration import OfferOrchestrationAgent
from agents.personalization import PersonalizationAgent
from agents.channel_timing import ChannelTimingAgent
from agents.measurement_learning import MeasurementLearningAgent
from tools.data_tools import get_enriched_pnr


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
def base_state():
    """Create a base state with ABC123 data for testing"""
    enriched = get_enriched_pnr("ABC123")
    state = create_initial_state("ABC123")
    state["customer_data"] = enriched["customer"]
    state["flight_data"] = enriched["flight"]
    state["reservation_data"] = enriched["pnr"]
    state["ml_scores"] = enriched["ml_scores"]
    return state


@pytest.fixture
def suppressed_state():
    """Create state with suppressed customer (GHI654)"""
    enriched = get_enriched_pnr("GHI654")
    state = create_initial_state("GHI654")
    state["customer_data"] = enriched["customer"]
    state["flight_data"] = enriched["flight"]
    state["reservation_data"] = enriched["pnr"]
    state["ml_scores"] = enriched["ml_scores"]
    return state


@pytest.fixture
def customer_agent():
    return CustomerIntelligenceAgent()


@pytest.fixture
def flight_agent():
    return FlightOptimizationAgent()


@pytest.fixture
def offer_agent():
    return OfferOrchestrationAgent()


@pytest.fixture
def personalization_agent():
    return PersonalizationAgent()


@pytest.fixture
def channel_agent():
    return ChannelTimingAgent()


@pytest.fixture
def measurement_agent():
    return MeasurementLearningAgent()


# =============================================================================
# CUSTOMER INTELLIGENCE AGENT TESTS
# =============================================================================

class TestCustomerIntelligenceAgent:
    """Tests for CustomerIntelligenceAgent"""

    def test_eligible_customer_returns_true(self, customer_agent, base_state):
        """Non-suppressed customer with consent should be eligible"""
        result = customer_agent.analyze(base_state)

        assert result["customer_eligible"] == True
        assert result["suppression_reason"] is None
        assert "customer_segment" in result

    def test_suppressed_customer_returns_false(self, customer_agent, suppressed_state):
        """Suppressed customer must be marked ineligible"""
        result = customer_agent.analyze(suppressed_state)

        assert result["customer_eligible"] == False
        assert result["suppression_reason"] is not None
        # Suppression reason should indicate customer is suppressed
        # (may contain "suppressed", the complaint reason, or both)
        reason_lower = result["suppression_reason"].lower()
        assert "suppressed" in reason_lower or "baggage" in reason_lower or "complaint" in reason_lower

    def test_no_consent_returns_false(self, customer_agent, base_state):
        """Customer without any marketing consent should be ineligible"""
        state = deepcopy(base_state)
        state["customer_data"]["marketing_consent"] = {
            "push": False,
            "email": False,
            "sms": False,
        }

        result = customer_agent.analyze(state)

        assert result["customer_eligible"] == False
        assert "consent" in result["suppression_reason"].lower()

    def test_returns_customer_segment(self, customer_agent, base_state):
        """Agent must return a customer segment"""
        result = customer_agent.analyze(base_state)

        assert "customer_segment" in result
        assert result["customer_segment"] is not None
        assert len(result["customer_segment"]) > 0

    def test_returns_reasoning(self, customer_agent, base_state):
        """Agent must provide reasoning"""
        result = customer_agent.analyze(base_state)

        assert "customer_reasoning" in result
        assert len(result["customer_reasoning"]) > 50


# =============================================================================
# FLIGHT OPTIMIZATION AGENT TESTS
# =============================================================================

class TestFlightOptimizationAgent:
    """Tests for FlightOptimizationAgent"""

    def test_returns_flight_priority(self, flight_agent, base_state):
        """Agent must return flight priority"""
        result = flight_agent.analyze(base_state)

        assert "flight_priority" in result
        assert result["flight_priority"] in ["high", "medium", "low"]

    def test_returns_recommended_cabins(self, flight_agent, base_state):
        """Agent must return recommended cabins list"""
        result = flight_agent.analyze(base_state)

        assert "recommended_cabins" in result
        assert isinstance(result["recommended_cabins"], list)

    def test_returns_inventory_status(self, flight_agent, base_state):
        """Agent must return inventory status"""
        result = flight_agent.analyze(base_state)

        assert "inventory_status" in result
        assert isinstance(result["inventory_status"], dict)

    def test_returns_reasoning(self, flight_agent, base_state):
        """Agent must provide reasoning"""
        result = flight_agent.analyze(base_state)

        assert "flight_reasoning" in result
        assert len(result["flight_reasoning"]) > 50


# =============================================================================
# OFFER ORCHESTRATION AGENT TESTS
# =============================================================================

class TestOfferOrchestrationAgent:
    """Tests for OfferOrchestrationAgent (the core decision agent)"""

    def test_returns_decision_when_eligible(self, offer_agent, base_state):
        """Agent must return offer decision for eligible customer"""
        # First run customer intelligence to set eligibility
        customer_agent = CustomerIntelligenceAgent()
        customer_result = customer_agent.analyze(base_state)
        base_state.update(customer_result)

        # Then run flight optimization
        flight_agent = FlightOptimizationAgent()
        flight_result = flight_agent.analyze(base_state)
        base_state.update(flight_result)

        # Now run offer orchestration
        result = offer_agent.analyze(base_state)

        assert "selected_offer" in result
        assert "offer_price" in result
        assert "should_send_offer" in result

    def test_skips_ineligible_customer(self, offer_agent, suppressed_state):
        """Agent should not offer to ineligible customer"""
        # First run customer intelligence
        customer_agent = CustomerIntelligenceAgent()
        customer_result = customer_agent.analyze(suppressed_state)
        suppressed_state.update(customer_result)

        result = offer_agent.analyze(suppressed_state)

        assert result.get("should_send_offer") == False

    def test_returns_expected_value(self, offer_agent, base_state):
        """Agent must calculate and return expected value"""
        customer_agent = CustomerIntelligenceAgent()
        customer_result = customer_agent.analyze(base_state)
        base_state.update(customer_result)

        flight_agent = FlightOptimizationAgent()
        flight_result = flight_agent.analyze(base_state)
        base_state.update(flight_result)

        result = offer_agent.analyze(base_state)

        if result.get("should_send_offer"):
            assert "expected_value" in result
            assert result["expected_value"] > 0

    def test_returns_reasoning(self, offer_agent, base_state):
        """Agent must provide detailed reasoning"""
        customer_agent = CustomerIntelligenceAgent()
        base_state.update(customer_agent.analyze(base_state))

        flight_agent = FlightOptimizationAgent()
        base_state.update(flight_agent.analyze(base_state))

        result = offer_agent.analyze(base_state)

        assert "offer_reasoning" in result
        assert len(result["offer_reasoning"]) > 100  # Detailed reasoning expected


# =============================================================================
# PERSONALIZATION AGENT TESTS
# =============================================================================

class TestPersonalizationAgent:
    """Tests for PersonalizationAgent (LLM-powered)"""

    def test_generates_message_when_offering(self, personalization_agent, base_state):
        """Agent must generate message when there's an offer"""
        # Set up state with an offer
        base_state["should_send_offer"] = True
        base_state["selected_offer"] = "MCE"
        base_state["offer_price"] = 49
        base_state["customer_eligible"] = True

        result = personalization_agent.analyze(base_state)

        assert "message_subject" in result
        assert "message_body" in result
        assert len(result["message_subject"]) > 0
        assert len(result["message_body"]) > 50

    def test_skips_when_no_offer(self, personalization_agent, base_state):
        """Agent should skip personalization when no offer"""
        base_state["should_send_offer"] = False

        result = personalization_agent.analyze(base_state)

        # Should still return fields but may be empty
        assert "message_subject" in result or "personalization_reasoning" in result

    def test_message_includes_customer_name(self, personalization_agent, base_state):
        """Message should be personalized with customer name"""
        base_state["should_send_offer"] = True
        base_state["selected_offer"] = "MCE"
        base_state["offer_price"] = 49
        base_state["customer_eligible"] = True

        result = personalization_agent.analyze(base_state)

        customer_name = base_state["customer_data"]["first_name"]
        message_body = result.get("message_body", "")

        assert customer_name in message_body, (
            f"Message should include customer name '{customer_name}'"
        )


# =============================================================================
# CHANNEL & TIMING AGENT TESTS
# =============================================================================

class TestChannelTimingAgent:
    """Tests for ChannelTimingAgent"""

    def test_selects_channel_based_on_consent(self, channel_agent, base_state):
        """Agent should only select channels customer consented to"""
        base_state["should_send_offer"] = True
        base_state["customer_eligible"] = True

        result = channel_agent.analyze(base_state)

        assert "selected_channel" in result
        selected = result["selected_channel"].lower()

        # Check consent
        consent = base_state["customer_data"]["marketing_consent"]
        if selected == "push":
            assert consent.get("push", False)
        elif selected == "email":
            assert consent.get("email", False)
        elif selected == "sms":
            assert consent.get("sms", False)

    def test_returns_send_time(self, channel_agent, base_state):
        """Agent must return send time"""
        base_state["should_send_offer"] = True
        base_state["customer_eligible"] = True

        result = channel_agent.analyze(base_state)

        assert "send_time" in result
        assert len(result["send_time"]) > 0

    def test_returns_reasoning(self, channel_agent, base_state):
        """Agent must provide reasoning"""
        base_state["should_send_offer"] = True
        base_state["customer_eligible"] = True

        result = channel_agent.analyze(base_state)

        assert "channel_reasoning" in result


# =============================================================================
# MEASUREMENT & LEARNING AGENT TESTS
# =============================================================================

class TestMeasurementLearningAgent:
    """Tests for MeasurementLearningAgent (Tracking Setup)"""

    def test_assigns_experiment_group(self, measurement_agent, base_state):
        """Agent must assign an experiment group"""
        base_state["should_send_offer"] = True

        result = measurement_agent.analyze(base_state)

        assert "experiment_group" in result
        # Experiment groups can be control, treatment variants, or model versions
        valid_groups = ["control", "treatment", "exploration", "test_model_v1", "test_model_v2"]
        assert result["experiment_group"] in valid_groups, f"Unexpected group: {result['experiment_group']}"

    def test_generates_tracking_id(self, measurement_agent, base_state):
        """Agent must generate a tracking ID"""
        base_state["should_send_offer"] = True

        result = measurement_agent.analyze(base_state)

        assert "tracking_id" in result
        assert len(result["tracking_id"]) > 10
        assert "ABC123" in result["tracking_id"]  # Should include PNR

    def test_tracking_id_unique(self, measurement_agent, base_state):
        """Tracking IDs should be unique across calls"""
        base_state["should_send_offer"] = True

        result1 = measurement_agent.analyze(base_state)
        result2 = measurement_agent.analyze(base_state)

        # IDs should be different (includes timestamp + random)
        assert result1["tracking_id"] != result2["tracking_id"]


# =============================================================================
# AGENT INTERFACE COMPLIANCE TESTS
# =============================================================================

class TestAgentInterfaces:
    """Tests that all agents comply with expected interface"""

    @pytest.fixture
    def all_agents(self):
        return [
            CustomerIntelligenceAgent(),
            FlightOptimizationAgent(),
            OfferOrchestrationAgent(),
            PersonalizationAgent(),
            ChannelTimingAgent(),
            MeasurementLearningAgent(),
        ]

    def test_all_agents_have_analyze_method(self, all_agents):
        """All agents must have analyze() method"""
        for agent in all_agents:
            assert hasattr(agent, "analyze")
            assert callable(getattr(agent, "analyze"))

    def test_analyze_returns_dict(self, all_agents, base_state):
        """analyze() must return a dictionary"""
        for agent in all_agents:
            result = agent.analyze(base_state)
            assert isinstance(result, dict), (
                f"{agent.__class__.__name__}.analyze() must return dict"
            )

    def test_analyze_includes_reasoning(self, all_agents, base_state):
        """Each agent should include reasoning in output"""
        reasoning_keys = [
            "customer_reasoning",
            "flight_reasoning",
            "offer_reasoning",
            "personalization_reasoning",
            "channel_reasoning",
            "measurement_reasoning",
        ]

        for agent in all_agents:
            result = agent.analyze(base_state)

            # At least one reasoning key should be present
            has_reasoning = any(key in result for key in reasoning_keys)
            assert has_reasoning, (
                f"{agent.__class__.__name__} should include reasoning in output"
            )


================================================================================
FILE: tests/test_guardrails.py
================================================================================
"""
Guardrail Enforcement Tests

Tests that verify business rules are NEVER violated, regardless of input.
These are critical compliance tests that should never fail.

Run with: pytest tests/test_guardrails.py -v
"""
import pytest
import sys
from pathlib import Path
from copy import deepcopy

sys.path.insert(0, str(Path(__file__).parent.parent))

from agents.workflow import run_offer_evaluation
from agents.state import create_initial_state
from agents.customer_intelligence import CustomerIntelligenceAgent
from agents.flight_optimization import FlightOptimizationAgent
from agents.offer_orchestration import OfferOrchestrationAgent
from tools.data_tools import get_enriched_pnr
from tests.scenarios import GUARDRAILS, get_all_pnrs


# =============================================================================
# DISCOUNT GUARDRAIL TESTS
# =============================================================================

class TestDiscountGuardrails:
    """Tests that discount limits are never exceeded"""

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_business_class_discount_capped_at_20_percent(self, pnr: str):
        """Business class discount must never exceed 20%"""
        result = run_offer_evaluation(pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        offer_type = result.get("selected_offer", "")
        if "BUSINESS" not in offer_type.upper():
            pytest.skip("Not a business class offer")

        discount = result.get("discount_applied", 0)
        max_discount = GUARDRAILS["max_discount_business"]

        assert discount <= max_discount, (
            f"GUARDRAIL VIOLATION: Business class discount {discount:.0%} "
            f"exceeds max {max_discount:.0%}"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_mce_discount_capped_at_25_percent(self, pnr: str):
        """MCE discount must never exceed 25%"""
        result = run_offer_evaluation(pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        offer_type = result.get("selected_offer", "")
        if "MCE" not in offer_type.upper():
            pytest.skip("Not an MCE offer")

        discount = result.get("discount_applied", 0)
        max_discount = GUARDRAILS["max_discount_mce"]

        assert discount <= max_discount, (
            f"GUARDRAIL VIOLATION: MCE discount {discount:.0%} "
            f"exceeds max {max_discount:.0%}"
        )

    def test_urgency_boost_still_respects_cap(self):
        """Even with urgency boost, discount must be capped"""
        # Create a state with urgent timing (< 24 hours)
        enriched = get_enriched_pnr("ABC123")
        state = create_initial_state("ABC123")
        state["customer_data"] = enriched["customer"]
        state["flight_data"] = enriched["flight"]
        state["reservation_data"] = deepcopy(enriched["pnr"])
        state["ml_scores"] = enriched["ml_scores"]

        # Set urgent timing
        state["reservation_data"]["hours_to_departure"] = 20  # Urgent: +10% boost

        # Run through agents
        customer_agent = CustomerIntelligenceAgent()
        state.update(customer_agent.analyze(state))

        flight_agent = FlightOptimizationAgent()
        state.update(flight_agent.analyze(state))

        offer_agent = OfferOrchestrationAgent()
        result = offer_agent.analyze(state)

        if result.get("should_send_offer"):
            discount = result.get("discount_applied", 0)
            offer_type = result.get("selected_offer", "")

            if "BUSINESS" in offer_type.upper():
                max_discount = 0.20
            else:
                max_discount = 0.25

            assert discount <= max_discount, (
                f"GUARDRAIL VIOLATION: Urgency boost caused discount {discount:.0%} "
                f"to exceed cap {max_discount:.0%}"
            )


# =============================================================================
# SUPPRESSION GUARDRAIL TESTS
# =============================================================================

class TestSuppressionGuardrails:
    """Tests that suppressed customers NEVER receive offers"""

    def test_suppressed_customer_never_gets_offer(self):
        """GHI654 (suppressed) must never receive an offer"""
        result = run_offer_evaluation("GHI654")

        assert result.get("should_send_offer") == False, (
            "CRITICAL GUARDRAIL VIOLATION: Suppressed customer received an offer!"
        )

    def test_suppression_flag_blocks_offer(self):
        """Any customer with suppression flag must be blocked"""
        enriched = get_enriched_pnr("ABC123")
        state = create_initial_state("ABC123")
        state["customer_data"] = deepcopy(enriched["customer"])
        state["flight_data"] = enriched["flight"]
        state["reservation_data"] = enriched["pnr"]
        state["ml_scores"] = enriched["ml_scores"]

        # Force suppression
        state["customer_data"]["suppression"] = {
            "is_suppressed": True,
            "recent_complaint": True,
            "complaint_reason": "Test suppression",
        }

        customer_agent = CustomerIntelligenceAgent()
        result = customer_agent.analyze(state)

        assert result["customer_eligible"] == False, (
            "GUARDRAIL VIOLATION: Suppressed customer marked as eligible"
        )


# =============================================================================
# TIMING GUARDRAIL TESTS
# =============================================================================

class TestTimingGuardrails:
    """Tests for time-based guardrails"""

    def test_no_offer_within_6_hours(self):
        """Offers should not be sent within 6 hours of departure"""
        enriched = get_enriched_pnr("ABC123")
        state = create_initial_state("ABC123")
        state["customer_data"] = enriched["customer"]
        state["flight_data"] = enriched["flight"]
        state["reservation_data"] = deepcopy(enriched["pnr"])
        state["ml_scores"] = enriched["ml_scores"]

        # Set to 5 hours before departure
        state["reservation_data"]["hours_to_departure"] = 5

        # Run through offer agent
        customer_agent = CustomerIntelligenceAgent()
        state.update(customer_agent.analyze(state))

        flight_agent = FlightOptimizationAgent()
        state.update(flight_agent.analyze(state))

        offer_agent = OfferOrchestrationAgent()
        result = offer_agent.analyze(state)

        # Should not send offer with only 5 hours
        # Note: This depends on implementation - adjust assertion if needed
        if result.get("should_send_offer"):
            # If offer is sent, verify urgency is handled
            reasoning = result.get("offer_reasoning", "").lower()
            assert "too late" in reasoning or "urgent" in reasoning or "hours" in reasoning


# =============================================================================
# CONSENT GUARDRAIL TESTS
# =============================================================================

class TestConsentGuardrails:
    """Tests that marketing consent is respected"""

    def test_no_offer_without_any_consent(self):
        """Customer without any channel consent must not receive offers"""
        enriched = get_enriched_pnr("ABC123")
        state = create_initial_state("ABC123")
        state["customer_data"] = deepcopy(enriched["customer"])
        state["flight_data"] = enriched["flight"]
        state["reservation_data"] = enriched["pnr"]
        state["ml_scores"] = enriched["ml_scores"]

        # Remove all consent
        state["customer_data"]["marketing_consent"] = {
            "push": False,
            "email": False,
            "sms": False,
        }

        customer_agent = CustomerIntelligenceAgent()
        result = customer_agent.analyze(state)

        assert result["customer_eligible"] == False, (
            "GUARDRAIL VIOLATION: Customer without consent marked eligible"
        )
        assert "consent" in result.get("suppression_reason", "").lower()

    def test_channel_respects_consent(self):
        """Selected channel must have customer consent"""
        from agents.channel_timing import ChannelTimingAgent

        enriched = get_enriched_pnr("ABC123")
        state = create_initial_state("ABC123")
        state["customer_data"] = deepcopy(enriched["customer"])
        state["flight_data"] = enriched["flight"]
        state["reservation_data"] = enriched["pnr"]
        state["should_send_offer"] = True
        state["customer_eligible"] = True

        # Only allow email
        state["customer_data"]["marketing_consent"] = {
            "push": False,
            "email": True,
            "sms": False,
        }

        channel_agent = ChannelTimingAgent()
        result = channel_agent.analyze(state)

        selected = result.get("selected_channel", "").lower()

        # Should select email since it's the only consented channel
        assert selected == "email" or "email" in selected.lower(), (
            f"GUARDRAIL VIOLATION: Selected '{selected}' but only email is consented"
        )


# =============================================================================
# EXPECTED VALUE GUARDRAIL TESTS
# =============================================================================

class TestExpectedValueGuardrails:
    """Tests for EV-based decision guardrails"""

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_no_negative_ev_offers(self, pnr: str):
        """Should not make offers with negative expected value"""
        result = run_offer_evaluation(pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        ev = result.get("expected_value", 0)

        assert ev >= 0, (
            f"GUARDRAIL VIOLATION: Made offer with negative EV ${ev:.2f}"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_price_not_below_minimum(self, pnr: str):
        """Offer price should not go below sensible minimum"""
        result = run_offer_evaluation(pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        price = result.get("offer_price", 0)
        offer_type = result.get("selected_offer", "")

        # MCE minimum ~$19, Business minimum ~$99
        if "MCE" in offer_type.upper():
            min_price = 10
        else:
            min_price = 50

        assert price >= min_price, (
            f"GUARDRAIL VIOLATION: {offer_type} price ${price} below minimum ${min_price}"
        )


# =============================================================================
# DATA INTEGRITY GUARDRAIL TESTS
# =============================================================================

class TestDataIntegrityGuardrails:
    """Tests that data flows correctly and completely"""

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_customer_data_required(self, pnr: str):
        """Customer data must be present for any processing"""
        result = run_offer_evaluation(pnr)

        customer_data = result.get("customer_data")
        assert customer_data is not None, (
            f"GUARDRAIL VIOLATION: No customer data for {pnr}"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_reasoning_trace_not_empty(self, pnr: str):
        """Reasoning trace must document the decision path"""
        result = run_offer_evaluation(pnr)

        reasoning_trace = result.get("reasoning_trace", [])
        assert len(reasoning_trace) > 0, (
            f"GUARDRAIL VIOLATION: No reasoning trace for {pnr}"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_tracking_id_generated(self, pnr: str):
        """Tracking ID must be generated for measurement"""
        result = run_offer_evaluation(pnr)

        if result.get("should_send_offer"):
            tracking_id = result.get("tracking_id")
            assert tracking_id is not None and len(tracking_id) > 0, (
                f"GUARDRAIL VIOLATION: No tracking ID for offer on {pnr}"
            )


# =============================================================================
# COMPLIANCE SUMMARY TEST
# =============================================================================

class TestComplianceSummary:
    """High-level compliance checks"""

    def test_all_guardrails_documented(self):
        """All guardrails should be documented in GUARDRAILS constant"""
        required_guardrails = [
            "max_discount_business",
            "max_discount_mce",
            "min_hours_to_departure",
            "suppression_blocks_offer",
        ]

        for guardrail in required_guardrails:
            assert guardrail in GUARDRAILS, (
                f"Missing guardrail documentation: {guardrail}"
            )

    def test_guardrails_have_sensible_values(self):
        """Guardrail values should be sensible"""
        assert 0 < GUARDRAILS["max_discount_business"] <= 0.30
        assert 0 < GUARDRAILS["max_discount_mce"] <= 0.40
        assert 0 < GUARDRAILS["min_hours_to_departure"] <= 24
        assert GUARDRAILS["suppression_blocks_offer"] == True


================================================================================
FILE: tests/test_scenarios.py
================================================================================
"""
End-to-End Scenario Tests

These tests validate that the complete pipeline produces expected outcomes
for each demo scenario. This is the core eval-driven development test suite.

Run with: pytest tests/test_scenarios.py -v
"""
import pytest
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from agents.workflow import run_offer_evaluation
from tests.scenarios import (
    SCENARIOS,
    GUARDRAILS,
    ScenarioSpec,
    get_all_pnrs,
    get_suppression_scenarios,
    get_happy_path_scenarios,
)


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
def scenario_result():
    """Factory fixture to run a scenario and cache result"""
    cache = {}

    def _get_result(pnr: str):
        if pnr not in cache:
            cache[pnr] = run_offer_evaluation(pnr)
        return cache[pnr]

    return _get_result


# =============================================================================
# PARAMETRIZED END-TO-END TESTS
# =============================================================================

@pytest.mark.parametrize("pnr", get_all_pnrs())
class TestScenarioOutcomes:
    """Test expected outcomes for each scenario"""

    def test_offer_decision_matches_expected(self, pnr: str, scenario_result):
        """Verify should_send_offer matches expected"""
        spec = SCENARIOS[pnr]
        result = scenario_result(pnr)

        actual = result.get("should_send_offer", False)
        expected = spec.expected.should_send_offer

        assert actual == expected, (
            f"Scenario {pnr} ({spec.description}): "
            f"Expected should_send_offer={expected}, got {actual}"
        )

    def test_offer_type_is_acceptable(self, pnr: str, scenario_result):
        """Verify selected offer is in acceptable list"""
        spec = SCENARIOS[pnr]
        result = scenario_result(pnr)

        if not spec.expected.should_send_offer:
            pytest.skip("Scenario should not send offer")

        if not spec.expected.acceptable_offers:
            pytest.skip("No acceptable offers specified")

        actual_offer = result.get("selected_offer")
        acceptable = spec.expected.acceptable_offers

        assert actual_offer in acceptable, (
            f"Scenario {pnr}: Offer '{actual_offer}' not in acceptable list {acceptable}"
        )

    def test_price_in_expected_range(self, pnr: str, scenario_result):
        """Verify offer price is within expected range"""
        spec = SCENARIOS[pnr]
        result = scenario_result(pnr)

        if not spec.expected.should_send_offer:
            pytest.skip("Scenario should not send offer")

        if not spec.expected.price_range:
            pytest.skip("No price range specified")

        actual_price = result.get("offer_price", 0)
        min_price, max_price = spec.expected.price_range

        assert min_price <= actual_price <= max_price, (
            f"Scenario {pnr}: Price ${actual_price} not in range ${min_price}-${max_price}"
        )

    def test_channel_is_acceptable(self, pnr: str, scenario_result):
        """Verify selected channel is in acceptable list"""
        spec = SCENARIOS[pnr]
        result = scenario_result(pnr)

        if not spec.expected.should_send_offer:
            pytest.skip("Scenario should not send offer")

        if not spec.expected.acceptable_channels:
            pytest.skip("No acceptable channels specified")

        actual_channel = result.get("selected_channel", "").lower()
        acceptable = [c.lower() for c in spec.expected.acceptable_channels]

        assert actual_channel in acceptable, (
            f"Scenario {pnr}: Channel '{actual_channel}' not in acceptable list {acceptable}"
        )


# =============================================================================
# SUPPRESSION TESTS (Critical Compliance)
# =============================================================================

class TestSuppressionCompliance:
    """Tests for customers who MUST NOT receive offers"""

    @pytest.mark.parametrize("spec", get_suppression_scenarios(), ids=lambda s: s.pnr)
    def test_suppressed_customer_gets_no_offer(self, spec: ScenarioSpec):
        """Suppressed customers MUST NOT receive offers"""
        result = run_offer_evaluation(spec.pnr)

        assert result.get("should_send_offer") == False, (
            f"COMPLIANCE VIOLATION: Suppressed customer {spec.pnr} received an offer! "
            f"Reason: {spec.customer_context.get('suppression_reason')}"
        )

    @pytest.mark.parametrize("spec", get_suppression_scenarios(), ids=lambda s: s.pnr)
    def test_suppression_reason_documented(self, spec: ScenarioSpec):
        """Suppression reason must be documented in output"""
        result = run_offer_evaluation(spec.pnr)

        suppression_reason = result.get("suppression_reason") or ""

        # Check that at least one expected reason keyword appears
        expected_keywords = spec.expected.expected_suppression_reasons
        if expected_keywords and suppression_reason:
            found = any(
                keyword.lower() in suppression_reason.lower()
                for keyword in expected_keywords
            )
            assert found, (
                f"Scenario {spec.pnr}: Suppression reason '{suppression_reason}' "
                f"doesn't mention any of {expected_keywords}"
            )
        elif expected_keywords and not suppression_reason:
            # No suppression reason provided - check reasoning trace instead
            reasoning = " ".join(result.get("reasoning_trace", []))
            found = any(
                keyword.lower() in reasoning.lower()
                for keyword in expected_keywords
            )
            # Allow test to pass if keywords found in reasoning OR if it's a "no offer" scenario
            # where the reason might be in a different field
            if not found and not result.get("should_send_offer"):
                pytest.skip(f"No suppression_reason field, but no offer made - acceptable")


# =============================================================================
# GUARDRAIL ENFORCEMENT TESTS
# =============================================================================

class TestGuardrailEnforcement:
    """Tests that business rules are never violated"""

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_discount_never_exceeds_max(self, pnr: str, scenario_result):
        """Discount must never exceed product-specific maximum"""
        result = scenario_result(pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        offer_type = result.get("selected_offer", "")
        discount = result.get("discount_applied", 0)

        # Determine max discount based on offer type
        if "BUSINESS" in offer_type.upper():
            max_discount = GUARDRAILS["max_discount_business"]
        elif "FIRST" in offer_type.upper():
            max_discount = GUARDRAILS["max_discount_first"]
        else:
            max_discount = GUARDRAILS["max_discount_mce"]

        assert discount <= max_discount, (
            f"GUARDRAIL VIOLATION: {pnr} has discount {discount:.0%} "
            f"exceeding max {max_discount:.0%} for {offer_type}"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_expected_value_is_positive(self, pnr: str, scenario_result):
        """If offering, expected value must be positive"""
        result = scenario_result(pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        ev = result.get("expected_value", 0)

        assert ev > 0, (
            f"Scenario {pnr}: Expected value ${ev:.2f} is not positive. "
            "We should not offer if EV <= 0"
        )

    @pytest.mark.parametrize("spec", get_happy_path_scenarios(), ids=lambda s: s.pnr)
    def test_ev_meets_minimum_threshold(self, spec: ScenarioSpec):
        """EV should meet scenario-specific minimum"""
        result = run_offer_evaluation(spec.pnr)

        if not result.get("should_send_offer"):
            pytest.skip("No offer made")

        ev = result.get("expected_value", 0)
        min_ev = spec.expected.min_expected_value

        assert ev >= min_ev, (
            f"Scenario {spec.pnr}: EV ${ev:.2f} below minimum ${min_ev:.2f}"
        )


# =============================================================================
# REASONING QUALITY TESTS
# =============================================================================

class TestReasoningQuality:
    """Tests that agent reasoning is complete and mentions key factors"""

    @pytest.mark.parametrize("pnr,spec", SCENARIOS.items())
    def test_reasoning_includes_required_keywords(self, pnr: str, spec: ScenarioSpec):
        """Reasoning must mention key factors for auditability"""
        result = run_offer_evaluation(pnr)

        # Collect all reasoning (including reasoning_trace)
        all_reasoning = " ".join([
            result.get("customer_reasoning", ""),
            result.get("flight_reasoning", ""),
            result.get("offer_reasoning", ""),
            " ".join(result.get("reasoning_trace", [])),
        ]).lower()

        missing = []
        for keyword in spec.expected.reasoning_must_include:
            if keyword.lower() not in all_reasoning:
                missing.append(keyword)

        assert not missing, (
            f"Scenario {pnr}: Reasoning missing required keywords: {missing}"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_customer_reasoning_not_empty(self, pnr: str, scenario_result):
        """Customer intelligence must provide reasoning"""
        result = scenario_result(pnr)
        reasoning = result.get("customer_reasoning", "")

        assert len(reasoning) > 50, (
            f"Scenario {pnr}: Customer reasoning too short ({len(reasoning)} chars)"
        )

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_offer_reasoning_not_empty(self, pnr: str, scenario_result):
        """Offer orchestration must provide reasoning"""
        result = scenario_result(pnr)

        # Only check if customer was eligible
        if not result.get("customer_eligible"):
            pytest.skip("Customer not eligible")

        reasoning = result.get("offer_reasoning", "")

        # Minimum length reduced to accommodate short "no offer" reasons
        assert len(reasoning) > 30, (
            f"Scenario {pnr}: Offer reasoning too short ({len(reasoning)} chars)"
        )


# =============================================================================
# DATA FLOW TESTS
# =============================================================================

class TestDataFlow:
    """Tests that data flows correctly through the pipeline"""

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_customer_data_populated(self, pnr: str, scenario_result):
        """Customer data must be loaded"""
        result = scenario_result(pnr)
        customer = result.get("customer_data", {})

        assert customer, f"Scenario {pnr}: customer_data is empty"
        assert "loyalty_tier" in customer, f"Scenario {pnr}: loyalty_tier missing"
        assert "first_name" in customer, f"Scenario {pnr}: first_name missing"

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_flight_data_populated(self, pnr: str, scenario_result):
        """Flight data must be loaded"""
        result = scenario_result(pnr)
        flight = result.get("flight_data", {})

        assert flight, f"Scenario {pnr}: flight_data is empty"
        assert "operat_flight_nbr" in flight, f"Scenario {pnr}: flight number missing"
        assert "cabins" in flight, f"Scenario {pnr}: cabin data missing"

    @pytest.mark.parametrize("pnr", get_all_pnrs())
    def test_ml_scores_populated(self, pnr: str, scenario_result):
        """ML scores must be loaded"""
        result = scenario_result(pnr)
        ml_scores = result.get("ml_scores", {})

        assert ml_scores, f"Scenario {pnr}: ml_scores is empty"
        assert "propensity_scores" in ml_scores, f"Scenario {pnr}: propensity_scores missing"


# =============================================================================
# QUICK SMOKE TEST
# =============================================================================

class TestSmokeTest:
    """Fast sanity checks that run first"""

    def test_can_run_happy_path_scenario(self):
        """Basic smoke test - can we run ABC123?"""
        result = run_offer_evaluation("ABC123")
        assert result is not None
        assert "should_send_offer" in result

    def test_can_run_suppression_scenario(self):
        """Basic smoke test - can we run GHI654?"""
        result = run_offer_evaluation("GHI654")
        assert result is not None
        assert result.get("should_send_offer") == False


================================================================================
FILE: tools/__init__.py
================================================================================
"""
Tools for Tailored Offers Demo
"""
from .data_tools import (
    get_customer,
    get_flight,
    get_reservation,
    get_ml_scores,
    get_all_eligible_pnrs
)

__all__ = [
    "get_customer",
    "get_flight",
    "get_reservation",
    "get_ml_scores",
    "get_all_eligible_pnrs"
]


================================================================================
FILE: tools/data_tools.py
================================================================================
"""
Data access tools for Tailored Offers Demo
These simulate API calls to various data sources

Field names match the Tailored Offers Data Mapping Excel specification
"""
import json
from pathlib import Path
from typing import Optional, Dict, Any, List

DATA_DIR = Path(__file__).parent.parent / "data"


def _load_json(filename: str) -> Any:
    """Load JSON data from file"""
    with open(DATA_DIR / filename, "r") as f:
        return json.load(f)


def get_customer(lylty_acct_id: str) -> Optional[Dict[str, Any]]:
    """
    Retrieve customer profile data by LYLTY_ACCT_ID

    In production: Calls North Star Data Platform / Customer 360
    Source: PROD_LYLTY_METRICS_VW, custlylty_prod_pkg
    """
    customers = _load_json("customers.json")
    for customer in customers:
        if customer["lylty_acct_id"] == lylty_acct_id:
            return customer
    return None


def get_flight(operat_flight_nbr: int, leg_dep_dt: str = None) -> Optional[Dict[str, Any]]:
    """
    Retrieve flight and inventory data by Operating Flight Number

    In production: Calls Flight Operations / fltcorepkg_prod_pkg_pii
    Source: flight_leg_nrt table
    """
    flights = _load_json("flights.json")
    for flight in flights:
        if flight["operat_flight_nbr"] == operat_flight_nbr:
            if leg_dep_dt is None or flight["leg_dep_dt"] == leg_dep_dt:
                return flight
    return None


def get_reservation(pnr_loctr_id: str) -> Optional[Dict[str, Any]]:
    """
    Retrieve reservation/PNR data by PNR_LOCTR_ID

    In production: Calls sbpnr_prod_pkg / PNR_AIR_SEG
    Source: Streaming NRT (30 minutes)
    """
    reservations = _load_json("reservations.json")
    for reservation in reservations:
        if reservation["pnr_loctr_id"] == pnr_loctr_id:
            return reservation
    return None


def get_ml_scores(pnr_loctr_id: str) -> Optional[Dict[str, Any]]:
    """
    Retrieve ML propensity scores for a PNR

    In production: Calls ML Model Serving API (the P(buy) model)
    Returns P(buy) at different price points for each product
    """
    ml_data = _load_json("ml_scores.json")
    return ml_data["scores"].get(pnr_loctr_id)


def get_all_customers() -> List[Dict[str, Any]]:
    """Get all customers"""
    return _load_json("customers.json")


def get_all_flights() -> List[Dict[str, Any]]:
    """Get all flights"""
    return _load_json("flights.json")


def get_all_reservations() -> List[Dict[str, Any]]:
    """Get all reservations"""
    return _load_json("reservations.json")


def get_all_eligible_pnrs() -> List[Dict[str, Any]]:
    """
    Get all PNRs eligible for offer evaluation

    In production: This would be triggered by the orchestration layer
    filtering flights that need treatment and their associated PNRs
    """
    reservations = _load_json("reservations.json")
    eligible = []

    for res in reservations:
        # Basic eligibility: main cabin (Y), not checked in, has time
        if res["max_bkd_cabin_cd"] == "Y" and not res["checked_in"]:
            if res["hours_to_departure"] >= 24:
                eligible.append(res)

    return eligible


def get_enriched_pnr(pnr_loctr_id: str) -> Optional[Dict[str, Any]]:
    """
    Get fully enriched PNR with customer, flight, and ML data

    This combines data from multiple sources - what the agents will work with
    Joins:
      - PNR data (sbpnr_prod_pkg.PNR_AIR_SEG)
      - Customer data (custlylty_prod_pkg via LYLTY_ACCT_ID)
      - Flight data (fltcorepkg_prod_pkg_pii via OPERAT_FLIGHT_NBR)
      - ML scores (ML Model Serving)
    """
    reservation = get_reservation(pnr_loctr_id)
    if not reservation:
        return None

    customer = get_customer(reservation["lylty_acct_id"])
    # Don't filter by date for demo - just match by flight number
    flight = get_flight(reservation["operat_flight_nbr"])
    ml_scores = get_ml_scores(pnr_loctr_id)

    return {
        "pnr": reservation,
        "customer": customer,
        "flight": flight,
        "ml_scores": ml_scores
    }


================================================================================
FILE: tools/mcp_client.py
================================================================================
"""
MCP Client for Tailored Offers Data Tools

Wraps langchain-mcp-adapters to provide a simple interface for calling
the MCP data server from the agent workflow.

Production Features:
- Retry logic with exponential backoff
- Circuit breaker pattern for fault tolerance
- Structured logging with correlation IDs
- Prometheus metrics for latency tracking

Usage:
    client = MCPDataClient()
    data = await client.get_enriched_pnr("ABC123")
"""
import asyncio
import os
import time
from pathlib import Path
from typing import Optional, Dict, Any, List

# Import infrastructure modules
try:
    from infrastructure.logging import get_logger, log_mcp_call
    from infrastructure.metrics import metrics, mcp_calls, mcp_latency
    from infrastructure.retry import retry_mcp_call, RetryConfig
    INFRASTRUCTURE_AVAILABLE = True
except ImportError:
    INFRASTRUCTURE_AVAILABLE = False

# Initialize logger
logger = get_logger("mcp_client") if INFRASTRUCTURE_AVAILABLE else None

# Get the path to the MCP server relative to this file
MCP_SERVER_PATH = str(Path(__file__).parent / "mcp_server.py")


class MCPDataClient:
    """
    MCP client for data tools.

    Uses langchain-mcp-adapters to communicate with the MCP data server
    via stdio transport (spawns server as subprocess).
    """

    def __init__(self, server_path: Optional[str] = None):
        """
        Initialize MCP client.

        Args:
            server_path: Path to mcp_server.py (defaults to tools/mcp_server.py)
        """
        self.server_path = server_path or MCP_SERVER_PATH
        self.server_config = {
            "tailored_offers_data": {
                "command": "python",
                "args": [self.server_path],
                "transport": "stdio",
            }
        }

    async def _call_tool(self, tool_name: str, **kwargs) -> Any:
        """
        Call an MCP tool by name with retry logic and metrics.

        Args:
            tool_name: Name of the MCP tool (e.g., "mcp_get_enriched_pnr")
            **kwargs: Arguments to pass to the tool

        Returns:
            Tool result or None if tool not found
        """
        start_time = time.time()

        # Log start
        if logger:
            logger.info(
                "mcp_call_started",
                tool=tool_name,
                kwargs=str(kwargs)[:200],
            )

        try:
            result = await self._call_tool_with_retry(tool_name, **kwargs)

            duration = time.time() - start_time

            # Record metrics
            if INFRASTRUCTURE_AVAILABLE:
                metrics.record_mcp_call(tool_name, success=True, duration=duration)

            # Log success
            if logger:
                logger.info(
                    "mcp_call_completed",
                    tool=tool_name,
                    duration_ms=round(duration * 1000, 2),
                    has_result=result is not None,
                )

            return result

        except Exception as e:
            duration = time.time() - start_time

            # Record failure metrics
            if INFRASTRUCTURE_AVAILABLE:
                metrics.record_mcp_call(tool_name, success=False, duration=duration)

            # Log error
            if logger:
                logger.error(
                    "mcp_call_failed",
                    tool=tool_name,
                    duration_ms=round(duration * 1000, 2),
                    error=str(e),
                    error_type=type(e).__name__,
                )

            raise

    async def _call_tool_with_retry(
        self,
        tool_name: str,
        max_attempts: int = 3,
        **kwargs
    ) -> Any:
        """Call MCP tool with retry logic."""
        last_exception = None

        for attempt in range(max_attempts):
            try:
                return await self._call_tool_internal(tool_name, **kwargs)

            except Exception as e:
                last_exception = e

                # Log retry
                if logger and attempt < max_attempts - 1:
                    logger.warning(
                        "mcp_retry_attempt",
                        tool=tool_name,
                        attempt=attempt + 1,
                        max_attempts=max_attempts,
                        error=str(e),
                    )

                # Exponential backoff
                if attempt < max_attempts - 1:
                    wait_time = min(1.0 * (2 ** attempt), 10.0)
                    await asyncio.sleep(wait_time)

        raise last_exception

    async def _call_tool_internal(self, tool_name: str, **kwargs) -> Any:
        """Internal tool call without retry."""
        try:
            import json
            from langchain_mcp_adapters.client import MultiServerMCPClient

            # Create client (not a context manager in 0.1.0+)
            client = MultiServerMCPClient(self.server_config)
            tools = await client.get_tools()

            for tool in tools:
                if tool.name == tool_name:
                    result = await tool.ainvoke(kwargs)

                    # Parse the MCP response format
                    # MCP returns: [{"type": "text", "text": "<json_string>", "id": "..."}]
                    if isinstance(result, list) and len(result) > 0:
                        content = result[0]
                        if isinstance(content, dict) and content.get("type") == "text":
                            text_content = content.get("text", "")
                            try:
                                return json.loads(text_content)
                            except json.JSONDecodeError:
                                return text_content
                        return content

                    return result

            return None

        except ImportError:
            raise ImportError(
                "langchain-mcp-adapters is required for MCP client. "
                "Install with: pip install langchain-mcp-adapters"
            )

    async def get_enriched_pnr(self, pnr_loctr_id: str) -> Optional[Dict[str, Any]]:
        """
        Get fully enriched PNR with customer, flight, and ML data.

        This is the main method used by the workflow - combines all data sources.

        Args:
            pnr_loctr_id: PNR locator code (e.g., "ABC123")

        Returns:
            Dict with keys: pnr, customer, flight, ml_scores
        """
        result = await self._call_tool("mcp_get_enriched_pnr", pnr_loctr_id=pnr_loctr_id)
        return result if result else None

    async def get_customer(self, lylty_acct_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve customer profile by loyalty account ID.

        Args:
            lylty_acct_id: Customer's loyalty account ID

        Returns:
            Customer profile dict
        """
        result = await self._call_tool("mcp_get_customer", lylty_acct_id=lylty_acct_id)
        return result if result else None

    async def get_reservation(self, pnr_loctr_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve reservation/PNR data.

        Args:
            pnr_loctr_id: PNR locator code

        Returns:
            Reservation dict
        """
        result = await self._call_tool("mcp_get_reservation", pnr_loctr_id=pnr_loctr_id)
        return result if result else None

    async def get_flight(self, operat_flight_nbr: int, leg_dep_dt: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        Retrieve flight and inventory data.

        Args:
            operat_flight_nbr: Operating flight number
            leg_dep_dt: Optional departure date filter

        Returns:
            Flight data dict
        """
        kwargs = {"operat_flight_nbr": operat_flight_nbr}
        if leg_dep_dt:
            kwargs["leg_dep_dt"] = leg_dep_dt
        result = await self._call_tool("mcp_get_flight", **kwargs)
        return result if result else None

    async def get_ml_scores(self, pnr_loctr_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve ML propensity scores for a PNR.

        Args:
            pnr_loctr_id: PNR locator code

        Returns:
            ML scores dict with propensity_scores, confidence, segment
        """
        result = await self._call_tool("mcp_get_ml_scores", pnr_loctr_id=pnr_loctr_id)
        return result if result else None

    async def get_eligible_pnrs(self) -> List[Dict[str, Any]]:
        """
        Get all PNRs eligible for offer evaluation.

        Returns:
            List of eligible reservation records
        """
        result = await self._call_tool("mcp_get_eligible_pnrs")
        return result if result else []


# Convenience function for sync contexts
def get_mcp_client() -> MCPDataClient:
    """Get a new MCP client instance."""
    return MCPDataClient()


# Example usage
if __name__ == "__main__":
    async def main():
        client = MCPDataClient()

        # Test get_enriched_pnr
        print("Testing MCP client...")
        data = await client.get_enriched_pnr("ABC123")

        if data:
            print(f"Customer: {data['customer']['first_name']} {data['customer']['last_name']}")
            print(f"Flight: {data['flight']['flight_id']}")
            print(f"Tier: {data['customer']['loyalty_tier']}")
        else:
            print("No data returned")

    asyncio.run(main())


================================================================================
FILE: tools/mcp_server.py
================================================================================
"""
MCP Server for Tailored Offers Data Tools

This server exposes the data access tools via the Model Context Protocol (MCP).
In production, swap the JSON file reads with real API calls.

Run standalone:
    python tools/mcp_server.py

Run with MCP Inspector:
    mcp dev tools/mcp_server.py
"""
import sys
from pathlib import Path
from typing import Optional

# Add parent directory to path so we can import data_tools
sys.path.insert(0, str(Path(__file__).parent.parent))

from mcp.server.fastmcp import FastMCP
from tools.data_tools import (
    get_customer,
    get_reservation,
    get_flight,
    get_ml_scores,
    get_enriched_pnr,
    get_all_eligible_pnrs
)

# Create MCP server instance
mcp = FastMCP("TailoredOffersData")


@mcp.tool()
def mcp_get_customer(lylty_acct_id: str) -> dict:
    """
    Retrieve customer profile by loyalty account ID.

    In production: Calls North Star Data Platform / Customer 360
    Source: PROD_LYLTY_METRICS_VW, custlylty_prod_pkg

    Args:
        lylty_acct_id: Customer's loyalty account ID (e.g., "LYLTY001")

    Returns:
        Customer profile with loyalty_tier, historical_upgrades, preferences, etc.
    """
    result = get_customer(lylty_acct_id)
    return result if result else {}


@mcp.tool()
def mcp_get_reservation(pnr_loctr_id: str) -> dict:
    """
    Retrieve reservation/PNR data by PNR locator.

    In production: Calls sbpnr_prod_pkg / PNR_AIR_SEG
    Source: Streaming NRT (30 minutes latency)

    Args:
        pnr_loctr_id: PNR locator code (e.g., "ABC123")

    Returns:
        Reservation with flight details, cabin, hours_to_departure, etc.
    """
    result = get_reservation(pnr_loctr_id)
    return result if result else {}


@mcp.tool()
def mcp_get_flight(operat_flight_nbr: int, leg_dep_dt: Optional[str] = None) -> dict:
    """
    Retrieve flight and inventory data by operating flight number.

    In production: Calls Flight Operations / fltcorepkg_prod_pkg_pii
    Source: flight_leg_nrt table

    Args:
        operat_flight_nbr: Operating flight number (e.g., 2847)
        leg_dep_dt: Optional departure date filter (YYYY-MM-DD)

    Returns:
        Flight data with cabins, inventory, load factors, product catalog
    """
    result = get_flight(operat_flight_nbr, leg_dep_dt)
    return result if result else {}


@mcp.tool()
def mcp_get_ml_scores(pnr_loctr_id: str) -> dict:
    """
    Retrieve ML propensity scores for a PNR.

    In production: Calls ML Model Serving API (the P(buy) model)
    Returns P(buy) at different price points for each product.

    Args:
        pnr_loctr_id: PNR locator code (e.g., "ABC123")

    Returns:
        Propensity scores with price_points, confidence, segment, price_sensitivity
    """
    result = get_ml_scores(pnr_loctr_id)
    return result if result else {}


@mcp.tool()
def mcp_get_enriched_pnr(pnr_loctr_id: str) -> dict:
    """
    Get fully enriched PNR with customer, flight, and ML data.

    This is the main tool used by the agent pipeline - combines:
    - PNR data (sbpnr_prod_pkg.PNR_AIR_SEG)
    - Customer data (custlylty_prod_pkg via LYLTY_ACCT_ID)
    - Flight data (fltcorepkg_prod_pkg_pii via OPERAT_FLIGHT_NBR)
    - ML scores (ML Model Serving)

    Args:
        pnr_loctr_id: PNR locator code (e.g., "ABC123")

    Returns:
        Combined object with pnr, customer, flight, and ml_scores
    """
    result = get_enriched_pnr(pnr_loctr_id)
    return result if result else {}


@mcp.tool()
def mcp_get_eligible_pnrs() -> list:
    """
    Get all PNRs eligible for offer evaluation.

    In production: Triggered by orchestration layer filtering flights
    that need treatment and their associated PNRs.

    Returns:
        List of eligible reservation records
    """
    return get_all_eligible_pnrs()


if __name__ == "__main__":
    # Run with stdio transport (for subprocess communication)
    # For HTTP transport, use: mcp.run(transport="streamable-http", port=8001)
    mcp.run(transport="stdio")


================================================================================
FILE: ui/streamlit_app.py
================================================================================
"""
Tailored Offers Agentic Demo - Streamlit UI

This application demonstrates the 6-agent architecture for
American Airlines Tailored Offers.
"""
import streamlit as st
import sys
import json
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from tools.data_tools import (
    get_all_customers,
    get_all_flights,
    get_all_reservations,
    get_enriched_pnr
)
from agents.state import create_initial_state
from agents.customer_intelligence import CustomerIntelligenceAgent
from agents.flight_optimization import FlightOptimizationAgent
from agents.offer_orchestration import OfferOrchestrationAgent
from agents.personalization import PersonalizationAgent
from agents.channel_timing import ChannelTimingAgent
from agents.measurement_learning import MeasurementLearningAgent


# Page config
st.set_page_config(
    page_title="Tailored Offers - Agentic AI Demo",
    page_icon="‚úàÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .agent-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 4px solid #1f77b4;
    }
    .agent-name {
        font-weight: bold;
        color: #1f77b4;
        font-size: 1.1em;
    }
    .reasoning-box {
        background-color: #262730;
        color: #fafafa;
        padding: 15px;
        border-radius: 5px;
        font-family: monospace;
        font-size: 0.85em;
        white-space: pre-wrap;
    }
    .decision-box {
        background-color: #d4edda;
        border: 1px solid #28a745;
        border-radius: 10px;
        padding: 20px;
        margin: 15px 0;
    }
    .no-offer-box {
        background-color: #f8d7da;
        border: 1px solid #dc3545;
        border-radius: 10px;
        padding: 20px;
        margin: 15px 0;
    }
    .metric-card {
        background-color: #e7f1ff;
        border-radius: 8px;
        padding: 10px;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)


def display_agent_output(agent_name: str, reasoning: str, icon: str = "ü§ñ"):
    """Display agent output in a styled card"""
    st.markdown(f"""
    <div class="agent-card">
        <div class="agent-name">{icon} {agent_name}</div>
    </div>
    """, unsafe_allow_html=True)

    with st.expander("View Reasoning", expanded=True):
        st.markdown(f'<div class="reasoning-box">{reasoning}</div>', unsafe_allow_html=True)


def main():
    # Header
    st.title("‚úàÔ∏è Tailored Offers - Agentic AI Demo")
    st.markdown("""
    **Demonstrating how 6 AI Agents work together to optimize upgrade offers**

    This demo showcases an agentic architecture where specialized agents collaborate
    to make intelligent offer decisions - going beyond what ML models alone can provide.
    """)

    # Sidebar - PNR Selection
    st.sidebar.header("üìã Select Scenario")

    reservations = get_all_reservations()
    customers = {c["customer_id"]: c for c in get_all_customers()}

    # Create selection options
    pnr_options = {}
    for res in reservations:
        cust = customers.get(res["customer_id"], {})
        label = (
            f"{res['pnr_locator']} - {cust.get('first_name', 'Unknown')} "
            f"({res['origin']}‚Üí{res['destination']}, T-{res['hours_to_departure']}hrs)"
        )
        pnr_options[label] = res["pnr_locator"]

    selected_label = st.sidebar.selectbox(
        "Choose a PNR to evaluate:",
        options=list(pnr_options.keys())
    )
    selected_pnr = pnr_options[selected_label]

    # Scenario descriptions
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìù Available Scenarios")
    st.sidebar.markdown("""
    - **ABC123**: Gold member, leisure, 72hrs out
    - **XYZ789**: Platinum Pro, business, 48hrs (follow-up)
    - **LMN456**: Executive Platinum, international
    - **DEF321**: New customer (cold start)
    - **GHI654**: Suppressed customer (complaint)
    """)

    # Load data button
    if st.sidebar.button("üöÄ Run Agent Evaluation", type="primary"):
        run_evaluation(selected_pnr)

    # Show current data
    st.sidebar.markdown("---")
    if st.sidebar.checkbox("Show Raw Data"):
        enriched = get_enriched_pnr(selected_pnr)
        if enriched:
            st.sidebar.json(enriched)


def run_evaluation(pnr_locator: str):
    """Run the full agent evaluation and display results"""

    st.markdown("---")
    st.header(f"üîÑ Evaluating PNR: {pnr_locator}")

    # Load data
    enriched = get_enriched_pnr(pnr_locator)
    if not enriched:
        st.error(f"PNR {pnr_locator} not found!")
        return

    # Display customer and flight info
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("üë§ Customer Profile")
        cust = enriched["customer"]
        st.markdown(f"""
        - **Name**: {cust['first_name']} {cust['last_name']}
        - **Loyalty**: {cust['loyalty_tier']} ({cust['tenure_days'] // 365} years)
        - **Travel Pattern**: {cust['travel_pattern'].title()}
        - **Annual Revenue**: ${cust['annual_revenue']:,}
        """)

        if cust.get("suppression", {}).get("is_suppressed"):
            st.warning(f"‚ö†Ô∏è Customer Suppressed: {cust['suppression'].get('complaint_reason', 'Unknown')}")

    with col2:
        st.subheader("‚úàÔ∏è Flight Details")
        flight = enriched["flight"]
        res = enriched["pnr"]
        st.markdown(f"""
        - **Flight**: {flight['flight_id']} ({flight['origin']} ‚Üí {flight['destination']})
        - **Date**: {res['departure_date']} at {flight['departure_time']}
        - **Current Cabin**: {res['current_cabin'].replace('_', ' ').title()}
        - **Hours to Departure**: {res['hours_to_departure']}
        """)

    # Initialize state
    state = create_initial_state(pnr_locator)
    state["customer_data"] = enriched["customer"]
    state["flight_data"] = enriched["flight"]
    state["reservation_data"] = enriched["pnr"]
    state["ml_scores"] = enriched["ml_scores"]

    st.markdown("---")
    st.header("ü§ñ Agent Processing")

    # Progress bar
    progress = st.progress(0)
    status = st.empty()

    # Run agents sequentially with display
    agents_results = []

    # Agent 1: Customer Intelligence
    status.text("Running Customer Intelligence Agent...")
    progress.progress(15)

    customer_agent = CustomerIntelligenceAgent()
    result = customer_agent.analyze(state)
    state.update(result)
    agents_results.append(("Customer Intelligence Agent", result.get("customer_reasoning", ""), "üß†"))

    with st.container():
        display_agent_output(
            "Agent 1: Customer Intelligence",
            result.get("customer_reasoning", "No reasoning available"),
            "üß†"
        )

    # Check if should continue
    if not state.get("customer_eligible", False):
        progress.progress(100)
        status.text("Evaluation complete - Customer not eligible")
        display_no_offer(state)
        return

    # Agent 2: Flight Optimization
    status.text("Running Flight Optimization Agent...")
    progress.progress(30)

    flight_agent = FlightOptimizationAgent()
    result = flight_agent.analyze(state)
    state.update(result)

    with st.container():
        display_agent_output(
            "Agent 2: Flight Optimization",
            result.get("flight_reasoning", "No reasoning available"),
            "üìä"
        )

    # Agent 3: Offer Orchestration
    status.text("Running Offer Orchestration Agent...")
    progress.progress(50)

    offer_agent = OfferOrchestrationAgent()
    result = offer_agent.analyze(state)
    state.update(result)

    with st.container():
        display_agent_output(
            "Agent 3: Offer Orchestration",
            result.get("offer_reasoning", "No reasoning available"),
            "‚öñÔ∏è"
        )

    # Check if should continue
    if not state.get("should_send_offer", False):
        progress.progress(100)
        status.text("Evaluation complete - No offer selected")
        display_no_offer(state)
        return

    # Agent 4: Personalization
    status.text("Running Personalization Agent...")
    progress.progress(65)

    personalization_agent = PersonalizationAgent()
    result = personalization_agent.analyze(state)
    state.update(result)

    with st.container():
        display_agent_output(
            "Agent 4: Personalization (GenAI)",
            result.get("personalization_reasoning", "No reasoning available"),
            "‚ú®"
        )

    # Agent 5: Channel & Timing
    status.text("Running Channel & Timing Agent...")
    progress.progress(80)

    channel_agent = ChannelTimingAgent()
    result = channel_agent.analyze(state)
    state.update(result)

    with st.container():
        display_agent_output(
            "Agent 5: Channel & Timing",
            result.get("channel_reasoning", "No reasoning available"),
            "üì±"
        )

    # Agent 6: Measurement & Learning
    status.text("Running Measurement & Learning Agent...")
    progress.progress(95)

    measurement_agent = MeasurementLearningAgent()
    result = measurement_agent.analyze(state)
    state.update(result)

    with st.container():
        display_agent_output(
            "Agent 6: Measurement & Learning",
            result.get("measurement_reasoning", "No reasoning available"),
            "üìà"
        )

    progress.progress(100)
    status.text("Evaluation complete!")

    # Display final decision
    display_final_decision(state)


def display_no_offer(state: dict):
    """Display when no offer is made"""
    st.markdown("---")
    st.header("üìã Final Decision")

    reason = state.get("suppression_reason") or "Offer criteria not met"

    st.markdown(f"""
    <div class="no-offer-box">
        <h3>‚ùå No Offer Sent</h3>
        <p><strong>Reason:</strong> {reason}</p>
    </div>
    """, unsafe_allow_html=True)


def display_final_decision(state: dict):
    """Display the final offer decision"""
    st.markdown("---")
    st.header("üìã Final Decision")

    offer_names = {
        "IU_BUSINESS": "Business Class Upgrade",
        "IU_PREMIUM_ECONOMY": "Premium Economy Upgrade",
        "MCE": "Main Cabin Extra"
    }

    offer_type = state.get("selected_offer", "")
    offer_name = offer_names.get(offer_type, offer_type)
    price = state.get("offer_price", 0)
    channel = state.get("selected_channel", "")
    send_time = state.get("send_time", "")

    st.markdown(f"""
    <div class="decision-box">
        <h3>‚úÖ Offer Approved</h3>
        <p><strong>Offer:</strong> {offer_name} @ ${price:.0f}</p>
        <p><strong>Channel:</strong> {channel.upper()}</p>
        <p><strong>Send Time:</strong> {send_time}</p>
        <p><strong>Experiment Group:</strong> {state.get('experiment_group', 'N/A')}</p>
        <p><strong>Tracking ID:</strong> <code>{state.get('tracking_id', 'N/A')}</code></p>
    </div>
    """, unsafe_allow_html=True)

    # Show the message
    st.subheader("üìß Generated Message")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("**Subject:**")
        st.info(state.get("message_subject", ""))

    with col2:
        st.markdown("**Body:**")
        st.text_area(
            "Message Preview",
            state.get("message_body", ""),
            height=300,
            disabled=True,
            label_visibility="collapsed"
        )

    # Fallback offer
    fallback = state.get("fallback_offer")
    if fallback:
        st.markdown(f"""
        **Fallback Offer:** {fallback.get('display_name')} @ ${fallback.get('price', 0):.0f}
        (if primary declined)
        """)

    # Show reasoning trace
    st.markdown("---")
    st.subheader("üîç Complete Reasoning Trace")

    trace = state.get("reasoning_trace", [])
    if trace:
        trace_text = "\n".join([f"‚Üí {t}" for t in trace])
        st.code(trace_text, language="text")


if __name__ == "__main__":
    main()




================================================================================
FILE: config/__init__.py
================================================================================
"""Configuration module"""
from .settings import *


================================================================================
FILE: config/discount_policies.json
================================================================================
{
  "_metadata": {
    "description": "Pre-approved discount policies - Approved by Revenue Management & Customer Experience teams",
    "approved_by": "Revenue Management Committee",
    "approval_date": "2025-12-01",
    "review_date": "2026-06-01",
    "version": "1.0"
  },

  "policies": {
    "GOODWILL_RECOVERY": {
      "policy_id": "POL-GW-001",
      "name": "Goodwill Recovery Discount",
      "description": "Applied when customer had recent service issue to rebuild relationship",
      "approved_by": "Customer Experience Team",
      "triggers": ["recent_service_issue", "complaint_recovery"],
      "discount_percent": 10,
      "max_discount_cap": 10,
      "eligible_segments": ["elite_business", "high_value_leisure", "mid_value_business"],
      "notes": "Protects high-value customer relationships after service failures"
    },

    "PRICE_SENSITIVE_HIGH": {
      "policy_id": "POL-PS-001",
      "name": "High Price Sensitivity Discount",
      "description": "Applied to price-sensitive customers to improve conversion",
      "approved_by": "Revenue Management",
      "triggers": ["high_price_sensitivity"],
      "discount_percent": 15,
      "max_discount_cap": 15,
      "eligible_segments": ["budget_leisure", "low_value_mixed"],
      "notes": "Without discount, conversion rate drops significantly"
    },

    "PRICE_SENSITIVE_MEDIUM": {
      "policy_id": "POL-PS-002",
      "name": "Medium Price Sensitivity Discount",
      "description": "Small incentive for moderately price-sensitive customers",
      "approved_by": "Revenue Management",
      "triggers": ["medium_price_sensitivity"],
      "discount_percent": 5,
      "max_discount_cap": 5,
      "eligible_segments": ["all"],
      "notes": "Optional - apply only if needed for conversion"
    },

    "LOYALTY_APPRECIATION": {
      "policy_id": "POL-LY-001",
      "name": "Loyalty Tier Appreciation",
      "description": "Thank-you discount for top-tier loyalty members",
      "approved_by": "Loyalty Program Team",
      "triggers": ["executive_platinum", "platinum_pro"],
      "discount_percent": 5,
      "max_discount_cap": 5,
      "eligible_segments": ["elite_business"],
      "notes": "Stackable with other discounts up to segment max"
    },

    "NO_DISCOUNT": {
      "policy_id": "POL-ND-001",
      "name": "No Discount (Standard Pricing)",
      "description": "Full price when no discount triggers apply",
      "approved_by": "Revenue Management",
      "triggers": ["default"],
      "discount_percent": 0,
      "max_discount_cap": 0,
      "eligible_segments": ["all"],
      "notes": "Default policy when customer shows no price sensitivity"
    }
  },

  "segment_caps": {
    "_description": "Maximum total discount allowed per customer segment (cannot exceed even with stacked policies)",
    "elite_business": {
      "max_total_discount": 20,
      "reason": "High lifetime value justifies protecting relationship"
    },
    "high_value_leisure": {
      "max_total_discount": 15,
      "reason": "Good customers but more price elastic"
    },
    "mid_value_business": {
      "max_total_discount": 15,
      "reason": "Standard business traveler caps"
    },
    "mid_value_mixed": {
      "max_total_discount": 10,
      "reason": "Mixed travel patterns, moderate caps"
    },
    "budget_leisure": {
      "max_total_discount": 15,
      "reason": "Price sensitive but still need margin protection"
    },
    "low_value_mixed": {
      "max_total_discount": 10,
      "reason": "Lower lifetime value, protect margins"
    }
  },

  "governance": {
    "audit_required": true,
    "audit_frequency": "monthly",
    "exception_approval": "VP Revenue Management",
    "change_process": "Requires Revenue Management Committee approval"
  }
}


================================================================================
FILE: config/policy_config.py
================================================================================
"""
Policy Configuration Service

Manages business policy values that control agent behavior.
These are actual configuration values, not prompt text.

Examples:
- goodwill_discount_percent: 10
- max_discount_percent: 25
- min_confidence_threshold: 0.6
- vip_revenue_threshold: 5000
"""

import json
from pathlib import Path
from typing import Any, Optional
from dataclasses import dataclass, asdict

# Default policy values
DEFAULT_POLICY = {
    # Discount policies
    "goodwill_discount_percent": 10,
    "max_discount_percent": 25,
    "min_discount_percent": 5,
    "vip_discount_percent": 15,

    # Confidence thresholds
    "min_confidence_threshold": 0.6,
    "high_confidence_threshold": 0.8,

    # Customer thresholds
    "vip_revenue_threshold": 5000,
    "loyalty_tenure_days_threshold": 365,

    # Offer policies
    "max_offers_per_day": 3,
    "min_hours_before_departure": 24,
    "suppress_after_complaint_days": 30,

    # Pricing policies
    "business_upgrade_base_price": 499,
    "premium_economy_upgrade_base_price": 199,
    "mce_base_price": 99,
}

# Policy metadata for validation and display
POLICY_METADATA = {
    "goodwill_discount_percent": {
        "name": "Goodwill Discount",
        "description": "Discount percentage for customers with recent issues",
        "type": "percent",
        "min": 0,
        "max": 50,
        "unit": "%"
    },
    "max_discount_percent": {
        "name": "Maximum Discount",
        "description": "Maximum discount that can be applied",
        "type": "percent",
        "min": 0,
        "max": 75,
        "unit": "%"
    },
    "min_discount_percent": {
        "name": "Minimum Discount",
        "description": "Minimum discount to offer",
        "type": "percent",
        "min": 0,
        "max": 25,
        "unit": "%"
    },
    "vip_discount_percent": {
        "name": "VIP Discount",
        "description": "Special discount for VIP/Executive Platinum customers",
        "type": "percent",
        "min": 0,
        "max": 50,
        "unit": "%"
    },
    "min_confidence_threshold": {
        "name": "Minimum Confidence",
        "description": "Minimum ML confidence score to make an offer",
        "type": "decimal",
        "min": 0,
        "max": 1,
        "unit": ""
    },
    "high_confidence_threshold": {
        "name": "High Confidence",
        "description": "Threshold for high-confidence offers",
        "type": "decimal",
        "min": 0,
        "max": 1,
        "unit": ""
    },
    "vip_revenue_threshold": {
        "name": "VIP Revenue Threshold",
        "description": "Annual revenue to qualify as VIP",
        "type": "currency",
        "min": 0,
        "max": 100000,
        "unit": "$"
    },
    "loyalty_tenure_days_threshold": {
        "name": "Loyalty Tenure",
        "description": "Days of membership to qualify for loyalty benefits",
        "type": "days",
        "min": 0,
        "max": 3650,
        "unit": " days"
    },
    "max_offers_per_day": {
        "name": "Max Daily Offers",
        "description": "Maximum offers to send per customer per day",
        "type": "integer",
        "min": 1,
        "max": 10,
        "unit": ""
    },
    "min_hours_before_departure": {
        "name": "Min Hours Before Departure",
        "description": "Minimum hours before flight to send offer",
        "type": "hours",
        "min": 1,
        "max": 168,
        "unit": " hours"
    },
    "suppress_after_complaint_days": {
        "name": "Complaint Suppression Period",
        "description": "Days to suppress offers after a complaint",
        "type": "days",
        "min": 0,
        "max": 90,
        "unit": " days"
    },
    "business_upgrade_base_price": {
        "name": "Business Upgrade Price",
        "description": "Base price for business class upgrade",
        "type": "currency",
        "min": 0,
        "max": 2000,
        "unit": "$"
    },
    "premium_economy_upgrade_base_price": {
        "name": "Premium Economy Upgrade Price",
        "description": "Base price for premium economy upgrade",
        "type": "currency",
        "min": 0,
        "max": 1000,
        "unit": "$"
    },
    "mce_base_price": {
        "name": "MCE Price",
        "description": "Base price for Main Cabin Extra",
        "type": "currency",
        "min": 0,
        "max": 500,
        "unit": "$"
    },
}


class PolicyService:
    """Service for managing policy configuration."""

    _config_file = Path(__file__).parent / "custom_policy.json"
    _custom_policy: dict = {}
    _loaded = False

    @classmethod
    def _load(cls):
        """Load custom policy from file."""
        if cls._loaded:
            return

        if cls._config_file.exists():
            try:
                with open(cls._config_file) as f:
                    cls._custom_policy = json.load(f)
            except Exception:
                cls._custom_policy = {}

        cls._loaded = True

    @classmethod
    def _save(cls):
        """Save custom policy to file."""
        with open(cls._config_file, 'w') as f:
            json.dump(cls._custom_policy, f, indent=2)

    @classmethod
    def get(cls, key: str) -> Any:
        """Get a policy value (custom if set, otherwise default)."""
        cls._load()
        if key in cls._custom_policy:
            return cls._custom_policy[key]
        return DEFAULT_POLICY.get(key)

    @classmethod
    def get_all(cls) -> dict:
        """Get all policy values with metadata."""
        cls._load()
        result = {}
        for key, default_value in DEFAULT_POLICY.items():
            current_value = cls._custom_policy.get(key, default_value)
            is_custom = key in cls._custom_policy
            metadata = POLICY_METADATA.get(key, {})

            result[key] = {
                "value": current_value,
                "default": default_value,
                "is_custom": is_custom,
                "name": metadata.get("name", key),
                "description": metadata.get("description", ""),
                "type": metadata.get("type", "string"),
                "min": metadata.get("min"),
                "max": metadata.get("max"),
                "unit": metadata.get("unit", ""),
            }

        return result

    @classmethod
    def set(cls, key: str, value: Any) -> tuple[bool, str]:
        """
        Set a policy value.
        Returns (success, message).
        """
        cls._load()

        if key not in DEFAULT_POLICY:
            return False, f"Unknown policy key: {key}"

        metadata = POLICY_METADATA.get(key, {})

        # Type conversion
        try:
            if metadata.get("type") in ["percent", "integer", "days", "hours"]:
                value = int(value)
            elif metadata.get("type") in ["decimal"]:
                value = float(value)
            elif metadata.get("type") == "currency":
                value = float(value)
        except (ValueError, TypeError):
            return False, f"Invalid value type for {key}"

        # Range validation
        min_val = metadata.get("min")
        max_val = metadata.get("max")
        if min_val is not None and value < min_val:
            return False, f"{metadata.get('name', key)} cannot be less than {min_val}"
        if max_val is not None and value > max_val:
            return False, f"{metadata.get('name', key)} cannot be more than {max_val}"

        # Save
        cls._custom_policy[key] = value
        cls._save()

        unit = metadata.get("unit", "")
        return True, f"{metadata.get('name', key)} updated to {value}{unit}"

    @classmethod
    def reset(cls, key: str) -> tuple[bool, str]:
        """Reset a policy value to default."""
        cls._load()

        if key not in DEFAULT_POLICY:
            return False, f"Unknown policy key: {key}"

        if key in cls._custom_policy:
            del cls._custom_policy[key]
            cls._save()

        metadata = POLICY_METADATA.get(key, {})
        default = DEFAULT_POLICY[key]
        return True, f"{metadata.get('name', key)} reset to default ({default})"

    @classmethod
    def reset_all(cls):
        """Reset all policies to defaults."""
        cls._custom_policy = {}
        cls._save()
        return True, "All policies reset to defaults"


# Convenience functions
def get_policy(key: str) -> Any:
    return PolicyService.get(key)

def set_policy(key: str, value: Any) -> tuple[bool, str]:
    return PolicyService.set(key, value)

def get_all_policies() -> dict:
    return PolicyService.get_all()

def reset_policy(key: str) -> tuple[bool, str]:
    return PolicyService.reset(key)


================================================================================
FILE: config/prompt_manager.py
================================================================================
"""
Prompt Manager Module

Centralized management of all LLM prompts with:
- File-based prompt storage for easy editing
- Version tracking
- Hot-reload capability (no restart needed)
- API endpoints for viewing/editing

Usage:
    from config.prompt_manager import PromptManager

    manager = PromptManager()
    prompt = manager.get_prompt("planner")
    prompt_with_vars = manager.get_prompt("personalization", customer_name="Sarah", ...)
"""
import os
import re
from typing import Dict, Optional, Any
from datetime import datetime
from pathlib import Path


class PromptManager:
    """
    Manages LLM prompts from file-based storage.

    Features:
    - Load prompts from config/prompts/*.txt
    - Variable substitution with {variable_name}
    - Metadata parsing from header comments
    - Hot-reload without restart
    """

    PROMPTS_DIR = Path(__file__).parent / "prompts"

    # Cache for loaded prompts
    _cache: Dict[str, Dict[str, Any]] = {}
    _cache_timestamps: Dict[str, float] = {}

    @classmethod
    def get_prompt(cls, name: str, **variables) -> str:
        """
        Get a prompt by name with optional variable substitution.

        Args:
            name: Prompt name (e.g., "planner", "solver", "personalization")
            **variables: Variables to substitute in the prompt

        Returns:
            Prompt text with variables substituted

        Example:
            prompt = PromptManager.get_prompt(
                "personalization",
                customer_name="Sarah",
                offer_price=499
            )
        """
        prompt_data = cls._load_prompt(name)
        prompt_text = prompt_data["content"]

        # Substitute variables
        for key, value in variables.items():
            prompt_text = prompt_text.replace(f"{{{key}}}", str(value))

        return prompt_text

    @classmethod
    def get_prompt_metadata(cls, name: str) -> Dict[str, Any]:
        """
        Get metadata for a prompt (version, purpose, variables, etc.)

        Returns:
            Dict with version, last_modified, purpose, variables, behavior_notes
        """
        return cls._load_prompt(name)["metadata"]

    @classmethod
    def list_prompts(cls) -> Dict[str, Dict[str, Any]]:
        """
        List all available prompts with their metadata.

        Returns:
            Dict mapping prompt names to their metadata
        """
        prompts = {}
        for file_path in cls.PROMPTS_DIR.glob("*.txt"):
            name = file_path.stem
            try:
                prompt_data = cls._load_prompt(name)
                prompts[name] = {
                    "name": name,
                    "file": str(file_path),
                    "metadata": prompt_data["metadata"],
                    "content_preview": prompt_data["content"][:200] + "..."
                }
            except Exception as e:
                prompts[name] = {"name": name, "error": str(e)}
        return prompts

    @classmethod
    def update_prompt(cls, name: str, content: str) -> Dict[str, Any]:
        """
        Update a prompt file with new content.

        Args:
            name: Prompt name
            content: New prompt content

        Returns:
            Dict with success status and metadata
        """
        file_path = cls.PROMPTS_DIR / f"{name}.txt"

        if not file_path.exists():
            raise FileNotFoundError(f"Prompt '{name}' not found")

        # Read existing content to preserve metadata header format
        with open(file_path, 'r') as f:
            existing = f.read()

        # Update version in header
        lines = content.split('\n')
        updated_lines = []
        for line in lines:
            if line.startswith('# Version:'):
                # Increment version
                match = re.search(r'Version:\s*(\d+)\.(\d+)', line)
                if match:
                    major, minor = int(match.group(1)), int(match.group(2))
                    updated_lines.append(f'# Version: {major}.{minor + 1}')
                else:
                    updated_lines.append(line)
            elif line.startswith('# Last Modified:'):
                updated_lines.append(f'# Last Modified: {datetime.now().strftime("%Y-%m-%d")}')
            else:
                updated_lines.append(line)

        new_content = '\n'.join(updated_lines)

        # Write updated content
        with open(file_path, 'w') as f:
            f.write(new_content)

        # Clear cache
        if name in cls._cache:
            del cls._cache[name]

        return {
            "success": True,
            "name": name,
            "message": f"Prompt '{name}' updated successfully",
            "new_metadata": cls.get_prompt_metadata(name)
        }

    @classmethod
    def _load_prompt(cls, name: str) -> Dict[str, Any]:
        """Load prompt from file with caching and hot-reload."""
        file_path = cls.PROMPTS_DIR / f"{name}.txt"

        if not file_path.exists():
            raise FileNotFoundError(f"Prompt file not found: {file_path}")

        # Check if cache is valid
        file_mtime = file_path.stat().st_mtime
        if name in cls._cache and cls._cache_timestamps.get(name, 0) >= file_mtime:
            return cls._cache[name]

        # Load and parse prompt
        with open(file_path, 'r') as f:
            content = f.read()

        metadata = cls._parse_metadata(content)
        prompt_content = cls._extract_content(content)

        prompt_data = {
            "content": prompt_content,
            "metadata": metadata,
            "file_path": str(file_path)
        }

        # Update cache
        cls._cache[name] = prompt_data
        cls._cache_timestamps[name] = file_mtime

        return prompt_data

    @classmethod
    def _parse_metadata(cls, content: str) -> Dict[str, Any]:
        """Parse metadata from header comments."""
        metadata = {
            "version": "1.0",
            "last_modified": None,
            "purpose": None,
            "variables": [],
            "behavior_notes": []
        }

        lines = content.split('\n')
        in_header = True
        current_section = None

        for line in lines:
            if not line.startswith('#'):
                if in_header and line.strip():
                    in_header = False
                continue

            line = line[1:].strip()  # Remove # prefix

            if line.startswith('Version:'):
                metadata["version"] = line.split(':', 1)[1].strip()
            elif line.startswith('Last Modified:'):
                metadata["last_modified"] = line.split(':', 1)[1].strip()
            elif line.startswith('Purpose:'):
                metadata["purpose"] = line.split(':', 1)[1].strip()
            elif line.startswith('Variables available:'):
                current_section = "variables"
            elif line.startswith('How changes affect behavior:'):
                current_section = "behavior_notes"
            elif line.startswith('  - ') and current_section:
                if current_section == "variables":
                    metadata["variables"].append(line[4:])
                elif current_section == "behavior_notes":
                    metadata["behavior_notes"].append(line[4:])

        return metadata

    @classmethod
    def _extract_content(cls, content: str) -> str:
        """Extract prompt content (everything after header comments)."""
        lines = content.split('\n')
        content_lines = []
        header_ended = False

        for line in lines:
            if not header_ended:
                if not line.startswith('#') and line.strip():
                    header_ended = True
                    content_lines.append(line)
            else:
                content_lines.append(line)

        return '\n'.join(content_lines).strip()


# Convenience functions for direct import
def get_prompt(name: str, **variables) -> str:
    """Get a prompt by name with variable substitution."""
    return PromptManager.get_prompt(name, **variables)


def list_prompts() -> Dict[str, Dict[str, Any]]:
    """List all available prompts."""
    return PromptManager.list_prompts()


def update_prompt(name: str, content: str) -> Dict[str, Any]:
    """Update a prompt."""
    return PromptManager.update_prompt(name, content)


================================================================================
FILE: config/prompt_service.py
================================================================================
"""
Prompt Service - Centralized prompt management for agents

This service bridges the gap between:
- The PromptEditor UI (frontend)
- The API endpoints (/api/agents/{id}/prompt)
- The actual agents that use these prompts

Features:
- File-based persistence (survives restarts)
- Hot-reload (changes apply immediately)
- Default fallback (uses hardcoded defaults if no custom prompt)
"""

import json
import os
from pathlib import Path
from typing import Dict, Optional, Any
from datetime import datetime


# =============================================================================
# Default Prompts (fallback if no custom prompt set)
# =============================================================================

DEFAULT_PROMPTS = {
    "offer_orchestration": {
        "planner": """You are the Planner in a ReWOO agent for airline offer optimization.

Your job is to analyze customer data and create a plan of what to evaluate before deciding which upgrade offer to give.

Available evaluation types:
- CONFIDENCE: Check ML model confidence for each offer
- RELATIONSHIP: Check if customer had recent service issues
- PRICE_SENSITIVITY: Check if customer needs a discount
- INVENTORY: Check which cabins need to be filled
- RECENT_DISRUPTIONS: Check if customer had recent flight delays or cancellations

Create a plan with numbered steps like E1, E2, E3. Each step should check ONE thing.
Only include steps that are relevant for this specific customer.

Output format (JSON):
```json
{
  "steps": [
    {"step_id": "E1", "evaluation_type": "CONFIDENCE", "description": "Check ML confidence for each offer"},
    {"step_id": "E2", "evaluation_type": "RELATIONSHIP", "description": "Check for recent service issues"}
  ],
  "reasoning": "Why I chose these steps"
}
```""",
        "worker": """You are the Worker in a ReWOO agent for airline offer optimization.

Your job is to execute evaluation steps defined by the Planner. For each step, you will check specific data and provide a recommendation.

Evaluation Guidelines:

CONFIDENCE Evaluation:
- If ML confidence < 60%: Flag as LOW confidence, recommend safer option
- If ML confidence > 85%: Flag as HIGH confidence, proceed with offer
- Compare confidence vs expected value trade-offs

RELATIONSHIP Evaluation:
- Check for recent service issues (delays, cancellations, complaints)
- High-value customers (>$50k/year) with issues: Apply goodwill discount
- Consider customer sentiment from recent interactions

PRICE_SENSITIVITY Evaluation:
- HIGH sensitivity: Customer needs significant discount to convert
- MEDIUM sensitivity: Small discount may help conversion
- LOW sensitivity: Customer will pay full price

INVENTORY Evaluation:
- HIGH priority cabins: Need to fill seats, be more aggressive
- Check load factor - proactive offers when LDF < 85%

For each evaluation, provide:
- Clear recommendation (e.g., "APPLY_DISCOUNT", "CHOOSE_SAFER", "PROCEED")
- Reasoning that references the actual data values
- Any policy IDs that should be applied""",
        "solver": """You are the Solver in a ReWOO agent for airline offer optimization.

The Planner created a plan and the Worker executed all evaluations. Now you have all the evidence.

Your job is to synthesize the evidence and make the final offer decision.

Consider:
- If confidence is low on expensive offers, choose a safer option
- If customer had recent issues, apply goodwill discount if policy allows
- If customer is price sensitive, apply appropriate discount per policy

Output format (JSON):
```json
{
  "selected_offer": "IU_BUSINESS" or "MCE" or "IU_PREMIUM_ECONOMY",
  "reasoning": "How I synthesized the evidence to reach this decision",
  "key_factors": ["factor1", "factor2"]
}
```"""
    },
    "personalization": {
        "system": """You are a Personalization Agent for American Airlines' Tailored Offers system.

Your role is to craft compelling, personalized upgrade offer messages that:
1. Address the customer by name and acknowledge their loyalty status
2. Highlight relevant benefits based on their profile
3. Create urgency without being pushy
4. Include the specific offer details (cabin, price, flight info)

Guidelines:
- Keep messages concise (2-3 short paragraphs max)
- Use a warm, professional tone befitting a premium airline
- Personalize based on loyalty tier, travel history, and context
- Never mention internal systems, ML models, or technical details
- Focus on the customer experience and value proposition

Output a JSON object with:
- "subject": Email subject line (compelling, personalized)
- "body": Email body (personalized message)
- "push_notification": Short push notification text (under 100 chars)
"""
    }
}


# =============================================================================
# Prompt Storage (File-based persistence)
# =============================================================================

class PromptStorage:
    """
    Persists custom prompts to a JSON file.

    File location: config/custom_prompts.json
    """

    STORAGE_PATH = Path(__file__).parent / "custom_prompts.json"

    _cache: Optional[Dict[str, Any]] = None
    _cache_mtime: float = 0

    @classmethod
    def load(cls) -> Dict[str, Any]:
        """Load custom prompts from file."""
        if not cls.STORAGE_PATH.exists():
            return {}

        try:
            # Check if file changed since last cache
            mtime = cls.STORAGE_PATH.stat().st_mtime
            if cls._cache is not None and cls._cache_mtime >= mtime:
                return cls._cache

            with open(cls.STORAGE_PATH, 'r') as f:
                cls._cache = json.load(f)
                cls._cache_mtime = mtime
                return cls._cache
        except Exception as e:
            print(f"Error loading custom prompts: {e}")
            return {}

    @classmethod
    def save(cls, prompts: Dict[str, Any]) -> bool:
        """Save custom prompts to file."""
        try:
            with open(cls.STORAGE_PATH, 'w') as f:
                json.dump(prompts, f, indent=2)
            cls._cache = prompts
            cls._cache_mtime = cls.STORAGE_PATH.stat().st_mtime
            return True
        except Exception as e:
            print(f"Error saving custom prompts: {e}")
            return False

    @classmethod
    def get(cls, key: str) -> Optional[str]:
        """Get a custom prompt by key."""
        prompts = cls.load()
        return prompts.get(key)

    @classmethod
    def set(cls, key: str, value: str) -> bool:
        """Set a custom prompt."""
        prompts = cls.load()
        prompts[key] = {
            "content": value,
            "updated_at": datetime.now().isoformat(),
        }
        return cls.save(prompts)

    @classmethod
    def delete(cls, key: str) -> bool:
        """Delete a custom prompt (reset to default)."""
        prompts = cls.load()
        if key in prompts:
            del prompts[key]
            return cls.save(prompts)
        return True

    @classmethod
    def has_custom(cls, key: str) -> bool:
        """Check if a custom prompt exists."""
        prompts = cls.load()
        return key in prompts


# =============================================================================
# Prompt Service (Main Interface)
# =============================================================================

class PromptService:
    """
    Main interface for getting prompts.

    Usage:
        from config.prompt_service import PromptService

        # Get planner prompt (custom if set, otherwise default)
        prompt = PromptService.get_planner_prompt()

        # Get personalization prompt
        prompt = PromptService.get_personalization_prompt()

        # Set custom prompt
        PromptService.set_custom_prompt("offer_orchestration.planner", "New prompt...")
    """

    # Key mappings for different agent prompts
    PROMPT_KEYS = {
        "offer_orchestration": "offer_orchestration.planner",  # Main agent prompt
        "offer_orchestration.planner": "offer_orchestration.planner",
        "offer_orchestration.worker": "offer_orchestration.worker",
        "offer_orchestration.solver": "offer_orchestration.solver",
        "personalization": "personalization.system",
        "personalization.system": "personalization.system",
    }

    @classmethod
    def get_prompt(cls, agent_id: str, prompt_type: str = "system") -> str:
        """
        Get the active prompt for an agent.

        Args:
            agent_id: Agent identifier (e.g., "offer_orchestration", "personalization")
            prompt_type: Type of prompt (e.g., "planner", "solver", "system")

        Returns:
            The custom prompt if set, otherwise the default prompt
        """
        key = f"{agent_id}.{prompt_type}"

        # Check for custom prompt
        custom = PromptStorage.get(key)
        if custom:
            return custom.get("content", "")

        # Fall back to default
        if agent_id in DEFAULT_PROMPTS:
            return DEFAULT_PROMPTS[agent_id].get(prompt_type, "")

        return ""

    @classmethod
    def get_planner_prompt(cls) -> str:
        """Get the ReWOO planner prompt."""
        return cls.get_prompt("offer_orchestration", "planner")

    @classmethod
    def get_worker_prompt(cls) -> str:
        """Get the ReWOO worker prompt (evaluation guidelines)."""
        return cls.get_prompt("offer_orchestration", "worker")

    @classmethod
    def get_solver_prompt(cls) -> str:
        """Get the ReWOO solver prompt."""
        return cls.get_prompt("offer_orchestration", "solver")

    @classmethod
    def get_personalization_prompt(cls) -> str:
        """Get the personalization agent prompt."""
        return cls.get_prompt("personalization", "system")

    @classmethod
    def set_custom_prompt(cls, key: str, content: str) -> bool:
        """
        Set a custom prompt.

        Args:
            key: Prompt key (e.g., "offer_orchestration.planner")
            content: The custom prompt content
        """
        return PromptStorage.set(key, content)

    @classmethod
    def reset_prompt(cls, key: str) -> bool:
        """Reset a prompt to its default."""
        return PromptStorage.delete(key)

    @classmethod
    def is_custom(cls, key: str) -> bool:
        """Check if a prompt has been customized."""
        return PromptStorage.has_custom(key)

    @classmethod
    def get_default_prompt(cls, agent_id: str, prompt_type: str = "system") -> str:
        """Get the default prompt (ignoring any customization)."""
        if agent_id in DEFAULT_PROMPTS:
            return DEFAULT_PROMPTS[agent_id].get(prompt_type, "")
        return ""

    @classmethod
    def get_all_prompts_info(cls) -> Dict[str, Any]:
        """Get information about all available prompts."""
        info = {}

        for agent_id, prompts in DEFAULT_PROMPTS.items():
            for prompt_type in prompts.keys():
                key = f"{agent_id}.{prompt_type}"
                info[key] = {
                    "agent_id": agent_id,
                    "prompt_type": prompt_type,
                    "is_custom": cls.is_custom(key),
                    "default_preview": prompts[prompt_type][:200] + "...",
                }

        return info


# =============================================================================
# Convenience Functions
# =============================================================================

def get_planner_prompt() -> str:
    """Get the ReWOO planner prompt."""
    return PromptService.get_planner_prompt()


def get_worker_prompt() -> str:
    """Get the ReWOO worker prompt (evaluation guidelines)."""
    return PromptService.get_worker_prompt()


def get_solver_prompt() -> str:
    """Get the ReWOO solver prompt."""
    return PromptService.get_solver_prompt()


def get_personalization_prompt() -> str:
    """Get the personalization agent prompt."""
    return PromptService.get_personalization_prompt()


def set_custom_prompt(key: str, content: str) -> bool:
    """Set a custom prompt."""
    return PromptService.set_custom_prompt(key, content)


def reset_prompt(key: str) -> bool:
    """Reset a prompt to default."""
    return PromptService.reset_prompt(key)


def is_prompt_custom(key: str) -> bool:
    """Check if a prompt is customized."""
    return PromptService.is_custom(key)


================================================================================
FILE: config/prompts/personalization.txt
================================================================================
# PERSONALIZATION PROMPT
# Version: 1.0
# Last Modified: 2026-01-20
# Purpose: Generates personalized offer messages
#
# Variables available:
#   - {customer_name}: Customer's first name
#   - {loyalty_tier}: Customer loyalty tier
#   - {offer_type}: Selected offer (IU_BUSINESS, MCE, etc.)
#   - {offer_price}: Final price after discounts
#   - {origin}: Origin airport code
#   - {destination}: Destination airport code
#   - {departure_date}: Flight departure date
#   - {travel_pattern}: business or leisure
#
# How changes affect behavior:
#   - Changing tone guidelines ‚Üí Different message style
#   - Adding/removing benefits ‚Üí Changes value proposition
#   - Modifying urgency rules ‚Üí Affects call-to-action strength

You are a personalization agent for airline upgrade offers. Generate a compelling, personalized message.

CUSTOMER CONTEXT:
- Name: {customer_name}
- Loyalty Tier: {loyalty_tier}
- Travel Pattern: {travel_pattern}
- Route: {origin} to {destination}
- Departure: {departure_date}

OFFER DETAILS:
- Offer Type: {offer_type}
- Price: ${offer_price}

TONE GUIDELINES:
- For business travelers: Professional, focus on productivity and comfort
- For leisure travelers: Warm, focus on experience and memories
- For elite tiers (E, K): Acknowledge their status, emphasize exclusivity
- For standard tiers (G, P): Focus on value and benefits

KEY BENEFITS TO HIGHLIGHT (by offer type):
- IU_BUSINESS: Lie-flat seat, priority boarding, premium dining, extra baggage
- IU_PREMIUM_ECONOMY: Extra legroom, enhanced meals, priority boarding
- MCE: Extra legroom, preferred boarding, complimentary drinks

OUTPUT FORMAT:
```json
{
  "subject": "Email subject line (max 60 chars)",
  "body": "Full message body with greeting, offer details, benefits, and call-to-action",
  "tone_used": "professional" or "warm" or "exclusive",
  "personalization_elements": ["element1", "element2"],
  "key_benefit_highlighted": "The main benefit emphasized"
}
```

Remember:
- Use customer's name naturally
- Reference their specific route
- Match urgency to time-to-departure
- Keep it concise but compelling


================================================================================
FILE: config/prompts/planner.txt
================================================================================
# PLANNER PROMPT
# Version: 2.0
# Last Modified: 2026-01-22
# Purpose: Make a simple plan for what to check before offering an upgrade
#
# What I have:
#   - Customer information (name, loyalty status)
#   - Different upgrade offers I can give them
#   - Data about the flight and customer
#
# What I need to do:
#   - Look at the data I have
#   - Make a simple plan of what things to check
#   - Write it down so the worker knows what to do

I have information about a customer and some upgrade offers I can give them.

My job is to look at this information and make a simple plan. I need to figure out: "What things should I check before deciding which offer to give?"

Here are the things I can check:
- CONFIDENCE: How sure is the computer that this customer will buy each offer?
- RELATIONSHIP: Did the customer have any problems recently with their flight?
- PRICE_SENSITIVITY: Will this customer only buy if I give them a discount?
- INVENTORY: Which airplane seats do we need to fill the most?

I need to write my plan like this:
```json
{
  "steps": [
    {"step_id": "E1", "evaluation_type": "CONFIDENCE", "description": "The computer is 50% sure about Business but 92% sure about Main Cabin Extra"},
    {"step_id": "E2", "evaluation_type": "RELATIONSHIP", "description": "Customer had a problem with their seat last week"},
    {"step_id": "E3", "evaluation_type": "PRICE_SENSITIVITY", "description": "Check if we need to give a discount to get them to buy"}
  ],
  "reasoning": "I see the computer is not very sure about Business class, and the customer had a recent problem, so I want to check both of these things carefully."
}
```

Important: Only check things that actually matter for this customer. Don't check everything if you don't need to.


================================================================================
FILE: config/prompts/reasoning_explanation.txt
================================================================================
# REASONING EXPLANATION PROMPT
# Version: 1.0
# Last Modified: 2026-01-20
# Purpose: Generates natural language explanations for agent decisions
#
# Variables available:
#   - {agent_name}: Name of the agent explaining
#   - {data_used}: Data sources and values used
#   - {decision}: The decision made
#   - {decision_details}: Additional decision context
#
# How changes affect behavior:
#   - Changing section headers ‚Üí Different output structure
#   - Adding/removing sections ‚Üí More/less detail in explanations
#   - Modifying tone ‚Üí Changes how explanations read

You are explaining a decision made by the {agent_name} in an airline offer system.

DATA USED:
{data_used}

DECISION: {decision}
DECISION DETAILS: {decision_details}

Write a clear, conversational explanation of this decision. Use these guidelines:

1. Start with "### DATA USED" section showing what data was pulled from which systems
2. Then "### ANALYSIS" explaining the key factors considered
3. Then "### DECISION" with the verdict
4. End with "### IN SIMPLE TERMS" - a 2-3 sentence plain English summary
5. Add "### WHY THIS AGENT MATTERS" - explain what could go wrong without this check

Use the actual data values provided. Be specific, not generic.
Format with clear sections and bullet points.
Keep it concise but informative.


================================================================================
FILE: config/prompts/solver.txt
================================================================================
# SOLVER PROMPT
# Version: 2.0
# Last Modified: 2026-01-22
# Purpose: Look at all the checks and decide which offer to give
#
# What I have now:
#   - All the information about the customer
#   - The results from all the checks the worker did
#   - List of offers I can give with their prices
#
# What I need to do:
#   - Look at everything the worker found
#   - Put it all together
#   - Decide which offer is best
#   - Give this offer to the channel for sending

The planner made a plan. The worker did all the checks. Now I have all the results.

My job is to look at everything and make the final decision about which upgrade offer to give this customer.

Here's what I have:
1. Information about the customer
2. Different upgrade offers I can give (with prices)
3. Results from all the checks that were done

Now I need to put it all together and decide:

Things to think about:
- If the computer is not very sure about an expensive offer, maybe I should give them a cheaper, safer offer instead
- If the customer had a problem recently, I should give them a discount to make them feel better
- If the customer usually only buys when things are on sale, I should give them a discount

I need to write my decision like this:
```json
{
  "selected_offer": "IU_BUSINESS" or "MCE" or "IU_PREMIUM_ECONOMY",
  "offer_price": <number>,
  "discount_percent": <0-20>,
  "confidence": "high" or "medium" or "low",
  "synthesis": "Simple explanation of how I made this decision",
  "key_factors": ["reason1", "reason2"]
}
```

After I make this decision, I will give it to the channel. The channel will figure out the best way to send it to the customer (email, app notification, etc).


================================================================================
FILE: config/prompts.py
================================================================================
"""
Prompt Versioning System

Provides centralized management of prompts with:
- Version tracking
- A/B testing support
- Evaluation score tracking
- Rollback capability
"""

import os
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum


class PromptStatus(Enum):
    """Status of a prompt version."""
    DRAFT = "draft"
    ACTIVE = "active"
    TESTING = "testing"
    DEPRECATED = "deprecated"


@dataclass
class PromptVersion:
    """A versioned prompt with metadata."""
    version: str
    prompt: str
    status: PromptStatus = PromptStatus.DRAFT
    created_at: datetime = field(default_factory=datetime.now)
    evaluation_score: Optional[float] = None
    description: str = ""
    tags: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "version": self.version,
            "status": self.status.value,
            "created_at": self.created_at.isoformat(),
            "evaluation_score": self.evaluation_score,
            "description": self.description,
            "tags": self.tags,
        }


# =============================================================================
# OFFER ORCHESTRATION PROMPTS
# =============================================================================

OFFER_ORCHESTRATION_V1_0 = """You are an Airline Revenue Management AI Agent specializing in offer optimization.

Your task is to select the BEST offer for a customer based on Expected Value (EV) optimization.

## Decision Framework

1. **Expected Value (EV) = Probability(Buy) √ó Price √ó Margin**
   - This is your PRIMARY metric for offer selection
   - Higher EV = Better for the airline

2. **Guardrails (MUST NOT EXCEED)**:
   - Business Class: Max 20% discount
   - Premium Economy: Max 15% discount
   - Main Cabin Extra: Max 25% discount

3. **Urgency Adjustments**:
   - T-6 to T-24 hours: URGENT - can add +10% to max discount
   - T-24 to T-48 hours: SOON - can add +5% to max discount
   - T-48+ hours: STANDARD - use base discounts

4. **Key Factors to Consider**:
   - Customer loyalty tier (higher tier = higher propensity)
   - ML propensity scores (primary predictor)
   - Cabin inventory availability
   - Time to departure

## Output Format

Return a JSON object with:
```json
{
    "selected_offer": "IU_BUSINESS" | "IU_PREMIUM_ECONOMY" | "MCE" | "NONE",
    "offer_price": <number>,
    "discount_percent": <0-25>,
    "confidence": "high" | "medium" | "low",
    "key_factors": ["factor1", "factor2", "factor3"],
    "reasoning": "<brief explanation>"
}
```

REMEMBER: Maximize REVENUE through Expected Value, not acceptance rate.
A $121 EV beats a $27 EV, even if the $27 option has higher acceptance rate."""


OFFER_ORCHESTRATION_V1_1 = """You are an Airline Revenue Management AI Agent specializing in intelligent offer optimization.

## Your Mission
Select the offer that maximizes Expected Value (EV) while respecting guardrails and customer experience.

## Core Formula
**EV = P(accept) √ó Price √ó Margin**

This is your north star. Higher EV = Better outcome.

## Decision Process

### Step 1: Calculate EV for Each Option
For each available offer, compute:
- P(accept): Use the ML propensity score
- Price: Base price minus any applicable discount
- Margin: Product-specific margin percentage

### Step 2: Apply Guardrails
Hard limits that cannot be exceeded:
| Product | Max Discount | Margin |
|---------|--------------|--------|
| Business Class | 20% | 90% |
| Premium Economy | 15% | 88% |
| Main Cabin Extra | 25% | 85% |

### Step 3: Consider Urgency
Time-based discount adjustments:
- **URGENT** (< 24h): +10% discount allowance
- **SOON** (24-48h): +5% discount allowance
- **STANDARD** (> 48h): Base discounts only

### Step 4: Make Decision
Select the offer with the highest EV that:
- Respects all guardrails
- Has available inventory
- Matches customer segment

## Output Format
```json
{
    "selected_offer": "IU_BUSINESS" | "IU_PREMIUM_ECONOMY" | "MCE" | "NONE",
    "offer_price": <number>,
    "discount_percent": <0-25>,
    "confidence": "high" | "medium" | "low",
    "key_factors": ["EV calculation", "factor2", "factor3"],
    "fallback_offer": "MCE" | null,
    "fallback_price": <number> | null,
    "reasoning": "<2-3 sentence explanation>"
}
```

## Important Reminders
- Revenue > Acceptance Rate (a $121 EV beats a $27 EV)
- Never exceed guardrail limits
- Always have a fallback for price-sensitive customers
- Consider customer lifetime value for loyalty members"""


OFFER_ORCHESTRATION_V2_0 = """You are an expert Airline Revenue Management Agent with deep expertise in pricing optimization and customer behavior.

## Context
You're part of a multi-agent system that determines personalized upgrade offers for airline customers. Your role is to select the optimal offer that maximizes expected revenue.

## Your Expertise
- Dynamic pricing and yield management
- Customer segmentation and propensity modeling
- Behavioral economics in purchase decisions

## Decision Framework

### Primary Objective
Maximize Expected Value (EV) = P(accept) √ó Price √ó Margin

### Input Analysis
You will receive:
1. **Customer Profile**: Loyalty tier, travel history, preferences
2. **ML Scores**: Propensity to buy each product (0.0 - 1.0)
3. **Available Offers**: Products with pricing and inventory
4. **Context**: Flight details, time to departure

### Guardrails (Non-Negotiable)
| Product | Max Discount | Notes |
|---------|--------------|-------|
| Business Class (IU_BUSINESS) | 20% | Premium product, protect margins |
| Premium Economy (IU_PREMIUM_ECONOMY) | 15% | Mid-tier, moderate discounting |
| Main Cabin Extra (MCE) | 25% | Entry product, more flexibility |

### Urgency Multipliers
- **URGENT** (T-6 to T-24h): Max discount +10%
- **SOON** (T-24 to T-48h): Max discount +5%
- **STANDARD** (T-48h+): Base limits apply

### Loyalty Considerations
- Executive Platinum: 1.3x propensity multiplier
- Platinum Pro: 1.2x propensity multiplier
- Platinum: 1.1x propensity multiplier
- Gold: 1.0x (baseline)
- General: 0.9x propensity multiplier

## Output Requirements

Return ONLY a JSON object:
```json
{
    "selected_offer": "IU_BUSINESS" | "IU_PREMIUM_ECONOMY" | "MCE" | "NONE",
    "offer_price": <final_price_after_discount>,
    "discount_percent": <0-30>,
    "confidence": "high" | "medium" | "low",
    "key_factors": ["primary_factor", "secondary_factor"],
    "fallback_offer": "<backup_offer_type>" | null,
    "fallback_price": <fallback_price> | null,
    "reasoning": "<concise_explanation>"
}
```

## Decision Guidelines
1. ALWAYS select the highest EV option that passes guardrails
2. NEVER exceed discount limits (this is a hard constraint)
3. INCLUDE a fallback offer for price-sensitive scenarios
4. USE "NONE" only if no profitable offer exists

Remember: Optimize for revenue, not acceptance rate. A lower-probability, higher-value offer often beats a higher-probability, lower-value one."""


# =============================================================================
# PERSONALIZATION PROMPTS
# =============================================================================

PERSONALIZATION_V1_0 = """You are a Marketing AI specializing in personalized airline communications.

Generate a personalized message for an upgrade offer based on the customer profile and offer details.

## Guidelines
1. Use the customer's first name
2. Reference their travel destination
3. Highlight benefits relevant to their travel type
4. Include the specific price
5. Create urgency appropriate to the timing

## Tone
- Professional yet warm
- Benefit-focused
- Action-oriented

## Output Format
```json
{
    "subject": "<email subject line, max 60 chars>",
    "body": "<message body, 2-3 paragraphs>",
    "tone": "professional" | "friendly" | "urgent",
    "cta_text": "<call to action button text>"
}
```

Keep messages concise and focused on value."""


PERSONALIZATION_V1_1 = """You are an expert Marketing AI for a premium airline, crafting personalized upgrade offers.

## Your Role
Create compelling, personalized messages that drive conversions while maintaining brand standards.

## Input Context
- Customer: Name, loyalty tier, preferences
- Offer: Type, price, benefits
- Flight: Route, departure time, timing window

## Message Strategy

### Subject Line (max 60 chars)
- Create curiosity or urgency
- Personalize when possible
- A/B test friendly

### Body Structure
1. **Opening**: Personal greeting, acknowledge loyalty status
2. **Value Proposition**: Lead with most relevant benefit
3. **Offer Details**: Clear pricing and what's included
4. **Urgency**: Time-sensitive element
5. **CTA**: Single, clear call to action

### Tone Calibration
| Customer Type | Tone | Focus |
|--------------|------|-------|
| Executive Platinum | Exclusive, VIP | Recognition, priority |
| Business Traveler | Professional | Productivity, comfort |
| Leisure Traveler | Friendly | Experience, value |
| Price-Sensitive | Direct | Savings, limited-time |

## Brand Guidelines
- Never use all caps
- Avoid excessive punctuation
- No placeholder text
- Specific numbers over vague claims

## Output Format
```json
{
    "subject": "<subject line, max 60 chars>",
    "body": "<complete message, 100-200 words>",
    "tone": "professional" | "friendly" | "urgent" | "exclusive",
    "cta_text": "<button text, max 30 chars>",
    "personalization_elements": ["element1", "element2"]
}
```"""


# =============================================================================
# PROMPT REGISTRY
# =============================================================================

class PromptRegistry:
    """
    Central registry for managing prompt versions.

    Supports:
    - Multiple versions per agent
    - A/B testing configuration
    - Evaluation score tracking
    - Environment-based version selection
    """

    def __init__(self):
        self._prompts: Dict[str, Dict[str, PromptVersion]] = {}
        self._active_versions: Dict[str, str] = {}
        self._initialize_prompts()

    def _initialize_prompts(self):
        """Initialize all prompt versions."""
        # Offer Orchestration prompts
        self.register_prompt(
            agent_id="offer_orchestration",
            version="v1.0",
            prompt=OFFER_ORCHESTRATION_V1_0,
            status=PromptStatus.DEPRECATED,
            description="Initial version - basic EV optimization",
        )
        self.register_prompt(
            agent_id="offer_orchestration",
            version="v1.1",
            prompt=OFFER_ORCHESTRATION_V1_1,
            status=PromptStatus.ACTIVE,
            description="Improved structure with fallback support",
        )
        self.register_prompt(
            agent_id="offer_orchestration",
            version="v2.0",
            prompt=OFFER_ORCHESTRATION_V2_0,
            status=PromptStatus.TESTING,
            description="Expert persona with loyalty multipliers",
            tags=["experimental", "a/b-test"],
        )

        # Personalization prompts
        self.register_prompt(
            agent_id="personalization",
            version="v1.0",
            prompt=PERSONALIZATION_V1_0,
            status=PromptStatus.ACTIVE,
            description="Initial version - basic personalization",
        )
        self.register_prompt(
            agent_id="personalization",
            version="v1.1",
            prompt=PERSONALIZATION_V1_1,
            status=PromptStatus.TESTING,
            description="Enhanced with tone calibration and brand guidelines",
            tags=["experimental"],
        )

        # Set active versions from environment or defaults
        self._active_versions = {
            "offer_orchestration": os.getenv("OFFER_ORCHESTRATION_PROMPT_VERSION", "v1.1"),
            "personalization": os.getenv("PERSONALIZATION_PROMPT_VERSION", "v1.0"),
        }

    def register_prompt(
        self,
        agent_id: str,
        version: str,
        prompt: str,
        status: PromptStatus = PromptStatus.DRAFT,
        description: str = "",
        tags: Optional[List[str]] = None,
    ) -> PromptVersion:
        """Register a new prompt version."""
        if agent_id not in self._prompts:
            self._prompts[agent_id] = {}

        prompt_version = PromptVersion(
            version=version,
            prompt=prompt,
            status=status,
            description=description,
            tags=tags or [],
        )

        self._prompts[agent_id][version] = prompt_version
        return prompt_version

    def get_prompt(
        self,
        agent_id: str,
        version: Optional[str] = None,
    ) -> str:
        """
        Get a prompt by agent ID and version.

        Args:
            agent_id: The agent identifier (e.g., "offer_orchestration")
            version: Optional version (defaults to active version)

        Returns:
            The prompt string
        """
        if agent_id not in self._prompts:
            raise ValueError(f"Unknown agent: {agent_id}")

        version = version or self._active_versions.get(agent_id)
        if not version or version not in self._prompts[agent_id]:
            # Fall back to first available version
            versions = list(self._prompts[agent_id].keys())
            if not versions:
                raise ValueError(f"No prompts registered for agent: {agent_id}")
            version = versions[-1]  # Most recent

        return self._prompts[agent_id][version].prompt

    def get_active_version(self, agent_id: str) -> str:
        """Get the active version for an agent."""
        return self._active_versions.get(agent_id, "v1.0")

    def set_active_version(self, agent_id: str, version: str):
        """Set the active version for an agent."""
        if agent_id not in self._prompts:
            raise ValueError(f"Unknown agent: {agent_id}")
        if version not in self._prompts[agent_id]:
            raise ValueError(f"Unknown version {version} for agent {agent_id}")

        self._active_versions[agent_id] = version

    def get_all_versions(self, agent_id: str) -> List[Dict[str, Any]]:
        """Get metadata for all versions of an agent's prompts."""
        if agent_id not in self._prompts:
            return []

        return [
            {
                **pv.to_dict(),
                "is_active": self._active_versions.get(agent_id) == pv.version,
            }
            for pv in self._prompts[agent_id].values()
        ]

    def record_evaluation(
        self,
        agent_id: str,
        version: str,
        score: float,
    ):
        """Record an evaluation score for a prompt version."""
        if agent_id in self._prompts and version in self._prompts[agent_id]:
            prompt = self._prompts[agent_id][version]
            # Running average
            if prompt.evaluation_score is None:
                prompt.evaluation_score = score
            else:
                prompt.evaluation_score = (prompt.evaluation_score + score) / 2

    def get_ab_test_version(
        self,
        agent_id: str,
        test_group: str,
    ) -> str:
        """
        Get prompt version for A/B testing.

        Args:
            agent_id: The agent identifier
            test_group: "control" or "treatment"

        Returns:
            Version string for the test group
        """
        if test_group == "treatment":
            # Return the testing version if available
            for version, pv in self._prompts.get(agent_id, {}).items():
                if pv.status == PromptStatus.TESTING:
                    return version

        # Default to active version
        return self._active_versions.get(agent_id, "v1.0")


# Global registry instance
_registry: Optional[PromptRegistry] = None


def get_prompt_registry() -> PromptRegistry:
    """Get the global prompt registry instance."""
    global _registry
    if _registry is None:
        _registry = PromptRegistry()
    return _registry


def get_prompt(agent_id: str, version: Optional[str] = None) -> str:
    """Convenience function to get a prompt."""
    return get_prompt_registry().get_prompt(agent_id, version)


def get_prompt_version(agent_id: str) -> str:
    """Convenience function to get the active prompt version."""
    return get_prompt_registry().get_active_version(agent_id)


================================================================================
FILE: config/settings.py
================================================================================
"""
Configuration settings for Tailored Offers Demo
"""
import os
from dotenv import load_dotenv

load_dotenv()

# =============================================================================
# LLM Configuration
# =============================================================================
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai")  # "anthropic" or "openai"
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MODEL_NAME = os.getenv("MODEL_NAME", "claude-sonnet-4-20250514")

# Demo Mode
DEMO_MODE = os.getenv("DEMO_MODE", "live")  # "live" or "simulated"

# =============================================================================
# Observability Configuration
# =============================================================================

# Structured Logging
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
LOG_FORMAT = os.getenv("LOG_FORMAT", "json")  # "json" or "console"
LOG_FILE = os.getenv("LOG_FILE", None)

# Prometheus Metrics
METRICS_ENABLED = os.getenv("METRICS_ENABLED", "true").lower() == "true"
METRICS_PORT = int(os.getenv("METRICS_PORT", "9090"))

# LangSmith Tracing
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY", "")
LANGSMITH_PROJECT = os.getenv("LANGSMITH_PROJECT", "tailored-offers")
LANGSMITH_TRACING = os.getenv("LANGSMITH_TRACING", "false").lower() == "true"

# LangFuse Tracing (alternative to LangSmith)
LANGFUSE_SECRET_KEY = os.getenv("LANGFUSE_SECRET_KEY", "")
LANGFUSE_PUBLIC_KEY = os.getenv("LANGFUSE_PUBLIC_KEY", "")
LANGFUSE_HOST = os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")

# =============================================================================
# Retry Configuration
# =============================================================================
LLM_RETRY_MAX_ATTEMPTS = int(os.getenv("LLM_RETRY_MAX_ATTEMPTS", "3"))
LLM_RETRY_MIN_WAIT = float(os.getenv("LLM_RETRY_MIN_WAIT", "2.0"))
LLM_RETRY_MAX_WAIT = float(os.getenv("LLM_RETRY_MAX_WAIT", "30.0"))
LLM_TIMEOUT_SECONDS = float(os.getenv("LLM_TIMEOUT_SECONDS", "60.0"))

MCP_RETRY_MAX_ATTEMPTS = int(os.getenv("MCP_RETRY_MAX_ATTEMPTS", "3"))
MCP_RETRY_MIN_WAIT = float(os.getenv("MCP_RETRY_MIN_WAIT", "1.0"))
MCP_RETRY_MAX_WAIT = float(os.getenv("MCP_RETRY_MAX_WAIT", "10.0"))
MCP_TIMEOUT_SECONDS = float(os.getenv("MCP_TIMEOUT_SECONDS", "30.0"))

# =============================================================================
# Prompt Versioning
# =============================================================================
OFFER_ORCHESTRATION_PROMPT_VERSION = os.getenv("OFFER_ORCHESTRATION_PROMPT_VERSION", "v1.1")
PERSONALIZATION_PROMPT_VERSION = os.getenv("PERSONALIZATION_PROMPT_VERSION", "v1.0")

# A/B Testing
AB_TEST_ENABLED = os.getenv("AB_TEST_ENABLED", "false").lower() == "true"
AB_TEST_TREATMENT_PERCENTAGE = float(os.getenv("AB_TEST_TREATMENT_PERCENTAGE", "0.1"))

# =============================================================================
# Validation Configuration
# =============================================================================
VALIDATION_ENABLED = os.getenv("VALIDATION_ENABLED", "true").lower() == "true"
VALIDATION_STRICT_MODE = os.getenv("VALIDATION_STRICT_MODE", "false").lower() == "true"

# Offer Configuration
OFFER_TYPES = {
    "IU_BUSINESS": {
        "name": "Instant Upgrade - Business Class",
        "base_price": 199,
        "min_discount": 0,
        "max_discount": 0.20,
        "margin": 0.90
    },
    "IU_PREMIUM_ECONOMY": {
        "name": "Instant Upgrade - Premium Economy",
        "base_price": 129,
        "min_discount": 0,
        "max_discount": 0.15,
        "margin": 0.88
    },
    "MCE": {
        "name": "Main Cabin Extra",
        "base_price": 39,
        "min_discount": 0,
        "max_discount": 0.25,
        "margin": 0.85
    }
}

# Channel Configuration
CHANNELS = {
    "push": {"priority": 1, "avg_open_rate": 0.45},
    "email": {"priority": 2, "avg_open_rate": 0.22},
    "in_app": {"priority": 3, "avg_open_rate": 0.65}
}

# Timing Windows
TIMING_WINDOWS = {
    "T-72": {"hours_before": 72, "urgency": "low"},
    "T-48": {"hours_before": 48, "urgency": "medium"},
    "T-24": {"hours_before": 24, "urgency": "high"}
}

# Loyalty Tiers
LOYALTY_TIERS = {
    "Executive Platinum": {"level": 5, "upgrade_multiplier": 1.3},
    "Platinum Pro": {"level": 4, "upgrade_multiplier": 1.2},
    "Platinum": {"level": 3, "upgrade_multiplier": 1.1},
    "Gold": {"level": 2, "upgrade_multiplier": 1.0},
    "General": {"level": 1, "upgrade_multiplier": 0.9}
}


================================================================================
FILE: data/customers.json
================================================================================
[
  {
    "_scenario": "EASY CHOICE - Standard Gold member, clear Business EV winner",
    "lylty_acct_id": "1234567890",
    "party_id": "P001234567",
    "name_prefix": "Ms",
    "first_name": "Sarah",
    "last_name": "Johnson",
    "age": 34,
    "loyalty_tier": "G",
    "max_loyalty_tier": "G",
    "aadv_tenure_days": 1095,
    "pgm_enroll_dt": "2023-01-15",
    "home_airport_cd": "DFW",
    "hub_ind": 1,
    "aadvantage_miles_balance": 45000,
    "curr_yr_loyalty_point_balance": 12000,
    "prev_yr_loyalty_point_balance": 15000,
    "cobrand_cardholder_ind": 1,
    "preferred_communication_channel": "push",
    "opted_out_pii": 0,
    "business_trip_likelihood": 0.25,
    "booking_count_history": 8,
    "days_between_bookings": 45,
    "days_between_flights": 30,
    "flight_revenue_amt_history": 4200,
    "flight_redemption_count_history": 1,
    "ticketed_premium_cabin_bookings": 0,
    "future_booking_count": 2,
    "future_revenue_amt": 890,
    "marketing_consent": {
      "push": true,
      "email": true,
      "sms": false
    },
    "suppression": {
      "is_suppressed": false,
      "recent_complaint": false,
      "last_offer_date": "2026-01-05"
    },
    "historical_upgrades": {
      "offers_received": 12,
      "offers_accepted": 4,
      "acceptance_rate": 0.33,
      "last_upgrade_type": "MCE",
      "avg_upgrade_spend": 45
    }
  },
  {
    "_scenario": "CONFIDENCE TRADE-OFF - High value customer BUT ML prediction is unreliable",
    "lylty_acct_id": "9876543210",
    "party_id": "P009876543",
    "name_prefix": "Mr",
    "first_name": "John",
    "last_name": "Smith",
    "age": 47,
    "loyalty_tier": "T",
    "max_loyalty_tier": "T",
    "aadv_tenure_days": 2190,
    "pgm_enroll_dt": "2020-01-10",
    "home_airport_cd": "ORD",
    "hub_ind": 1,
    "aadvantage_miles_balance": 320000,
    "curr_yr_loyalty_point_balance": 95000,
    "prev_yr_loyalty_point_balance": 88000,
    "cobrand_cardholder_ind": 1,
    "preferred_communication_channel": "push",
    "opted_out_pii": 0,
    "business_trip_likelihood": 0.92,
    "booking_count_history": 52,
    "days_between_bookings": 7,
    "days_between_flights": 4,
    "flight_revenue_amt_history": 48000,
    "flight_redemption_count_history": 3,
    "ticketed_premium_cabin_bookings": 28,
    "future_booking_count": 8,
    "future_revenue_amt": 12500,
    "marketing_consent": {
      "push": true,
      "email": true,
      "sms": true
    },
    "suppression": {
      "is_suppressed": false,
      "recent_complaint": false,
      "last_offer_date": "2026-01-08"
    },
    "historical_upgrades": {
      "offers_received": 45,
      "offers_accepted": 18,
      "acceptance_rate": 0.40,
      "last_upgrade_type": "IU_BUSINESS",
      "avg_upgrade_spend": 175
    }
  },
  {
    "_scenario": "RELATIONSHIP TRADE-OFF - Exec Plat with recent service recovery, needs gentle approach",
    "lylty_acct_id": "5555555555",
    "party_id": "P005555555",
    "name_prefix": "Ms",
    "first_name": "Emily",
    "last_name": "Chen",
    "age": 52,
    "loyalty_tier": "E",
    "max_loyalty_tier": "E",
    "aadv_tenure_days": 3650,
    "pgm_enroll_dt": "2016-01-20",
    "home_airport_cd": "LAX",
    "hub_ind": 1,
    "aadvantage_miles_balance": 850000,
    "curr_yr_loyalty_point_balance": 185000,
    "prev_yr_loyalty_point_balance": 172000,
    "cobrand_cardholder_ind": 1,
    "preferred_communication_channel": "email",
    "opted_out_pii": 0,
    "business_trip_likelihood": 0.95,
    "booking_count_history": 98,
    "days_between_bookings": 4,
    "days_between_flights": 2,
    "flight_revenue_amt_history": 118000,
    "flight_redemption_count_history": 8,
    "ticketed_premium_cabin_bookings": 72,
    "future_booking_count": 12,
    "future_revenue_amt": 28000,
    "marketing_consent": {
      "push": true,
      "email": true,
      "sms": true
    },
    "suppression": {
      "is_suppressed": false,
      "recent_complaint": false,
      "last_offer_date": "2026-01-02"
    },
    "recent_service_recovery": {
      "had_issue": true,
      "issue_date": "2026-01-10",
      "issue_type": "seat_assignment_change",
      "resolution": "apology_miles_credited",
      "customer_sentiment": "neutral_recovering",
      "_note": "NOT suppressed, but agent should consider relationship health"
    },
    "historical_upgrades": {
      "offers_received": 89,
      "offers_accepted": 52,
      "acceptance_rate": 0.58,
      "last_upgrade_type": "IU_BUSINESS",
      "avg_upgrade_spend": 210
    }
  },
  {
    "_scenario": "GUARDRAIL: INVENTORY - Good customer, but Flight MCP says 0 seats",
    "lylty_acct_id": "1111111111",
    "party_id": "P001111111",
    "name_prefix": "Mr",
    "first_name": "Michael",
    "last_name": "Brown",
    "age": 38,
    "loyalty_tier": "G",
    "max_loyalty_tier": "G",
    "aadv_tenure_days": 800,
    "pgm_enroll_dt": "2024-01-15",
    "home_airport_cd": "MIA",
    "hub_ind": 1,
    "aadvantage_miles_balance": 35000,
    "curr_yr_loyalty_point_balance": 18000,
    "prev_yr_loyalty_point_balance": 12000,
    "cobrand_cardholder_ind": 1,
    "preferred_communication_channel": "email",
    "opted_out_pii": 0,
    "business_trip_likelihood": 0.60,
    "booking_count_history": 10,
    "days_between_bookings": 35,
    "days_between_flights": 25,
    "flight_revenue_amt_history": 5200,
    "flight_redemption_count_history": 1,
    "ticketed_premium_cabin_bookings": 2,
    "future_booking_count": 1,
    "future_revenue_amt": 450,
    "marketing_consent": {
      "push": true,
      "email": true,
      "sms": false
    },
    "suppression": {
      "is_suppressed": false,
      "recent_complaint": false,
      "last_offer_date": "2025-12-20"
    },
    "historical_upgrades": {
      "offers_received": 8,
      "offers_accepted": 3,
      "acceptance_rate": 0.38,
      "last_upgrade_type": "MCE",
      "avg_upgrade_spend": 65
    }
  },
  {
    "_scenario": "GUARDRAIL: CUSTOMER - Customer MCP returns suppression flag",
    "lylty_acct_id": "2222222222",
    "party_id": "P002222222",
    "name_prefix": "Mrs",
    "first_name": "Lisa",
    "last_name": "Martinez",
    "age": 41,
    "loyalty_tier": "P",
    "max_loyalty_tier": "P",
    "aadv_tenure_days": 1460,
    "pgm_enroll_dt": "2022-01-12",
    "home_airport_cd": "DFW",
    "hub_ind": 1,
    "aadvantage_miles_balance": 125000,
    "curr_yr_loyalty_point_balance": 42000,
    "prev_yr_loyalty_point_balance": 38000,
    "cobrand_cardholder_ind": 1,
    "preferred_communication_channel": "push",
    "opted_out_pii": 0,
    "business_trip_likelihood": 0.55,
    "booking_count_history": 24,
    "days_between_bookings": 15,
    "days_between_flights": 11,
    "flight_revenue_amt_history": 16500,
    "flight_redemption_count_history": 2,
    "ticketed_premium_cabin_bookings": 5,
    "future_booking_count": 3,
    "future_revenue_amt": 2100,
    "marketing_consent": {
      "push": true,
      "email": true,
      "sms": false
    },
    "suppression": {
      "is_suppressed": true,
      "recent_complaint": true,
      "complaint_date": "2026-01-08",
      "complaint_reason": "Delayed baggage on previous flight",
      "last_offer_date": "2026-01-01"
    },
    "historical_upgrades": {
      "offers_received": 28,
      "offers_accepted": 9,
      "acceptance_rate": 0.32,
      "last_upgrade_type": "MCE",
      "avg_upgrade_spend": 55
    }
  },
  {
    "_scenario": "PRICE + DISRUPTION - Price sensitive AND had recent delay (demo: agent gap)",
    "lylty_acct_id": "3333333333",
    "party_id": "P003333333",
    "name_prefix": "Mr",
    "first_name": "David",
    "last_name": "Kim",
    "age": 32,
    "loyalty_tier": "G",
    "max_loyalty_tier": "G",
    "aadv_tenure_days": 730,
    "pgm_enroll_dt": "2024-01-15",
    "home_airport_cd": "DFW",
    "hub_ind": 1,
    "aadvantage_miles_balance": 28000,
    "curr_yr_loyalty_point_balance": 8500,
    "prev_yr_loyalty_point_balance": 9200,
    "cobrand_cardholder_ind": 0,
    "preferred_communication_channel": "email",
    "opted_out_pii": 0,
    "business_trip_likelihood": 0.15,
    "booking_count_history": 6,
    "days_between_bookings": 60,
    "days_between_flights": 45,
    "flight_revenue_amt_history": 1800,
    "flight_redemption_count_history": 0,
    "ticketed_premium_cabin_bookings": 0,
    "future_booking_count": 1,
    "future_revenue_amt": 320,
    "marketing_consent": {
      "push": false,
      "email": true,
      "sms": false
    },
    "suppression": {
      "is_suppressed": false,
      "recent_complaint": false,
      "last_offer_date": "2025-12-15"
    },
    "recent_disruption": {
      "had_disruption": true,
      "disruption_date": "2026-01-25",
      "disruption_type": "delay",
      "delay_minutes": 180,
      "flight_number": "AA1234",
      "route": "DFW-ORD",
      "compensation_offered": false,
      "_note": "3-hour delay yesterday - agent should consider this before offering"
    },
    "historical_upgrades": {
      "offers_received": 8,
      "offers_accepted": 1,
      "acceptance_rate": 0.125,
      "last_upgrade_type": "MCE",
      "avg_upgrade_spend": 29,
      "note": "Only accepts upgrades when deeply discounted"
    }
  }
]


================================================================================
FILE: data/flights.json
================================================================================
[
  {
    "_scenario": "Used by: ABC123 (Easy Choice), GHI654 (Guardrail:Customer), JKL789 (Price Trade-off)",
    "operat_flight_nbr": 2847,
    "operat_airln_cd": "AA",
    "leg": 1,
    "leg_dep_dt": "2026-01-15",
    "schd_leg_dep_airprt_iata_cd": "DFW",
    "schd_leg_arvl_airprt_iata_cd": "LAX",
    "schd_leg_dep_lcl_tms": "14:00",
    "schd_leg_arvl_lcl_tms": "15:30",
    "equipment_model": "777-200",
    "distance": 1235,
    "local_bid_price": 125.00,
    "cabins": {
      "F": {
        "cabin_capacity": 37,
        "cabin_total_pax": 30,
        "cabin_ticketed_actual_pax": 30,
        "cabin_available": 7,
        "expected_load_factor": 0.81,
        "cabin_aadvantage_pax": 22,
        "cabin_total_revenue": 45000,
        "cabin_mileage_burn_rev": 8500,
        "cabin_iu_rev": 3200,
        "cabin_iu_miles_burn_rev": 650
      },
      "W": {
        "cabin_capacity": 24,
        "cabin_total_pax": 18,
        "cabin_ticketed_actual_pax": 18,
        "cabin_available": 6,
        "expected_load_factor": 0.75,
        "cabin_aadvantage_pax": 15,
        "cabin_total_revenue": 12500,
        "cabin_mileage_burn_rev": 2100,
        "cabin_iu_rev": 1800,
        "cabin_iu_miles_burn_rev": 320
      },
      "MCE": {
        "cabin_capacity": 60,
        "cabin_total_pax": 36,
        "cabin_ticketed_actual_pax": 36,
        "cabin_available": 24,
        "expected_load_factor": 0.60,
        "cabin_aadvantage_pax": 28,
        "cabin_total_revenue": 2340,
        "cabin_mileage_burn_rev": 0
      },
      "Y": {
        "cabin_capacity": 167,
        "cabin_total_pax": 152,
        "cabin_ticketed_actual_pax": 152,
        "cabin_available": 15,
        "expected_load_factor": 0.91,
        "cabin_aadvantage_pax": 89,
        "cabin_total_revenue": 38200
      }
    },
    "product_catalog": {
      "mce_available": true,
      "mce_price": 39,
      "iu_available": true,
      "iu_business_price": 199,
      "iu_premium_economy_price": 129
    }
  },
  {
    "_scenario": "Used by: XYZ789 (Confidence Trade-off - good inventory, ML confidence is low)",
    "operat_flight_nbr": 1234,
    "operat_airln_cd": "AA",
    "leg": 1,
    "leg_dep_dt": "2026-01-14",
    "schd_leg_dep_airprt_iata_cd": "ORD",
    "schd_leg_arvl_airprt_iata_cd": "MIA",
    "schd_leg_dep_lcl_tms": "09:00",
    "schd_leg_arvl_lcl_tms": "12:30",
    "equipment_model": "A321",
    "distance": 1197,
    "local_bid_price": 95.00,
    "cabins": {
      "F": {
        "cabin_capacity": 16,
        "cabin_total_pax": 10,
        "cabin_ticketed_actual_pax": 10,
        "cabin_available": 6,
        "expected_load_factor": 0.63,
        "cabin_aadvantage_pax": 8,
        "cabin_total_revenue": 12800,
        "cabin_mileage_burn_rev": 2400,
        "cabin_iu_rev": 1950,
        "cabin_iu_miles_burn_rev": 380
      },
      "MCE": {
        "cabin_capacity": 30,
        "cabin_total_pax": 12,
        "cabin_ticketed_actual_pax": 12,
        "cabin_available": 18,
        "expected_load_factor": 0.40,
        "cabin_aadvantage_pax": 9,
        "cabin_total_revenue": 348,
        "cabin_mileage_burn_rev": 0
      },
      "Y": {
        "cabin_capacity": 143,
        "cabin_total_pax": 135,
        "cabin_ticketed_actual_pax": 135,
        "cabin_available": 8,
        "expected_load_factor": 0.94,
        "cabin_aadvantage_pax": 72,
        "cabin_total_revenue": 28500
      }
    },
    "product_catalog": {
      "mce_available": true,
      "mce_price": 29,
      "iu_available": true,
      "iu_business_price": 179,
      "iu_premium_economy_price": 0
    }
  },
  {
    "_scenario": "Used by: LMN456 (Relationship Trade-off - long-haul, high-value customer needs care)",
    "operat_flight_nbr": 100,
    "operat_airln_cd": "AA",
    "leg": 1,
    "leg_dep_dt": "2026-01-16",
    "schd_leg_dep_airprt_iata_cd": "LAX",
    "schd_leg_arvl_airprt_iata_cd": "LHR",
    "schd_leg_dep_lcl_tms": "18:00",
    "schd_leg_arvl_lcl_tms": "06:30",
    "equipment_model": "777-300ER",
    "distance": 5456,
    "local_bid_price": 450.00,
    "cabins": {
      "F": {
        "cabin_capacity": 52,
        "cabin_total_pax": 36,
        "cabin_ticketed_actual_pax": 36,
        "cabin_available": 16,
        "expected_load_factor": 0.69,
        "cabin_aadvantage_pax": 28,
        "cabin_total_revenue": 138000,
        "cabin_mileage_burn_rev": 32000,
        "cabin_iu_rev": 14500,
        "cabin_iu_miles_burn_rev": 3200
      },
      "W": {
        "cabin_capacity": 28,
        "cabin_total_pax": 20,
        "cabin_ticketed_actual_pax": 20,
        "cabin_available": 8,
        "expected_load_factor": 0.71,
        "cabin_aadvantage_pax": 14,
        "cabin_total_revenue": 28000,
        "cabin_mileage_burn_rev": 5600,
        "cabin_iu_rev": 4800,
        "cabin_iu_miles_burn_rev": 920
      },
      "MCE": {
        "cabin_capacity": 44,
        "cabin_total_pax": 30,
        "cabin_ticketed_actual_pax": 30,
        "cabin_available": 14,
        "expected_load_factor": 0.68,
        "cabin_aadvantage_pax": 22,
        "cabin_total_revenue": 2670,
        "cabin_mileage_burn_rev": 0
      },
      "Y": {
        "cabin_capacity": 180,
        "cabin_total_pax": 172,
        "cabin_ticketed_actual_pax": 172,
        "cabin_available": 8,
        "expected_load_factor": 0.96,
        "cabin_aadvantage_pax": 95,
        "cabin_total_revenue": 125000
      }
    },
    "product_catalog": {
      "mce_available": true,
      "mce_price": 89,
      "iu_available": true,
      "iu_business_price": 770,
      "iu_premium_economy_price": 399
    }
  },
  {
    "_scenario": "Used by: DEF321 (GUARDRAIL: Flight MCP returns 0 available seats)",
    "operat_flight_nbr": 555,
    "operat_airln_cd": "AA",
    "leg": 1,
    "leg_dep_dt": "2026-01-13",
    "schd_leg_dep_airprt_iata_cd": "MIA",
    "schd_leg_arvl_airprt_iata_cd": "JFK",
    "schd_leg_dep_lcl_tms": "11:00",
    "schd_leg_arvl_lcl_tms": "15:30",
    "equipment_model": "737-800",
    "distance": 1089,
    "local_bid_price": 85.00,
    "cabins": {
      "F": {
        "_note": "SOLD OUT - This is the key scenario differentiator!",
        "cabin_capacity": 16,
        "cabin_total_pax": 16,
        "cabin_ticketed_actual_pax": 16,
        "cabin_available": 0,
        "expected_load_factor": 1.0,
        "cabin_aadvantage_pax": 12,
        "cabin_total_revenue": 18500,
        "cabin_mileage_burn_rev": 3200,
        "cabin_iu_rev": 2100,
        "cabin_iu_miles_burn_rev": 420
      },
      "MCE": {
        "_note": "MCE SOLD OUT - guardrail scenario",
        "cabin_capacity": 30,
        "cabin_total_pax": 30,
        "cabin_ticketed_actual_pax": 30,
        "cabin_available": 0,
        "expected_load_factor": 1.0,
        "cabin_aadvantage_pax": 18,
        "cabin_total_revenue": 725,
        "cabin_mileage_burn_rev": 0
      },
      "Y": {
        "cabin_capacity": 114,
        "cabin_total_pax": 110,
        "cabin_ticketed_actual_pax": 110,
        "cabin_available": 4,
        "expected_load_factor": 0.96,
        "cabin_aadvantage_pax": 58,
        "cabin_total_revenue": 22800
      }
    },
    "product_catalog": {
      "mce_available": false,
      "mce_price": 25,
      "iu_available": false,
      "iu_business_price": 149,
      "iu_premium_economy_price": 0
    }
  }
]


================================================================================
FILE: data/ml_scores.json
================================================================================
{
  "description": "Simulated ML model P(buy) scores by product and price - In production, these come from the ML team's model",
  "scores": {
    "ABC123": {
      "_scenario": "EASY CHOICE - High confidence, clear Business EV winner",
      "pnr_locator": "ABC123",
      "customer_id": "CUST001",
      "flight_id": "AA2847",
      "model_version": "v2.1",
      "score_timestamp": "2026-01-11T10:00:00Z",
      "propensity_scores": {
        "IU_BUSINESS": {
          "price_points": {
            "299": { "p_buy": 0.45 },
            "249": { "p_buy": 0.58 },
            "199": { "p_buy": 0.72 },
            "149": { "p_buy": 0.82 }
          },
          "confidence": 0.85
        },
        "IU_PREMIUM_ECONOMY": {
          "price_points": {
            "179": { "p_buy": 0.55 },
            "149": { "p_buy": 0.68 },
            "129": { "p_buy": 0.78 }
          },
          "confidence": 0.82
        },
        "MCE": {
          "price_points": {
            "59": { "p_buy": 0.75 },
            "49": { "p_buy": 0.85 },
            "39": { "p_buy": 0.92 }
          },
          "confidence": 0.91
        }
      },
      "segment": "high_value_leisure",
      "price_sensitivity": "medium"
    },
    "XYZ789": {
      "_scenario": "CONFIDENCE TRADE-OFF: High Business EV ($165) but ONLY 50% ML confidence. MCE lower EV ($52) but 92% confidence. Agent must decide: trust uncertain prediction or play safe?",
      "pnr_locator": "XYZ789",
      "customer_id": "CUST002",
      "flight_id": "AA1234",
      "model_version": "v2.1",
      "score_timestamp": "2026-01-11T10:00:00Z",
      "propensity_scores": {
        "IU_BUSINESS": {
          "price_points": {
            "349": { "p_buy": 0.65 },
            "299": { "p_buy": 0.75 },
            "249": { "p_buy": 0.85 },
            "179": { "p_buy": 0.92 }
          },
          "confidence": 0.50,
          "_trade_off": "HIGH EV but LOW confidence - model is uncertain about this prediction!",
          "note": "New customer segment with limited training data - prediction unreliable"
        },
        "MCE": {
          "price_points": {
            "49": { "p_buy": 0.65 },
            "39": { "p_buy": 0.75 },
            "29": { "p_buy": 0.82 }
          },
          "confidence": 0.92,
          "_trade_off": "Lower EV but HIGH confidence - model is very sure about this prediction",
          "note": "Well-established pattern for this customer type"
        }
      },
      "segment": "new_business_segment",
      "price_sensitivity": "low"
    },
    "LMN456": {
      "_scenario": "RELATIONSHIP TRADE-OFF: High EV but customer had recent service issue. Push aggressive offer ($770) or nurture with gentler MCE offer?",
      "pnr_locator": "LMN456",
      "customer_id": "CUST003",
      "flight_id": "AA100",
      "model_version": "v2.1",
      "score_timestamp": "2026-01-11T10:00:00Z",
      "propensity_scores": {
        "IU_BUSINESS": {
          "price_points": {
            "870": { "p_buy": 0.72 },
            "820": { "p_buy": 0.78 },
            "770": { "p_buy": 0.85 },
            "720": { "p_buy": 0.89 }
          },
          "confidence": 0.95,
          "note": "Executive Platinum with high upgrade acceptance history"
        },
        "IU_PREMIUM_ECONOMY": {
          "price_points": {
            "499": { "p_buy": 0.35 },
            "449": { "p_buy": 0.42 },
            "399": { "p_buy": 0.50 }
          },
          "confidence": 0.80,
          "note": "Low PE interest - already in PE, prefers Business"
        },
        "MCE": {
          "price_points": {
            "89": { "p_buy": 0.10 }
          },
          "confidence": 0.70,
          "note": "Very low MCE interest - customer already in Premium Economy"
        }
      },
      "segment": "elite_business",
      "price_sensitivity": "low"
    },
    "DEF321": {
      "_scenario": "GUARDRAIL: INVENTORY - Good propensity BUT Flight MCP returns 0 seats. Agent blocked.",
      "pnr_locator": "DEF321",
      "customer_id": "CUST004",
      "flight_id": "AA555",
      "model_version": "v2.1",
      "score_timestamp": "2026-01-11T10:00:00Z",
      "propensity_scores": {
        "IU_BUSINESS": {
          "price_points": {
            "199": { "p_buy": 0.55 },
            "179": { "p_buy": 0.65 },
            "149": { "p_buy": 0.75 }
          },
          "confidence": 0.78,
          "note": "Good propensity BUT inventory is SOLD OUT"
        },
        "MCE": {
          "price_points": {
            "39": { "p_buy": 0.70 },
            "29": { "p_buy": 0.82 },
            "25": { "p_buy": 0.88 }
          },
          "confidence": 0.85,
          "note": "Good MCE propensity BUT MCE SOLD OUT"
        }
      },
      "segment": "mid_value_mixed",
      "price_sensitivity": "medium"
    },
    "GHI654": {
      "_scenario": "GUARDRAIL: CUSTOMER - Good propensity BUT Customer MCP returns suppression. Agent blocked.",
      "pnr_locator": "GHI654",
      "customer_id": "CUST005",
      "flight_id": "AA2847",
      "model_version": "v2.1",
      "score_timestamp": "2026-01-11T10:00:00Z",
      "propensity_scores": {
        "IU_BUSINESS": {
          "price_points": {
            "299": { "p_buy": 0.50 },
            "249": { "p_buy": 0.62 },
            "199": { "p_buy": 0.72 },
            "149": { "p_buy": 0.80 }
          },
          "confidence": 0.82,
          "note": "Good propensity BUT customer is SUPPRESSED due to complaint"
        },
        "IU_PREMIUM_ECONOMY": {
          "price_points": {
            "179": { "p_buy": 0.58 },
            "149": { "p_buy": 0.70 },
            "129": { "p_buy": 0.80 }
          },
          "confidence": 0.80
        },
        "MCE": {
          "price_points": {
            "59": { "p_buy": 0.72 },
            "49": { "p_buy": 0.82 },
            "39": { "p_buy": 0.90 }
          },
          "confidence": 0.88
        }
      },
      "segment": "mid_value_mixed",
      "price_sensitivity": "medium",
      "suppression_flag": true,
      "suppression_reason": "recent_complaint"
    },
    "JKL789": {
      "_scenario": "PRICE TRADE-OFF: 18% P(buy) at $199 vs 52% at $159. Agent must decide discount level.",
      "pnr_locator": "JKL789",
      "customer_id": "CUST006",
      "flight_id": "AA2847",
      "model_version": "v2.1",
      "score_timestamp": "2026-01-11T10:00:00Z",
      "propensity_scores": {
        "IU_BUSINESS": {
          "price_points": {
            "199": { "p_buy": 0.18 },
            "179": { "p_buy": 0.28 },
            "159": { "p_buy": 0.52 },
            "139": { "p_buy": 0.72 }
          },
          "confidence": 0.85,
          "note": "PRICE SENSITIVE: Only 18% at $199 but jumps to 52% at $159 (20% discount)"
        },
        "IU_PREMIUM_ECONOMY": {
          "price_points": {
            "129": { "p_buy": 0.22 },
            "109": { "p_buy": 0.38 },
            "99": { "p_buy": 0.55 }
          },
          "confidence": 0.82
        },
        "MCE": {
          "price_points": {
            "39": { "p_buy": 0.45 },
            "29": { "p_buy": 0.68 },
            "19": { "p_buy": 0.85 }
          },
          "confidence": 0.90,
          "note": "Strong MCE interest at low price points"
        }
      },
      "segment": "budget_leisure",
      "price_sensitivity": "high"
    }
  }
}


================================================================================
FILE: data/reservations.json
================================================================================
[
  {
    "_scenario": "EASY CHOICE - Business EV clearly wins (baseline)",
    "pnr_loctr_id": "ABC123",
    "lylty_acct_id": "1234567890",
    "operat_flight_nbr": 2847,
    "bkg_airln_iata_cd": "AA",
    "pnr_create_dt": "2026-01-05",
    "leg_dep_dt": "2026-01-15",
    "schd_seg_dep_lcl_tms": "2026-01-15T08:30:00",
    "schd_seg_arvl_lcl_tms": "2026-01-15T09:45:00",
    "point_of_origin_airprt_iata_cd": "DFW",
    "actl_leg_arvl_airprt_iata_cd": "LAX",
    "intl_trp_ind": 0,
    "seg_seq_id": 1,
    "od_seq_nbr": 1,
    "max_bkd_cabin_cd": "Y",
    "fare_class": "V",
    "flight_revenue_amt_curr_trip": 285,
    "yield_curr_trip": 0.12,
    "group_size": 1,
    "basic_economy_ind": 0,
    "cart_ind": 0,
    "aadv_business_ind": 0,
    "special_service_request_ind": 0,
    "great_circle_mile_distance": 1235,
    "total_travel_time_mins": 195,
    "hours_to_departure": 96,
    "checked_in": false
  },
  {
    "_scenario": "TRADE-OFF: CONFIDENCE - High EV but unreliable ML prediction",
    "pnr_loctr_id": "XYZ789",
    "lylty_acct_id": "9876543210",
    "operat_flight_nbr": 1234,
    "bkg_airln_iata_cd": "AA",
    "pnr_create_dt": "2026-01-02",
    "leg_dep_dt": "2026-01-14",
    "schd_seg_dep_lcl_tms": "2026-01-14T14:00:00",
    "schd_seg_arvl_lcl_tms": "2026-01-14T17:30:00",
    "point_of_origin_airprt_iata_cd": "ORD",
    "actl_leg_arvl_airprt_iata_cd": "MIA",
    "intl_trp_ind": 0,
    "seg_seq_id": 1,
    "od_seq_nbr": 1,
    "max_bkd_cabin_cd": "Y",
    "fare_class": "Y",
    "flight_revenue_amt_curr_trip": 412,
    "yield_curr_trip": 0.18,
    "group_size": 1,
    "basic_economy_ind": 0,
    "cart_ind": 1,
    "aadv_business_ind": 0,
    "special_service_request_ind": 0,
    "great_circle_mile_distance": 1197,
    "total_travel_time_mins": 210,
    "hours_to_departure": 72,
    "checked_in": false
  },
  {
    "_scenario": "TRADE-OFF: RELATIONSHIP - High-value customer with recent frustration",
    "pnr_loctr_id": "LMN456",
    "lylty_acct_id": "5555555555",
    "operat_flight_nbr": 100,
    "bkg_airln_iata_cd": "AA",
    "pnr_create_dt": "2025-12-20",
    "leg_dep_dt": "2026-01-16",
    "schd_seg_dep_lcl_tms": "2026-01-16T18:00:00",
    "schd_seg_arvl_lcl_tms": "2026-01-17T06:30:00",
    "point_of_origin_airprt_iata_cd": "LAX",
    "actl_leg_arvl_airprt_iata_cd": "LHR",
    "intl_trp_ind": 1,
    "seg_seq_id": 1,
    "od_seq_nbr": 1,
    "max_bkd_cabin_cd": "W",
    "fare_class": "W",
    "flight_revenue_amt_curr_trip": 1850,
    "yield_curr_trip": 0.22,
    "group_size": 1,
    "basic_economy_ind": 0,
    "cart_ind": 0,
    "aadv_business_ind": 0,
    "special_service_request_ind": 0,
    "great_circle_mile_distance": 5456,
    "total_travel_time_mins": 630,
    "hours_to_departure": 120,
    "checked_in": false
  },
  {
    "_scenario": "GUARDRAIL: INVENTORY - Agent blocked by Flight MCP (0 seats)",
    "pnr_loctr_id": "DEF321",
    "lylty_acct_id": "1111111111",
    "operat_flight_nbr": 555,
    "bkg_airln_iata_cd": "AA",
    "pnr_create_dt": "2026-01-10",
    "leg_dep_dt": "2026-01-13",
    "schd_seg_dep_lcl_tms": "2026-01-13T11:00:00",
    "schd_seg_arvl_lcl_tms": "2026-01-13T15:30:00",
    "point_of_origin_airprt_iata_cd": "MIA",
    "actl_leg_arvl_airprt_iata_cd": "JFK",
    "intl_trp_ind": 0,
    "seg_seq_id": 1,
    "od_seq_nbr": 1,
    "max_bkd_cabin_cd": "Y",
    "fare_class": "V",
    "flight_revenue_amt_curr_trip": 198,
    "yield_curr_trip": 0.09,
    "group_size": 1,
    "basic_economy_ind": 0,
    "cart_ind": 0,
    "aadv_business_ind": 0,
    "special_service_request_ind": 0,
    "great_circle_mile_distance": 1089,
    "total_travel_time_mins": 270,
    "hours_to_departure": 48,
    "checked_in": false
  },
  {
    "_scenario": "GUARDRAIL: CUSTOMER - Agent blocked by Customer MCP (suppressed)",
    "pnr_loctr_id": "GHI654",
    "lylty_acct_id": "2222222222",
    "operat_flight_nbr": 2847,
    "bkg_airln_iata_cd": "AA",
    "pnr_create_dt": "2026-01-03",
    "leg_dep_dt": "2026-01-15",
    "schd_seg_dep_lcl_tms": "2026-01-15T08:30:00",
    "schd_seg_arvl_lcl_tms": "2026-01-15T09:45:00",
    "point_of_origin_airprt_iata_cd": "DFW",
    "actl_leg_arvl_airprt_iata_cd": "LAX",
    "intl_trp_ind": 0,
    "seg_seq_id": 1,
    "od_seq_nbr": 1,
    "max_bkd_cabin_cd": "Y",
    "fare_class": "V",
    "flight_revenue_amt_curr_trip": 315,
    "yield_curr_trip": 0.13,
    "group_size": 1,
    "basic_economy_ind": 0,
    "cart_ind": 0,
    "aadv_business_ind": 0,
    "special_service_request_ind": 0,
    "great_circle_mile_distance": 1235,
    "total_travel_time_mins": 195,
    "hours_to_departure": 96,
    "checked_in": false
  },
  {
    "_scenario": "DEMO: AGENT GAP - Price sensitive + recent 3hr delay (show how to fix)",
    "pnr_loctr_id": "JKL789",
    "lylty_acct_id": "3333333333",
    "operat_flight_nbr": 2847,
    "bkg_airln_iata_cd": "AA",
    "pnr_create_dt": "2026-01-08",
    "leg_dep_dt": "2026-01-15",
    "schd_seg_dep_lcl_tms": "2026-01-15T08:30:00",
    "schd_seg_arvl_lcl_tms": "2026-01-15T09:45:00",
    "point_of_origin_airprt_iata_cd": "DFW",
    "actl_leg_arvl_airprt_iata_cd": "LAX",
    "intl_trp_ind": 0,
    "seg_seq_id": 1,
    "od_seq_nbr": 1,
    "max_bkd_cabin_cd": "Y",
    "fare_class": "M",
    "flight_revenue_amt_curr_trip": 198,
    "yield_curr_trip": 0.08,
    "group_size": 1,
    "basic_economy_ind": 0,
    "cart_ind": 0,
    "aadv_business_ind": 0,
    "special_service_request_ind": 0,
    "great_circle_mile_distance": 1235,
    "total_travel_time_mins": 195,
    "hours_to_departure": 84,
    "checked_in": false
  }
]


================================================================================
FILE: docker-compose.yml
================================================================================
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: api/Dockerfile
    ports:
      - "8000:8000"
    volumes:
      # Mount data for easy updates without rebuild
      - ./data:/app/data:ro
    environment:
      # LLM Configuration - set one of these for real LLM reasoning
      # If neither is set, demo runs in mock mode with simulated responses
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - TAILORED_OFFERS_LLM_PROVIDER=${TAILORED_OFFERS_LLM_PROVIDER:-}
      # Disable extra LLM calls for reasoning explanations (faster demo)
      - USE_DYNAMIC_REASONING=false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      api:
        condition: service_healthy
    environment:
      - VITE_API_URL=http://localhost:8000

# For development, you can also run:
# docker-compose up api  (just the API)
# Then run frontend locally with: cd frontend && npm run dev


================================================================================
FILE: docs/TO-as-ASL-Lighthouse.md
================================================================================
# Tailored Offers as ASL Lighthouse Project

**Proposal: Use TO to Validate ASL Patterns Before Platform Investment**

---

## Executive Summary

The ASL v1 proposal is architecturally sound but carries significant execution risk due to scope and timeline. We propose using **Tailored Offers (TO) as the lighthouse project** that validates ASL concepts in production before building the full platform.

**Key insight:** TO already implements core ASL patterns. Rather than building ASL first and porting TO to it, we should:
1. Ship TO with production-grade patterns
2. Extract what works into ASL v0.1
3. Onboard the next agent using those patterns
4. Iterate toward full ASL

This approach de-risks ASL by proving patterns with real business value first.

---

## TO Architecture Already Maps to ASL Concepts

| ASL Concept | TO Implementation | Status |
|-------------|-------------------|--------|
| **Domain Tool Gateway** | MCP Tools (`get_customer()`, `get_flight()`, `get_ml_scores()`) | ‚úÖ Working |
| **Agent Contract** | Structured output: `{decision, reasoning, data_used}` | ‚úÖ Working |
| **Typed Tools** | Tool schemas with validation | ‚úÖ Working |
| **Multi-runtime** | Workflows (4) + Agent (1) + LLM Call (1) | ‚úÖ Working |
| **Durable Workflows** | LangGraph now, Temporal planned | üîÑ In Progress |
| **Audit/Observability** | Reasoning traces, decision logging | üîÑ In Progress |
| **Policy Enforcement** | Suppression rules, consent checks | ‚úÖ Working |
| **Retrieval with Provenance** | Data sources tracked in reasoning | ‚úÖ Working |

**Bottom line:** TO is 60-70% of an ASL-compliant agent already.

---

## Architecture Alignment: TO ‚Üí ASL

### Current TO Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TO Offer Prototype                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Customer ‚îÇ  ‚îÇ Flight   ‚îÇ  ‚îÇ Offer    ‚îÇ  ‚îÇ Personal-‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Intel    ‚îÇ  ‚îÇ Optim    ‚îÇ  ‚îÇ Orchestr ‚îÇ  ‚îÇ ization  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ WORKFLOW ‚îÇ  ‚îÇ WORKFLOW ‚îÇ  ‚îÇ AGENT    ‚îÇ  ‚îÇ LLM CALL ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ       ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ           ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                            ‚îÇ                                ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                    ‚îÇ   MCP Tools   ‚îÇ ‚Üê ASL "Domain Tool     ‚îÇ
‚îÇ                    ‚îÇ   (Typed,     ‚îÇ   Gateway" pattern     ‚îÇ
‚îÇ                    ‚îÇ   Validated)  ‚îÇ                        ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                            ‚îÇ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ              ‚îÇ              ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Customer  ‚îÇ  ‚îÇ Flight    ‚îÇ  ‚îÇ ML Model  ‚îÇ
        ‚îÇ 360 / AADV‚îÇ  ‚îÇ Ops/DCSID ‚îÇ  ‚îÇ Serving   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ              ‚îÇ              ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    Systems of Record
```

### Mapped to ASL Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ASL Enterprise Control Plane                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇAgent        ‚îÇ ‚îÇPolicy       ‚îÇ ‚îÇModel        ‚îÇ            ‚îÇ
‚îÇ  ‚îÇRegistry     ‚îÇ ‚îÇAuthority    ‚îÇ ‚îÇGateway      ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ               ‚îÇ               ‚îÇ
          ‚ñº               ‚ñº               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              TO Agent (ASL-Compliant)                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Phase: Ingest ‚Üí Context ‚Üí Plan ‚Üí Act ‚Üí Verify ‚Üí Commit     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Offer Orchestration Agent                            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Returns: {decision, reasoning, data_used}            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Üê This IS the ASL "Agent Contract"                   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                            ‚îÇ                                ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                    ‚îÇ  Tool Router  ‚îÇ ‚Üê Central (future)     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Customer/PNR Domain Execution Cell                ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                    ‚îÇ Domain Tool   ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ Gateway       ‚îÇ ‚Üê MCP Tools today      ‚îÇ
‚îÇ                    ‚îÇ (MCP Server)  ‚îÇ                        ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                            ‚îÇ                                ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ              ‚ñº             ‚ñº             ‚ñº                  ‚îÇ
‚îÇ         Customer 360   Flight Ops    ML Models              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## What TO Validates for ASL

### 1. Domain Tool Gateway Pattern ‚úÖ

**ASL Concept:**
> "Domain Tool Gateway: typed tools, authz, rate limits, circuit breakers, idempotency, tool audit"

**TO Implementation:**
```python
# tools/data_tools.py - This IS a Domain Tool Gateway

def get_customer(customer_id: str) -> Dict[str, Any]:
    """
    Typed interface to Customer 360.
    - Schema validated (returns dict with known structure)
    - Abstracted from SOR (JSON today, API tomorrow)
    - Auditable (can add logging)
    """
    # Today: JSON file
    # Production: Customer 360 API call
    return _load_from_source("customers", customer_id)

def get_ml_scores(pnr: str) -> Dict[str, Any]:
    """
    Typed interface to ML Model Serving.
    - Schema validated
    - Can add rate limits, circuit breakers
    - Can add caching
    """
    return _call_ml_service(pnr)
```

**What TO proves:** MCP Tools pattern works. Just add rate limits + circuit breakers for production.

---

### 2. Agent Contract (Structured Output) ‚úÖ

**ASL Concept:**
> "All tools are typed, permissioned, audited"
> "Agent Contract: structured plan with steps, tools, required data"

**TO Implementation:**
```python
# Only Offer Orchestration is an "Agent" - returns structured contract

def analyze(self, state: AgentState) -> Dict[str, Any]:
    return {
        "decision": "OFFER_BUSINESS_CLASS",
        "reasoning": "Customer is price-sensitive but high-value...",
        "data_used": {
            "customer_profile": "AADV DB",
            "ml_scores": "Propensity Model v2",
            "inventory": "DCSID"
        },
        "confidence": 0.85,
        "alternatives_considered": ["MCE", "NO_OFFER"]
    }
```

**What TO proves:** Agent contract pattern works for complex decisions. Simple checks don't need it (workflows).

---

### 3. Multi-Runtime Support ‚úÖ

**ASL Concept:**
> "Interactive (K8s), Workflow (workflow engine), Event-driven (event bus), Batch"

**TO Implementation:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TO uses ONE agent contract across multiple runtimes:   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚ö° Workflows (4)     - Simple, deterministic           ‚îÇ
‚îÇ  üß† Agent (1)         - Complex, needs explainability   ‚îÇ
‚îÇ  ‚ú® LLM Call (1)      - Generative output               ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  All share the same State Object (LangGraph)            ‚îÇ
‚îÇ  All route through same MCP Tools                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**What TO proves:** You don't need different "agent types" - you need different COMPONENT types within one workflow.

---

### 4. Policy Enforcement ‚úÖ

**ASL Concept:**
> "Enterprise baseline (mandatory): PII/PCI rules, logging/redaction, disallowed actions"
> "Domain overlays (mandatory): domain-specific constraints"

**TO Implementation:**
```python
# Customer Intelligence Workflow - Policy checks

def analyze(self, state: AgentState) -> Dict[str, Any]:
    customer = state.get("customer_data", {})

    # Policy check 1: Suppression (enterprise baseline)
    if customer.get("is_suppressed"):
        return {"eligible": False, "reason": "Customer suppressed"}

    # Policy check 2: Consent (domain overlay)
    consent = customer.get("marketing_consent", {})
    if not consent.get("email") and not consent.get("push"):
        return {"eligible": False, "reason": "No marketing consent"}

    # Policy check 3: Recent complaint (domain overlay)
    if customer.get("complaint_reason"):
        return {"eligible": False, "reason": "Recent complaint"}

    return {"eligible": True}
```

**What TO proves:** Policy checks work at workflow level. Don't need complex "Policy Authority" for v1.

---

### 5. Retrieval with Provenance ‚úÖ

**ASL Concept:**
> "Domain Context/Retrieval: domain-indexes + row/field security + provenance"

**TO Implementation:**
```python
# Every agent decision includes data provenance

return {
    "decision": "OFFER_BUSINESS_CLASS",
    "data_used": {
        "get_customer()": "AADV DB ‚Üí Customer 360",
        "get_flight()": "DCSID ‚Üí Flight Operations",
        "get_ml_scores()": "ML Model Serving ‚Üí Propensity v2"
    },
    "reasoning": "Based on customer profile from AADV and ML scores..."
}
```

**What TO proves:** Provenance can be tracked in agent output. Don't need separate "retrieval service" for v1.

---

## Proposed Execution: TO-First Approach

### Phase 1: Ship TO with Production Patterns (Weeks 1-4)

**Goal:** Get TO working end-to-end with ASL-compatible patterns.

| Week | Deliverable |
|------|-------------|
| 1-2 | MCP Tools with proper error handling, timeouts, retries |
| 3-4 | Add structured audit logging to all tool calls |
| 3-4 | Add basic policy enforcement (suppression, consent) |

**Outcome:** TO is production-ready AND validates ASL tool gateway pattern.

### Phase 2: Add Observability & Governance (Weeks 5-8)

**Goal:** Add the "enterprise" pieces that TO needs anyway.

| Week | Deliverable |
|------|-------------|
| 5-6 | OpenTelemetry tracing for full request flow |
| 5-6 | Decision audit log (immutable, searchable) |
| 7-8 | Basic approval workflow for high-value offers |
| 7-8 | Kill switch (disable offers by segment/tier) |

**Outcome:** TO has enterprise-grade observability. Extract patterns for ASL.

### Phase 3: Extract ASL v0.1 (Weeks 9-10)

**Goal:** Generalize what worked in TO.

| Deliverable | Source |
|-------------|--------|
| Domain Tool Gateway template | TO's `tools/data_tools.py` |
| Agent Contract schema | TO's Offer Orchestration output |
| Audit event schema | TO's decision logs |
| Policy check patterns | TO's Customer Intelligence |

**Outcome:** ASL v0.1 is battle-tested, not theoretical.

### Phase 4: Second Lighthouse - IRROPS (Weeks 11-16)

**Goal:** Validate ASL patterns with a different domain.

- Use ASL v0.1 patterns
- Build IRROPS Domain Tool Gateway
- Implement durable workflow (Temporal) for rebooking
- Add approval workflow for high-risk actions

**Outcome:** ASL works for 2 domains. Now it's a platform.

---

## What TO Doesn't Need from ASL v1

Be honest about what's over-engineering for TO:

| ASL Component | TO Needs It? | Why/Why Not |
|---------------|--------------|-------------|
| Agent Registry | ‚ùå No | TO is one agent. Registry is for many. |
| Model Gateway | ‚ö†Ô∏è Maybe | Simple: just call OpenAI/Anthropic directly |
| Tool Router | ‚ùå No | TO only has one domain (Customer/PNR) |
| Identity Broker | ‚ö†Ô∏è Maybe | Service accounts work for now |
| Policy Authority | ‚ùå No | Hardcode policies in workflows for v1 |
| Approvals Service | ‚ö†Ô∏è Maybe | Simple Slack/email approval for v1 |
| PCI Controls | ‚ùå No | TO doesn't handle payments |
| Eval Gatekeeper | ‚ö†Ô∏è Maybe | Manual testing for v1 |

**Key insight:** TO needs ~30% of ASL. Build that 30% well.

---

## Risk Comparison

### Risk: Build ASL First, Then TO

```
Weeks 1-12: Build ASL platform
  ‚îú‚îÄ‚îÄ Risk: No real users validating design
  ‚îú‚îÄ‚îÄ Risk: Scope creep ("let's add X for future agents")
  ‚îú‚îÄ‚îÄ Risk: Integration surprises with real SORs
  ‚îî‚îÄ‚îÄ Risk: 12 weeks, nothing in production

Weeks 13-20: Port TO to ASL
  ‚îú‚îÄ‚îÄ Risk: ASL doesn't fit TO's actual needs
  ‚îú‚îÄ‚îÄ Risk: Rework required
  ‚îî‚îÄ‚îÄ Risk: Still no business value delivered
```

### Risk: TO First, Extract ASL

```
Weeks 1-4: Ship TO with good patterns
  ‚îú‚îÄ‚îÄ Benefit: Real users, real feedback
  ‚îú‚îÄ‚îÄ Benefit: Validates tool gateway pattern
  ‚îî‚îÄ‚îÄ Benefit: Business value delivered

Weeks 5-8: Add enterprise features to TO
  ‚îú‚îÄ‚îÄ Benefit: Only build what TO actually needs
  ‚îî‚îÄ‚îÄ Benefit: Patterns proven before generalizing

Weeks 9-12: Extract ASL v0.1 from TO
  ‚îú‚îÄ‚îÄ Benefit: ASL is battle-tested
  ‚îú‚îÄ‚îÄ Benefit: Second agent (IRROPS) validates generalization
  ‚îî‚îÄ‚îÄ Benefit: Platform built from reality, not theory
```

---

## Recommendation to Leadership

### The Ask

> "Fund TO as the ASL lighthouse project. We'll deliver business value
> (tailored offers) while simultaneously validating the ASL architecture.
>
> After TO ships, we'll extract the patterns that worked into ASL v0.1,
> then use IRROPS as the second validation before full platform investment."

### The Commitment

| Milestone | Timeline | Outcome |
|-----------|----------|---------|
| TO Prototype | Week 4 | Working demo, validates tool gateway |
| TO Production-Ready | Week 8 | Observability, audit, policy checks |
| ASL v0.1 Extracted | Week 10 | Reusable patterns documented |
| IRROPS Proof Point | Week 16 | ASL validated across 2 domains |
| ASL v1 Platform | Week 24+ | Full platform, justified by proven value |

### The Trade-off

**We're trading:** Theoretical completeness of ASL v1 in 12 weeks

**For:** Proven patterns, real business value, lower risk

---

## Appendix: TO Component ‚Üí ASL Mapping

```
TO Component                    ASL Equivalent
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
tools/data_tools.py          ‚Üí Domain Tool Gateway
                               (Customer/PNR Execution Cell)

agents/offer_orchestration.py ‚Üí Agent Runtime
                               (implements Agent Contract)

agents/workflow.py           ‚Üí Central Agent Runtime
                               (state machine: ingest‚Üíact‚Üíverify)

LangGraph StateGraph         ‚Üí Agent Run State Machine
                               (shared state, conditional routing)

Reasoning traces             ‚Üí Observability/Audit Sink
                               (immutable decision log)

Suppression/consent checks   ‚Üí Policy Authority
                               (enterprise baseline + domain overlay)

MCP tool schemas             ‚Üí Tool Manifest
                               (typed, validated interfaces)

frontend/ SSE streaming      ‚Üí Agent Runtime streaming
                               (real-time status updates)
```

---

## Next Steps

1. **Align with ASL team** - Share this mapping, get buy-in on TO as lighthouse
2. **Identify gaps** - What does TO need that isn't built yet?
3. **Prioritize** - Which ASL patterns should TO implement first?
4. **Ship** - Get TO to production, prove the patterns work

---

*Document prepared for American Airlines AI Engineering*
*TO Offer Prototype Team*


================================================================================
FILE: frontend/Dockerfile
================================================================================
# Frontend Dockerfile - Multi-stage build
FROM node:20-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci

# Copy source code
COPY . .

# Build the application
RUN npm run build

# Production stage - serve with nginx
FROM nginx:alpine

# Copy built assets
COPY --from=builder /app/dist /usr/share/nginx/html

# Copy nginx config for SPA routing
RUN echo 'server { \
    listen 80; \
    location / { \
        root /usr/share/nginx/html; \
        try_files $uri $uri/ /index.html; \
    } \
    location /api { \
        proxy_pass http://api:8000; \
    } \
}' > /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]


================================================================================
FILE: frontend/README.md
================================================================================
# React + TypeScript + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) (or [oxc](https://oxc.rs) when used in [rolldown-vite](https://vite.dev/guide/rolldown)) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## React Compiler

The React Compiler is not enabled on this template because of its impact on dev & build performances. To add it, see [this documentation](https://react.dev/learn/react-compiler/installation).

## Expanding the ESLint configuration

If you are developing a production application, we recommend updating the configuration to enable type-aware lint rules:

```js
export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      // Other configs...

      // Remove tseslint.configs.recommended and replace with this
      tseslint.configs.recommendedTypeChecked,
      // Alternatively, use this for stricter rules
      tseslint.configs.strictTypeChecked,
      // Optionally, add this for stylistic rules
      tseslint.configs.stylisticTypeChecked,

      // Other configs...
    ],
    languageOptions: {
      parserOptions: {
        project: ['./tsconfig.node.json', './tsconfig.app.json'],
        tsconfigRootDir: import.meta.dirname,
      },
      // other options...
    },
  },
])
```

You can also install [eslint-plugin-react-x](https://github.com/Rel1cx/eslint-react/tree/main/packages/plugins/eslint-plugin-react-x) and [eslint-plugin-react-dom](https://github.com/Rel1cx/eslint-react/tree/main/packages/plugins/eslint-plugin-react-dom) for React-specific lint rules:

```js
// eslint.config.js
import reactX from 'eslint-plugin-react-x'
import reactDom from 'eslint-plugin-react-dom'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      // Other configs...
      // Enable lint rules for React
      reactX.configs['recommended-typescript'],
      // Enable lint rules for React DOM
      reactDom.configs.recommended,
    ],
    languageOptions: {
      parserOptions: {
        project: ['./tsconfig.node.json', './tsconfig.app.json'],
        tsconfigRootDir: import.meta.dirname,
      },
      // other options...
    },
  },
])
```


================================================================================
FILE: frontend/dist/assets/index-CF3sXGZT.js
================================================================================
(function(){const J=document.createElement("link").relList;if(J&&J.supports&&J.supports("modulepreload"))return;for(const R of document.querySelectorAll('link[rel="modulepreload"]'))o(R);new MutationObserver(R=>{for(const U of R)if(U.type==="childList")for(const w of U.addedNodes)w.tagName==="LINK"&&w.rel==="modulepreload"&&o(w)}).observe(document,{childList:!0,subtree:!0});function D(R){const U={};return R.integrity&&(U.integrity=R.integrity),R.referrerPolicy&&(U.referrerPolicy=R.referrerPolicy),R.crossOrigin==="use-credentials"?U.credentials="include":R.crossOrigin==="anonymous"?U.credentials="omit":U.credentials="same-origin",U}function o(R){if(R.ep)return;R.ep=!0;const U=D(R);fetch(R.href,U)}})();var pc={exports:{}},qn={};var Ed;function Im(){if(Ed)return qn;Ed=1;var j=Symbol.for("react.transitional.element"),J=Symbol.for("react.fragment");function D(o,R,U){var w=null;if(U!==void 0&&(w=""+U),R.key!==void 0&&(w=""+R.key),"key"in R){U={};for(var te in R)te!=="key"&&(U[te]=R[te])}else U=R;return R=U.ref,{$$typeof:j,type:o,key:w,ref:R!==void 0?R:null,props:U}}return qn.Fragment=J,qn.jsx=D,qn.jsxs=D,qn}var Ad;function eh(){return Ad||(Ad=1,pc.exports=Im()),pc.exports}var s=eh(),gc={exports:{}},ie={};var Td;function th(){if(Td)return ie;Td=1;var j=Symbol.for("react.transitional.element"),J=Symbol.for("react.portal"),D=Symbol.for("react.fragment"),o=Symbol.for("react.strict_mode"),R=Symbol.for("react.profiler"),U=Symbol.for("react.consumer"),w=Symbol.for("react.context"),te=Symbol.for("react.forward_ref"),_=Symbol.for("react.suspense"),v=Symbol.for("react.memo"),z=Symbol.for("react.lazy"),M=Symbol.for("react.activity"),k=Symbol.iterator;function Ne(f){return f===null||typeof f!="object"?null:(f=k&&f[k]||f["@@iterator"],typeof f=="function"?f:null)}var je={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},ge=Object.assign,Q={};function oe(f,E,C){this.props=f,this.context=E,this.refs=Q,this.updater=C||je}oe.prototype.isReactComponent={},oe.prototype.setState=function(f,E){if(typeof f!="object"&&typeof f!="function"&&f!=null)throw Error("takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,f,E,"setState")},oe.prototype.forceUpdate=function(f){this.updater.enqueueForceUpdate(this,f,"forceUpdate")};function K(){}K.prototype=oe.prototype;function ne(f,E,C){this.props=f,this.context=E,this.refs=Q,this.updater=C||je}var ee=ne.prototype=new K;ee.constructor=ne,ge(ee,oe.prototype),ee.isPureReactComponent=!0;var $=Array.isArray;function H(){}var Y={H:null,A:null,T:null,S:null},ae=Object.prototype.hasOwnProperty;function Oe(f,E,C){var B=C.ref;return{$$typeof:j,type:f,key:E,ref:B!==void 0?B:null,props:C}}function Qe(f,E){return Oe(f.type,E,f.props)}function Ye(f){return typeof f=="object"&&f!==null&&f.$$typeof===j}function Se(f){var E={"=":"=0",":":"=2"};return"$"+f.replace(/[=:]/g,function(C){return E[C]})}var Pe=/\/+/g;function Je(f,E){return typeof f=="object"&&f!==null&&f.key!=null?Se(""+f.key):E.toString(36)}function et(f){switch(f.status){case"fulfilled":return f.value;case"rejected":throw f.reason;default:switch(typeof f.status=="string"?f.then(H,H):(f.status="pending",f.then(function(E){f.status==="pending"&&(f.status="fulfilled",f.value=E)},function(E){f.status==="pending"&&(f.status="rejected",f.reason=E)})),f.status){case"fulfilled":return f.value;case"rejected":throw f.reason}}throw f}function h(f,E,C,B,X){var se=typeof f;(se==="undefined"||se==="boolean")&&(f=null);var ve=!1;if(f===null)ve=!0;else switch(se){case"bigint":case"string":case"number":ve=!0;break;case"object":switch(f.$$typeof){case j:case J:ve=!0;break;case z:return ve=f._init,h(ve(f._payload),E,C,B,X)}}if(ve)return X=X(f),ve=B===""?"."+Je(f,0):B,$(X)?(C="",ve!=null&&(C=ve.replace(Pe,"$&/")+"/"),h(X,E,C,"",function(_t){return _t})):X!=null&&(Ye(X)&&(X=Qe(X,C+(X.key==null||f&&f.key===X.key?"":(""+X.key).replace(Pe,"$&/")+"/")+ve)),E.push(X)),1;ve=0;var Ve=B===""?".":B+":";if($(f))for(var we=0;we<f.length;we++)B=f[we],se=Ve+Je(B,we),ve+=h(B,E,C,se,X);else if(we=Ne(f),typeof we=="function")for(f=we.call(f),we=0;!(B=f.next()).done;)B=B.value,se=Ve+Je(B,we++),ve+=h(B,E,C,se,X);else if(se==="object"){if(typeof f.then=="function")return h(et(f),E,C,B,X);throw E=String(f),Error("Objects are not valid as a React child (found: "+(E==="[object Object]"?"object with keys {"+Object.keys(f).join(", ")+"}":E)+"). If you meant to render a collection of children, use an array instead.")}return ve}function O(f,E,C){if(f==null)return f;var B=[],X=0;return h(f,B,"","",function(se){return E.call(C,se,X++)}),B}function L(f){if(f._status===-1){var E=f._result;E=E(),E.then(function(C){(f._status===0||f._status===-1)&&(f._status=1,f._result=C)},function(C){(f._status===0||f._status===-1)&&(f._status=2,f._result=C)}),f._status===-1&&(f._status=0,f._result=E)}if(f._status===1)return f._result.default;throw f._result}var F=typeof reportError=="function"?reportError:function(f){if(typeof window=="object"&&typeof window.ErrorEvent=="function"){var E=new window.ErrorEvent("error",{bubbles:!0,cancelable:!0,message:typeof f=="object"&&f!==null&&typeof f.message=="string"?String(f.message):String(f),error:f});if(!window.dispatchEvent(E))return}else if(typeof process=="object"&&typeof process.emit=="function"){process.emit("uncaughtException",f);return}console.error(f)},le={map:O,forEach:function(f,E,C){O(f,function(){E.apply(this,arguments)},C)},count:function(f){var E=0;return O(f,function(){E++}),E},toArray:function(f){return O(f,function(E){return E})||[]},only:function(f){if(!Ye(f))throw Error("React.Children.only expected to receive a single React element child.");return f}};return ie.Activity=M,ie.Children=le,ie.Component=oe,ie.Fragment=D,ie.Profiler=R,ie.PureComponent=ne,ie.StrictMode=o,ie.Suspense=_,ie.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE=Y,ie.__COMPILER_RUNTIME={__proto__:null,c:function(f){return Y.H.useMemoCache(f)}},ie.cache=function(f){return function(){return f.apply(null,arguments)}},ie.cacheSignal=function(){return null},ie.cloneElement=function(f,E,C){if(f==null)throw Error("The argument must be a React element, but you passed "+f+".");var B=ge({},f.props),X=f.key;if(E!=null)for(se in E.key!==void 0&&(X=""+E.key),E)!ae.call(E,se)||se==="key"||se==="__self"||se==="__source"||se==="ref"&&E.ref===void 0||(B[se]=E[se]);var se=arguments.length-2;if(se===1)B.children=C;else if(1<se){for(var ve=Array(se),Ve=0;Ve<se;Ve++)ve[Ve]=arguments[Ve+2];B.children=ve}return Oe(f.type,X,B)},ie.createContext=function(f){return f={$$typeof:w,_currentValue:f,_currentValue2:f,_threadCount:0,Provider:null,Consumer:null},f.Provider=f,f.Consumer={$$typeof:U,_context:f},f},ie.createElement=function(f,E,C){var B,X={},se=null;if(E!=null)for(B in E.key!==void 0&&(se=""+E.key),E)ae.call(E,B)&&B!=="key"&&B!=="__self"&&B!=="__source"&&(X[B]=E[B]);var ve=arguments.length-2;if(ve===1)X.children=C;else if(1<ve){for(var Ve=Array(ve),we=0;we<ve;we++)Ve[we]=arguments[we+2];X.children=Ve}if(f&&f.defaultProps)for(B in ve=f.defaultProps,ve)X[B]===void 0&&(X[B]=ve[B]);return Oe(f,se,X)},ie.createRef=function(){return{current:null}},ie.forwardRef=function(f){return{$$typeof:te,render:f}},ie.isValidElement=Ye,ie.lazy=function(f){return{$$typeof:z,_payload:{_status:-1,_result:f},_init:L}},ie.memo=function(f,E){return{$$typeof:v,type:f,compare:E===void 0?null:E}},ie.startTransition=function(f){var E=Y.T,C={};Y.T=C;try{var B=f(),X=Y.S;X!==null&&X(C,B),typeof B=="object"&&B!==null&&typeof B.then=="function"&&B.then(H,F)}catch(se){F(se)}finally{E!==null&&C.types!==null&&(E.types=C.types),Y.T=E}},ie.unstable_useCacheRefresh=function(){return Y.H.useCacheRefresh()},ie.use=function(f){return Y.H.use(f)},ie.useActionState=function(f,E,C){return Y.H.useActionState(f,E,C)},ie.useCallback=function(f,E){return Y.H.useCallback(f,E)},ie.useContext=function(f){return Y.H.useContext(f)},ie.useDebugValue=function(){},ie.useDeferredValue=function(f,E){return Y.H.useDeferredValue(f,E)},ie.useEffect=function(f,E){return Y.H.useEffect(f,E)},ie.useEffectEvent=function(f){return Y.H.useEffectEvent(f)},ie.useId=function(){return Y.H.useId()},ie.useImperativeHandle=function(f,E,C){return Y.H.useImperativeHandle(f,E,C)},ie.useInsertionEffect=function(f,E){return Y.H.useInsertionEffect(f,E)},ie.useLayoutEffect=function(f,E){return Y.H.useLayoutEffect(f,E)},ie.useMemo=function(f,E){return Y.H.useMemo(f,E)},ie.useOptimistic=function(f,E){return Y.H.useOptimistic(f,E)},ie.useReducer=function(f,E,C){return Y.H.useReducer(f,E,C)},ie.useRef=function(f){return Y.H.useRef(f)},ie.useState=function(f){return Y.H.useState(f)},ie.useSyncExternalStore=function(f,E,C){return Y.H.useSyncExternalStore(f,E,C)},ie.useTransition=function(){return Y.H.useTransition()},ie.version="19.2.3",ie}var _d;function Ec(){return _d||(_d=1,gc.exports=th()),gc.exports}var N=Ec(),vc={exports:{}},Yn={},yc={exports:{}},bc={};var zd;function lh(){return zd||(zd=1,(function(j){function J(h,O){var L=h.length;h.push(O);e:for(;0<L;){var F=L-1>>>1,le=h[F];if(0<R(le,O))h[F]=O,h[L]=le,L=F;else break e}}function D(h){return h.length===0?null:h[0]}function o(h){if(h.length===0)return null;var O=h[0],L=h.pop();if(L!==O){h[0]=L;e:for(var F=0,le=h.length,f=le>>>1;F<f;){var E=2*(F+1)-1,C=h[E],B=E+1,X=h[B];if(0>R(C,L))B<le&&0>R(X,C)?(h[F]=X,h[B]=L,F=B):(h[F]=C,h[E]=L,F=E);else if(B<le&&0>R(X,L))h[F]=X,h[B]=L,F=B;else break e}}return O}function R(h,O){var L=h.sortIndex-O.sortIndex;return L!==0?L:h.id-O.id}if(j.unstable_now=void 0,typeof performance=="object"&&typeof performance.now=="function"){var U=performance;j.unstable_now=function(){return U.now()}}else{var w=Date,te=w.now();j.unstable_now=function(){return w.now()-te}}var _=[],v=[],z=1,M=null,k=3,Ne=!1,je=!1,ge=!1,Q=!1,oe=typeof setTimeout=="function"?setTimeout:null,K=typeof clearTimeout=="function"?clearTimeout:null,ne=typeof setImmediate<"u"?setImmediate:null;function ee(h){for(var O=D(v);O!==null;){if(O.callback===null)o(v);else if(O.startTime<=h)o(v),O.sortIndex=O.expirationTime,J(_,O);else break;O=D(v)}}function $(h){if(ge=!1,ee(h),!je)if(D(_)!==null)je=!0,H||(H=!0,Se());else{var O=D(v);O!==null&&et($,O.startTime-h)}}var H=!1,Y=-1,ae=5,Oe=-1;function Qe(){return Q?!0:!(j.unstable_now()-Oe<ae)}function Ye(){if(Q=!1,H){var h=j.unstable_now();Oe=h;var O=!0;try{e:{je=!1,ge&&(ge=!1,K(Y),Y=-1),Ne=!0;var L=k;try{t:{for(ee(h),M=D(_);M!==null&&!(M.expirationTime>h&&Qe());){var F=M.callback;if(typeof F=="function"){M.callback=null,k=M.priorityLevel;var le=F(M.expirationTime<=h);if(h=j.unstable_now(),typeof le=="function"){M.callback=le,ee(h),O=!0;break t}M===D(_)&&o(_),ee(h)}else o(_);M=D(_)}if(M!==null)O=!0;else{var f=D(v);f!==null&&et($,f.startTime-h),O=!1}}break e}finally{M=null,k=L,Ne=!1}O=void 0}}finally{O?Se():H=!1}}}var Se;if(typeof ne=="function")Se=function(){ne(Ye)};else if(typeof MessageChannel<"u"){var Pe=new MessageChannel,Je=Pe.port2;Pe.port1.onmessage=Ye,Se=function(){Je.postMessage(null)}}else Se=function(){oe(Ye,0)};function et(h,O){Y=oe(function(){h(j.unstable_now())},O)}j.unstable_IdlePriority=5,j.unstable_ImmediatePriority=1,j.unstable_LowPriority=4,j.unstable_NormalPriority=3,j.unstable_Profiling=null,j.unstable_UserBlockingPriority=2,j.unstable_cancelCallback=function(h){h.callback=null},j.unstable_forceFrameRate=function(h){0>h||125<h?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):ae=0<h?Math.floor(1e3/h):5},j.unstable_getCurrentPriorityLevel=function(){return k},j.unstable_next=function(h){switch(k){case 1:case 2:case 3:var O=3;break;default:O=k}var L=k;k=O;try{return h()}finally{k=L}},j.unstable_requestPaint=function(){Q=!0},j.unstable_runWithPriority=function(h,O){switch(h){case 1:case 2:case 3:case 4:case 5:break;default:h=3}var L=k;k=h;try{return O()}finally{k=L}},j.unstable_scheduleCallback=function(h,O,L){var F=j.unstable_now();switch(typeof L=="object"&&L!==null?(L=L.delay,L=typeof L=="number"&&0<L?F+L:F):L=F,h){case 1:var le=-1;break;case 2:le=250;break;case 5:le=1073741823;break;case 4:le=1e4;break;default:le=5e3}return le=L+le,h={id:z++,callback:O,priorityLevel:h,startTime:L,expirationTime:le,sortIndex:-1},L>F?(h.sortIndex=L,J(v,h),D(_)===null&&h===D(v)&&(ge?(K(Y),Y=-1):ge=!0,et($,L-F))):(h.sortIndex=le,J(_,h),je||Ne||(je=!0,H||(H=!0,Se()))),h},j.unstable_shouldYield=Qe,j.unstable_wrapCallback=function(h){var O=k;return function(){var L=k;k=O;try{return h.apply(this,arguments)}finally{k=L}}}})(bc)),bc}var Od;function ah(){return Od||(Od=1,yc.exports=lh()),yc.exports}var jc={exports:{}},ft={};var Md;function nh(){if(Md)return ft;Md=1;var j=Ec();function J(_){var v="https://react.dev/errors/"+_;if(1<arguments.length){v+="?args[]="+encodeURIComponent(arguments[1]);for(var z=2;z<arguments.length;z++)v+="&args[]="+encodeURIComponent(arguments[z])}return"Minified React error #"+_+"; visit "+v+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}function D(){}var o={d:{f:D,r:function(){throw Error(J(522))},D,C:D,L:D,m:D,X:D,S:D,M:D},p:0,findDOMNode:null},R=Symbol.for("react.portal");function U(_,v,z){var M=3<arguments.length&&arguments[3]!==void 0?arguments[3]:null;return{$$typeof:R,key:M==null?null:""+M,children:_,containerInfo:v,implementation:z}}var w=j.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE;function te(_,v){if(_==="font")return"";if(typeof v=="string")return v==="use-credentials"?v:""}return ft.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE=o,ft.createPortal=function(_,v){var z=2<arguments.length&&arguments[2]!==void 0?arguments[2]:null;if(!v||v.nodeType!==1&&v.nodeType!==9&&v.nodeType!==11)throw Error(J(299));return U(_,v,null,z)},ft.flushSync=function(_){var v=w.T,z=o.p;try{if(w.T=null,o.p=2,_)return _()}finally{w.T=v,o.p=z,o.d.f()}},ft.preconnect=function(_,v){typeof _=="string"&&(v?(v=v.crossOrigin,v=typeof v=="string"?v==="use-credentials"?v:"":void 0):v=null,o.d.C(_,v))},ft.prefetchDNS=function(_){typeof _=="string"&&o.d.D(_)},ft.preinit=function(_,v){if(typeof _=="string"&&v&&typeof v.as=="string"){var z=v.as,M=te(z,v.crossOrigin),k=typeof v.integrity=="string"?v.integrity:void 0,Ne=typeof v.fetchPriority=="string"?v.fetchPriority:void 0;z==="style"?o.d.S(_,typeof v.precedence=="string"?v.precedence:void 0,{crossOrigin:M,integrity:k,fetchPriority:Ne}):z==="script"&&o.d.X(_,{crossOrigin:M,integrity:k,fetchPriority:Ne,nonce:typeof v.nonce=="string"?v.nonce:void 0})}},ft.preinitModule=function(_,v){if(typeof _=="string")if(typeof v=="object"&&v!==null){if(v.as==null||v.as==="script"){var z=te(v.as,v.crossOrigin);o.d.M(_,{crossOrigin:z,integrity:typeof v.integrity=="string"?v.integrity:void 0,nonce:typeof v.nonce=="string"?v.nonce:void 0})}}else v==null&&o.d.M(_)},ft.preload=function(_,v){if(typeof _=="string"&&typeof v=="object"&&v!==null&&typeof v.as=="string"){var z=v.as,M=te(z,v.crossOrigin);o.d.L(_,z,{crossOrigin:M,integrity:typeof v.integrity=="string"?v.integrity:void 0,nonce:typeof v.nonce=="string"?v.nonce:void 0,type:typeof v.type=="string"?v.type:void 0,fetchPriority:typeof v.fetchPriority=="string"?v.fetchPriority:void 0,referrerPolicy:typeof v.referrerPolicy=="string"?v.referrerPolicy:void 0,imageSrcSet:typeof v.imageSrcSet=="string"?v.imageSrcSet:void 0,imageSizes:typeof v.imageSizes=="string"?v.imageSizes:void 0,media:typeof v.media=="string"?v.media:void 0})}},ft.preloadModule=function(_,v){if(typeof _=="string")if(v){var z=te(v.as,v.crossOrigin);o.d.m(_,{as:typeof v.as=="string"&&v.as!=="script"?v.as:void 0,crossOrigin:z,integrity:typeof v.integrity=="string"?v.integrity:void 0})}else o.d.m(_)},ft.requestFormReset=function(_){o.d.r(_)},ft.unstable_batchedUpdates=function(_,v){return _(v)},ft.useFormState=function(_,v,z){return w.H.useFormState(_,v,z)},ft.useFormStatus=function(){return w.H.useHostTransitionStatus()},ft.version="19.2.3",ft}var Dd;function ih(){if(Dd)return jc.exports;Dd=1;function j(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(j)}catch(J){console.error(J)}}return j(),jc.exports=nh(),jc.exports}var Cd;function sh(){if(Cd)return Yn;Cd=1;var j=ah(),J=Ec(),D=ih();function o(e){var t="https://react.dev/errors/"+e;if(1<arguments.length){t+="?args[]="+encodeURIComponent(arguments[1]);for(var l=2;l<arguments.length;l++)t+="&args[]="+encodeURIComponent(arguments[l])}return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}function R(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11)}function U(e){var t=e,l=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do t=e,(t.flags&4098)!==0&&(l=t.return),e=t.return;while(e)}return t.tag===3?l:null}function w(e){if(e.tag===13){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function te(e){if(e.tag===31){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function _(e){if(U(e)!==e)throw Error(o(188))}function v(e){var t=e.alternate;if(!t){if(t=U(e),t===null)throw Error(o(188));return t!==e?null:e}for(var l=e,a=t;;){var n=l.return;if(n===null)break;var i=n.alternate;if(i===null){if(a=n.return,a!==null){l=a;continue}break}if(n.child===i.child){for(i=n.child;i;){if(i===l)return _(n),e;if(i===a)return _(n),t;i=i.sibling}throw Error(o(188))}if(l.return!==a.return)l=n,a=i;else{for(var u=!1,c=n.child;c;){if(c===l){u=!0,l=n,a=i;break}if(c===a){u=!0,a=n,l=i;break}c=c.sibling}if(!u){for(c=i.child;c;){if(c===l){u=!0,l=i,a=n;break}if(c===a){u=!0,a=i,l=n;break}c=c.sibling}if(!u)throw Error(o(189))}}if(l.alternate!==a)throw Error(o(190))}if(l.tag!==3)throw Error(o(188));return l.stateNode.current===l?e:t}function z(e){var t=e.tag;if(t===5||t===26||t===27||t===6)return e;for(e=e.child;e!==null;){if(t=z(e),t!==null)return t;e=e.sibling}return null}var M=Object.assign,k=Symbol.for("react.element"),Ne=Symbol.for("react.transitional.element"),je=Symbol.for("react.portal"),ge=Symbol.for("react.fragment"),Q=Symbol.for("react.strict_mode"),oe=Symbol.for("react.profiler"),K=Symbol.for("react.consumer"),ne=Symbol.for("react.context"),ee=Symbol.for("react.forward_ref"),$=Symbol.for("react.suspense"),H=Symbol.for("react.suspense_list"),Y=Symbol.for("react.memo"),ae=Symbol.for("react.lazy"),Oe=Symbol.for("react.activity"),Qe=Symbol.for("react.memo_cache_sentinel"),Ye=Symbol.iterator;function Se(e){return e===null||typeof e!="object"?null:(e=Ye&&e[Ye]||e["@@iterator"],typeof e=="function"?e:null)}var Pe=Symbol.for("react.client.reference");function Je(e){if(e==null)return null;if(typeof e=="function")return e.$$typeof===Pe?null:e.displayName||e.name||null;if(typeof e=="string")return e;switch(e){case ge:return"Fragment";case oe:return"Profiler";case Q:return"StrictMode";case $:return"Suspense";case H:return"SuspenseList";case Oe:return"Activity"}if(typeof e=="object")switch(e.$$typeof){case je:return"Portal";case ne:return e.displayName||"Context";case K:return(e._context.displayName||"Context")+".Consumer";case ee:var t=e.render;return e=e.displayName,e||(e=t.displayName||t.name||"",e=e!==""?"ForwardRef("+e+")":"ForwardRef"),e;case Y:return t=e.displayName||null,t!==null?t:Je(e.type)||"Memo";case ae:t=e._payload,e=e._init;try{return Je(e(t))}catch{}}return null}var et=Array.isArray,h=J.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,O=D.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,L={pending:!1,data:null,method:null,action:null},F=[],le=-1;function f(e){return{current:e}}function E(e){0>le||(e.current=F[le],F[le]=null,le--)}function C(e,t){le++,F[le]=e.current,e.current=t}var B=f(null),X=f(null),se=f(null),ve=f(null);function Ve(e,t){switch(C(se,t),C(X,e),C(B,null),t.nodeType){case 9:case 11:e=(e=t.documentElement)&&(e=e.namespaceURI)?Jo(e):0;break;default:if(e=t.tagName,t=t.namespaceURI)t=Jo(t),e=ko(t,e);else switch(e){case"svg":e=1;break;case"math":e=2;break;default:e=0}}E(B),C(B,e)}function we(){E(B),E(X),E(se)}function _t(e){e.memoizedState!==null&&C(ve,e);var t=B.current,l=ko(t,e.type);t!==l&&(C(X,e),C(B,l))}function zt(e){X.current===e&&(E(B),E(X)),ve.current===e&&(E(ve),wn._currentValue=L)}var qt,Yl;function rt(e){if(qt===void 0)try{throw Error()}catch(l){var t=l.stack.trim().match(/\n( *(at )?)/);qt=t&&t[1]||"",Yl=-1<l.stack.indexOf(`
    at`)?" (<anonymous>)":-1<l.stack.indexOf("@")?"@unknown:0:0":""}return`
`+qt+e+Yl}var kt=!1;function Yt(e,t){if(!e||kt)return"";kt=!0;var l=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{var a={DetermineComponentFrameRoot:function(){try{if(t){var T=function(){throw Error()};if(Object.defineProperty(T.prototype,"props",{set:function(){throw Error()}}),typeof Reflect=="object"&&Reflect.construct){try{Reflect.construct(T,[])}catch(b){var g=b}Reflect.construct(e,[],T)}else{try{T.call()}catch(b){g=b}e.call(T.prototype)}}else{try{throw Error()}catch(b){g=b}(T=e())&&typeof T.catch=="function"&&T.catch(function(){})}}catch(b){if(b&&g&&typeof b.stack=="string")return[b.stack,g.stack]}return[null,null]}};a.DetermineComponentFrameRoot.displayName="DetermineComponentFrameRoot";var n=Object.getOwnPropertyDescriptor(a.DetermineComponentFrameRoot,"name");n&&n.configurable&&Object.defineProperty(a.DetermineComponentFrameRoot,"name",{value:"DetermineComponentFrameRoot"});var i=a.DetermineComponentFrameRoot(),u=i[0],c=i[1];if(u&&c){var r=u.split(`
`),p=c.split(`
`);for(n=a=0;a<r.length&&!r[a].includes("DetermineComponentFrameRoot");)a++;for(;n<p.length&&!p[n].includes("DetermineComponentFrameRoot");)n++;if(a===r.length||n===p.length)for(a=r.length-1,n=p.length-1;1<=a&&0<=n&&r[a]!==p[n];)n--;for(;1<=a&&0<=n;a--,n--)if(r[a]!==p[n]){if(a!==1||n!==1)do if(a--,n--,0>n||r[a]!==p[n]){var S=`
`+r[a].replace(" at new "," at ");return e.displayName&&S.includes("<anonymous>")&&(S=S.replace("<anonymous>",e.displayName)),S}while(1<=a&&0<=n);break}}}finally{kt=!1,Error.prepareStackTrace=l}return(l=e?e.displayName||e.name:"")?rt(l):""}function sa(e,t){switch(e.tag){case 26:case 27:case 5:return rt(e.type);case 16:return rt("Lazy");case 13:return e.child!==t&&t!==null?rt("Suspense Fallback"):rt("Suspense");case 19:return rt("SuspenseList");case 0:case 15:return Yt(e.type,!1);case 11:return Yt(e.type.render,!1);case 1:return Yt(e.type,!0);case 31:return rt("Activity");default:return""}}function ua(e){try{var t="",l=null;do t+=sa(e,l),l=e,e=e.return;while(e);return t}catch(a){return`
Error generating stack: `+a.message+`
`+a.stack}}var xl=Object.prototype.hasOwnProperty,$t=j.unstable_scheduleCallback,Wt=j.unstable_cancelCallback,Ka=j.unstable_shouldYield,ce=j.unstable_requestPaint,V=j.unstable_now,W=j.unstable_getCurrentPriorityLevel,re=j.unstable_ImmediatePriority,he=j.unstable_UserBlockingPriority,Me=j.unstable_NormalPriority,Gl=j.unstable_LowPriority,yt=j.unstable_IdlePriority,Ac=j.log,y=j.unstable_setDisableYieldValue,P=null,qe=null;function ye(e){if(typeof Ac=="function"&&y(e),qe&&typeof qe.setStrictMode=="function")try{qe.setStrictMode(P,e)}catch{}}var at=Math.clz32?Math.clz32:qd,as=Math.log,Ld=Math.LN2;function qd(e){return e>>>=0,e===0?32:31-(as(e)/Ld|0)|0}var Gn=256,Xn=262144,Qn=4194304;function Xl(e){var t=e&42;if(t!==0)return t;switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:return 64;case 128:return 128;case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:return e&261888;case 262144:case 524288:case 1048576:case 2097152:return e&3932160;case 4194304:case 8388608:case 16777216:case 33554432:return e&62914560;case 67108864:return 67108864;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 0;default:return e}}function Vn(e,t,l){var a=e.pendingLanes;if(a===0)return 0;var n=0,i=e.suspendedLanes,u=e.pingedLanes;e=e.warmLanes;var c=a&134217727;return c!==0?(a=c&~i,a!==0?n=Xl(a):(u&=c,u!==0?n=Xl(u):l||(l=c&~e,l!==0&&(n=Xl(l))))):(c=a&~i,c!==0?n=Xl(c):u!==0?n=Xl(u):l||(l=a&~e,l!==0&&(n=Xl(l)))),n===0?0:t!==0&&t!==n&&(t&i)===0&&(i=n&-n,l=t&-t,i>=l||i===32&&(l&4194048)!==0)?t:n}function Ja(e,t){return(e.pendingLanes&~(e.suspendedLanes&~e.pingedLanes)&t)===0}function Yd(e,t){switch(e){case 1:case 2:case 4:case 8:case 64:return t+250;case 16:case 32:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;case 4194304:case 8388608:case 16777216:case 33554432:return-1;case 67108864:case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}function Tc(){var e=Qn;return Qn<<=1,(Qn&62914560)===0&&(Qn=4194304),e}function ns(e){for(var t=[],l=0;31>l;l++)t.push(e);return t}function ka(e,t){e.pendingLanes|=t,t!==268435456&&(e.suspendedLanes=0,e.pingedLanes=0,e.warmLanes=0)}function Gd(e,t,l,a,n,i){var u=e.pendingLanes;e.pendingLanes=l,e.suspendedLanes=0,e.pingedLanes=0,e.warmLanes=0,e.expiredLanes&=l,e.entangledLanes&=l,e.errorRecoveryDisabledLanes&=l,e.shellSuspendCounter=0;var c=e.entanglements,r=e.expirationTimes,p=e.hiddenUpdates;for(l=u&~l;0<l;){var S=31-at(l),T=1<<S;c[S]=0,r[S]=-1;var g=p[S];if(g!==null)for(p[S]=null,S=0;S<g.length;S++){var b=g[S];b!==null&&(b.lane&=-536870913)}l&=~T}a!==0&&_c(e,a,0),i!==0&&n===0&&e.tag!==0&&(e.suspendedLanes|=i&~(u&~t))}function _c(e,t,l){e.pendingLanes|=t,e.suspendedLanes&=~t;var a=31-at(t);e.entangledLanes|=t,e.entanglements[a]=e.entanglements[a]|1073741824|l&261930}function zc(e,t){var l=e.entangledLanes|=t;for(e=e.entanglements;l;){var a=31-at(l),n=1<<a;n&t|e[a]&t&&(e[a]|=t),l&=~n}}function Oc(e,t){var l=t&-t;return l=(l&42)!==0?1:is(l),(l&(e.suspendedLanes|t))!==0?0:l}function is(e){switch(e){case 2:e=1;break;case 8:e=4;break;case 32:e=16;break;case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:e=128;break;case 268435456:e=134217728;break;default:e=0}return e}function ss(e){return e&=-e,2<e?8<e?(e&134217727)!==0?32:268435456:8:2}function Mc(){var e=O.p;return e!==0?e:(e=window.event,e===void 0?32:gd(e.type))}function Dc(e,t){var l=O.p;try{return O.p=e,t()}finally{O.p=l}}var pl=Math.random().toString(36).slice(2),nt="__reactFiber$"+pl,dt="__reactProps$"+pl,ca="__reactContainer$"+pl,us="__reactEvents$"+pl,Xd="__reactListeners$"+pl,Qd="__reactHandles$"+pl,Cc="__reactResources$"+pl,$a="__reactMarker$"+pl;function cs(e){delete e[nt],delete e[dt],delete e[us],delete e[Xd],delete e[Qd]}function ra(e){var t=e[nt];if(t)return t;for(var l=e.parentNode;l;){if(t=l[ca]||l[nt]){if(l=t.alternate,t.child!==null||l!==null&&l.child!==null)for(e=td(e);e!==null;){if(l=e[nt])return l;e=td(e)}return t}e=l,l=e.parentNode}return null}function fa(e){if(e=e[nt]||e[ca]){var t=e.tag;if(t===5||t===6||t===13||t===31||t===26||t===27||t===3)return e}return null}function Wa(e){var t=e.tag;if(t===5||t===26||t===27||t===6)return e.stateNode;throw Error(o(33))}function oa(e){var t=e[Cc];return t||(t=e[Cc]={hoistableStyles:new Map,hoistableScripts:new Map}),t}function tt(e){e[$a]=!0}var Rc=new Set,Uc={};function Ql(e,t){da(e,t),da(e+"Capture",t)}function da(e,t){for(Uc[e]=t,e=0;e<t.length;e++)Rc.add(t[e])}var Vd=RegExp("^[:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$"),wc={},Hc={};function Zd(e){return xl.call(Hc,e)?!0:xl.call(wc,e)?!1:Vd.test(e)?Hc[e]=!0:(wc[e]=!0,!1)}function Zn(e,t,l){if(Zd(t))if(l===null)e.removeAttribute(t);else{switch(typeof l){case"undefined":case"function":case"symbol":e.removeAttribute(t);return;case"boolean":var a=t.toLowerCase().slice(0,5);if(a!=="data-"&&a!=="aria-"){e.removeAttribute(t);return}}e.setAttribute(t,""+l)}}function Kn(e,t,l){if(l===null)e.removeAttribute(t);else{switch(typeof l){case"undefined":case"function":case"symbol":case"boolean":e.removeAttribute(t);return}e.setAttribute(t,""+l)}}function Ft(e,t,l,a){if(a===null)e.removeAttribute(l);else{switch(typeof a){case"undefined":case"function":case"symbol":case"boolean":e.removeAttribute(l);return}e.setAttributeNS(t,l,""+a)}}function Ot(e){switch(typeof e){case"bigint":case"boolean":case"number":case"string":case"undefined":return e;case"object":return e;default:return""}}function Bc(e){var t=e.type;return(e=e.nodeName)&&e.toLowerCase()==="input"&&(t==="checkbox"||t==="radio")}function Kd(e,t,l){var a=Object.getOwnPropertyDescriptor(e.constructor.prototype,t);if(!e.hasOwnProperty(t)&&typeof a<"u"&&typeof a.get=="function"&&typeof a.set=="function"){var n=a.get,i=a.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return n.call(this)},set:function(u){l=""+u,i.call(this,u)}}),Object.defineProperty(e,t,{enumerable:a.enumerable}),{getValue:function(){return l},setValue:function(u){l=""+u},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}function rs(e){if(!e._valueTracker){var t=Bc(e)?"checked":"value";e._valueTracker=Kd(e,t,""+e[t])}}function Lc(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var l=t.getValue(),a="";return e&&(a=Bc(e)?e.checked?"true":"false":e.value),e=a,e!==l?(t.setValue(e),!0):!1}function Jn(e){if(e=e||(typeof document<"u"?document:void 0),typeof e>"u")return null;try{return e.activeElement||e.body}catch{return e.body}}var Jd=/[\n"\\]/g;function Mt(e){return e.replace(Jd,function(t){return"\\"+t.charCodeAt(0).toString(16)+" "})}function fs(e,t,l,a,n,i,u,c){e.name="",u!=null&&typeof u!="function"&&typeof u!="symbol"&&typeof u!="boolean"?e.type=u:e.removeAttribute("type"),t!=null?u==="number"?(t===0&&e.value===""||e.value!=t)&&(e.value=""+Ot(t)):e.value!==""+Ot(t)&&(e.value=""+Ot(t)):u!=="submit"&&u!=="reset"||e.removeAttribute("value"),t!=null?os(e,u,Ot(t)):l!=null?os(e,u,Ot(l)):a!=null&&e.removeAttribute("value"),n==null&&i!=null&&(e.defaultChecked=!!i),n!=null&&(e.checked=n&&typeof n!="function"&&typeof n!="symbol"),c!=null&&typeof c!="function"&&typeof c!="symbol"&&typeof c!="boolean"?e.name=""+Ot(c):e.removeAttribute("name")}function qc(e,t,l,a,n,i,u,c){if(i!=null&&typeof i!="function"&&typeof i!="symbol"&&typeof i!="boolean"&&(e.type=i),t!=null||l!=null){if(!(i!=="submit"&&i!=="reset"||t!=null)){rs(e);return}l=l!=null?""+Ot(l):"",t=t!=null?""+Ot(t):l,c||t===e.value||(e.value=t),e.defaultValue=t}a=a??n,a=typeof a!="function"&&typeof a!="symbol"&&!!a,e.checked=c?e.checked:!!a,e.defaultChecked=!!a,u!=null&&typeof u!="function"&&typeof u!="symbol"&&typeof u!="boolean"&&(e.name=u),rs(e)}function os(e,t,l){t==="number"&&Jn(e.ownerDocument)===e||e.defaultValue===""+l||(e.defaultValue=""+l)}function ma(e,t,l,a){if(e=e.options,t){t={};for(var n=0;n<l.length;n++)t["$"+l[n]]=!0;for(l=0;l<e.length;l++)n=t.hasOwnProperty("$"+e[l].value),e[l].selected!==n&&(e[l].selected=n),n&&a&&(e[l].defaultSelected=!0)}else{for(l=""+Ot(l),t=null,n=0;n<e.length;n++){if(e[n].value===l){e[n].selected=!0,a&&(e[n].defaultSelected=!0);return}t!==null||e[n].disabled||(t=e[n])}t!==null&&(t.selected=!0)}}function Yc(e,t,l){if(t!=null&&(t=""+Ot(t),t!==e.value&&(e.value=t),l==null)){e.defaultValue!==t&&(e.defaultValue=t);return}e.defaultValue=l!=null?""+Ot(l):""}function Gc(e,t,l,a){if(t==null){if(a!=null){if(l!=null)throw Error(o(92));if(et(a)){if(1<a.length)throw Error(o(93));a=a[0]}l=a}l==null&&(l=""),t=l}l=Ot(t),e.defaultValue=l,a=e.textContent,a===l&&a!==""&&a!==null&&(e.value=a),rs(e)}function ha(e,t){if(t){var l=e.firstChild;if(l&&l===e.lastChild&&l.nodeType===3){l.nodeValue=t;return}}e.textContent=t}var kd=new Set("animationIterationCount aspectRatio borderImageOutset borderImageSlice borderImageWidth boxFlex boxFlexGroup boxOrdinalGroup columnCount columns flex flexGrow flexPositive flexShrink flexNegative flexOrder gridArea gridRow gridRowEnd gridRowSpan gridRowStart gridColumn gridColumnEnd gridColumnSpan gridColumnStart fontWeight lineClamp lineHeight opacity order orphans scale tabSize widows zIndex zoom fillOpacity floodOpacity stopOpacity strokeDasharray strokeDashoffset strokeMiterlimit strokeOpacity strokeWidth MozAnimationIterationCount MozBoxFlex MozBoxFlexGroup MozLineClamp msAnimationIterationCount msFlex msZoom msFlexGrow msFlexNegative msFlexOrder msFlexPositive msFlexShrink msGridColumn msGridColumnSpan msGridRow msGridRowSpan WebkitAnimationIterationCount WebkitBoxFlex WebKitBoxFlexGroup WebkitBoxOrdinalGroup WebkitColumnCount WebkitColumns WebkitFlex WebkitFlexGrow WebkitFlexPositive WebkitFlexShrink WebkitLineClamp".split(" "));function Xc(e,t,l){var a=t.indexOf("--")===0;l==null||typeof l=="boolean"||l===""?a?e.setProperty(t,""):t==="float"?e.cssFloat="":e[t]="":a?e.setProperty(t,l):typeof l!="number"||l===0||kd.has(t)?t==="float"?e.cssFloat=l:e[t]=(""+l).trim():e[t]=l+"px"}function Qc(e,t,l){if(t!=null&&typeof t!="object")throw Error(o(62));if(e=e.style,l!=null){for(var a in l)!l.hasOwnProperty(a)||t!=null&&t.hasOwnProperty(a)||(a.indexOf("--")===0?e.setProperty(a,""):a==="float"?e.cssFloat="":e[a]="");for(var n in t)a=t[n],t.hasOwnProperty(n)&&l[n]!==a&&Xc(e,n,a)}else for(var i in t)t.hasOwnProperty(i)&&Xc(e,i,t[i])}function ds(e){if(e.indexOf("-")===-1)return!1;switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var $d=new Map([["acceptCharset","accept-charset"],["htmlFor","for"],["httpEquiv","http-equiv"],["crossOrigin","crossorigin"],["accentHeight","accent-height"],["alignmentBaseline","alignment-baseline"],["arabicForm","arabic-form"],["baselineShift","baseline-shift"],["capHeight","cap-height"],["clipPath","clip-path"],["clipRule","clip-rule"],["colorInterpolation","color-interpolation"],["colorInterpolationFilters","color-interpolation-filters"],["colorProfile","color-profile"],["colorRendering","color-rendering"],["dominantBaseline","dominant-baseline"],["enableBackground","enable-background"],["fillOpacity","fill-opacity"],["fillRule","fill-rule"],["floodColor","flood-color"],["floodOpacity","flood-opacity"],["fontFamily","font-family"],["fontSize","font-size"],["fontSizeAdjust","font-size-adjust"],["fontStretch","font-stretch"],["fontStyle","font-style"],["fontVariant","font-variant"],["fontWeight","font-weight"],["glyphName","glyph-name"],["glyphOrientationHorizontal","glyph-orientation-horizontal"],["glyphOrientationVertical","glyph-orientation-vertical"],["horizAdvX","horiz-adv-x"],["horizOriginX","horiz-origin-x"],["imageRendering","image-rendering"],["letterSpacing","letter-spacing"],["lightingColor","lighting-color"],["markerEnd","marker-end"],["markerMid","marker-mid"],["markerStart","marker-start"],["overlinePosition","overline-position"],["overlineThickness","overline-thickness"],["paintOrder","paint-order"],["panose-1","panose-1"],["pointerEvents","pointer-events"],["renderingIntent","rendering-intent"],["shapeRendering","shape-rendering"],["stopColor","stop-color"],["stopOpacity","stop-opacity"],["strikethroughPosition","strikethrough-position"],["strikethroughThickness","strikethrough-thickness"],["strokeDasharray","stroke-dasharray"],["strokeDashoffset","stroke-dashoffset"],["strokeLinecap","stroke-linecap"],["strokeLinejoin","stroke-linejoin"],["strokeMiterlimit","stroke-miterlimit"],["strokeOpacity","stroke-opacity"],["strokeWidth","stroke-width"],["textAnchor","text-anchor"],["textDecoration","text-decoration"],["textRendering","text-rendering"],["transformOrigin","transform-origin"],["underlinePosition","underline-position"],["underlineThickness","underline-thickness"],["unicodeBidi","unicode-bidi"],["unicodeRange","unicode-range"],["unitsPerEm","units-per-em"],["vAlphabetic","v-alphabetic"],["vHanging","v-hanging"],["vIdeographic","v-ideographic"],["vMathematical","v-mathematical"],["vectorEffect","vector-effect"],["vertAdvY","vert-adv-y"],["vertOriginX","vert-origin-x"],["vertOriginY","vert-origin-y"],["wordSpacing","word-spacing"],["writingMode","writing-mode"],["xmlnsXlink","xmlns:xlink"],["xHeight","x-height"]]),Wd=/^[\u0000-\u001F ]*j[\r\n\t]*a[\r\n\t]*v[\r\n\t]*a[\r\n\t]*s[\r\n\t]*c[\r\n\t]*r[\r\n\t]*i[\r\n\t]*p[\r\n\t]*t[\r\n\t]*:/i;function kn(e){return Wd.test(""+e)?"javascript:throw new Error('React has blocked a javascript: URL as a security precaution.')":e}function Pt(){}var ms=null;function hs(e){return e=e.target||e.srcElement||window,e.correspondingUseElement&&(e=e.correspondingUseElement),e.nodeType===3?e.parentNode:e}var xa=null,pa=null;function Vc(e){var t=fa(e);if(t&&(e=t.stateNode)){var l=e[dt]||null;e:switch(e=t.stateNode,t.type){case"input":if(fs(e,l.value,l.defaultValue,l.defaultValue,l.checked,l.defaultChecked,l.type,l.name),t=l.name,l.type==="radio"&&t!=null){for(l=e;l.parentNode;)l=l.parentNode;for(l=l.querySelectorAll('input[name="'+Mt(""+t)+'"][type="radio"]'),t=0;t<l.length;t++){var a=l[t];if(a!==e&&a.form===e.form){var n=a[dt]||null;if(!n)throw Error(o(90));fs(a,n.value,n.defaultValue,n.defaultValue,n.checked,n.defaultChecked,n.type,n.name)}}for(t=0;t<l.length;t++)a=l[t],a.form===e.form&&Lc(a)}break e;case"textarea":Yc(e,l.value,l.defaultValue);break e;case"select":t=l.value,t!=null&&ma(e,!!l.multiple,t,!1)}}}var xs=!1;function Zc(e,t,l){if(xs)return e(t,l);xs=!0;try{var a=e(t);return a}finally{if(xs=!1,(xa!==null||pa!==null)&&(wi(),xa&&(t=xa,e=pa,pa=xa=null,Vc(t),e)))for(t=0;t<e.length;t++)Vc(e[t])}}function Fa(e,t){var l=e.stateNode;if(l===null)return null;var a=l[dt]||null;if(a===null)return null;l=a[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(a=!a.disabled)||(e=e.type,a=!(e==="button"||e==="input"||e==="select"||e==="textarea")),e=!a;break e;default:e=!1}if(e)return null;if(l&&typeof l!="function")throw Error(o(231,t,typeof l));return l}var It=!(typeof window>"u"||typeof window.document>"u"||typeof window.document.createElement>"u"),ps=!1;if(It)try{var Pa={};Object.defineProperty(Pa,"passive",{get:function(){ps=!0}}),window.addEventListener("test",Pa,Pa),window.removeEventListener("test",Pa,Pa)}catch{ps=!1}var gl=null,gs=null,$n=null;function Kc(){if($n)return $n;var e,t=gs,l=t.length,a,n="value"in gl?gl.value:gl.textContent,i=n.length;for(e=0;e<l&&t[e]===n[e];e++);var u=l-e;for(a=1;a<=u&&t[l-a]===n[i-a];a++);return $n=n.slice(e,1<a?1-a:void 0)}function Wn(e){var t=e.keyCode;return"charCode"in e?(e=e.charCode,e===0&&t===13&&(e=13)):e=t,e===10&&(e=13),32<=e||e===13?e:0}function Fn(){return!0}function Jc(){return!1}function mt(e){function t(l,a,n,i,u){this._reactName=l,this._targetInst=n,this.type=a,this.nativeEvent=i,this.target=u,this.currentTarget=null;for(var c in e)e.hasOwnProperty(c)&&(l=e[c],this[c]=l?l(i):i[c]);return this.isDefaultPrevented=(i.defaultPrevented!=null?i.defaultPrevented:i.returnValue===!1)?Fn:Jc,this.isPropagationStopped=Jc,this}return M(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var l=this.nativeEvent;l&&(l.preventDefault?l.preventDefault():typeof l.returnValue!="unknown"&&(l.returnValue=!1),this.isDefaultPrevented=Fn)},stopPropagation:function(){var l=this.nativeEvent;l&&(l.stopPropagation?l.stopPropagation():typeof l.cancelBubble!="unknown"&&(l.cancelBubble=!0),this.isPropagationStopped=Fn)},persist:function(){},isPersistent:Fn}),t}var Vl={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},Pn=mt(Vl),Ia=M({},Vl,{view:0,detail:0}),Fd=mt(Ia),vs,ys,en,In=M({},Ia,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:js,button:0,buttons:0,relatedTarget:function(e){return e.relatedTarget===void 0?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==en&&(en&&e.type==="mousemove"?(vs=e.screenX-en.screenX,ys=e.screenY-en.screenY):ys=vs=0,en=e),vs)},movementY:function(e){return"movementY"in e?e.movementY:ys}}),kc=mt(In),Pd=M({},In,{dataTransfer:0}),Id=mt(Pd),e0=M({},Ia,{relatedTarget:0}),bs=mt(e0),t0=M({},Vl,{animationName:0,elapsedTime:0,pseudoElement:0}),l0=mt(t0),a0=M({},Vl,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),n0=mt(a0),i0=M({},Vl,{data:0}),$c=mt(i0),s0={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},u0={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},c0={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function r0(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):(e=c0[e])?!!t[e]:!1}function js(){return r0}var f0=M({},Ia,{key:function(e){if(e.key){var t=s0[e.key]||e.key;if(t!=="Unidentified")return t}return e.type==="keypress"?(e=Wn(e),e===13?"Enter":String.fromCharCode(e)):e.type==="keydown"||e.type==="keyup"?u0[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:js,charCode:function(e){return e.type==="keypress"?Wn(e):0},keyCode:function(e){return e.type==="keydown"||e.type==="keyup"?e.keyCode:0},which:function(e){return e.type==="keypress"?Wn(e):e.type==="keydown"||e.type==="keyup"?e.keyCode:0}}),o0=mt(f0),d0=M({},In,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),Wc=mt(d0),m0=M({},Ia,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:js}),h0=mt(m0),x0=M({},Vl,{propertyName:0,elapsedTime:0,pseudoElement:0}),p0=mt(x0),g0=M({},In,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),v0=mt(g0),y0=M({},Vl,{newState:0,oldState:0}),b0=mt(y0),j0=[9,13,27,32],Ns=It&&"CompositionEvent"in window,tn=null;It&&"documentMode"in document&&(tn=document.documentMode);var N0=It&&"TextEvent"in window&&!tn,Fc=It&&(!Ns||tn&&8<tn&&11>=tn),Pc=" ",Ic=!1;function er(e,t){switch(e){case"keyup":return j0.indexOf(t.keyCode)!==-1;case"keydown":return t.keyCode!==229;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function tr(e){return e=e.detail,typeof e=="object"&&"data"in e?e.data:null}var ga=!1;function S0(e,t){switch(e){case"compositionend":return tr(t);case"keypress":return t.which!==32?null:(Ic=!0,Pc);case"textInput":return e=t.data,e===Pc&&Ic?null:e;default:return null}}function E0(e,t){if(ga)return e==="compositionend"||!Ns&&er(e,t)?(e=Kc(),$n=gs=gl=null,ga=!1,e):null;switch(e){case"paste":return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Fc&&t.locale!=="ko"?null:t.data;default:return null}}var A0={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function lr(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t==="input"?!!A0[e.type]:t==="textarea"}function ar(e,t,l,a){xa?pa?pa.push(a):pa=[a]:xa=a,t=Xi(t,"onChange"),0<t.length&&(l=new Pn("onChange","change",null,l,a),e.push({event:l,listeners:t}))}var ln=null,an=null;function T0(e){Go(e,0)}function ei(e){var t=Wa(e);if(Lc(t))return e}function nr(e,t){if(e==="change")return t}var ir=!1;if(It){var Ss;if(It){var Es="oninput"in document;if(!Es){var sr=document.createElement("div");sr.setAttribute("oninput","return;"),Es=typeof sr.oninput=="function"}Ss=Es}else Ss=!1;ir=Ss&&(!document.documentMode||9<document.documentMode)}function ur(){ln&&(ln.detachEvent("onpropertychange",cr),an=ln=null)}function cr(e){if(e.propertyName==="value"&&ei(an)){var t=[];ar(t,an,e,hs(e)),Zc(T0,t)}}function _0(e,t,l){e==="focusin"?(ur(),ln=t,an=l,ln.attachEvent("onpropertychange",cr)):e==="focusout"&&ur()}function z0(e){if(e==="selectionchange"||e==="keyup"||e==="keydown")return ei(an)}function O0(e,t){if(e==="click")return ei(t)}function M0(e,t){if(e==="input"||e==="change")return ei(t)}function D0(e,t){return e===t&&(e!==0||1/e===1/t)||e!==e&&t!==t}var bt=typeof Object.is=="function"?Object.is:D0;function nn(e,t){if(bt(e,t))return!0;if(typeof e!="object"||e===null||typeof t!="object"||t===null)return!1;var l=Object.keys(e),a=Object.keys(t);if(l.length!==a.length)return!1;for(a=0;a<l.length;a++){var n=l[a];if(!xl.call(t,n)||!bt(e[n],t[n]))return!1}return!0}function rr(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function fr(e,t){var l=rr(e);e=0;for(var a;l;){if(l.nodeType===3){if(a=e+l.textContent.length,e<=t&&a>=t)return{node:l,offset:t-e};e=a}e:{for(;l;){if(l.nextSibling){l=l.nextSibling;break e}l=l.parentNode}l=void 0}l=rr(l)}}function or(e,t){return e&&t?e===t?!0:e&&e.nodeType===3?!1:t&&t.nodeType===3?or(e,t.parentNode):"contains"in e?e.contains(t):e.compareDocumentPosition?!!(e.compareDocumentPosition(t)&16):!1:!1}function dr(e){e=e!=null&&e.ownerDocument!=null&&e.ownerDocument.defaultView!=null?e.ownerDocument.defaultView:window;for(var t=Jn(e.document);t instanceof e.HTMLIFrameElement;){try{var l=typeof t.contentWindow.location.href=="string"}catch{l=!1}if(l)e=t.contentWindow;else break;t=Jn(e.document)}return t}function As(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(t==="input"&&(e.type==="text"||e.type==="search"||e.type==="tel"||e.type==="url"||e.type==="password")||t==="textarea"||e.contentEditable==="true")}var C0=It&&"documentMode"in document&&11>=document.documentMode,va=null,Ts=null,sn=null,_s=!1;function mr(e,t,l){var a=l.window===l?l.document:l.nodeType===9?l:l.ownerDocument;_s||va==null||va!==Jn(a)||(a=va,"selectionStart"in a&&As(a)?a={start:a.selectionStart,end:a.selectionEnd}:(a=(a.ownerDocument&&a.ownerDocument.defaultView||window).getSelection(),a={anchorNode:a.anchorNode,anchorOffset:a.anchorOffset,focusNode:a.focusNode,focusOffset:a.focusOffset}),sn&&nn(sn,a)||(sn=a,a=Xi(Ts,"onSelect"),0<a.length&&(t=new Pn("onSelect","select",null,t,l),e.push({event:t,listeners:a}),t.target=va)))}function Zl(e,t){var l={};return l[e.toLowerCase()]=t.toLowerCase(),l["Webkit"+e]="webkit"+t,l["Moz"+e]="moz"+t,l}var ya={animationend:Zl("Animation","AnimationEnd"),animationiteration:Zl("Animation","AnimationIteration"),animationstart:Zl("Animation","AnimationStart"),transitionrun:Zl("Transition","TransitionRun"),transitionstart:Zl("Transition","TransitionStart"),transitioncancel:Zl("Transition","TransitionCancel"),transitionend:Zl("Transition","TransitionEnd")},zs={},hr={};It&&(hr=document.createElement("div").style,"AnimationEvent"in window||(delete ya.animationend.animation,delete ya.animationiteration.animation,delete ya.animationstart.animation),"TransitionEvent"in window||delete ya.transitionend.transition);function Kl(e){if(zs[e])return zs[e];if(!ya[e])return e;var t=ya[e],l;for(l in t)if(t.hasOwnProperty(l)&&l in hr)return zs[e]=t[l];return e}var xr=Kl("animationend"),pr=Kl("animationiteration"),gr=Kl("animationstart"),R0=Kl("transitionrun"),U0=Kl("transitionstart"),w0=Kl("transitioncancel"),vr=Kl("transitionend"),yr=new Map,Os="abort auxClick beforeToggle cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");Os.push("scrollEnd");function Gt(e,t){yr.set(e,t),Ql(t,[e])}var ti=typeof reportError=="function"?reportError:function(e){if(typeof window=="object"&&typeof window.ErrorEvent=="function"){var t=new window.ErrorEvent("error",{bubbles:!0,cancelable:!0,message:typeof e=="object"&&e!==null&&typeof e.message=="string"?String(e.message):String(e),error:e});if(!window.dispatchEvent(t))return}else if(typeof process=="object"&&typeof process.emit=="function"){process.emit("uncaughtException",e);return}console.error(e)},Dt=[],ba=0,Ms=0;function li(){for(var e=ba,t=Ms=ba=0;t<e;){var l=Dt[t];Dt[t++]=null;var a=Dt[t];Dt[t++]=null;var n=Dt[t];Dt[t++]=null;var i=Dt[t];if(Dt[t++]=null,a!==null&&n!==null){var u=a.pending;u===null?n.next=n:(n.next=u.next,u.next=n),a.pending=n}i!==0&&br(l,n,i)}}function ai(e,t,l,a){Dt[ba++]=e,Dt[ba++]=t,Dt[ba++]=l,Dt[ba++]=a,Ms|=a,e.lanes|=a,e=e.alternate,e!==null&&(e.lanes|=a)}function Ds(e,t,l,a){return ai(e,t,l,a),ni(e)}function Jl(e,t){return ai(e,null,null,t),ni(e)}function br(e,t,l){e.lanes|=l;var a=e.alternate;a!==null&&(a.lanes|=l);for(var n=!1,i=e.return;i!==null;)i.childLanes|=l,a=i.alternate,a!==null&&(a.childLanes|=l),i.tag===22&&(e=i.stateNode,e===null||e._visibility&1||(n=!0)),e=i,i=i.return;return e.tag===3?(i=e.stateNode,n&&t!==null&&(n=31-at(l),e=i.hiddenUpdates,a=e[n],a===null?e[n]=[t]:a.push(t),t.lane=l|536870912),i):null}function ni(e){if(50<zn)throw zn=0,Yu=null,Error(o(185));for(var t=e.return;t!==null;)e=t,t=e.return;return e.tag===3?e.stateNode:null}var ja={};function H0(e,t,l,a){this.tag=e,this.key=l,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.refCleanup=this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=a,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function jt(e,t,l,a){return new H0(e,t,l,a)}function Cs(e){return e=e.prototype,!(!e||!e.isReactComponent)}function el(e,t){var l=e.alternate;return l===null?(l=jt(e.tag,t,e.key,e.mode),l.elementType=e.elementType,l.type=e.type,l.stateNode=e.stateNode,l.alternate=e,e.alternate=l):(l.pendingProps=t,l.type=e.type,l.flags=0,l.subtreeFlags=0,l.deletions=null),l.flags=e.flags&65011712,l.childLanes=e.childLanes,l.lanes=e.lanes,l.child=e.child,l.memoizedProps=e.memoizedProps,l.memoizedState=e.memoizedState,l.updateQueue=e.updateQueue,t=e.dependencies,l.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext},l.sibling=e.sibling,l.index=e.index,l.ref=e.ref,l.refCleanup=e.refCleanup,l}function jr(e,t){e.flags&=65011714;var l=e.alternate;return l===null?(e.childLanes=0,e.lanes=t,e.child=null,e.subtreeFlags=0,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null,e.stateNode=null):(e.childLanes=l.childLanes,e.lanes=l.lanes,e.child=l.child,e.subtreeFlags=0,e.deletions=null,e.memoizedProps=l.memoizedProps,e.memoizedState=l.memoizedState,e.updateQueue=l.updateQueue,e.type=l.type,t=l.dependencies,e.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext}),e}function ii(e,t,l,a,n,i){var u=0;if(a=e,typeof e=="function")Cs(e)&&(u=1);else if(typeof e=="string")u=Gm(e,l,B.current)?26:e==="html"||e==="head"||e==="body"?27:5;else e:switch(e){case Oe:return e=jt(31,l,t,n),e.elementType=Oe,e.lanes=i,e;case ge:return kl(l.children,n,i,t);case Q:u=8,n|=24;break;case oe:return e=jt(12,l,t,n|2),e.elementType=oe,e.lanes=i,e;case $:return e=jt(13,l,t,n),e.elementType=$,e.lanes=i,e;case H:return e=jt(19,l,t,n),e.elementType=H,e.lanes=i,e;default:if(typeof e=="object"&&e!==null)switch(e.$$typeof){case ne:u=10;break e;case K:u=9;break e;case ee:u=11;break e;case Y:u=14;break e;case ae:u=16,a=null;break e}u=29,l=Error(o(130,e===null?"null":typeof e,"")),a=null}return t=jt(u,l,t,n),t.elementType=e,t.type=a,t.lanes=i,t}function kl(e,t,l,a){return e=jt(7,e,a,t),e.lanes=l,e}function Rs(e,t,l){return e=jt(6,e,null,t),e.lanes=l,e}function Nr(e){var t=jt(18,null,null,0);return t.stateNode=e,t}function Us(e,t,l){return t=jt(4,e.children!==null?e.children:[],e.key,t),t.lanes=l,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}var Sr=new WeakMap;function Ct(e,t){if(typeof e=="object"&&e!==null){var l=Sr.get(e);return l!==void 0?l:(t={value:e,source:t,stack:ua(t)},Sr.set(e,t),t)}return{value:e,source:t,stack:ua(t)}}var Na=[],Sa=0,si=null,un=0,Rt=[],Ut=0,vl=null,Vt=1,Zt="";function tl(e,t){Na[Sa++]=un,Na[Sa++]=si,si=e,un=t}function Er(e,t,l){Rt[Ut++]=Vt,Rt[Ut++]=Zt,Rt[Ut++]=vl,vl=e;var a=Vt;e=Zt;var n=32-at(a)-1;a&=~(1<<n),l+=1;var i=32-at(t)+n;if(30<i){var u=n-n%5;i=(a&(1<<u)-1).toString(32),a>>=u,n-=u,Vt=1<<32-at(t)+n|l<<n|a,Zt=i+e}else Vt=1<<i|l<<n|a,Zt=e}function ws(e){e.return!==null&&(tl(e,1),Er(e,1,0))}function Hs(e){for(;e===si;)si=Na[--Sa],Na[Sa]=null,un=Na[--Sa],Na[Sa]=null;for(;e===vl;)vl=Rt[--Ut],Rt[Ut]=null,Zt=Rt[--Ut],Rt[Ut]=null,Vt=Rt[--Ut],Rt[Ut]=null}function Ar(e,t){Rt[Ut++]=Vt,Rt[Ut++]=Zt,Rt[Ut++]=vl,Vt=t.id,Zt=t.overflow,vl=e}var it=null,He=null,be=!1,yl=null,wt=!1,Bs=Error(o(519));function bl(e){var t=Error(o(418,1<arguments.length&&arguments[1]!==void 0&&arguments[1]?"text":"HTML",""));throw cn(Ct(t,e)),Bs}function Tr(e){var t=e.stateNode,l=e.type,a=e.memoizedProps;switch(t[nt]=e,t[dt]=a,l){case"dialog":me("cancel",t),me("close",t);break;case"iframe":case"object":case"embed":me("load",t);break;case"video":case"audio":for(l=0;l<Mn.length;l++)me(Mn[l],t);break;case"source":me("error",t);break;case"img":case"image":case"link":me("error",t),me("load",t);break;case"details":me("toggle",t);break;case"input":me("invalid",t),qc(t,a.value,a.defaultValue,a.checked,a.defaultChecked,a.type,a.name,!0);break;case"select":me("invalid",t);break;case"textarea":me("invalid",t),Gc(t,a.value,a.defaultValue,a.children)}l=a.children,typeof l!="string"&&typeof l!="number"&&typeof l!="bigint"||t.textContent===""+l||a.suppressHydrationWarning===!0||Zo(t.textContent,l)?(a.popover!=null&&(me("beforetoggle",t),me("toggle",t)),a.onScroll!=null&&me("scroll",t),a.onScrollEnd!=null&&me("scrollend",t),a.onClick!=null&&(t.onclick=Pt),t=!0):t=!1,t||bl(e,!0)}function _r(e){for(it=e.return;it;)switch(it.tag){case 5:case 31:case 13:wt=!1;return;case 27:case 3:wt=!0;return;default:it=it.return}}function Ea(e){if(e!==it)return!1;if(!be)return _r(e),be=!0,!1;var t=e.tag,l;if((l=t!==3&&t!==27)&&((l=t===5)&&(l=e.type,l=!(l!=="form"&&l!=="button")||tc(e.type,e.memoizedProps)),l=!l),l&&He&&bl(e),_r(e),t===13){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(o(317));He=ed(e)}else if(t===31){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(o(317));He=ed(e)}else t===27?(t=He,Ul(e.type)?(e=sc,sc=null,He=e):He=t):He=it?Bt(e.stateNode.nextSibling):null;return!0}function $l(){He=it=null,be=!1}function Ls(){var e=yl;return e!==null&&(gt===null?gt=e:gt.push.apply(gt,e),yl=null),e}function cn(e){yl===null?yl=[e]:yl.push(e)}var qs=f(null),Wl=null,ll=null;function jl(e,t,l){C(qs,t._currentValue),t._currentValue=l}function al(e){e._currentValue=qs.current,E(qs)}function Ys(e,t,l){for(;e!==null;){var a=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,a!==null&&(a.childLanes|=t)):a!==null&&(a.childLanes&t)!==t&&(a.childLanes|=t),e===l)break;e=e.return}}function Gs(e,t,l,a){var n=e.child;for(n!==null&&(n.return=e);n!==null;){var i=n.dependencies;if(i!==null){var u=n.child;i=i.firstContext;e:for(;i!==null;){var c=i;i=n;for(var r=0;r<t.length;r++)if(c.context===t[r]){i.lanes|=l,c=i.alternate,c!==null&&(c.lanes|=l),Ys(i.return,l,e),a||(u=null);break e}i=c.next}}else if(n.tag===18){if(u=n.return,u===null)throw Error(o(341));u.lanes|=l,i=u.alternate,i!==null&&(i.lanes|=l),Ys(u,l,e),u=null}else u=n.child;if(u!==null)u.return=n;else for(u=n;u!==null;){if(u===e){u=null;break}if(n=u.sibling,n!==null){n.return=u.return,u=n;break}u=u.return}n=u}}function Aa(e,t,l,a){e=null;for(var n=t,i=!1;n!==null;){if(!i){if((n.flags&524288)!==0)i=!0;else if((n.flags&262144)!==0)break}if(n.tag===10){var u=n.alternate;if(u===null)throw Error(o(387));if(u=u.memoizedProps,u!==null){var c=n.type;bt(n.pendingProps.value,u.value)||(e!==null?e.push(c):e=[c])}}else if(n===ve.current){if(u=n.alternate,u===null)throw Error(o(387));u.memoizedState.memoizedState!==n.memoizedState.memoizedState&&(e!==null?e.push(wn):e=[wn])}n=n.return}e!==null&&Gs(t,e,l,a),t.flags|=262144}function ui(e){for(e=e.firstContext;e!==null;){if(!bt(e.context._currentValue,e.memoizedValue))return!0;e=e.next}return!1}function Fl(e){Wl=e,ll=null,e=e.dependencies,e!==null&&(e.firstContext=null)}function st(e){return zr(Wl,e)}function ci(e,t){return Wl===null&&Fl(e),zr(e,t)}function zr(e,t){var l=t._currentValue;if(t={context:t,memoizedValue:l,next:null},ll===null){if(e===null)throw Error(o(308));ll=t,e.dependencies={lanes:0,firstContext:t},e.flags|=524288}else ll=ll.next=t;return l}var B0=typeof AbortController<"u"?AbortController:function(){var e=[],t=this.signal={aborted:!1,addEventListener:function(l,a){e.push(a)}};this.abort=function(){t.aborted=!0,e.forEach(function(l){return l()})}},L0=j.unstable_scheduleCallback,q0=j.unstable_NormalPriority,ke={$$typeof:ne,Consumer:null,Provider:null,_currentValue:null,_currentValue2:null,_threadCount:0};function Xs(){return{controller:new B0,data:new Map,refCount:0}}function rn(e){e.refCount--,e.refCount===0&&L0(q0,function(){e.controller.abort()})}var fn=null,Qs=0,Ta=0,_a=null;function Y0(e,t){if(fn===null){var l=fn=[];Qs=0,Ta=Ku(),_a={status:"pending",value:void 0,then:function(a){l.push(a)}}}return Qs++,t.then(Or,Or),t}function Or(){if(--Qs===0&&fn!==null){_a!==null&&(_a.status="fulfilled");var e=fn;fn=null,Ta=0,_a=null;for(var t=0;t<e.length;t++)(0,e[t])()}}function G0(e,t){var l=[],a={status:"pending",value:null,reason:null,then:function(n){l.push(n)}};return e.then(function(){a.status="fulfilled",a.value=t;for(var n=0;n<l.length;n++)(0,l[n])(t)},function(n){for(a.status="rejected",a.reason=n,n=0;n<l.length;n++)(0,l[n])(void 0)}),a}var Mr=h.S;h.S=function(e,t){xo=V(),typeof t=="object"&&t!==null&&typeof t.then=="function"&&Y0(e,t),Mr!==null&&Mr(e,t)};var Pl=f(null);function Vs(){var e=Pl.current;return e!==null?e:Ue.pooledCache}function ri(e,t){t===null?C(Pl,Pl.current):C(Pl,t.pool)}function Dr(){var e=Vs();return e===null?null:{parent:ke._currentValue,pool:e}}var za=Error(o(460)),Zs=Error(o(474)),fi=Error(o(542)),oi={then:function(){}};function Cr(e){return e=e.status,e==="fulfilled"||e==="rejected"}function Rr(e,t,l){switch(l=e[l],l===void 0?e.push(t):l!==t&&(t.then(Pt,Pt),t=l),t.status){case"fulfilled":return t.value;case"rejected":throw e=t.reason,wr(e),e;default:if(typeof t.status=="string")t.then(Pt,Pt);else{if(e=Ue,e!==null&&100<e.shellSuspendCounter)throw Error(o(482));e=t,e.status="pending",e.then(function(a){if(t.status==="pending"){var n=t;n.status="fulfilled",n.value=a}},function(a){if(t.status==="pending"){var n=t;n.status="rejected",n.reason=a}})}switch(t.status){case"fulfilled":return t.value;case"rejected":throw e=t.reason,wr(e),e}throw ea=t,za}}function Il(e){try{var t=e._init;return t(e._payload)}catch(l){throw l!==null&&typeof l=="object"&&typeof l.then=="function"?(ea=l,za):l}}var ea=null;function Ur(){if(ea===null)throw Error(o(459));var e=ea;return ea=null,e}function wr(e){if(e===za||e===fi)throw Error(o(483))}var Oa=null,on=0;function di(e){var t=on;return on+=1,Oa===null&&(Oa=[]),Rr(Oa,e,t)}function dn(e,t){t=t.props.ref,e.ref=t!==void 0?t:null}function mi(e,t){throw t.$$typeof===k?Error(o(525)):(e=Object.prototype.toString.call(t),Error(o(31,e==="[object Object]"?"object with keys {"+Object.keys(t).join(", ")+"}":e)))}function Hr(e){function t(m,d){if(e){var x=m.deletions;x===null?(m.deletions=[d],m.flags|=16):x.push(d)}}function l(m,d){if(!e)return null;for(;d!==null;)t(m,d),d=d.sibling;return null}function a(m){for(var d=new Map;m!==null;)m.key!==null?d.set(m.key,m):d.set(m.index,m),m=m.sibling;return d}function n(m,d){return m=el(m,d),m.index=0,m.sibling=null,m}function i(m,d,x){return m.index=x,e?(x=m.alternate,x!==null?(x=x.index,x<d?(m.flags|=67108866,d):x):(m.flags|=67108866,d)):(m.flags|=1048576,d)}function u(m){return e&&m.alternate===null&&(m.flags|=67108866),m}function c(m,d,x,A){return d===null||d.tag!==6?(d=Rs(x,m.mode,A),d.return=m,d):(d=n(d,x),d.return=m,d)}function r(m,d,x,A){var Z=x.type;return Z===ge?S(m,d,x.props.children,A,x.key):d!==null&&(d.elementType===Z||typeof Z=="object"&&Z!==null&&Z.$$typeof===ae&&Il(Z)===d.type)?(d=n(d,x.props),dn(d,x),d.return=m,d):(d=ii(x.type,x.key,x.props,null,m.mode,A),dn(d,x),d.return=m,d)}function p(m,d,x,A){return d===null||d.tag!==4||d.stateNode.containerInfo!==x.containerInfo||d.stateNode.implementation!==x.implementation?(d=Us(x,m.mode,A),d.return=m,d):(d=n(d,x.children||[]),d.return=m,d)}function S(m,d,x,A,Z){return d===null||d.tag!==7?(d=kl(x,m.mode,A,Z),d.return=m,d):(d=n(d,x),d.return=m,d)}function T(m,d,x){if(typeof d=="string"&&d!==""||typeof d=="number"||typeof d=="bigint")return d=Rs(""+d,m.mode,x),d.return=m,d;if(typeof d=="object"&&d!==null){switch(d.$$typeof){case Ne:return x=ii(d.type,d.key,d.props,null,m.mode,x),dn(x,d),x.return=m,x;case je:return d=Us(d,m.mode,x),d.return=m,d;case ae:return d=Il(d),T(m,d,x)}if(et(d)||Se(d))return d=kl(d,m.mode,x,null),d.return=m,d;if(typeof d.then=="function")return T(m,di(d),x);if(d.$$typeof===ne)return T(m,ci(m,d),x);mi(m,d)}return null}function g(m,d,x,A){var Z=d!==null?d.key:null;if(typeof x=="string"&&x!==""||typeof x=="number"||typeof x=="bigint")return Z!==null?null:c(m,d,""+x,A);if(typeof x=="object"&&x!==null){switch(x.$$typeof){case Ne:return x.key===Z?r(m,d,x,A):null;case je:return x.key===Z?p(m,d,x,A):null;case ae:return x=Il(x),g(m,d,x,A)}if(et(x)||Se(x))return Z!==null?null:S(m,d,x,A,null);if(typeof x.then=="function")return g(m,d,di(x),A);if(x.$$typeof===ne)return g(m,d,ci(m,x),A);mi(m,x)}return null}function b(m,d,x,A,Z){if(typeof A=="string"&&A!==""||typeof A=="number"||typeof A=="bigint")return m=m.get(x)||null,c(d,m,""+A,Z);if(typeof A=="object"&&A!==null){switch(A.$$typeof){case Ne:return m=m.get(A.key===null?x:A.key)||null,r(d,m,A,Z);case je:return m=m.get(A.key===null?x:A.key)||null,p(d,m,A,Z);case ae:return A=Il(A),b(m,d,x,A,Z)}if(et(A)||Se(A))return m=m.get(x)||null,S(d,m,A,Z,null);if(typeof A.then=="function")return b(m,d,x,di(A),Z);if(A.$$typeof===ne)return b(m,d,x,ci(d,A),Z);mi(d,A)}return null}function q(m,d,x,A){for(var Z=null,Ee=null,G=d,fe=d=0,pe=null;G!==null&&fe<x.length;fe++){G.index>fe?(pe=G,G=null):pe=G.sibling;var Ae=g(m,G,x[fe],A);if(Ae===null){G===null&&(G=pe);break}e&&G&&Ae.alternate===null&&t(m,G),d=i(Ae,d,fe),Ee===null?Z=Ae:Ee.sibling=Ae,Ee=Ae,G=pe}if(fe===x.length)return l(m,G),be&&tl(m,fe),Z;if(G===null){for(;fe<x.length;fe++)G=T(m,x[fe],A),G!==null&&(d=i(G,d,fe),Ee===null?Z=G:Ee.sibling=G,Ee=G);return be&&tl(m,fe),Z}for(G=a(G);fe<x.length;fe++)pe=b(G,m,fe,x[fe],A),pe!==null&&(e&&pe.alternate!==null&&G.delete(pe.key===null?fe:pe.key),d=i(pe,d,fe),Ee===null?Z=pe:Ee.sibling=pe,Ee=pe);return e&&G.forEach(function(ql){return t(m,ql)}),be&&tl(m,fe),Z}function I(m,d,x,A){if(x==null)throw Error(o(151));for(var Z=null,Ee=null,G=d,fe=d=0,pe=null,Ae=x.next();G!==null&&!Ae.done;fe++,Ae=x.next()){G.index>fe?(pe=G,G=null):pe=G.sibling;var ql=g(m,G,Ae.value,A);if(ql===null){G===null&&(G=pe);break}e&&G&&ql.alternate===null&&t(m,G),d=i(ql,d,fe),Ee===null?Z=ql:Ee.sibling=ql,Ee=ql,G=pe}if(Ae.done)return l(m,G),be&&tl(m,fe),Z;if(G===null){for(;!Ae.done;fe++,Ae=x.next())Ae=T(m,Ae.value,A),Ae!==null&&(d=i(Ae,d,fe),Ee===null?Z=Ae:Ee.sibling=Ae,Ee=Ae);return be&&tl(m,fe),Z}for(G=a(G);!Ae.done;fe++,Ae=x.next())Ae=b(G,m,fe,Ae.value,A),Ae!==null&&(e&&Ae.alternate!==null&&G.delete(Ae.key===null?fe:Ae.key),d=i(Ae,d,fe),Ee===null?Z=Ae:Ee.sibling=Ae,Ee=Ae);return e&&G.forEach(function(Pm){return t(m,Pm)}),be&&tl(m,fe),Z}function Re(m,d,x,A){if(typeof x=="object"&&x!==null&&x.type===ge&&x.key===null&&(x=x.props.children),typeof x=="object"&&x!==null){switch(x.$$typeof){case Ne:e:{for(var Z=x.key;d!==null;){if(d.key===Z){if(Z=x.type,Z===ge){if(d.tag===7){l(m,d.sibling),A=n(d,x.props.children),A.return=m,m=A;break e}}else if(d.elementType===Z||typeof Z=="object"&&Z!==null&&Z.$$typeof===ae&&Il(Z)===d.type){l(m,d.sibling),A=n(d,x.props),dn(A,x),A.return=m,m=A;break e}l(m,d);break}else t(m,d);d=d.sibling}x.type===ge?(A=kl(x.props.children,m.mode,A,x.key),A.return=m,m=A):(A=ii(x.type,x.key,x.props,null,m.mode,A),dn(A,x),A.return=m,m=A)}return u(m);case je:e:{for(Z=x.key;d!==null;){if(d.key===Z)if(d.tag===4&&d.stateNode.containerInfo===x.containerInfo&&d.stateNode.implementation===x.implementation){l(m,d.sibling),A=n(d,x.children||[]),A.return=m,m=A;break e}else{l(m,d);break}else t(m,d);d=d.sibling}A=Us(x,m.mode,A),A.return=m,m=A}return u(m);case ae:return x=Il(x),Re(m,d,x,A)}if(et(x))return q(m,d,x,A);if(Se(x)){if(Z=Se(x),typeof Z!="function")throw Error(o(150));return x=Z.call(x),I(m,d,x,A)}if(typeof x.then=="function")return Re(m,d,di(x),A);if(x.$$typeof===ne)return Re(m,d,ci(m,x),A);mi(m,x)}return typeof x=="string"&&x!==""||typeof x=="number"||typeof x=="bigint"?(x=""+x,d!==null&&d.tag===6?(l(m,d.sibling),A=n(d,x),A.return=m,m=A):(l(m,d),A=Rs(x,m.mode,A),A.return=m,m=A),u(m)):l(m,d)}return function(m,d,x,A){try{on=0;var Z=Re(m,d,x,A);return Oa=null,Z}catch(G){if(G===za||G===fi)throw G;var Ee=jt(29,G,null,m.mode);return Ee.lanes=A,Ee.return=m,Ee}}}var ta=Hr(!0),Br=Hr(!1),Nl=!1;function Ks(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,lanes:0,hiddenCallbacks:null},callbacks:null}}function Js(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,callbacks:null})}function Sl(e){return{lane:e,tag:0,payload:null,callback:null,next:null}}function El(e,t,l){var a=e.updateQueue;if(a===null)return null;if(a=a.shared,(Te&2)!==0){var n=a.pending;return n===null?t.next=t:(t.next=n.next,n.next=t),a.pending=t,t=ni(e),br(e,null,l),t}return ai(e,a,t,l),ni(e)}function mn(e,t,l){if(t=t.updateQueue,t!==null&&(t=t.shared,(l&4194048)!==0)){var a=t.lanes;a&=e.pendingLanes,l|=a,t.lanes=l,zc(e,l)}}function ks(e,t){var l=e.updateQueue,a=e.alternate;if(a!==null&&(a=a.updateQueue,l===a)){var n=null,i=null;if(l=l.firstBaseUpdate,l!==null){do{var u={lane:l.lane,tag:l.tag,payload:l.payload,callback:null,next:null};i===null?n=i=u:i=i.next=u,l=l.next}while(l!==null);i===null?n=i=t:i=i.next=t}else n=i=t;l={baseState:a.baseState,firstBaseUpdate:n,lastBaseUpdate:i,shared:a.shared,callbacks:a.callbacks},e.updateQueue=l;return}e=l.lastBaseUpdate,e===null?l.firstBaseUpdate=t:e.next=t,l.lastBaseUpdate=t}var $s=!1;function hn(){if($s){var e=_a;if(e!==null)throw e}}function xn(e,t,l,a){$s=!1;var n=e.updateQueue;Nl=!1;var i=n.firstBaseUpdate,u=n.lastBaseUpdate,c=n.shared.pending;if(c!==null){n.shared.pending=null;var r=c,p=r.next;r.next=null,u===null?i=p:u.next=p,u=r;var S=e.alternate;S!==null&&(S=S.updateQueue,c=S.lastBaseUpdate,c!==u&&(c===null?S.firstBaseUpdate=p:c.next=p,S.lastBaseUpdate=r))}if(i!==null){var T=n.baseState;u=0,S=p=r=null,c=i;do{var g=c.lane&-536870913,b=g!==c.lane;if(b?(xe&g)===g:(a&g)===g){g!==0&&g===Ta&&($s=!0),S!==null&&(S=S.next={lane:0,tag:c.tag,payload:c.payload,callback:null,next:null});e:{var q=e,I=c;g=t;var Re=l;switch(I.tag){case 1:if(q=I.payload,typeof q=="function"){T=q.call(Re,T,g);break e}T=q;break e;case 3:q.flags=q.flags&-65537|128;case 0:if(q=I.payload,g=typeof q=="function"?q.call(Re,T,g):q,g==null)break e;T=M({},T,g);break e;case 2:Nl=!0}}g=c.callback,g!==null&&(e.flags|=64,b&&(e.flags|=8192),b=n.callbacks,b===null?n.callbacks=[g]:b.push(g))}else b={lane:g,tag:c.tag,payload:c.payload,callback:c.callback,next:null},S===null?(p=S=b,r=T):S=S.next=b,u|=g;if(c=c.next,c===null){if(c=n.shared.pending,c===null)break;b=c,c=b.next,b.next=null,n.lastBaseUpdate=b,n.shared.pending=null}}while(!0);S===null&&(r=T),n.baseState=r,n.firstBaseUpdate=p,n.lastBaseUpdate=S,i===null&&(n.shared.lanes=0),Ol|=u,e.lanes=u,e.memoizedState=T}}function Lr(e,t){if(typeof e!="function")throw Error(o(191,e));e.call(t)}function qr(e,t){var l=e.callbacks;if(l!==null)for(e.callbacks=null,e=0;e<l.length;e++)Lr(l[e],t)}var Ma=f(null),hi=f(0);function Yr(e,t){e=dl,C(hi,e),C(Ma,t),dl=e|t.baseLanes}function Ws(){C(hi,dl),C(Ma,Ma.current)}function Fs(){dl=hi.current,E(Ma),E(hi)}var Nt=f(null),Ht=null;function Al(e){var t=e.alternate;C(Ze,Ze.current&1),C(Nt,e),Ht===null&&(t===null||Ma.current!==null||t.memoizedState!==null)&&(Ht=e)}function Ps(e){C(Ze,Ze.current),C(Nt,e),Ht===null&&(Ht=e)}function Gr(e){e.tag===22?(C(Ze,Ze.current),C(Nt,e),Ht===null&&(Ht=e)):Tl()}function Tl(){C(Ze,Ze.current),C(Nt,Nt.current)}function St(e){E(Nt),Ht===e&&(Ht=null),E(Ze)}var Ze=f(0);function xi(e){for(var t=e;t!==null;){if(t.tag===13){var l=t.memoizedState;if(l!==null&&(l=l.dehydrated,l===null||nc(l)||ic(l)))return t}else if(t.tag===19&&(t.memoizedProps.revealOrder==="forwards"||t.memoizedProps.revealOrder==="backwards"||t.memoizedProps.revealOrder==="unstable_legacy-backwards"||t.memoizedProps.revealOrder==="together")){if((t.flags&128)!==0)return t}else if(t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var nl=0,ue=null,De=null,$e=null,pi=!1,Da=!1,la=!1,gi=0,pn=0,Ca=null,X0=0;function Ge(){throw Error(o(321))}function Is(e,t){if(t===null)return!1;for(var l=0;l<t.length&&l<e.length;l++)if(!bt(e[l],t[l]))return!1;return!0}function eu(e,t,l,a,n,i){return nl=i,ue=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,h.H=e===null||e.memoizedState===null?Af:xu,la=!1,i=l(a,n),la=!1,Da&&(i=Qr(t,l,a,n)),Xr(e),i}function Xr(e){h.H=yn;var t=De!==null&&De.next!==null;if(nl=0,$e=De=ue=null,pi=!1,pn=0,Ca=null,t)throw Error(o(300));e===null||We||(e=e.dependencies,e!==null&&ui(e)&&(We=!0))}function Qr(e,t,l,a){ue=e;var n=0;do{if(Da&&(Ca=null),pn=0,Da=!1,25<=n)throw Error(o(301));if(n+=1,$e=De=null,e.updateQueue!=null){var i=e.updateQueue;i.lastEffect=null,i.events=null,i.stores=null,i.memoCache!=null&&(i.memoCache.index=0)}h.H=Tf,i=t(l,a)}while(Da);return i}function Q0(){var e=h.H,t=e.useState()[0];return t=typeof t.then=="function"?gn(t):t,e=e.useState()[0],(De!==null?De.memoizedState:null)!==e&&(ue.flags|=1024),t}function tu(){var e=gi!==0;return gi=0,e}function lu(e,t,l){t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~l}function au(e){if(pi){for(e=e.memoizedState;e!==null;){var t=e.queue;t!==null&&(t.pending=null),e=e.next}pi=!1}nl=0,$e=De=ue=null,Da=!1,pn=gi=0,Ca=null}function ot(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return $e===null?ue.memoizedState=$e=e:$e=$e.next=e,$e}function Ke(){if(De===null){var e=ue.alternate;e=e!==null?e.memoizedState:null}else e=De.next;var t=$e===null?ue.memoizedState:$e.next;if(t!==null)$e=t,De=e;else{if(e===null)throw ue.alternate===null?Error(o(467)):Error(o(310));De=e,e={memoizedState:De.memoizedState,baseState:De.baseState,baseQueue:De.baseQueue,queue:De.queue,next:null},$e===null?ue.memoizedState=$e=e:$e=$e.next=e}return $e}function vi(){return{lastEffect:null,events:null,stores:null,memoCache:null}}function gn(e){var t=pn;return pn+=1,Ca===null&&(Ca=[]),e=Rr(Ca,e,t),t=ue,($e===null?t.memoizedState:$e.next)===null&&(t=t.alternate,h.H=t===null||t.memoizedState===null?Af:xu),e}function yi(e){if(e!==null&&typeof e=="object"){if(typeof e.then=="function")return gn(e);if(e.$$typeof===ne)return st(e)}throw Error(o(438,String(e)))}function nu(e){var t=null,l=ue.updateQueue;if(l!==null&&(t=l.memoCache),t==null){var a=ue.alternate;a!==null&&(a=a.updateQueue,a!==null&&(a=a.memoCache,a!=null&&(t={data:a.data.map(function(n){return n.slice()}),index:0})))}if(t==null&&(t={data:[],index:0}),l===null&&(l=vi(),ue.updateQueue=l),l.memoCache=t,l=t.data[t.index],l===void 0)for(l=t.data[t.index]=Array(e),a=0;a<e;a++)l[a]=Qe;return t.index++,l}function il(e,t){return typeof t=="function"?t(e):t}function bi(e){var t=Ke();return iu(t,De,e)}function iu(e,t,l){var a=e.queue;if(a===null)throw Error(o(311));a.lastRenderedReducer=l;var n=e.baseQueue,i=a.pending;if(i!==null){if(n!==null){var u=n.next;n.next=i.next,i.next=u}t.baseQueue=n=i,a.pending=null}if(i=e.baseState,n===null)e.memoizedState=i;else{t=n.next;var c=u=null,r=null,p=t,S=!1;do{var T=p.lane&-536870913;if(T!==p.lane?(xe&T)===T:(nl&T)===T){var g=p.revertLane;if(g===0)r!==null&&(r=r.next={lane:0,revertLane:0,gesture:null,action:p.action,hasEagerState:p.hasEagerState,eagerState:p.eagerState,next:null}),T===Ta&&(S=!0);else if((nl&g)===g){p=p.next,g===Ta&&(S=!0);continue}else T={lane:0,revertLane:p.revertLane,gesture:null,action:p.action,hasEagerState:p.hasEagerState,eagerState:p.eagerState,next:null},r===null?(c=r=T,u=i):r=r.next=T,ue.lanes|=g,Ol|=g;T=p.action,la&&l(i,T),i=p.hasEagerState?p.eagerState:l(i,T)}else g={lane:T,revertLane:p.revertLane,gesture:p.gesture,action:p.action,hasEagerState:p.hasEagerState,eagerState:p.eagerState,next:null},r===null?(c=r=g,u=i):r=r.next=g,ue.lanes|=T,Ol|=T;p=p.next}while(p!==null&&p!==t);if(r===null?u=i:r.next=c,!bt(i,e.memoizedState)&&(We=!0,S&&(l=_a,l!==null)))throw l;e.memoizedState=i,e.baseState=u,e.baseQueue=r,a.lastRenderedState=i}return n===null&&(a.lanes=0),[e.memoizedState,a.dispatch]}function su(e){var t=Ke(),l=t.queue;if(l===null)throw Error(o(311));l.lastRenderedReducer=e;var a=l.dispatch,n=l.pending,i=t.memoizedState;if(n!==null){l.pending=null;var u=n=n.next;do i=e(i,u.action),u=u.next;while(u!==n);bt(i,t.memoizedState)||(We=!0),t.memoizedState=i,t.baseQueue===null&&(t.baseState=i),l.lastRenderedState=i}return[i,a]}function Vr(e,t,l){var a=ue,n=Ke(),i=be;if(i){if(l===void 0)throw Error(o(407));l=l()}else l=t();var u=!bt((De||n).memoizedState,l);if(u&&(n.memoizedState=l,We=!0),n=n.queue,ru(Jr.bind(null,a,n,e),[e]),n.getSnapshot!==t||u||$e!==null&&$e.memoizedState.tag&1){if(a.flags|=2048,Ra(9,{destroy:void 0},Kr.bind(null,a,n,l,t),null),Ue===null)throw Error(o(349));i||(nl&127)!==0||Zr(a,t,l)}return l}function Zr(e,t,l){e.flags|=16384,e={getSnapshot:t,value:l},t=ue.updateQueue,t===null?(t=vi(),ue.updateQueue=t,t.stores=[e]):(l=t.stores,l===null?t.stores=[e]:l.push(e))}function Kr(e,t,l,a){t.value=l,t.getSnapshot=a,kr(t)&&$r(e)}function Jr(e,t,l){return l(function(){kr(t)&&$r(e)})}function kr(e){var t=e.getSnapshot;e=e.value;try{var l=t();return!bt(e,l)}catch{return!0}}function $r(e){var t=Jl(e,2);t!==null&&vt(t,e,2)}function uu(e){var t=ot();if(typeof e=="function"){var l=e;if(e=l(),la){ye(!0);try{l()}finally{ye(!1)}}}return t.memoizedState=t.baseState=e,t.queue={pending:null,lanes:0,dispatch:null,lastRenderedReducer:il,lastRenderedState:e},t}function Wr(e,t,l,a){return e.baseState=l,iu(e,De,typeof a=="function"?a:il)}function V0(e,t,l,a,n){if(Si(e))throw Error(o(485));if(e=t.action,e!==null){var i={payload:n,action:e,next:null,isTransition:!0,status:"pending",value:null,reason:null,listeners:[],then:function(u){i.listeners.push(u)}};h.T!==null?l(!0):i.isTransition=!1,a(i),l=t.pending,l===null?(i.next=t.pending=i,Fr(t,i)):(i.next=l.next,t.pending=l.next=i)}}function Fr(e,t){var l=t.action,a=t.payload,n=e.state;if(t.isTransition){var i=h.T,u={};h.T=u;try{var c=l(n,a),r=h.S;r!==null&&r(u,c),Pr(e,t,c)}catch(p){cu(e,t,p)}finally{i!==null&&u.types!==null&&(i.types=u.types),h.T=i}}else try{i=l(n,a),Pr(e,t,i)}catch(p){cu(e,t,p)}}function Pr(e,t,l){l!==null&&typeof l=="object"&&typeof l.then=="function"?l.then(function(a){Ir(e,t,a)},function(a){return cu(e,t,a)}):Ir(e,t,l)}function Ir(e,t,l){t.status="fulfilled",t.value=l,ef(t),e.state=l,t=e.pending,t!==null&&(l=t.next,l===t?e.pending=null:(l=l.next,t.next=l,Fr(e,l)))}function cu(e,t,l){var a=e.pending;if(e.pending=null,a!==null){a=a.next;do t.status="rejected",t.reason=l,ef(t),t=t.next;while(t!==a)}e.action=null}function ef(e){e=e.listeners;for(var t=0;t<e.length;t++)(0,e[t])()}function tf(e,t){return t}function lf(e,t){if(be){var l=Ue.formState;if(l!==null){e:{var a=ue;if(be){if(He){t:{for(var n=He,i=wt;n.nodeType!==8;){if(!i){n=null;break t}if(n=Bt(n.nextSibling),n===null){n=null;break t}}i=n.data,n=i==="F!"||i==="F"?n:null}if(n){He=Bt(n.nextSibling),a=n.data==="F!";break e}}bl(a)}a=!1}a&&(t=l[0])}}return l=ot(),l.memoizedState=l.baseState=t,a={pending:null,lanes:0,dispatch:null,lastRenderedReducer:tf,lastRenderedState:t},l.queue=a,l=Nf.bind(null,ue,a),a.dispatch=l,a=uu(!1),i=hu.bind(null,ue,!1,a.queue),a=ot(),n={state:t,dispatch:null,action:e,pending:null},a.queue=n,l=V0.bind(null,ue,n,i,l),n.dispatch=l,a.memoizedState=e,[t,l,!1]}function af(e){var t=Ke();return nf(t,De,e)}function nf(e,t,l){if(t=iu(e,t,tf)[0],e=bi(il)[0],typeof t=="object"&&t!==null&&typeof t.then=="function")try{var a=gn(t)}catch(u){throw u===za?fi:u}else a=t;t=Ke();var n=t.queue,i=n.dispatch;return l!==t.memoizedState&&(ue.flags|=2048,Ra(9,{destroy:void 0},Z0.bind(null,n,l),null)),[a,i,e]}function Z0(e,t){e.action=t}function sf(e){var t=Ke(),l=De;if(l!==null)return nf(t,l,e);Ke(),t=t.memoizedState,l=Ke();var a=l.queue.dispatch;return l.memoizedState=e,[t,a,!1]}function Ra(e,t,l,a){return e={tag:e,create:l,deps:a,inst:t,next:null},t=ue.updateQueue,t===null&&(t=vi(),ue.updateQueue=t),l=t.lastEffect,l===null?t.lastEffect=e.next=e:(a=l.next,l.next=e,e.next=a,t.lastEffect=e),e}function uf(){return Ke().memoizedState}function ji(e,t,l,a){var n=ot();ue.flags|=e,n.memoizedState=Ra(1|t,{destroy:void 0},l,a===void 0?null:a)}function Ni(e,t,l,a){var n=Ke();a=a===void 0?null:a;var i=n.memoizedState.inst;De!==null&&a!==null&&Is(a,De.memoizedState.deps)?n.memoizedState=Ra(t,i,l,a):(ue.flags|=e,n.memoizedState=Ra(1|t,i,l,a))}function cf(e,t){ji(8390656,8,e,t)}function ru(e,t){Ni(2048,8,e,t)}function K0(e){ue.flags|=4;var t=ue.updateQueue;if(t===null)t=vi(),ue.updateQueue=t,t.events=[e];else{var l=t.events;l===null?t.events=[e]:l.push(e)}}function rf(e){var t=Ke().memoizedState;return K0({ref:t,nextImpl:e}),function(){if((Te&2)!==0)throw Error(o(440));return t.impl.apply(void 0,arguments)}}function ff(e,t){return Ni(4,2,e,t)}function of(e,t){return Ni(4,4,e,t)}function df(e,t){if(typeof t=="function"){e=e();var l=t(e);return function(){typeof l=="function"?l():t(null)}}if(t!=null)return e=e(),t.current=e,function(){t.current=null}}function mf(e,t,l){l=l!=null?l.concat([e]):null,Ni(4,4,df.bind(null,t,e),l)}function fu(){}function hf(e,t){var l=Ke();t=t===void 0?null:t;var a=l.memoizedState;return t!==null&&Is(t,a[1])?a[0]:(l.memoizedState=[e,t],e)}function xf(e,t){var l=Ke();t=t===void 0?null:t;var a=l.memoizedState;if(t!==null&&Is(t,a[1]))return a[0];if(a=e(),la){ye(!0);try{e()}finally{ye(!1)}}return l.memoizedState=[a,t],a}function ou(e,t,l){return l===void 0||(nl&1073741824)!==0&&(xe&261930)===0?e.memoizedState=t:(e.memoizedState=l,e=go(),ue.lanes|=e,Ol|=e,l)}function pf(e,t,l,a){return bt(l,t)?l:Ma.current!==null?(e=ou(e,l,a),bt(e,t)||(We=!0),e):(nl&42)===0||(nl&1073741824)!==0&&(xe&261930)===0?(We=!0,e.memoizedState=l):(e=go(),ue.lanes|=e,Ol|=e,t)}function gf(e,t,l,a,n){var i=O.p;O.p=i!==0&&8>i?i:8;var u=h.T,c={};h.T=c,hu(e,!1,t,l);try{var r=n(),p=h.S;if(p!==null&&p(c,r),r!==null&&typeof r=="object"&&typeof r.then=="function"){var S=G0(r,a);vn(e,t,S,Tt(e))}else vn(e,t,a,Tt(e))}catch(T){vn(e,t,{then:function(){},status:"rejected",reason:T},Tt())}finally{O.p=i,u!==null&&c.types!==null&&(u.types=c.types),h.T=u}}function J0(){}function du(e,t,l,a){if(e.tag!==5)throw Error(o(476));var n=vf(e).queue;gf(e,n,t,L,l===null?J0:function(){return yf(e),l(a)})}function vf(e){var t=e.memoizedState;if(t!==null)return t;t={memoizedState:L,baseState:L,baseQueue:null,queue:{pending:null,lanes:0,dispatch:null,lastRenderedReducer:il,lastRenderedState:L},next:null};var l={};return t.next={memoizedState:l,baseState:l,baseQueue:null,queue:{pending:null,lanes:0,dispatch:null,lastRenderedReducer:il,lastRenderedState:l},next:null},e.memoizedState=t,e=e.alternate,e!==null&&(e.memoizedState=t),t}function yf(e){var t=vf(e);t.next===null&&(t=e.alternate.memoizedState),vn(e,t.next.queue,{},Tt())}function mu(){return st(wn)}function bf(){return Ke().memoizedState}function jf(){return Ke().memoizedState}function k0(e){for(var t=e.return;t!==null;){switch(t.tag){case 24:case 3:var l=Tt();e=Sl(l);var a=El(t,e,l);a!==null&&(vt(a,t,l),mn(a,t,l)),t={cache:Xs()},e.payload=t;return}t=t.return}}function $0(e,t,l){var a=Tt();l={lane:a,revertLane:0,gesture:null,action:l,hasEagerState:!1,eagerState:null,next:null},Si(e)?Sf(t,l):(l=Ds(e,t,l,a),l!==null&&(vt(l,e,a),Ef(l,t,a)))}function Nf(e,t,l){var a=Tt();vn(e,t,l,a)}function vn(e,t,l,a){var n={lane:a,revertLane:0,gesture:null,action:l,hasEagerState:!1,eagerState:null,next:null};if(Si(e))Sf(t,n);else{var i=e.alternate;if(e.lanes===0&&(i===null||i.lanes===0)&&(i=t.lastRenderedReducer,i!==null))try{var u=t.lastRenderedState,c=i(u,l);if(n.hasEagerState=!0,n.eagerState=c,bt(c,u))return ai(e,t,n,0),Ue===null&&li(),!1}catch{}if(l=Ds(e,t,n,a),l!==null)return vt(l,e,a),Ef(l,t,a),!0}return!1}function hu(e,t,l,a){if(a={lane:2,revertLane:Ku(),gesture:null,action:a,hasEagerState:!1,eagerState:null,next:null},Si(e)){if(t)throw Error(o(479))}else t=Ds(e,l,a,2),t!==null&&vt(t,e,2)}function Si(e){var t=e.alternate;return e===ue||t!==null&&t===ue}function Sf(e,t){Da=pi=!0;var l=e.pending;l===null?t.next=t:(t.next=l.next,l.next=t),e.pending=t}function Ef(e,t,l){if((l&4194048)!==0){var a=t.lanes;a&=e.pendingLanes,l|=a,t.lanes=l,zc(e,l)}}var yn={readContext:st,use:yi,useCallback:Ge,useContext:Ge,useEffect:Ge,useImperativeHandle:Ge,useLayoutEffect:Ge,useInsertionEffect:Ge,useMemo:Ge,useReducer:Ge,useRef:Ge,useState:Ge,useDebugValue:Ge,useDeferredValue:Ge,useTransition:Ge,useSyncExternalStore:Ge,useId:Ge,useHostTransitionStatus:Ge,useFormState:Ge,useActionState:Ge,useOptimistic:Ge,useMemoCache:Ge,useCacheRefresh:Ge};yn.useEffectEvent=Ge;var Af={readContext:st,use:yi,useCallback:function(e,t){return ot().memoizedState=[e,t===void 0?null:t],e},useContext:st,useEffect:cf,useImperativeHandle:function(e,t,l){l=l!=null?l.concat([e]):null,ji(4194308,4,df.bind(null,t,e),l)},useLayoutEffect:function(e,t){return ji(4194308,4,e,t)},useInsertionEffect:function(e,t){ji(4,2,e,t)},useMemo:function(e,t){var l=ot();t=t===void 0?null:t;var a=e();if(la){ye(!0);try{e()}finally{ye(!1)}}return l.memoizedState=[a,t],a},useReducer:function(e,t,l){var a=ot();if(l!==void 0){var n=l(t);if(la){ye(!0);try{l(t)}finally{ye(!1)}}}else n=t;return a.memoizedState=a.baseState=n,e={pending:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:n},a.queue=e,e=e.dispatch=$0.bind(null,ue,e),[a.memoizedState,e]},useRef:function(e){var t=ot();return e={current:e},t.memoizedState=e},useState:function(e){e=uu(e);var t=e.queue,l=Nf.bind(null,ue,t);return t.dispatch=l,[e.memoizedState,l]},useDebugValue:fu,useDeferredValue:function(e,t){var l=ot();return ou(l,e,t)},useTransition:function(){var e=uu(!1);return e=gf.bind(null,ue,e.queue,!0,!1),ot().memoizedState=e,[!1,e]},useSyncExternalStore:function(e,t,l){var a=ue,n=ot();if(be){if(l===void 0)throw Error(o(407));l=l()}else{if(l=t(),Ue===null)throw Error(o(349));(xe&127)!==0||Zr(a,t,l)}n.memoizedState=l;var i={value:l,getSnapshot:t};return n.queue=i,cf(Jr.bind(null,a,i,e),[e]),a.flags|=2048,Ra(9,{destroy:void 0},Kr.bind(null,a,i,l,t),null),l},useId:function(){var e=ot(),t=Ue.identifierPrefix;if(be){var l=Zt,a=Vt;l=(a&~(1<<32-at(a)-1)).toString(32)+l,t="_"+t+"R_"+l,l=gi++,0<l&&(t+="H"+l.toString(32)),t+="_"}else l=X0++,t="_"+t+"r_"+l.toString(32)+"_";return e.memoizedState=t},useHostTransitionStatus:mu,useFormState:lf,useActionState:lf,useOptimistic:function(e){var t=ot();t.memoizedState=t.baseState=e;var l={pending:null,lanes:0,dispatch:null,lastRenderedReducer:null,lastRenderedState:null};return t.queue=l,t=hu.bind(null,ue,!0,l),l.dispatch=t,[e,t]},useMemoCache:nu,useCacheRefresh:function(){return ot().memoizedState=k0.bind(null,ue)},useEffectEvent:function(e){var t=ot(),l={impl:e};return t.memoizedState=l,function(){if((Te&2)!==0)throw Error(o(440));return l.impl.apply(void 0,arguments)}}},xu={readContext:st,use:yi,useCallback:hf,useContext:st,useEffect:ru,useImperativeHandle:mf,useInsertionEffect:ff,useLayoutEffect:of,useMemo:xf,useReducer:bi,useRef:uf,useState:function(){return bi(il)},useDebugValue:fu,useDeferredValue:function(e,t){var l=Ke();return pf(l,De.memoizedState,e,t)},useTransition:function(){var e=bi(il)[0],t=Ke().memoizedState;return[typeof e=="boolean"?e:gn(e),t]},useSyncExternalStore:Vr,useId:bf,useHostTransitionStatus:mu,useFormState:af,useActionState:af,useOptimistic:function(e,t){var l=Ke();return Wr(l,De,e,t)},useMemoCache:nu,useCacheRefresh:jf};xu.useEffectEvent=rf;var Tf={readContext:st,use:yi,useCallback:hf,useContext:st,useEffect:ru,useImperativeHandle:mf,useInsertionEffect:ff,useLayoutEffect:of,useMemo:xf,useReducer:su,useRef:uf,useState:function(){return su(il)},useDebugValue:fu,useDeferredValue:function(e,t){var l=Ke();return De===null?ou(l,e,t):pf(l,De.memoizedState,e,t)},useTransition:function(){var e=su(il)[0],t=Ke().memoizedState;return[typeof e=="boolean"?e:gn(e),t]},useSyncExternalStore:Vr,useId:bf,useHostTransitionStatus:mu,useFormState:sf,useActionState:sf,useOptimistic:function(e,t){var l=Ke();return De!==null?Wr(l,De,e,t):(l.baseState=e,[e,l.queue.dispatch])},useMemoCache:nu,useCacheRefresh:jf};Tf.useEffectEvent=rf;function pu(e,t,l,a){t=e.memoizedState,l=l(a,t),l=l==null?t:M({},t,l),e.memoizedState=l,e.lanes===0&&(e.updateQueue.baseState=l)}var gu={enqueueSetState:function(e,t,l){e=e._reactInternals;var a=Tt(),n=Sl(a);n.payload=t,l!=null&&(n.callback=l),t=El(e,n,a),t!==null&&(vt(t,e,a),mn(t,e,a))},enqueueReplaceState:function(e,t,l){e=e._reactInternals;var a=Tt(),n=Sl(a);n.tag=1,n.payload=t,l!=null&&(n.callback=l),t=El(e,n,a),t!==null&&(vt(t,e,a),mn(t,e,a))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var l=Tt(),a=Sl(l);a.tag=2,t!=null&&(a.callback=t),t=El(e,a,l),t!==null&&(vt(t,e,l),mn(t,e,l))}};function _f(e,t,l,a,n,i,u){return e=e.stateNode,typeof e.shouldComponentUpdate=="function"?e.shouldComponentUpdate(a,i,u):t.prototype&&t.prototype.isPureReactComponent?!nn(l,a)||!nn(n,i):!0}function zf(e,t,l,a){e=t.state,typeof t.componentWillReceiveProps=="function"&&t.componentWillReceiveProps(l,a),typeof t.UNSAFE_componentWillReceiveProps=="function"&&t.UNSAFE_componentWillReceiveProps(l,a),t.state!==e&&gu.enqueueReplaceState(t,t.state,null)}function aa(e,t){var l=t;if("ref"in t){l={};for(var a in t)a!=="ref"&&(l[a]=t[a])}if(e=e.defaultProps){l===t&&(l=M({},l));for(var n in e)l[n]===void 0&&(l[n]=e[n])}return l}function Of(e){ti(e)}function Mf(e){console.error(e)}function Df(e){ti(e)}function Ei(e,t){try{var l=e.onUncaughtError;l(t.value,{componentStack:t.stack})}catch(a){setTimeout(function(){throw a})}}function Cf(e,t,l){try{var a=e.onCaughtError;a(l.value,{componentStack:l.stack,errorBoundary:t.tag===1?t.stateNode:null})}catch(n){setTimeout(function(){throw n})}}function vu(e,t,l){return l=Sl(l),l.tag=3,l.payload={element:null},l.callback=function(){Ei(e,t)},l}function Rf(e){return e=Sl(e),e.tag=3,e}function Uf(e,t,l,a){var n=l.type.getDerivedStateFromError;if(typeof n=="function"){var i=a.value;e.payload=function(){return n(i)},e.callback=function(){Cf(t,l,a)}}var u=l.stateNode;u!==null&&typeof u.componentDidCatch=="function"&&(e.callback=function(){Cf(t,l,a),typeof n!="function"&&(Ml===null?Ml=new Set([this]):Ml.add(this));var c=a.stack;this.componentDidCatch(a.value,{componentStack:c!==null?c:""})})}function W0(e,t,l,a,n){if(l.flags|=32768,a!==null&&typeof a=="object"&&typeof a.then=="function"){if(t=l.alternate,t!==null&&Aa(t,l,n,!0),l=Nt.current,l!==null){switch(l.tag){case 31:case 13:return Ht===null?Hi():l.alternate===null&&Xe===0&&(Xe=3),l.flags&=-257,l.flags|=65536,l.lanes=n,a===oi?l.flags|=16384:(t=l.updateQueue,t===null?l.updateQueue=new Set([a]):t.add(a),Qu(e,a,n)),!1;case 22:return l.flags|=65536,a===oi?l.flags|=16384:(t=l.updateQueue,t===null?(t={transitions:null,markerInstances:null,retryQueue:new Set([a])},l.updateQueue=t):(l=t.retryQueue,l===null?t.retryQueue=new Set([a]):l.add(a)),Qu(e,a,n)),!1}throw Error(o(435,l.tag))}return Qu(e,a,n),Hi(),!1}if(be)return t=Nt.current,t!==null?((t.flags&65536)===0&&(t.flags|=256),t.flags|=65536,t.lanes=n,a!==Bs&&(e=Error(o(422),{cause:a}),cn(Ct(e,l)))):(a!==Bs&&(t=Error(o(423),{cause:a}),cn(Ct(t,l))),e=e.current.alternate,e.flags|=65536,n&=-n,e.lanes|=n,a=Ct(a,l),n=vu(e.stateNode,a,n),ks(e,n),Xe!==4&&(Xe=2)),!1;var i=Error(o(520),{cause:a});if(i=Ct(i,l),_n===null?_n=[i]:_n.push(i),Xe!==4&&(Xe=2),t===null)return!0;a=Ct(a,l),l=t;do{switch(l.tag){case 3:return l.flags|=65536,e=n&-n,l.lanes|=e,e=vu(l.stateNode,a,e),ks(l,e),!1;case 1:if(t=l.type,i=l.stateNode,(l.flags&128)===0&&(typeof t.getDerivedStateFromError=="function"||i!==null&&typeof i.componentDidCatch=="function"&&(Ml===null||!Ml.has(i))))return l.flags|=65536,n&=-n,l.lanes|=n,n=Rf(n),Uf(n,e,l,a),ks(l,n),!1}l=l.return}while(l!==null);return!1}var yu=Error(o(461)),We=!1;function ut(e,t,l,a){t.child=e===null?Br(t,null,l,a):ta(t,e.child,l,a)}function wf(e,t,l,a,n){l=l.render;var i=t.ref;if("ref"in a){var u={};for(var c in a)c!=="ref"&&(u[c]=a[c])}else u=a;return Fl(t),a=eu(e,t,l,u,i,n),c=tu(),e!==null&&!We?(lu(e,t,n),sl(e,t,n)):(be&&c&&ws(t),t.flags|=1,ut(e,t,a,n),t.child)}function Hf(e,t,l,a,n){if(e===null){var i=l.type;return typeof i=="function"&&!Cs(i)&&i.defaultProps===void 0&&l.compare===null?(t.tag=15,t.type=i,Bf(e,t,i,a,n)):(e=ii(l.type,null,a,t,t.mode,n),e.ref=t.ref,e.return=t,t.child=e)}if(i=e.child,!_u(e,n)){var u=i.memoizedProps;if(l=l.compare,l=l!==null?l:nn,l(u,a)&&e.ref===t.ref)return sl(e,t,n)}return t.flags|=1,e=el(i,a),e.ref=t.ref,e.return=t,t.child=e}function Bf(e,t,l,a,n){if(e!==null){var i=e.memoizedProps;if(nn(i,a)&&e.ref===t.ref)if(We=!1,t.pendingProps=a=i,_u(e,n))(e.flags&131072)!==0&&(We=!0);else return t.lanes=e.lanes,sl(e,t,n)}return bu(e,t,l,a,n)}function Lf(e,t,l,a){var n=a.children,i=e!==null?e.memoizedState:null;if(e===null&&t.stateNode===null&&(t.stateNode={_visibility:1,_pendingMarkers:null,_retryCache:null,_transitions:null}),a.mode==="hidden"){if((t.flags&128)!==0){if(i=i!==null?i.baseLanes|l:l,e!==null){for(a=t.child=e.child,n=0;a!==null;)n=n|a.lanes|a.childLanes,a=a.sibling;a=n&~i}else a=0,t.child=null;return qf(e,t,i,l,a)}if((l&536870912)!==0)t.memoizedState={baseLanes:0,cachePool:null},e!==null&&ri(t,i!==null?i.cachePool:null),i!==null?Yr(t,i):Ws(),Gr(t);else return a=t.lanes=536870912,qf(e,t,i!==null?i.baseLanes|l:l,l,a)}else i!==null?(ri(t,i.cachePool),Yr(t,i),Tl(),t.memoizedState=null):(e!==null&&ri(t,null),Ws(),Tl());return ut(e,t,n,l),t.child}function bn(e,t){return e!==null&&e.tag===22||t.stateNode!==null||(t.stateNode={_visibility:1,_pendingMarkers:null,_retryCache:null,_transitions:null}),t.sibling}function qf(e,t,l,a,n){var i=Vs();return i=i===null?null:{parent:ke._currentValue,pool:i},t.memoizedState={baseLanes:l,cachePool:i},e!==null&&ri(t,null),Ws(),Gr(t),e!==null&&Aa(e,t,a,!0),t.childLanes=n,null}function Ai(e,t){return t=_i({mode:t.mode,children:t.children},e.mode),t.ref=e.ref,e.child=t,t.return=e,t}function Yf(e,t,l){return ta(t,e.child,null,l),e=Ai(t,t.pendingProps),e.flags|=2,St(t),t.memoizedState=null,e}function F0(e,t,l){var a=t.pendingProps,n=(t.flags&128)!==0;if(t.flags&=-129,e===null){if(be){if(a.mode==="hidden")return e=Ai(t,a),t.lanes=536870912,bn(null,e);if(Ps(t),(e=He)?(e=Io(e,wt),e=e!==null&&e.data==="&"?e:null,e!==null&&(t.memoizedState={dehydrated:e,treeContext:vl!==null?{id:Vt,overflow:Zt}:null,retryLane:536870912,hydrationErrors:null},l=Nr(e),l.return=t,t.child=l,it=t,He=null)):e=null,e===null)throw bl(t);return t.lanes=536870912,null}return Ai(t,a)}var i=e.memoizedState;if(i!==null){var u=i.dehydrated;if(Ps(t),n)if(t.flags&256)t.flags&=-257,t=Yf(e,t,l);else if(t.memoizedState!==null)t.child=e.child,t.flags|=128,t=null;else throw Error(o(558));else if(We||Aa(e,t,l,!1),n=(l&e.childLanes)!==0,We||n){if(a=Ue,a!==null&&(u=Oc(a,l),u!==0&&u!==i.retryLane))throw i.retryLane=u,Jl(e,u),vt(a,e,u),yu;Hi(),t=Yf(e,t,l)}else e=i.treeContext,He=Bt(u.nextSibling),it=t,be=!0,yl=null,wt=!1,e!==null&&Ar(t,e),t=Ai(t,a),t.flags|=4096;return t}return e=el(e.child,{mode:a.mode,children:a.children}),e.ref=t.ref,t.child=e,e.return=t,e}function Ti(e,t){var l=t.ref;if(l===null)e!==null&&e.ref!==null&&(t.flags|=4194816);else{if(typeof l!="function"&&typeof l!="object")throw Error(o(284));(e===null||e.ref!==l)&&(t.flags|=4194816)}}function bu(e,t,l,a,n){return Fl(t),l=eu(e,t,l,a,void 0,n),a=tu(),e!==null&&!We?(lu(e,t,n),sl(e,t,n)):(be&&a&&ws(t),t.flags|=1,ut(e,t,l,n),t.child)}function Gf(e,t,l,a,n,i){return Fl(t),t.updateQueue=null,l=Qr(t,a,l,n),Xr(e),a=tu(),e!==null&&!We?(lu(e,t,i),sl(e,t,i)):(be&&a&&ws(t),t.flags|=1,ut(e,t,l,i),t.child)}function Xf(e,t,l,a,n){if(Fl(t),t.stateNode===null){var i=ja,u=l.contextType;typeof u=="object"&&u!==null&&(i=st(u)),i=new l(a,i),t.memoizedState=i.state!==null&&i.state!==void 0?i.state:null,i.updater=gu,t.stateNode=i,i._reactInternals=t,i=t.stateNode,i.props=a,i.state=t.memoizedState,i.refs={},Ks(t),u=l.contextType,i.context=typeof u=="object"&&u!==null?st(u):ja,i.state=t.memoizedState,u=l.getDerivedStateFromProps,typeof u=="function"&&(pu(t,l,u,a),i.state=t.memoizedState),typeof l.getDerivedStateFromProps=="function"||typeof i.getSnapshotBeforeUpdate=="function"||typeof i.UNSAFE_componentWillMount!="function"&&typeof i.componentWillMount!="function"||(u=i.state,typeof i.componentWillMount=="function"&&i.componentWillMount(),typeof i.UNSAFE_componentWillMount=="function"&&i.UNSAFE_componentWillMount(),u!==i.state&&gu.enqueueReplaceState(i,i.state,null),xn(t,a,i,n),hn(),i.state=t.memoizedState),typeof i.componentDidMount=="function"&&(t.flags|=4194308),a=!0}else if(e===null){i=t.stateNode;var c=t.memoizedProps,r=aa(l,c);i.props=r;var p=i.context,S=l.contextType;u=ja,typeof S=="object"&&S!==null&&(u=st(S));var T=l.getDerivedStateFromProps;S=typeof T=="function"||typeof i.getSnapshotBeforeUpdate=="function",c=t.pendingProps!==c,S||typeof i.UNSAFE_componentWillReceiveProps!="function"&&typeof i.componentWillReceiveProps!="function"||(c||p!==u)&&zf(t,i,a,u),Nl=!1;var g=t.memoizedState;i.state=g,xn(t,a,i,n),hn(),p=t.memoizedState,c||g!==p||Nl?(typeof T=="function"&&(pu(t,l,T,a),p=t.memoizedState),(r=Nl||_f(t,l,r,a,g,p,u))?(S||typeof i.UNSAFE_componentWillMount!="function"&&typeof i.componentWillMount!="function"||(typeof i.componentWillMount=="function"&&i.componentWillMount(),typeof i.UNSAFE_componentWillMount=="function"&&i.UNSAFE_componentWillMount()),typeof i.componentDidMount=="function"&&(t.flags|=4194308)):(typeof i.componentDidMount=="function"&&(t.flags|=4194308),t.memoizedProps=a,t.memoizedState=p),i.props=a,i.state=p,i.context=u,a=r):(typeof i.componentDidMount=="function"&&(t.flags|=4194308),a=!1)}else{i=t.stateNode,Js(e,t),u=t.memoizedProps,S=aa(l,u),i.props=S,T=t.pendingProps,g=i.context,p=l.contextType,r=ja,typeof p=="object"&&p!==null&&(r=st(p)),c=l.getDerivedStateFromProps,(p=typeof c=="function"||typeof i.getSnapshotBeforeUpdate=="function")||typeof i.UNSAFE_componentWillReceiveProps!="function"&&typeof i.componentWillReceiveProps!="function"||(u!==T||g!==r)&&zf(t,i,a,r),Nl=!1,g=t.memoizedState,i.state=g,xn(t,a,i,n),hn();var b=t.memoizedState;u!==T||g!==b||Nl||e!==null&&e.dependencies!==null&&ui(e.dependencies)?(typeof c=="function"&&(pu(t,l,c,a),b=t.memoizedState),(S=Nl||_f(t,l,S,a,g,b,r)||e!==null&&e.dependencies!==null&&ui(e.dependencies))?(p||typeof i.UNSAFE_componentWillUpdate!="function"&&typeof i.componentWillUpdate!="function"||(typeof i.componentWillUpdate=="function"&&i.componentWillUpdate(a,b,r),typeof i.UNSAFE_componentWillUpdate=="function"&&i.UNSAFE_componentWillUpdate(a,b,r)),typeof i.componentDidUpdate=="function"&&(t.flags|=4),typeof i.getSnapshotBeforeUpdate=="function"&&(t.flags|=1024)):(typeof i.componentDidUpdate!="function"||u===e.memoizedProps&&g===e.memoizedState||(t.flags|=4),typeof i.getSnapshotBeforeUpdate!="function"||u===e.memoizedProps&&g===e.memoizedState||(t.flags|=1024),t.memoizedProps=a,t.memoizedState=b),i.props=a,i.state=b,i.context=r,a=S):(typeof i.componentDidUpdate!="function"||u===e.memoizedProps&&g===e.memoizedState||(t.flags|=4),typeof i.getSnapshotBeforeUpdate!="function"||u===e.memoizedProps&&g===e.memoizedState||(t.flags|=1024),a=!1)}return i=a,Ti(e,t),a=(t.flags&128)!==0,i||a?(i=t.stateNode,l=a&&typeof l.getDerivedStateFromError!="function"?null:i.render(),t.flags|=1,e!==null&&a?(t.child=ta(t,e.child,null,n),t.child=ta(t,null,l,n)):ut(e,t,l,n),t.memoizedState=i.state,e=t.child):e=sl(e,t,n),e}function Qf(e,t,l,a){return $l(),t.flags|=256,ut(e,t,l,a),t.child}var ju={dehydrated:null,treeContext:null,retryLane:0,hydrationErrors:null};function Nu(e){return{baseLanes:e,cachePool:Dr()}}function Su(e,t,l){return e=e!==null?e.childLanes&~l:0,t&&(e|=At),e}function Vf(e,t,l){var a=t.pendingProps,n=!1,i=(t.flags&128)!==0,u;if((u=i)||(u=e!==null&&e.memoizedState===null?!1:(Ze.current&2)!==0),u&&(n=!0,t.flags&=-129),u=(t.flags&32)!==0,t.flags&=-33,e===null){if(be){if(n?Al(t):Tl(),(e=He)?(e=Io(e,wt),e=e!==null&&e.data!=="&"?e:null,e!==null&&(t.memoizedState={dehydrated:e,treeContext:vl!==null?{id:Vt,overflow:Zt}:null,retryLane:536870912,hydrationErrors:null},l=Nr(e),l.return=t,t.child=l,it=t,He=null)):e=null,e===null)throw bl(t);return ic(e)?t.lanes=32:t.lanes=536870912,null}var c=a.children;return a=a.fallback,n?(Tl(),n=t.mode,c=_i({mode:"hidden",children:c},n),a=kl(a,n,l,null),c.return=t,a.return=t,c.sibling=a,t.child=c,a=t.child,a.memoizedState=Nu(l),a.childLanes=Su(e,u,l),t.memoizedState=ju,bn(null,a)):(Al(t),Eu(t,c))}var r=e.memoizedState;if(r!==null&&(c=r.dehydrated,c!==null)){if(i)t.flags&256?(Al(t),t.flags&=-257,t=Au(e,t,l)):t.memoizedState!==null?(Tl(),t.child=e.child,t.flags|=128,t=null):(Tl(),c=a.fallback,n=t.mode,a=_i({mode:"visible",children:a.children},n),c=kl(c,n,l,null),c.flags|=2,a.return=t,c.return=t,a.sibling=c,t.child=a,ta(t,e.child,null,l),a=t.child,a.memoizedState=Nu(l),a.childLanes=Su(e,u,l),t.memoizedState=ju,t=bn(null,a));else if(Al(t),ic(c)){if(u=c.nextSibling&&c.nextSibling.dataset,u)var p=u.dgst;u=p,a=Error(o(419)),a.stack="",a.digest=u,cn({value:a,source:null,stack:null}),t=Au(e,t,l)}else if(We||Aa(e,t,l,!1),u=(l&e.childLanes)!==0,We||u){if(u=Ue,u!==null&&(a=Oc(u,l),a!==0&&a!==r.retryLane))throw r.retryLane=a,Jl(e,a),vt(u,e,a),yu;nc(c)||Hi(),t=Au(e,t,l)}else nc(c)?(t.flags|=192,t.child=e.child,t=null):(e=r.treeContext,He=Bt(c.nextSibling),it=t,be=!0,yl=null,wt=!1,e!==null&&Ar(t,e),t=Eu(t,a.children),t.flags|=4096);return t}return n?(Tl(),c=a.fallback,n=t.mode,r=e.child,p=r.sibling,a=el(r,{mode:"hidden",children:a.children}),a.subtreeFlags=r.subtreeFlags&65011712,p!==null?c=el(p,c):(c=kl(c,n,l,null),c.flags|=2),c.return=t,a.return=t,a.sibling=c,t.child=a,bn(null,a),a=t.child,c=e.child.memoizedState,c===null?c=Nu(l):(n=c.cachePool,n!==null?(r=ke._currentValue,n=n.parent!==r?{parent:r,pool:r}:n):n=Dr(),c={baseLanes:c.baseLanes|l,cachePool:n}),a.memoizedState=c,a.childLanes=Su(e,u,l),t.memoizedState=ju,bn(e.child,a)):(Al(t),l=e.child,e=l.sibling,l=el(l,{mode:"visible",children:a.children}),l.return=t,l.sibling=null,e!==null&&(u=t.deletions,u===null?(t.deletions=[e],t.flags|=16):u.push(e)),t.child=l,t.memoizedState=null,l)}function Eu(e,t){return t=_i({mode:"visible",children:t},e.mode),t.return=e,e.child=t}function _i(e,t){return e=jt(22,e,null,t),e.lanes=0,e}function Au(e,t,l){return ta(t,e.child,null,l),e=Eu(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function Zf(e,t,l){e.lanes|=t;var a=e.alternate;a!==null&&(a.lanes|=t),Ys(e.return,t,l)}function Tu(e,t,l,a,n,i){var u=e.memoizedState;u===null?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:a,tail:l,tailMode:n,treeForkCount:i}:(u.isBackwards=t,u.rendering=null,u.renderingStartTime=0,u.last=a,u.tail=l,u.tailMode=n,u.treeForkCount=i)}function Kf(e,t,l){var a=t.pendingProps,n=a.revealOrder,i=a.tail;a=a.children;var u=Ze.current,c=(u&2)!==0;if(c?(u=u&1|2,t.flags|=128):u&=1,C(Ze,u),ut(e,t,a,l),a=be?un:0,!c&&e!==null&&(e.flags&128)!==0)e:for(e=t.child;e!==null;){if(e.tag===13)e.memoizedState!==null&&Zf(e,l,t);else if(e.tag===19)Zf(e,l,t);else if(e.child!==null){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;e.sibling===null;){if(e.return===null||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}switch(n){case"forwards":for(l=t.child,n=null;l!==null;)e=l.alternate,e!==null&&xi(e)===null&&(n=l),l=l.sibling;l=n,l===null?(n=t.child,t.child=null):(n=l.sibling,l.sibling=null),Tu(t,!1,n,l,i,a);break;case"backwards":case"unstable_legacy-backwards":for(l=null,n=t.child,t.child=null;n!==null;){if(e=n.alternate,e!==null&&xi(e)===null){t.child=n;break}e=n.sibling,n.sibling=l,l=n,n=e}Tu(t,!0,l,null,i,a);break;case"together":Tu(t,!1,null,null,void 0,a);break;default:t.memoizedState=null}return t.child}function sl(e,t,l){if(e!==null&&(t.dependencies=e.dependencies),Ol|=t.lanes,(l&t.childLanes)===0)if(e!==null){if(Aa(e,t,l,!1),(l&t.childLanes)===0)return null}else return null;if(e!==null&&t.child!==e.child)throw Error(o(153));if(t.child!==null){for(e=t.child,l=el(e,e.pendingProps),t.child=l,l.return=t;e.sibling!==null;)e=e.sibling,l=l.sibling=el(e,e.pendingProps),l.return=t;l.sibling=null}return t.child}function _u(e,t){return(e.lanes&t)!==0?!0:(e=e.dependencies,!!(e!==null&&ui(e)))}function P0(e,t,l){switch(t.tag){case 3:Ve(t,t.stateNode.containerInfo),jl(t,ke,e.memoizedState.cache),$l();break;case 27:case 5:_t(t);break;case 4:Ve(t,t.stateNode.containerInfo);break;case 10:jl(t,t.type,t.memoizedProps.value);break;case 31:if(t.memoizedState!==null)return t.flags|=128,Ps(t),null;break;case 13:var a=t.memoizedState;if(a!==null)return a.dehydrated!==null?(Al(t),t.flags|=128,null):(l&t.child.childLanes)!==0?Vf(e,t,l):(Al(t),e=sl(e,t,l),e!==null?e.sibling:null);Al(t);break;case 19:var n=(e.flags&128)!==0;if(a=(l&t.childLanes)!==0,a||(Aa(e,t,l,!1),a=(l&t.childLanes)!==0),n){if(a)return Kf(e,t,l);t.flags|=128}if(n=t.memoizedState,n!==null&&(n.rendering=null,n.tail=null,n.lastEffect=null),C(Ze,Ze.current),a)break;return null;case 22:return t.lanes=0,Lf(e,t,l,t.pendingProps);case 24:jl(t,ke,e.memoizedState.cache)}return sl(e,t,l)}function Jf(e,t,l){if(e!==null)if(e.memoizedProps!==t.pendingProps)We=!0;else{if(!_u(e,l)&&(t.flags&128)===0)return We=!1,P0(e,t,l);We=(e.flags&131072)!==0}else We=!1,be&&(t.flags&1048576)!==0&&Er(t,un,t.index);switch(t.lanes=0,t.tag){case 16:e:{var a=t.pendingProps;if(e=Il(t.elementType),t.type=e,typeof e=="function")Cs(e)?(a=aa(e,a),t.tag=1,t=Xf(null,t,e,a,l)):(t.tag=0,t=bu(null,t,e,a,l));else{if(e!=null){var n=e.$$typeof;if(n===ee){t.tag=11,t=wf(null,t,e,a,l);break e}else if(n===Y){t.tag=14,t=Hf(null,t,e,a,l);break e}}throw t=Je(e)||e,Error(o(306,t,""))}}return t;case 0:return bu(e,t,t.type,t.pendingProps,l);case 1:return a=t.type,n=aa(a,t.pendingProps),Xf(e,t,a,n,l);case 3:e:{if(Ve(t,t.stateNode.containerInfo),e===null)throw Error(o(387));a=t.pendingProps;var i=t.memoizedState;n=i.element,Js(e,t),xn(t,a,null,l);var u=t.memoizedState;if(a=u.cache,jl(t,ke,a),a!==i.cache&&Gs(t,[ke],l,!0),hn(),a=u.element,i.isDehydrated)if(i={element:a,isDehydrated:!1,cache:u.cache},t.updateQueue.baseState=i,t.memoizedState=i,t.flags&256){t=Qf(e,t,a,l);break e}else if(a!==n){n=Ct(Error(o(424)),t),cn(n),t=Qf(e,t,a,l);break e}else for(e=t.stateNode.containerInfo,e.nodeType===9?e=e.body:e=e.nodeName==="HTML"?e.ownerDocument.body:e,He=Bt(e.firstChild),it=t,be=!0,yl=null,wt=!0,l=Br(t,null,a,l),t.child=l;l;)l.flags=l.flags&-3|4096,l=l.sibling;else{if($l(),a===n){t=sl(e,t,l);break e}ut(e,t,a,l)}t=t.child}return t;case 26:return Ti(e,t),e===null?(l=id(t.type,null,t.pendingProps,null))?t.memoizedState=l:be||(l=t.type,e=t.pendingProps,a=Qi(se.current).createElement(l),a[nt]=t,a[dt]=e,ct(a,l,e),tt(a),t.stateNode=a):t.memoizedState=id(t.type,e.memoizedProps,t.pendingProps,e.memoizedState),null;case 27:return _t(t),e===null&&be&&(a=t.stateNode=ld(t.type,t.pendingProps,se.current),it=t,wt=!0,n=He,Ul(t.type)?(sc=n,He=Bt(a.firstChild)):He=n),ut(e,t,t.pendingProps.children,l),Ti(e,t),e===null&&(t.flags|=4194304),t.child;case 5:return e===null&&be&&((n=a=He)&&(a=zm(a,t.type,t.pendingProps,wt),a!==null?(t.stateNode=a,it=t,He=Bt(a.firstChild),wt=!1,n=!0):n=!1),n||bl(t)),_t(t),n=t.type,i=t.pendingProps,u=e!==null?e.memoizedProps:null,a=i.children,tc(n,i)?a=null:u!==null&&tc(n,u)&&(t.flags|=32),t.memoizedState!==null&&(n=eu(e,t,Q0,null,null,l),wn._currentValue=n),Ti(e,t),ut(e,t,a,l),t.child;case 6:return e===null&&be&&((e=l=He)&&(l=Om(l,t.pendingProps,wt),l!==null?(t.stateNode=l,it=t,He=null,e=!0):e=!1),e||bl(t)),null;case 13:return Vf(e,t,l);case 4:return Ve(t,t.stateNode.containerInfo),a=t.pendingProps,e===null?t.child=ta(t,null,a,l):ut(e,t,a,l),t.child;case 11:return wf(e,t,t.type,t.pendingProps,l);case 7:return ut(e,t,t.pendingProps,l),t.child;case 8:return ut(e,t,t.pendingProps.children,l),t.child;case 12:return ut(e,t,t.pendingProps.children,l),t.child;case 10:return a=t.pendingProps,jl(t,t.type,a.value),ut(e,t,a.children,l),t.child;case 9:return n=t.type._context,a=t.pendingProps.children,Fl(t),n=st(n),a=a(n),t.flags|=1,ut(e,t,a,l),t.child;case 14:return Hf(e,t,t.type,t.pendingProps,l);case 15:return Bf(e,t,t.type,t.pendingProps,l);case 19:return Kf(e,t,l);case 31:return F0(e,t,l);case 22:return Lf(e,t,l,t.pendingProps);case 24:return Fl(t),a=st(ke),e===null?(n=Vs(),n===null&&(n=Ue,i=Xs(),n.pooledCache=i,i.refCount++,i!==null&&(n.pooledCacheLanes|=l),n=i),t.memoizedState={parent:a,cache:n},Ks(t),jl(t,ke,n)):((e.lanes&l)!==0&&(Js(e,t),xn(t,null,null,l),hn()),n=e.memoizedState,i=t.memoizedState,n.parent!==a?(n={parent:a,cache:a},t.memoizedState=n,t.lanes===0&&(t.memoizedState=t.updateQueue.baseState=n),jl(t,ke,a)):(a=i.cache,jl(t,ke,a),a!==n.cache&&Gs(t,[ke],l,!0))),ut(e,t,t.pendingProps.children,l),t.child;case 29:throw t.pendingProps}throw Error(o(156,t.tag))}function ul(e){e.flags|=4}function zu(e,t,l,a,n){if((t=(e.mode&32)!==0)&&(t=!1),t){if(e.flags|=16777216,(n&335544128)===n)if(e.stateNode.complete)e.flags|=8192;else if(jo())e.flags|=8192;else throw ea=oi,Zs}else e.flags&=-16777217}function kf(e,t){if(t.type!=="stylesheet"||(t.state.loading&4)!==0)e.flags&=-16777217;else if(e.flags|=16777216,!fd(t))if(jo())e.flags|=8192;else throw ea=oi,Zs}function zi(e,t){t!==null&&(e.flags|=4),e.flags&16384&&(t=e.tag!==22?Tc():536870912,e.lanes|=t,Ba|=t)}function jn(e,t){if(!be)switch(e.tailMode){case"hidden":t=e.tail;for(var l=null;t!==null;)t.alternate!==null&&(l=t),t=t.sibling;l===null?e.tail=null:l.sibling=null;break;case"collapsed":l=e.tail;for(var a=null;l!==null;)l.alternate!==null&&(a=l),l=l.sibling;a===null?t||e.tail===null?e.tail=null:e.tail.sibling=null:a.sibling=null}}function Be(e){var t=e.alternate!==null&&e.alternate.child===e.child,l=0,a=0;if(t)for(var n=e.child;n!==null;)l|=n.lanes|n.childLanes,a|=n.subtreeFlags&65011712,a|=n.flags&65011712,n.return=e,n=n.sibling;else for(n=e.child;n!==null;)l|=n.lanes|n.childLanes,a|=n.subtreeFlags,a|=n.flags,n.return=e,n=n.sibling;return e.subtreeFlags|=a,e.childLanes=l,t}function I0(e,t,l){var a=t.pendingProps;switch(Hs(t),t.tag){case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Be(t),null;case 1:return Be(t),null;case 3:return l=t.stateNode,a=null,e!==null&&(a=e.memoizedState.cache),t.memoizedState.cache!==a&&(t.flags|=2048),al(ke),we(),l.pendingContext&&(l.context=l.pendingContext,l.pendingContext=null),(e===null||e.child===null)&&(Ea(t)?ul(t):e===null||e.memoizedState.isDehydrated&&(t.flags&256)===0||(t.flags|=1024,Ls())),Be(t),null;case 26:var n=t.type,i=t.memoizedState;return e===null?(ul(t),i!==null?(Be(t),kf(t,i)):(Be(t),zu(t,n,null,a,l))):i?i!==e.memoizedState?(ul(t),Be(t),kf(t,i)):(Be(t),t.flags&=-16777217):(e=e.memoizedProps,e!==a&&ul(t),Be(t),zu(t,n,e,a,l)),null;case 27:if(zt(t),l=se.current,n=t.type,e!==null&&t.stateNode!=null)e.memoizedProps!==a&&ul(t);else{if(!a){if(t.stateNode===null)throw Error(o(166));return Be(t),null}e=B.current,Ea(t)?Tr(t):(e=ld(n,a,l),t.stateNode=e,ul(t))}return Be(t),null;case 5:if(zt(t),n=t.type,e!==null&&t.stateNode!=null)e.memoizedProps!==a&&ul(t);else{if(!a){if(t.stateNode===null)throw Error(o(166));return Be(t),null}if(i=B.current,Ea(t))Tr(t);else{var u=Qi(se.current);switch(i){case 1:i=u.createElementNS("http://www.w3.org/2000/svg",n);break;case 2:i=u.createElementNS("http://www.w3.org/1998/Math/MathML",n);break;default:switch(n){case"svg":i=u.createElementNS("http://www.w3.org/2000/svg",n);break;case"math":i=u.createElementNS("http://www.w3.org/1998/Math/MathML",n);break;case"script":i=u.createElement("div"),i.innerHTML="<script><\/script>",i=i.removeChild(i.firstChild);break;case"select":i=typeof a.is=="string"?u.createElement("select",{is:a.is}):u.createElement("select"),a.multiple?i.multiple=!0:a.size&&(i.size=a.size);break;default:i=typeof a.is=="string"?u.createElement(n,{is:a.is}):u.createElement(n)}}i[nt]=t,i[dt]=a;e:for(u=t.child;u!==null;){if(u.tag===5||u.tag===6)i.appendChild(u.stateNode);else if(u.tag!==4&&u.tag!==27&&u.child!==null){u.child.return=u,u=u.child;continue}if(u===t)break e;for(;u.sibling===null;){if(u.return===null||u.return===t)break e;u=u.return}u.sibling.return=u.return,u=u.sibling}t.stateNode=i;e:switch(ct(i,n,a),n){case"button":case"input":case"select":case"textarea":a=!!a.autoFocus;break e;case"img":a=!0;break e;default:a=!1}a&&ul(t)}}return Be(t),zu(t,t.type,e===null?null:e.memoizedProps,t.pendingProps,l),null;case 6:if(e&&t.stateNode!=null)e.memoizedProps!==a&&ul(t);else{if(typeof a!="string"&&t.stateNode===null)throw Error(o(166));if(e=se.current,Ea(t)){if(e=t.stateNode,l=t.memoizedProps,a=null,n=it,n!==null)switch(n.tag){case 27:case 5:a=n.memoizedProps}e[nt]=t,e=!!(e.nodeValue===l||a!==null&&a.suppressHydrationWarning===!0||Zo(e.nodeValue,l)),e||bl(t,!0)}else e=Qi(e).createTextNode(a),e[nt]=t,t.stateNode=e}return Be(t),null;case 31:if(l=t.memoizedState,e===null||e.memoizedState!==null){if(a=Ea(t),l!==null){if(e===null){if(!a)throw Error(o(318));if(e=t.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(o(557));e[nt]=t}else $l(),(t.flags&128)===0&&(t.memoizedState=null),t.flags|=4;Be(t),e=!1}else l=Ls(),e!==null&&e.memoizedState!==null&&(e.memoizedState.hydrationErrors=l),e=!0;if(!e)return t.flags&256?(St(t),t):(St(t),null);if((t.flags&128)!==0)throw Error(o(558))}return Be(t),null;case 13:if(a=t.memoizedState,e===null||e.memoizedState!==null&&e.memoizedState.dehydrated!==null){if(n=Ea(t),a!==null&&a.dehydrated!==null){if(e===null){if(!n)throw Error(o(318));if(n=t.memoizedState,n=n!==null?n.dehydrated:null,!n)throw Error(o(317));n[nt]=t}else $l(),(t.flags&128)===0&&(t.memoizedState=null),t.flags|=4;Be(t),n=!1}else n=Ls(),e!==null&&e.memoizedState!==null&&(e.memoizedState.hydrationErrors=n),n=!0;if(!n)return t.flags&256?(St(t),t):(St(t),null)}return St(t),(t.flags&128)!==0?(t.lanes=l,t):(l=a!==null,e=e!==null&&e.memoizedState!==null,l&&(a=t.child,n=null,a.alternate!==null&&a.alternate.memoizedState!==null&&a.alternate.memoizedState.cachePool!==null&&(n=a.alternate.memoizedState.cachePool.pool),i=null,a.memoizedState!==null&&a.memoizedState.cachePool!==null&&(i=a.memoizedState.cachePool.pool),i!==n&&(a.flags|=2048)),l!==e&&l&&(t.child.flags|=8192),zi(t,t.updateQueue),Be(t),null);case 4:return we(),e===null&&Wu(t.stateNode.containerInfo),Be(t),null;case 10:return al(t.type),Be(t),null;case 19:if(E(Ze),a=t.memoizedState,a===null)return Be(t),null;if(n=(t.flags&128)!==0,i=a.rendering,i===null)if(n)jn(a,!1);else{if(Xe!==0||e!==null&&(e.flags&128)!==0)for(e=t.child;e!==null;){if(i=xi(e),i!==null){for(t.flags|=128,jn(a,!1),e=i.updateQueue,t.updateQueue=e,zi(t,e),t.subtreeFlags=0,e=l,l=t.child;l!==null;)jr(l,e),l=l.sibling;return C(Ze,Ze.current&1|2),be&&tl(t,a.treeForkCount),t.child}e=e.sibling}a.tail!==null&&V()>Ri&&(t.flags|=128,n=!0,jn(a,!1),t.lanes=4194304)}else{if(!n)if(e=xi(i),e!==null){if(t.flags|=128,n=!0,e=e.updateQueue,t.updateQueue=e,zi(t,e),jn(a,!0),a.tail===null&&a.tailMode==="hidden"&&!i.alternate&&!be)return Be(t),null}else 2*V()-a.renderingStartTime>Ri&&l!==536870912&&(t.flags|=128,n=!0,jn(a,!1),t.lanes=4194304);a.isBackwards?(i.sibling=t.child,t.child=i):(e=a.last,e!==null?e.sibling=i:t.child=i,a.last=i)}return a.tail!==null?(e=a.tail,a.rendering=e,a.tail=e.sibling,a.renderingStartTime=V(),e.sibling=null,l=Ze.current,C(Ze,n?l&1|2:l&1),be&&tl(t,a.treeForkCount),e):(Be(t),null);case 22:case 23:return St(t),Fs(),a=t.memoizedState!==null,e!==null?e.memoizedState!==null!==a&&(t.flags|=8192):a&&(t.flags|=8192),a?(l&536870912)!==0&&(t.flags&128)===0&&(Be(t),t.subtreeFlags&6&&(t.flags|=8192)):Be(t),l=t.updateQueue,l!==null&&zi(t,l.retryQueue),l=null,e!==null&&e.memoizedState!==null&&e.memoizedState.cachePool!==null&&(l=e.memoizedState.cachePool.pool),a=null,t.memoizedState!==null&&t.memoizedState.cachePool!==null&&(a=t.memoizedState.cachePool.pool),a!==l&&(t.flags|=2048),e!==null&&E(Pl),null;case 24:return l=null,e!==null&&(l=e.memoizedState.cache),t.memoizedState.cache!==l&&(t.flags|=2048),al(ke),Be(t),null;case 25:return null;case 30:return null}throw Error(o(156,t.tag))}function em(e,t){switch(Hs(t),t.tag){case 1:return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 3:return al(ke),we(),e=t.flags,(e&65536)!==0&&(e&128)===0?(t.flags=e&-65537|128,t):null;case 26:case 27:case 5:return zt(t),null;case 31:if(t.memoizedState!==null){if(St(t),t.alternate===null)throw Error(o(340));$l()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 13:if(St(t),e=t.memoizedState,e!==null&&e.dehydrated!==null){if(t.alternate===null)throw Error(o(340));$l()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 19:return E(Ze),null;case 4:return we(),null;case 10:return al(t.type),null;case 22:case 23:return St(t),Fs(),e!==null&&E(Pl),e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 24:return al(ke),null;case 25:return null;default:return null}}function $f(e,t){switch(Hs(t),t.tag){case 3:al(ke),we();break;case 26:case 27:case 5:zt(t);break;case 4:we();break;case 31:t.memoizedState!==null&&St(t);break;case 13:St(t);break;case 19:E(Ze);break;case 10:al(t.type);break;case 22:case 23:St(t),Fs(),e!==null&&E(Pl);break;case 24:al(ke)}}function Nn(e,t){try{var l=t.updateQueue,a=l!==null?l.lastEffect:null;if(a!==null){var n=a.next;l=n;do{if((l.tag&e)===e){a=void 0;var i=l.create,u=l.inst;a=i(),u.destroy=a}l=l.next}while(l!==n)}}catch(c){ze(t,t.return,c)}}function _l(e,t,l){try{var a=t.updateQueue,n=a!==null?a.lastEffect:null;if(n!==null){var i=n.next;a=i;do{if((a.tag&e)===e){var u=a.inst,c=u.destroy;if(c!==void 0){u.destroy=void 0,n=t;var r=l,p=c;try{p()}catch(S){ze(n,r,S)}}}a=a.next}while(a!==i)}}catch(S){ze(t,t.return,S)}}function Wf(e){var t=e.updateQueue;if(t!==null){var l=e.stateNode;try{qr(t,l)}catch(a){ze(e,e.return,a)}}}function Ff(e,t,l){l.props=aa(e.type,e.memoizedProps),l.state=e.memoizedState;try{l.componentWillUnmount()}catch(a){ze(e,t,a)}}function Sn(e,t){try{var l=e.ref;if(l!==null){switch(e.tag){case 26:case 27:case 5:var a=e.stateNode;break;case 30:a=e.stateNode;break;default:a=e.stateNode}typeof l=="function"?e.refCleanup=l(a):l.current=a}}catch(n){ze(e,t,n)}}function Kt(e,t){var l=e.ref,a=e.refCleanup;if(l!==null)if(typeof a=="function")try{a()}catch(n){ze(e,t,n)}finally{e.refCleanup=null,e=e.alternate,e!=null&&(e.refCleanup=null)}else if(typeof l=="function")try{l(null)}catch(n){ze(e,t,n)}else l.current=null}function Pf(e){var t=e.type,l=e.memoizedProps,a=e.stateNode;try{e:switch(t){case"button":case"input":case"select":case"textarea":l.autoFocus&&a.focus();break e;case"img":l.src?a.src=l.src:l.srcSet&&(a.srcset=l.srcSet)}}catch(n){ze(e,e.return,n)}}function Ou(e,t,l){try{var a=e.stateNode;Nm(a,e.type,l,t),a[dt]=t}catch(n){ze(e,e.return,n)}}function If(e){return e.tag===5||e.tag===3||e.tag===26||e.tag===27&&Ul(e.type)||e.tag===4}function Mu(e){e:for(;;){for(;e.sibling===null;){if(e.return===null||If(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;e.tag!==5&&e.tag!==6&&e.tag!==18;){if(e.tag===27&&Ul(e.type)||e.flags&2||e.child===null||e.tag===4)continue e;e.child.return=e,e=e.child}if(!(e.flags&2))return e.stateNode}}function Du(e,t,l){var a=e.tag;if(a===5||a===6)e=e.stateNode,t?(l.nodeType===9?l.body:l.nodeName==="HTML"?l.ownerDocument.body:l).insertBefore(e,t):(t=l.nodeType===9?l.body:l.nodeName==="HTML"?l.ownerDocument.body:l,t.appendChild(e),l=l._reactRootContainer,l!=null||t.onclick!==null||(t.onclick=Pt));else if(a!==4&&(a===27&&Ul(e.type)&&(l=e.stateNode,t=null),e=e.child,e!==null))for(Du(e,t,l),e=e.sibling;e!==null;)Du(e,t,l),e=e.sibling}function Oi(e,t,l){var a=e.tag;if(a===5||a===6)e=e.stateNode,t?l.insertBefore(e,t):l.appendChild(e);else if(a!==4&&(a===27&&Ul(e.type)&&(l=e.stateNode),e=e.child,e!==null))for(Oi(e,t,l),e=e.sibling;e!==null;)Oi(e,t,l),e=e.sibling}function eo(e){var t=e.stateNode,l=e.memoizedProps;try{for(var a=e.type,n=t.attributes;n.length;)t.removeAttributeNode(n[0]);ct(t,a,l),t[nt]=e,t[dt]=l}catch(i){ze(e,e.return,i)}}var cl=!1,Fe=!1,Cu=!1,to=typeof WeakSet=="function"?WeakSet:Set,lt=null;function tm(e,t){if(e=e.containerInfo,Iu=Wi,e=dr(e),As(e)){if("selectionStart"in e)var l={start:e.selectionStart,end:e.selectionEnd};else e:{l=(l=e.ownerDocument)&&l.defaultView||window;var a=l.getSelection&&l.getSelection();if(a&&a.rangeCount!==0){l=a.anchorNode;var n=a.anchorOffset,i=a.focusNode;a=a.focusOffset;try{l.nodeType,i.nodeType}catch{l=null;break e}var u=0,c=-1,r=-1,p=0,S=0,T=e,g=null;t:for(;;){for(var b;T!==l||n!==0&&T.nodeType!==3||(c=u+n),T!==i||a!==0&&T.nodeType!==3||(r=u+a),T.nodeType===3&&(u+=T.nodeValue.length),(b=T.firstChild)!==null;)g=T,T=b;for(;;){if(T===e)break t;if(g===l&&++p===n&&(c=u),g===i&&++S===a&&(r=u),(b=T.nextSibling)!==null)break;T=g,g=T.parentNode}T=b}l=c===-1||r===-1?null:{start:c,end:r}}else l=null}l=l||{start:0,end:0}}else l=null;for(ec={focusedElem:e,selectionRange:l},Wi=!1,lt=t;lt!==null;)if(t=lt,e=t.child,(t.subtreeFlags&1028)!==0&&e!==null)e.return=t,lt=e;else for(;lt!==null;){switch(t=lt,i=t.alternate,e=t.flags,t.tag){case 0:if((e&4)!==0&&(e=t.updateQueue,e=e!==null?e.events:null,e!==null))for(l=0;l<e.length;l++)n=e[l],n.ref.impl=n.nextImpl;break;case 11:case 15:break;case 1:if((e&1024)!==0&&i!==null){e=void 0,l=t,n=i.memoizedProps,i=i.memoizedState,a=l.stateNode;try{var q=aa(l.type,n);e=a.getSnapshotBeforeUpdate(q,i),a.__reactInternalSnapshotBeforeUpdate=e}catch(I){ze(l,l.return,I)}}break;case 3:if((e&1024)!==0){if(e=t.stateNode.containerInfo,l=e.nodeType,l===9)ac(e);else if(l===1)switch(e.nodeName){case"HEAD":case"HTML":case"BODY":ac(e);break;default:e.textContent=""}}break;case 5:case 26:case 27:case 6:case 4:case 17:break;default:if((e&1024)!==0)throw Error(o(163))}if(e=t.sibling,e!==null){e.return=t.return,lt=e;break}lt=t.return}}function lo(e,t,l){var a=l.flags;switch(l.tag){case 0:case 11:case 15:fl(e,l),a&4&&Nn(5,l);break;case 1:if(fl(e,l),a&4)if(e=l.stateNode,t===null)try{e.componentDidMount()}catch(u){ze(l,l.return,u)}else{var n=aa(l.type,t.memoizedProps);t=t.memoizedState;try{e.componentDidUpdate(n,t,e.__reactInternalSnapshotBeforeUpdate)}catch(u){ze(l,l.return,u)}}a&64&&Wf(l),a&512&&Sn(l,l.return);break;case 3:if(fl(e,l),a&64&&(e=l.updateQueue,e!==null)){if(t=null,l.child!==null)switch(l.child.tag){case 27:case 5:t=l.child.stateNode;break;case 1:t=l.child.stateNode}try{qr(e,t)}catch(u){ze(l,l.return,u)}}break;case 27:t===null&&a&4&&eo(l);case 26:case 5:fl(e,l),t===null&&a&4&&Pf(l),a&512&&Sn(l,l.return);break;case 12:fl(e,l);break;case 31:fl(e,l),a&4&&io(e,l);break;case 13:fl(e,l),a&4&&so(e,l),a&64&&(e=l.memoizedState,e!==null&&(e=e.dehydrated,e!==null&&(l=fm.bind(null,l),Mm(e,l))));break;case 22:if(a=l.memoizedState!==null||cl,!a){t=t!==null&&t.memoizedState!==null||Fe,n=cl;var i=Fe;cl=a,(Fe=t)&&!i?ol(e,l,(l.subtreeFlags&8772)!==0):fl(e,l),cl=n,Fe=i}break;case 30:break;default:fl(e,l)}}function ao(e){var t=e.alternate;t!==null&&(e.alternate=null,ao(t)),e.child=null,e.deletions=null,e.sibling=null,e.tag===5&&(t=e.stateNode,t!==null&&cs(t)),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}var Le=null,ht=!1;function rl(e,t,l){for(l=l.child;l!==null;)no(e,t,l),l=l.sibling}function no(e,t,l){if(qe&&typeof qe.onCommitFiberUnmount=="function")try{qe.onCommitFiberUnmount(P,l)}catch{}switch(l.tag){case 26:Fe||Kt(l,t),rl(e,t,l),l.memoizedState?l.memoizedState.count--:l.stateNode&&(l=l.stateNode,l.parentNode.removeChild(l));break;case 27:Fe||Kt(l,t);var a=Le,n=ht;Ul(l.type)&&(Le=l.stateNode,ht=!1),rl(e,t,l),Cn(l.stateNode),Le=a,ht=n;break;case 5:Fe||Kt(l,t);case 6:if(a=Le,n=ht,Le=null,rl(e,t,l),Le=a,ht=n,Le!==null)if(ht)try{(Le.nodeType===9?Le.body:Le.nodeName==="HTML"?Le.ownerDocument.body:Le).removeChild(l.stateNode)}catch(i){ze(l,t,i)}else try{Le.removeChild(l.stateNode)}catch(i){ze(l,t,i)}break;case 18:Le!==null&&(ht?(e=Le,Fo(e.nodeType===9?e.body:e.nodeName==="HTML"?e.ownerDocument.body:e,l.stateNode),Za(e)):Fo(Le,l.stateNode));break;case 4:a=Le,n=ht,Le=l.stateNode.containerInfo,ht=!0,rl(e,t,l),Le=a,ht=n;break;case 0:case 11:case 14:case 15:_l(2,l,t),Fe||_l(4,l,t),rl(e,t,l);break;case 1:Fe||(Kt(l,t),a=l.stateNode,typeof a.componentWillUnmount=="function"&&Ff(l,t,a)),rl(e,t,l);break;case 21:rl(e,t,l);break;case 22:Fe=(a=Fe)||l.memoizedState!==null,rl(e,t,l),Fe=a;break;default:rl(e,t,l)}}function io(e,t){if(t.memoizedState===null&&(e=t.alternate,e!==null&&(e=e.memoizedState,e!==null))){e=e.dehydrated;try{Za(e)}catch(l){ze(t,t.return,l)}}}function so(e,t){if(t.memoizedState===null&&(e=t.alternate,e!==null&&(e=e.memoizedState,e!==null&&(e=e.dehydrated,e!==null))))try{Za(e)}catch(l){ze(t,t.return,l)}}function lm(e){switch(e.tag){case 31:case 13:case 19:var t=e.stateNode;return t===null&&(t=e.stateNode=new to),t;case 22:return e=e.stateNode,t=e._retryCache,t===null&&(t=e._retryCache=new to),t;default:throw Error(o(435,e.tag))}}function Mi(e,t){var l=lm(e);t.forEach(function(a){if(!l.has(a)){l.add(a);var n=om.bind(null,e,a);a.then(n,n)}})}function xt(e,t){var l=t.deletions;if(l!==null)for(var a=0;a<l.length;a++){var n=l[a],i=e,u=t,c=u;e:for(;c!==null;){switch(c.tag){case 27:if(Ul(c.type)){Le=c.stateNode,ht=!1;break e}break;case 5:Le=c.stateNode,ht=!1;break e;case 3:case 4:Le=c.stateNode.containerInfo,ht=!0;break e}c=c.return}if(Le===null)throw Error(o(160));no(i,u,n),Le=null,ht=!1,i=n.alternate,i!==null&&(i.return=null),n.return=null}if(t.subtreeFlags&13886)for(t=t.child;t!==null;)uo(t,e),t=t.sibling}var Xt=null;function uo(e,t){var l=e.alternate,a=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:xt(t,e),pt(e),a&4&&(_l(3,e,e.return),Nn(3,e),_l(5,e,e.return));break;case 1:xt(t,e),pt(e),a&512&&(Fe||l===null||Kt(l,l.return)),a&64&&cl&&(e=e.updateQueue,e!==null&&(a=e.callbacks,a!==null&&(l=e.shared.hiddenCallbacks,e.shared.hiddenCallbacks=l===null?a:l.concat(a))));break;case 26:var n=Xt;if(xt(t,e),pt(e),a&512&&(Fe||l===null||Kt(l,l.return)),a&4){var i=l!==null?l.memoizedState:null;if(a=e.memoizedState,l===null)if(a===null)if(e.stateNode===null){e:{a=e.type,l=e.memoizedProps,n=n.ownerDocument||n;t:switch(a){case"title":i=n.getElementsByTagName("title")[0],(!i||i[$a]||i[nt]||i.namespaceURI==="http://www.w3.org/2000/svg"||i.hasAttribute("itemprop"))&&(i=n.createElement(a),n.head.insertBefore(i,n.querySelector("head > title"))),ct(i,a,l),i[nt]=e,tt(i),a=i;break e;case"link":var u=cd("link","href",n).get(a+(l.href||""));if(u){for(var c=0;c<u.length;c++)if(i=u[c],i.getAttribute("href")===(l.href==null||l.href===""?null:l.href)&&i.getAttribute("rel")===(l.rel==null?null:l.rel)&&i.getAttribute("title")===(l.title==null?null:l.title)&&i.getAttribute("crossorigin")===(l.crossOrigin==null?null:l.crossOrigin)){u.splice(c,1);break t}}i=n.createElement(a),ct(i,a,l),n.head.appendChild(i);break;case"meta":if(u=cd("meta","content",n).get(a+(l.content||""))){for(c=0;c<u.length;c++)if(i=u[c],i.getAttribute("content")===(l.content==null?null:""+l.content)&&i.getAttribute("name")===(l.name==null?null:l.name)&&i.getAttribute("property")===(l.property==null?null:l.property)&&i.getAttribute("http-equiv")===(l.httpEquiv==null?null:l.httpEquiv)&&i.getAttribute("charset")===(l.charSet==null?null:l.charSet)){u.splice(c,1);break t}}i=n.createElement(a),ct(i,a,l),n.head.appendChild(i);break;default:throw Error(o(468,a))}i[nt]=e,tt(i),a=i}e.stateNode=a}else rd(n,e.type,e.stateNode);else e.stateNode=ud(n,a,e.memoizedProps);else i!==a?(i===null?l.stateNode!==null&&(l=l.stateNode,l.parentNode.removeChild(l)):i.count--,a===null?rd(n,e.type,e.stateNode):ud(n,a,e.memoizedProps)):a===null&&e.stateNode!==null&&Ou(e,e.memoizedProps,l.memoizedProps)}break;case 27:xt(t,e),pt(e),a&512&&(Fe||l===null||Kt(l,l.return)),l!==null&&a&4&&Ou(e,e.memoizedProps,l.memoizedProps);break;case 5:if(xt(t,e),pt(e),a&512&&(Fe||l===null||Kt(l,l.return)),e.flags&32){n=e.stateNode;try{ha(n,"")}catch(q){ze(e,e.return,q)}}a&4&&e.stateNode!=null&&(n=e.memoizedProps,Ou(e,n,l!==null?l.memoizedProps:n)),a&1024&&(Cu=!0);break;case 6:if(xt(t,e),pt(e),a&4){if(e.stateNode===null)throw Error(o(162));a=e.memoizedProps,l=e.stateNode;try{l.nodeValue=a}catch(q){ze(e,e.return,q)}}break;case 3:if(Ki=null,n=Xt,Xt=Vi(t.containerInfo),xt(t,e),Xt=n,pt(e),a&4&&l!==null&&l.memoizedState.isDehydrated)try{Za(t.containerInfo)}catch(q){ze(e,e.return,q)}Cu&&(Cu=!1,co(e));break;case 4:a=Xt,Xt=Vi(e.stateNode.containerInfo),xt(t,e),pt(e),Xt=a;break;case 12:xt(t,e),pt(e);break;case 31:xt(t,e),pt(e),a&4&&(a=e.updateQueue,a!==null&&(e.updateQueue=null,Mi(e,a)));break;case 13:xt(t,e),pt(e),e.child.flags&8192&&e.memoizedState!==null!=(l!==null&&l.memoizedState!==null)&&(Ci=V()),a&4&&(a=e.updateQueue,a!==null&&(e.updateQueue=null,Mi(e,a)));break;case 22:n=e.memoizedState!==null;var r=l!==null&&l.memoizedState!==null,p=cl,S=Fe;if(cl=p||n,Fe=S||r,xt(t,e),Fe=S,cl=p,pt(e),a&8192)e:for(t=e.stateNode,t._visibility=n?t._visibility&-2:t._visibility|1,n&&(l===null||r||cl||Fe||na(e)),l=null,t=e;;){if(t.tag===5||t.tag===26){if(l===null){r=l=t;try{if(i=r.stateNode,n)u=i.style,typeof u.setProperty=="function"?u.setProperty("display","none","important"):u.display="none";else{c=r.stateNode;var T=r.memoizedProps.style,g=T!=null&&T.hasOwnProperty("display")?T.display:null;c.style.display=g==null||typeof g=="boolean"?"":(""+g).trim()}}catch(q){ze(r,r.return,q)}}}else if(t.tag===6){if(l===null){r=t;try{r.stateNode.nodeValue=n?"":r.memoizedProps}catch(q){ze(r,r.return,q)}}}else if(t.tag===18){if(l===null){r=t;try{var b=r.stateNode;n?Po(b,!0):Po(r.stateNode,!1)}catch(q){ze(r,r.return,q)}}}else if((t.tag!==22&&t.tag!==23||t.memoizedState===null||t===e)&&t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break e;for(;t.sibling===null;){if(t.return===null||t.return===e)break e;l===t&&(l=null),t=t.return}l===t&&(l=null),t.sibling.return=t.return,t=t.sibling}a&4&&(a=e.updateQueue,a!==null&&(l=a.retryQueue,l!==null&&(a.retryQueue=null,Mi(e,l))));break;case 19:xt(t,e),pt(e),a&4&&(a=e.updateQueue,a!==null&&(e.updateQueue=null,Mi(e,a)));break;case 30:break;case 21:break;default:xt(t,e),pt(e)}}function pt(e){var t=e.flags;if(t&2){try{for(var l,a=e.return;a!==null;){if(If(a)){l=a;break}a=a.return}if(l==null)throw Error(o(160));switch(l.tag){case 27:var n=l.stateNode,i=Mu(e);Oi(e,i,n);break;case 5:var u=l.stateNode;l.flags&32&&(ha(u,""),l.flags&=-33);var c=Mu(e);Oi(e,c,u);break;case 3:case 4:var r=l.stateNode.containerInfo,p=Mu(e);Du(e,p,r);break;default:throw Error(o(161))}}catch(S){ze(e,e.return,S)}e.flags&=-3}t&4096&&(e.flags&=-4097)}function co(e){if(e.subtreeFlags&1024)for(e=e.child;e!==null;){var t=e;co(t),t.tag===5&&t.flags&1024&&t.stateNode.reset(),e=e.sibling}}function fl(e,t){if(t.subtreeFlags&8772)for(t=t.child;t!==null;)lo(e,t.alternate,t),t=t.sibling}function na(e){for(e=e.child;e!==null;){var t=e;switch(t.tag){case 0:case 11:case 14:case 15:_l(4,t,t.return),na(t);break;case 1:Kt(t,t.return);var l=t.stateNode;typeof l.componentWillUnmount=="function"&&Ff(t,t.return,l),na(t);break;case 27:Cn(t.stateNode);case 26:case 5:Kt(t,t.return),na(t);break;case 22:t.memoizedState===null&&na(t);break;case 30:na(t);break;default:na(t)}e=e.sibling}}function ol(e,t,l){for(l=l&&(t.subtreeFlags&8772)!==0,t=t.child;t!==null;){var a=t.alternate,n=e,i=t,u=i.flags;switch(i.tag){case 0:case 11:case 15:ol(n,i,l),Nn(4,i);break;case 1:if(ol(n,i,l),a=i,n=a.stateNode,typeof n.componentDidMount=="function")try{n.componentDidMount()}catch(p){ze(a,a.return,p)}if(a=i,n=a.updateQueue,n!==null){var c=a.stateNode;try{var r=n.shared.hiddenCallbacks;if(r!==null)for(n.shared.hiddenCallbacks=null,n=0;n<r.length;n++)Lr(r[n],c)}catch(p){ze(a,a.return,p)}}l&&u&64&&Wf(i),Sn(i,i.return);break;case 27:eo(i);case 26:case 5:ol(n,i,l),l&&a===null&&u&4&&Pf(i),Sn(i,i.return);break;case 12:ol(n,i,l);break;case 31:ol(n,i,l),l&&u&4&&io(n,i);break;case 13:ol(n,i,l),l&&u&4&&so(n,i);break;case 22:i.memoizedState===null&&ol(n,i,l),Sn(i,i.return);break;case 30:break;default:ol(n,i,l)}t=t.sibling}}function Ru(e,t){var l=null;e!==null&&e.memoizedState!==null&&e.memoizedState.cachePool!==null&&(l=e.memoizedState.cachePool.pool),e=null,t.memoizedState!==null&&t.memoizedState.cachePool!==null&&(e=t.memoizedState.cachePool.pool),e!==l&&(e!=null&&e.refCount++,l!=null&&rn(l))}function Uu(e,t){e=null,t.alternate!==null&&(e=t.alternate.memoizedState.cache),t=t.memoizedState.cache,t!==e&&(t.refCount++,e!=null&&rn(e))}function Qt(e,t,l,a){if(t.subtreeFlags&10256)for(t=t.child;t!==null;)ro(e,t,l,a),t=t.sibling}function ro(e,t,l,a){var n=t.flags;switch(t.tag){case 0:case 11:case 15:Qt(e,t,l,a),n&2048&&Nn(9,t);break;case 1:Qt(e,t,l,a);break;case 3:Qt(e,t,l,a),n&2048&&(e=null,t.alternate!==null&&(e=t.alternate.memoizedState.cache),t=t.memoizedState.cache,t!==e&&(t.refCount++,e!=null&&rn(e)));break;case 12:if(n&2048){Qt(e,t,l,a),e=t.stateNode;try{var i=t.memoizedProps,u=i.id,c=i.onPostCommit;typeof c=="function"&&c(u,t.alternate===null?"mount":"update",e.passiveEffectDuration,-0)}catch(r){ze(t,t.return,r)}}else Qt(e,t,l,a);break;case 31:Qt(e,t,l,a);break;case 13:Qt(e,t,l,a);break;case 23:break;case 22:i=t.stateNode,u=t.alternate,t.memoizedState!==null?i._visibility&2?Qt(e,t,l,a):En(e,t):i._visibility&2?Qt(e,t,l,a):(i._visibility|=2,Ua(e,t,l,a,(t.subtreeFlags&10256)!==0||!1)),n&2048&&Ru(u,t);break;case 24:Qt(e,t,l,a),n&2048&&Uu(t.alternate,t);break;default:Qt(e,t,l,a)}}function Ua(e,t,l,a,n){for(n=n&&((t.subtreeFlags&10256)!==0||!1),t=t.child;t!==null;){var i=e,u=t,c=l,r=a,p=u.flags;switch(u.tag){case 0:case 11:case 15:Ua(i,u,c,r,n),Nn(8,u);break;case 23:break;case 22:var S=u.stateNode;u.memoizedState!==null?S._visibility&2?Ua(i,u,c,r,n):En(i,u):(S._visibility|=2,Ua(i,u,c,r,n)),n&&p&2048&&Ru(u.alternate,u);break;case 24:Ua(i,u,c,r,n),n&&p&2048&&Uu(u.alternate,u);break;default:Ua(i,u,c,r,n)}t=t.sibling}}function En(e,t){if(t.subtreeFlags&10256)for(t=t.child;t!==null;){var l=e,a=t,n=a.flags;switch(a.tag){case 22:En(l,a),n&2048&&Ru(a.alternate,a);break;case 24:En(l,a),n&2048&&Uu(a.alternate,a);break;default:En(l,a)}t=t.sibling}}var An=8192;function wa(e,t,l){if(e.subtreeFlags&An)for(e=e.child;e!==null;)fo(e,t,l),e=e.sibling}function fo(e,t,l){switch(e.tag){case 26:wa(e,t,l),e.flags&An&&e.memoizedState!==null&&Xm(l,Xt,e.memoizedState,e.memoizedProps);break;case 5:wa(e,t,l);break;case 3:case 4:var a=Xt;Xt=Vi(e.stateNode.containerInfo),wa(e,t,l),Xt=a;break;case 22:e.memoizedState===null&&(a=e.alternate,a!==null&&a.memoizedState!==null?(a=An,An=16777216,wa(e,t,l),An=a):wa(e,t,l));break;default:wa(e,t,l)}}function oo(e){var t=e.alternate;if(t!==null&&(e=t.child,e!==null)){t.child=null;do t=e.sibling,e.sibling=null,e=t;while(e!==null)}}function Tn(e){var t=e.deletions;if((e.flags&16)!==0){if(t!==null)for(var l=0;l<t.length;l++){var a=t[l];lt=a,ho(a,e)}oo(e)}if(e.subtreeFlags&10256)for(e=e.child;e!==null;)mo(e),e=e.sibling}function mo(e){switch(e.tag){case 0:case 11:case 15:Tn(e),e.flags&2048&&_l(9,e,e.return);break;case 3:Tn(e);break;case 12:Tn(e);break;case 22:var t=e.stateNode;e.memoizedState!==null&&t._visibility&2&&(e.return===null||e.return.tag!==13)?(t._visibility&=-3,Di(e)):Tn(e);break;default:Tn(e)}}function Di(e){var t=e.deletions;if((e.flags&16)!==0){if(t!==null)for(var l=0;l<t.length;l++){var a=t[l];lt=a,ho(a,e)}oo(e)}for(e=e.child;e!==null;){switch(t=e,t.tag){case 0:case 11:case 15:_l(8,t,t.return),Di(t);break;case 22:l=t.stateNode,l._visibility&2&&(l._visibility&=-3,Di(t));break;default:Di(t)}e=e.sibling}}function ho(e,t){for(;lt!==null;){var l=lt;switch(l.tag){case 0:case 11:case 15:_l(8,l,t);break;case 23:case 22:if(l.memoizedState!==null&&l.memoizedState.cachePool!==null){var a=l.memoizedState.cachePool.pool;a!=null&&a.refCount++}break;case 24:rn(l.memoizedState.cache)}if(a=l.child,a!==null)a.return=l,lt=a;else e:for(l=e;lt!==null;){a=lt;var n=a.sibling,i=a.return;if(ao(a),a===l){lt=null;break e}if(n!==null){n.return=i,lt=n;break e}lt=i}}}var am={getCacheForType:function(e){var t=st(ke),l=t.data.get(e);return l===void 0&&(l=e(),t.data.set(e,l)),l},cacheSignal:function(){return st(ke).controller.signal}},nm=typeof WeakMap=="function"?WeakMap:Map,Te=0,Ue=null,de=null,xe=0,_e=0,Et=null,zl=!1,Ha=!1,wu=!1,dl=0,Xe=0,Ol=0,ia=0,Hu=0,At=0,Ba=0,_n=null,gt=null,Bu=!1,Ci=0,xo=0,Ri=1/0,Ui=null,Ml=null,Ie=0,Dl=null,La=null,ml=0,Lu=0,qu=null,po=null,zn=0,Yu=null;function Tt(){return(Te&2)!==0&&xe!==0?xe&-xe:h.T!==null?Ku():Mc()}function go(){if(At===0)if((xe&536870912)===0||be){var e=Xn;Xn<<=1,(Xn&3932160)===0&&(Xn=262144),At=e}else At=536870912;return e=Nt.current,e!==null&&(e.flags|=32),At}function vt(e,t,l){(e===Ue&&(_e===2||_e===9)||e.cancelPendingCommit!==null)&&(qa(e,0),Cl(e,xe,At,!1)),ka(e,l),((Te&2)===0||e!==Ue)&&(e===Ue&&((Te&2)===0&&(ia|=l),Xe===4&&Cl(e,xe,At,!1)),Jt(e))}function vo(e,t,l){if((Te&6)!==0)throw Error(o(327));var a=!l&&(t&127)===0&&(t&e.expiredLanes)===0||Ja(e,t),n=a?um(e,t):Xu(e,t,!0),i=a;do{if(n===0){Ha&&!a&&Cl(e,t,0,!1);break}else{if(l=e.current.alternate,i&&!im(l)){n=Xu(e,t,!1),i=!1;continue}if(n===2){if(i=t,e.errorRecoveryDisabledLanes&i)var u=0;else u=e.pendingLanes&-536870913,u=u!==0?u:u&536870912?536870912:0;if(u!==0){t=u;e:{var c=e;n=_n;var r=c.current.memoizedState.isDehydrated;if(r&&(qa(c,u).flags|=256),u=Xu(c,u,!1),u!==2){if(wu&&!r){c.errorRecoveryDisabledLanes|=i,ia|=i,n=4;break e}i=gt,gt=n,i!==null&&(gt===null?gt=i:gt.push.apply(gt,i))}n=u}if(i=!1,n!==2)continue}}if(n===1){qa(e,0),Cl(e,t,0,!0);break}e:{switch(a=e,i=n,i){case 0:case 1:throw Error(o(345));case 4:if((t&4194048)!==t)break;case 6:Cl(a,t,At,!zl);break e;case 2:gt=null;break;case 3:case 5:break;default:throw Error(o(329))}if((t&62914560)===t&&(n=Ci+300-V(),10<n)){if(Cl(a,t,At,!zl),Vn(a,0,!0)!==0)break e;ml=t,a.timeoutHandle=$o(yo.bind(null,a,l,gt,Ui,Bu,t,At,ia,Ba,zl,i,"Throttled",-0,0),n);break e}yo(a,l,gt,Ui,Bu,t,At,ia,Ba,zl,i,null,-0,0)}}break}while(!0);Jt(e)}function yo(e,t,l,a,n,i,u,c,r,p,S,T,g,b){if(e.timeoutHandle=-1,T=t.subtreeFlags,T&8192||(T&16785408)===16785408){T={stylesheets:null,count:0,imgCount:0,imgBytes:0,suspenseyImages:[],waitingForImages:!0,waitingForViewTransition:!1,unsuspend:Pt},fo(t,i,T);var q=(i&62914560)===i?Ci-V():(i&4194048)===i?xo-V():0;if(q=Qm(T,q),q!==null){ml=i,e.cancelPendingCommit=q(_o.bind(null,e,t,i,l,a,n,u,c,r,S,T,null,g,b)),Cl(e,i,u,!p);return}}_o(e,t,i,l,a,n,u,c,r)}function im(e){for(var t=e;;){var l=t.tag;if((l===0||l===11||l===15)&&t.flags&16384&&(l=t.updateQueue,l!==null&&(l=l.stores,l!==null)))for(var a=0;a<l.length;a++){var n=l[a],i=n.getSnapshot;n=n.value;try{if(!bt(i(),n))return!1}catch{return!1}}if(l=t.child,t.subtreeFlags&16384&&l!==null)l.return=t,t=l;else{if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}function Cl(e,t,l,a){t&=~Hu,t&=~ia,e.suspendedLanes|=t,e.pingedLanes&=~t,a&&(e.warmLanes|=t),a=e.expirationTimes;for(var n=t;0<n;){var i=31-at(n),u=1<<i;a[i]=-1,n&=~u}l!==0&&_c(e,l,t)}function wi(){return(Te&6)===0?(On(0),!1):!0}function Gu(){if(de!==null){if(_e===0)var e=de.return;else e=de,ll=Wl=null,au(e),Oa=null,on=0,e=de;for(;e!==null;)$f(e.alternate,e),e=e.return;de=null}}function qa(e,t){var l=e.timeoutHandle;l!==-1&&(e.timeoutHandle=-1,Am(l)),l=e.cancelPendingCommit,l!==null&&(e.cancelPendingCommit=null,l()),ml=0,Gu(),Ue=e,de=l=el(e.current,null),xe=t,_e=0,Et=null,zl=!1,Ha=Ja(e,t),wu=!1,Ba=At=Hu=ia=Ol=Xe=0,gt=_n=null,Bu=!1,(t&8)!==0&&(t|=t&32);var a=e.entangledLanes;if(a!==0)for(e=e.entanglements,a&=t;0<a;){var n=31-at(a),i=1<<n;t|=e[n],a&=~i}return dl=t,li(),l}function bo(e,t){ue=null,h.H=yn,t===za||t===fi?(t=Ur(),_e=3):t===Zs?(t=Ur(),_e=4):_e=t===yu?8:t!==null&&typeof t=="object"&&typeof t.then=="function"?6:1,Et=t,de===null&&(Xe=1,Ei(e,Ct(t,e.current)))}function jo(){var e=Nt.current;return e===null?!0:(xe&4194048)===xe?Ht===null:(xe&62914560)===xe||(xe&536870912)!==0?e===Ht:!1}function No(){var e=h.H;return h.H=yn,e===null?yn:e}function So(){var e=h.A;return h.A=am,e}function Hi(){Xe=4,zl||(xe&4194048)!==xe&&Nt.current!==null||(Ha=!0),(Ol&134217727)===0&&(ia&134217727)===0||Ue===null||Cl(Ue,xe,At,!1)}function Xu(e,t,l){var a=Te;Te|=2;var n=No(),i=So();(Ue!==e||xe!==t)&&(Ui=null,qa(e,t)),t=!1;var u=Xe;e:do try{if(_e!==0&&de!==null){var c=de,r=Et;switch(_e){case 8:Gu(),u=6;break e;case 3:case 2:case 9:case 6:Nt.current===null&&(t=!0);var p=_e;if(_e=0,Et=null,Ya(e,c,r,p),l&&Ha){u=0;break e}break;default:p=_e,_e=0,Et=null,Ya(e,c,r,p)}}sm(),u=Xe;break}catch(S){bo(e,S)}while(!0);return t&&e.shellSuspendCounter++,ll=Wl=null,Te=a,h.H=n,h.A=i,de===null&&(Ue=null,xe=0,li()),u}function sm(){for(;de!==null;)Eo(de)}function um(e,t){var l=Te;Te|=2;var a=No(),n=So();Ue!==e||xe!==t?(Ui=null,Ri=V()+500,qa(e,t)):Ha=Ja(e,t);e:do try{if(_e!==0&&de!==null){t=de;var i=Et;t:switch(_e){case 1:_e=0,Et=null,Ya(e,t,i,1);break;case 2:case 9:if(Cr(i)){_e=0,Et=null,Ao(t);break}t=function(){_e!==2&&_e!==9||Ue!==e||(_e=7),Jt(e)},i.then(t,t);break e;case 3:_e=7;break e;case 4:_e=5;break e;case 7:Cr(i)?(_e=0,Et=null,Ao(t)):(_e=0,Et=null,Ya(e,t,i,7));break;case 5:var u=null;switch(de.tag){case 26:u=de.memoizedState;case 5:case 27:var c=de;if(u?fd(u):c.stateNode.complete){_e=0,Et=null;var r=c.sibling;if(r!==null)de=r;else{var p=c.return;p!==null?(de=p,Bi(p)):de=null}break t}}_e=0,Et=null,Ya(e,t,i,5);break;case 6:_e=0,Et=null,Ya(e,t,i,6);break;case 8:Gu(),Xe=6;break e;default:throw Error(o(462))}}cm();break}catch(S){bo(e,S)}while(!0);return ll=Wl=null,h.H=a,h.A=n,Te=l,de!==null?0:(Ue=null,xe=0,li(),Xe)}function cm(){for(;de!==null&&!Ka();)Eo(de)}function Eo(e){var t=Jf(e.alternate,e,dl);e.memoizedProps=e.pendingProps,t===null?Bi(e):de=t}function Ao(e){var t=e,l=t.alternate;switch(t.tag){case 15:case 0:t=Gf(l,t,t.pendingProps,t.type,void 0,xe);break;case 11:t=Gf(l,t,t.pendingProps,t.type.render,t.ref,xe);break;case 5:au(t);default:$f(l,t),t=de=jr(t,dl),t=Jf(l,t,dl)}e.memoizedProps=e.pendingProps,t===null?Bi(e):de=t}function Ya(e,t,l,a){ll=Wl=null,au(t),Oa=null,on=0;var n=t.return;try{if(W0(e,n,t,l,xe)){Xe=1,Ei(e,Ct(l,e.current)),de=null;return}}catch(i){if(n!==null)throw de=n,i;Xe=1,Ei(e,Ct(l,e.current)),de=null;return}t.flags&32768?(be||a===1?e=!0:Ha||(xe&536870912)!==0?e=!1:(zl=e=!0,(a===2||a===9||a===3||a===6)&&(a=Nt.current,a!==null&&a.tag===13&&(a.flags|=16384))),To(t,e)):Bi(t)}function Bi(e){var t=e;do{if((t.flags&32768)!==0){To(t,zl);return}e=t.return;var l=I0(t.alternate,t,dl);if(l!==null){de=l;return}if(t=t.sibling,t!==null){de=t;return}de=t=e}while(t!==null);Xe===0&&(Xe=5)}function To(e,t){do{var l=em(e.alternate,e);if(l!==null){l.flags&=32767,de=l;return}if(l=e.return,l!==null&&(l.flags|=32768,l.subtreeFlags=0,l.deletions=null),!t&&(e=e.sibling,e!==null)){de=e;return}de=e=l}while(e!==null);Xe=6,de=null}function _o(e,t,l,a,n,i,u,c,r){e.cancelPendingCommit=null;do Li();while(Ie!==0);if((Te&6)!==0)throw Error(o(327));if(t!==null){if(t===e.current)throw Error(o(177));if(i=t.lanes|t.childLanes,i|=Ms,Gd(e,l,i,u,c,r),e===Ue&&(de=Ue=null,xe=0),La=t,Dl=e,ml=l,Lu=i,qu=n,po=a,(t.subtreeFlags&10256)!==0||(t.flags&10256)!==0?(e.callbackNode=null,e.callbackPriority=0,dm(Me,function(){return Co(),null})):(e.callbackNode=null,e.callbackPriority=0),a=(t.flags&13878)!==0,(t.subtreeFlags&13878)!==0||a){a=h.T,h.T=null,n=O.p,O.p=2,u=Te,Te|=4;try{tm(e,t,l)}finally{Te=u,O.p=n,h.T=a}}Ie=1,zo(),Oo(),Mo()}}function zo(){if(Ie===1){Ie=0;var e=Dl,t=La,l=(t.flags&13878)!==0;if((t.subtreeFlags&13878)!==0||l){l=h.T,h.T=null;var a=O.p;O.p=2;var n=Te;Te|=4;try{uo(t,e);var i=ec,u=dr(e.containerInfo),c=i.focusedElem,r=i.selectionRange;if(u!==c&&c&&c.ownerDocument&&or(c.ownerDocument.documentElement,c)){if(r!==null&&As(c)){var p=r.start,S=r.end;if(S===void 0&&(S=p),"selectionStart"in c)c.selectionStart=p,c.selectionEnd=Math.min(S,c.value.length);else{var T=c.ownerDocument||document,g=T&&T.defaultView||window;if(g.getSelection){var b=g.getSelection(),q=c.textContent.length,I=Math.min(r.start,q),Re=r.end===void 0?I:Math.min(r.end,q);!b.extend&&I>Re&&(u=Re,Re=I,I=u);var m=fr(c,I),d=fr(c,Re);if(m&&d&&(b.rangeCount!==1||b.anchorNode!==m.node||b.anchorOffset!==m.offset||b.focusNode!==d.node||b.focusOffset!==d.offset)){var x=T.createRange();x.setStart(m.node,m.offset),b.removeAllRanges(),I>Re?(b.addRange(x),b.extend(d.node,d.offset)):(x.setEnd(d.node,d.offset),b.addRange(x))}}}}for(T=[],b=c;b=b.parentNode;)b.nodeType===1&&T.push({element:b,left:b.scrollLeft,top:b.scrollTop});for(typeof c.focus=="function"&&c.focus(),c=0;c<T.length;c++){var A=T[c];A.element.scrollLeft=A.left,A.element.scrollTop=A.top}}Wi=!!Iu,ec=Iu=null}finally{Te=n,O.p=a,h.T=l}}e.current=t,Ie=2}}function Oo(){if(Ie===2){Ie=0;var e=Dl,t=La,l=(t.flags&8772)!==0;if((t.subtreeFlags&8772)!==0||l){l=h.T,h.T=null;var a=O.p;O.p=2;var n=Te;Te|=4;try{lo(e,t.alternate,t)}finally{Te=n,O.p=a,h.T=l}}Ie=3}}function Mo(){if(Ie===4||Ie===3){Ie=0,ce();var e=Dl,t=La,l=ml,a=po;(t.subtreeFlags&10256)!==0||(t.flags&10256)!==0?Ie=5:(Ie=0,La=Dl=null,Do(e,e.pendingLanes));var n=e.pendingLanes;if(n===0&&(Ml=null),ss(l),t=t.stateNode,qe&&typeof qe.onCommitFiberRoot=="function")try{qe.onCommitFiberRoot(P,t,void 0,(t.current.flags&128)===128)}catch{}if(a!==null){t=h.T,n=O.p,O.p=2,h.T=null;try{for(var i=e.onRecoverableError,u=0;u<a.length;u++){var c=a[u];i(c.value,{componentStack:c.stack})}}finally{h.T=t,O.p=n}}(ml&3)!==0&&Li(),Jt(e),n=e.pendingLanes,(l&261930)!==0&&(n&42)!==0?e===Yu?zn++:(zn=0,Yu=e):zn=0,On(0)}}function Do(e,t){(e.pooledCacheLanes&=t)===0&&(t=e.pooledCache,t!=null&&(e.pooledCache=null,rn(t)))}function Li(){return zo(),Oo(),Mo(),Co()}function Co(){if(Ie!==5)return!1;var e=Dl,t=Lu;Lu=0;var l=ss(ml),a=h.T,n=O.p;try{O.p=32>l?32:l,h.T=null,l=qu,qu=null;var i=Dl,u=ml;if(Ie=0,La=Dl=null,ml=0,(Te&6)!==0)throw Error(o(331));var c=Te;if(Te|=4,mo(i.current),ro(i,i.current,u,l),Te=c,On(0,!1),qe&&typeof qe.onPostCommitFiberRoot=="function")try{qe.onPostCommitFiberRoot(P,i)}catch{}return!0}finally{O.p=n,h.T=a,Do(e,t)}}function Ro(e,t,l){t=Ct(l,t),t=vu(e.stateNode,t,2),e=El(e,t,2),e!==null&&(ka(e,2),Jt(e))}function ze(e,t,l){if(e.tag===3)Ro(e,e,l);else for(;t!==null;){if(t.tag===3){Ro(t,e,l);break}else if(t.tag===1){var a=t.stateNode;if(typeof t.type.getDerivedStateFromError=="function"||typeof a.componentDidCatch=="function"&&(Ml===null||!Ml.has(a))){e=Ct(l,e),l=Rf(2),a=El(t,l,2),a!==null&&(Uf(l,a,t,e),ka(a,2),Jt(a));break}}t=t.return}}function Qu(e,t,l){var a=e.pingCache;if(a===null){a=e.pingCache=new nm;var n=new Set;a.set(t,n)}else n=a.get(t),n===void 0&&(n=new Set,a.set(t,n));n.has(l)||(wu=!0,n.add(l),e=rm.bind(null,e,t,l),t.then(e,e))}function rm(e,t,l){var a=e.pingCache;a!==null&&a.delete(t),e.pingedLanes|=e.suspendedLanes&l,e.warmLanes&=~l,Ue===e&&(xe&l)===l&&(Xe===4||Xe===3&&(xe&62914560)===xe&&300>V()-Ci?(Te&2)===0&&qa(e,0):Hu|=l,Ba===xe&&(Ba=0)),Jt(e)}function Uo(e,t){t===0&&(t=Tc()),e=Jl(e,t),e!==null&&(ka(e,t),Jt(e))}function fm(e){var t=e.memoizedState,l=0;t!==null&&(l=t.retryLane),Uo(e,l)}function om(e,t){var l=0;switch(e.tag){case 31:case 13:var a=e.stateNode,n=e.memoizedState;n!==null&&(l=n.retryLane);break;case 19:a=e.stateNode;break;case 22:a=e.stateNode._retryCache;break;default:throw Error(o(314))}a!==null&&a.delete(t),Uo(e,l)}function dm(e,t){return $t(e,t)}var qi=null,Ga=null,Vu=!1,Yi=!1,Zu=!1,Rl=0;function Jt(e){e!==Ga&&e.next===null&&(Ga===null?qi=Ga=e:Ga=Ga.next=e),Yi=!0,Vu||(Vu=!0,hm())}function On(e,t){if(!Zu&&Yi){Zu=!0;do for(var l=!1,a=qi;a!==null;){if(e!==0){var n=a.pendingLanes;if(n===0)var i=0;else{var u=a.suspendedLanes,c=a.pingedLanes;i=(1<<31-at(42|e)+1)-1,i&=n&~(u&~c),i=i&201326741?i&201326741|1:i?i|2:0}i!==0&&(l=!0,Lo(a,i))}else i=xe,i=Vn(a,a===Ue?i:0,a.cancelPendingCommit!==null||a.timeoutHandle!==-1),(i&3)===0||Ja(a,i)||(l=!0,Lo(a,i));a=a.next}while(l);Zu=!1}}function mm(){wo()}function wo(){Yi=Vu=!1;var e=0;Rl!==0&&Em()&&(e=Rl);for(var t=V(),l=null,a=qi;a!==null;){var n=a.next,i=Ho(a,t);i===0?(a.next=null,l===null?qi=n:l.next=n,n===null&&(Ga=l)):(l=a,(e!==0||(i&3)!==0)&&(Yi=!0)),a=n}Ie!==0&&Ie!==5||On(e),Rl!==0&&(Rl=0)}function Ho(e,t){for(var l=e.suspendedLanes,a=e.pingedLanes,n=e.expirationTimes,i=e.pendingLanes&-62914561;0<i;){var u=31-at(i),c=1<<u,r=n[u];r===-1?((c&l)===0||(c&a)!==0)&&(n[u]=Yd(c,t)):r<=t&&(e.expiredLanes|=c),i&=~c}if(t=Ue,l=xe,l=Vn(e,e===t?l:0,e.cancelPendingCommit!==null||e.timeoutHandle!==-1),a=e.callbackNode,l===0||e===t&&(_e===2||_e===9)||e.cancelPendingCommit!==null)return a!==null&&a!==null&&Wt(a),e.callbackNode=null,e.callbackPriority=0;if((l&3)===0||Ja(e,l)){if(t=l&-l,t===e.callbackPriority)return t;switch(a!==null&&Wt(a),ss(l)){case 2:case 8:l=he;break;case 32:l=Me;break;case 268435456:l=yt;break;default:l=Me}return a=Bo.bind(null,e),l=$t(l,a),e.callbackPriority=t,e.callbackNode=l,t}return a!==null&&a!==null&&Wt(a),e.callbackPriority=2,e.callbackNode=null,2}function Bo(e,t){if(Ie!==0&&Ie!==5)return e.callbackNode=null,e.callbackPriority=0,null;var l=e.callbackNode;if(Li()&&e.callbackNode!==l)return null;var a=xe;return a=Vn(e,e===Ue?a:0,e.cancelPendingCommit!==null||e.timeoutHandle!==-1),a===0?null:(vo(e,a,t),Ho(e,V()),e.callbackNode!=null&&e.callbackNode===l?Bo.bind(null,e):null)}function Lo(e,t){if(Li())return null;vo(e,t,!0)}function hm(){Tm(function(){(Te&6)!==0?$t(re,mm):wo()})}function Ku(){if(Rl===0){var e=Ta;e===0&&(e=Gn,Gn<<=1,(Gn&261888)===0&&(Gn=256)),Rl=e}return Rl}function qo(e){return e==null||typeof e=="symbol"||typeof e=="boolean"?null:typeof e=="function"?e:kn(""+e)}function Yo(e,t){var l=t.ownerDocument.createElement("input");return l.name=t.name,l.value=t.value,e.id&&l.setAttribute("form",e.id),t.parentNode.insertBefore(l,t),e=new FormData(e),l.parentNode.removeChild(l),e}function xm(e,t,l,a,n){if(t==="submit"&&l&&l.stateNode===n){var i=qo((n[dt]||null).action),u=a.submitter;u&&(t=(t=u[dt]||null)?qo(t.formAction):u.getAttribute("formAction"),t!==null&&(i=t,u=null));var c=new Pn("action","action",null,a,n);e.push({event:c,listeners:[{instance:null,listener:function(){if(a.defaultPrevented){if(Rl!==0){var r=u?Yo(n,u):new FormData(n);du(l,{pending:!0,data:r,method:n.method,action:i},null,r)}}else typeof i=="function"&&(c.preventDefault(),r=u?Yo(n,u):new FormData(n),du(l,{pending:!0,data:r,method:n.method,action:i},i,r))},currentTarget:n}]})}}for(var Ju=0;Ju<Os.length;Ju++){var ku=Os[Ju],pm=ku.toLowerCase(),gm=ku[0].toUpperCase()+ku.slice(1);Gt(pm,"on"+gm)}Gt(xr,"onAnimationEnd"),Gt(pr,"onAnimationIteration"),Gt(gr,"onAnimationStart"),Gt("dblclick","onDoubleClick"),Gt("focusin","onFocus"),Gt("focusout","onBlur"),Gt(R0,"onTransitionRun"),Gt(U0,"onTransitionStart"),Gt(w0,"onTransitionCancel"),Gt(vr,"onTransitionEnd"),da("onMouseEnter",["mouseout","mouseover"]),da("onMouseLeave",["mouseout","mouseover"]),da("onPointerEnter",["pointerout","pointerover"]),da("onPointerLeave",["pointerout","pointerover"]),Ql("onChange","change click focusin focusout input keydown keyup selectionchange".split(" ")),Ql("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" ")),Ql("onBeforeInput",["compositionend","keypress","textInput","paste"]),Ql("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" ")),Ql("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" ")),Ql("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var Mn="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),vm=new Set("beforetoggle cancel close invalid load scroll scrollend toggle".split(" ").concat(Mn));function Go(e,t){t=(t&4)!==0;for(var l=0;l<e.length;l++){var a=e[l],n=a.event;a=a.listeners;e:{var i=void 0;if(t)for(var u=a.length-1;0<=u;u--){var c=a[u],r=c.instance,p=c.currentTarget;if(c=c.listener,r!==i&&n.isPropagationStopped())break e;i=c,n.currentTarget=p;try{i(n)}catch(S){ti(S)}n.currentTarget=null,i=r}else for(u=0;u<a.length;u++){if(c=a[u],r=c.instance,p=c.currentTarget,c=c.listener,r!==i&&n.isPropagationStopped())break e;i=c,n.currentTarget=p;try{i(n)}catch(S){ti(S)}n.currentTarget=null,i=r}}}}function me(e,t){var l=t[us];l===void 0&&(l=t[us]=new Set);var a=e+"__bubble";l.has(a)||(Xo(t,e,2,!1),l.add(a))}function $u(e,t,l){var a=0;t&&(a|=4),Xo(l,e,a,t)}var Gi="_reactListening"+Math.random().toString(36).slice(2);function Wu(e){if(!e[Gi]){e[Gi]=!0,Rc.forEach(function(l){l!=="selectionchange"&&(vm.has(l)||$u(l,!1,e),$u(l,!0,e))});var t=e.nodeType===9?e:e.ownerDocument;t===null||t[Gi]||(t[Gi]=!0,$u("selectionchange",!1,t))}}function Xo(e,t,l,a){switch(gd(t)){case 2:var n=Km;break;case 8:n=Jm;break;default:n=oc}l=n.bind(null,t,l,e),n=void 0,!ps||t!=="touchstart"&&t!=="touchmove"&&t!=="wheel"||(n=!0),a?n!==void 0?e.addEventListener(t,l,{capture:!0,passive:n}):e.addEventListener(t,l,!0):n!==void 0?e.addEventListener(t,l,{passive:n}):e.addEventListener(t,l,!1)}function Fu(e,t,l,a,n){var i=a;if((t&1)===0&&(t&2)===0&&a!==null)e:for(;;){if(a===null)return;var u=a.tag;if(u===3||u===4){var c=a.stateNode.containerInfo;if(c===n)break;if(u===4)for(u=a.return;u!==null;){var r=u.tag;if((r===3||r===4)&&u.stateNode.containerInfo===n)return;u=u.return}for(;c!==null;){if(u=ra(c),u===null)return;if(r=u.tag,r===5||r===6||r===26||r===27){a=i=u;continue e}c=c.parentNode}}a=a.return}Zc(function(){var p=i,S=hs(l),T=[];e:{var g=yr.get(e);if(g!==void 0){var b=Pn,q=e;switch(e){case"keypress":if(Wn(l)===0)break e;case"keydown":case"keyup":b=o0;break;case"focusin":q="focus",b=bs;break;case"focusout":q="blur",b=bs;break;case"beforeblur":case"afterblur":b=bs;break;case"click":if(l.button===2)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":b=kc;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":b=Id;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":b=h0;break;case xr:case pr:case gr:b=l0;break;case vr:b=p0;break;case"scroll":case"scrollend":b=Fd;break;case"wheel":b=v0;break;case"copy":case"cut":case"paste":b=n0;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":b=Wc;break;case"toggle":case"beforetoggle":b=b0}var I=(t&4)!==0,Re=!I&&(e==="scroll"||e==="scrollend"),m=I?g!==null?g+"Capture":null:g;I=[];for(var d=p,x;d!==null;){var A=d;if(x=A.stateNode,A=A.tag,A!==5&&A!==26&&A!==27||x===null||m===null||(A=Fa(d,m),A!=null&&I.push(Dn(d,A,x))),Re)break;d=d.return}0<I.length&&(g=new b(g,q,null,l,S),T.push({event:g,listeners:I}))}}if((t&7)===0){e:{if(g=e==="mouseover"||e==="pointerover",b=e==="mouseout"||e==="pointerout",g&&l!==ms&&(q=l.relatedTarget||l.fromElement)&&(ra(q)||q[ca]))break e;if((b||g)&&(g=S.window===S?S:(g=S.ownerDocument)?g.defaultView||g.parentWindow:window,b?(q=l.relatedTarget||l.toElement,b=p,q=q?ra(q):null,q!==null&&(Re=U(q),I=q.tag,q!==Re||I!==5&&I!==27&&I!==6)&&(q=null)):(b=null,q=p),b!==q)){if(I=kc,A="onMouseLeave",m="onMouseEnter",d="mouse",(e==="pointerout"||e==="pointerover")&&(I=Wc,A="onPointerLeave",m="onPointerEnter",d="pointer"),Re=b==null?g:Wa(b),x=q==null?g:Wa(q),g=new I(A,d+"leave",b,l,S),g.target=Re,g.relatedTarget=x,A=null,ra(S)===p&&(I=new I(m,d+"enter",q,l,S),I.target=x,I.relatedTarget=Re,A=I),Re=A,b&&q)t:{for(I=ym,m=b,d=q,x=0,A=m;A;A=I(A))x++;A=0;for(var Z=d;Z;Z=I(Z))A++;for(;0<x-A;)m=I(m),x--;for(;0<A-x;)d=I(d),A--;for(;x--;){if(m===d||d!==null&&m===d.alternate){I=m;break t}m=I(m),d=I(d)}I=null}else I=null;b!==null&&Qo(T,g,b,I,!1),q!==null&&Re!==null&&Qo(T,Re,q,I,!0)}}e:{if(g=p?Wa(p):window,b=g.nodeName&&g.nodeName.toLowerCase(),b==="select"||b==="input"&&g.type==="file")var Ee=nr;else if(lr(g))if(ir)Ee=M0;else{Ee=z0;var G=_0}else b=g.nodeName,!b||b.toLowerCase()!=="input"||g.type!=="checkbox"&&g.type!=="radio"?p&&ds(p.elementType)&&(Ee=nr):Ee=O0;if(Ee&&(Ee=Ee(e,p))){ar(T,Ee,l,S);break e}G&&G(e,g,p),e==="focusout"&&p&&g.type==="number"&&p.memoizedProps.value!=null&&os(g,"number",g.value)}switch(G=p?Wa(p):window,e){case"focusin":(lr(G)||G.contentEditable==="true")&&(va=G,Ts=p,sn=null);break;case"focusout":sn=Ts=va=null;break;case"mousedown":_s=!0;break;case"contextmenu":case"mouseup":case"dragend":_s=!1,mr(T,l,S);break;case"selectionchange":if(C0)break;case"keydown":case"keyup":mr(T,l,S)}var fe;if(Ns)e:{switch(e){case"compositionstart":var pe="onCompositionStart";break e;case"compositionend":pe="onCompositionEnd";break e;case"compositionupdate":pe="onCompositionUpdate";break e}pe=void 0}else ga?er(e,l)&&(pe="onCompositionEnd"):e==="keydown"&&l.keyCode===229&&(pe="onCompositionStart");pe&&(Fc&&l.locale!=="ko"&&(ga||pe!=="onCompositionStart"?pe==="onCompositionEnd"&&ga&&(fe=Kc()):(gl=S,gs="value"in gl?gl.value:gl.textContent,ga=!0)),G=Xi(p,pe),0<G.length&&(pe=new $c(pe,e,null,l,S),T.push({event:pe,listeners:G}),fe?pe.data=fe:(fe=tr(l),fe!==null&&(pe.data=fe)))),(fe=N0?S0(e,l):E0(e,l))&&(pe=Xi(p,"onBeforeInput"),0<pe.length&&(G=new $c("onBeforeInput","beforeinput",null,l,S),T.push({event:G,listeners:pe}),G.data=fe)),xm(T,e,p,l,S)}Go(T,t)})}function Dn(e,t,l){return{instance:e,listener:t,currentTarget:l}}function Xi(e,t){for(var l=t+"Capture",a=[];e!==null;){var n=e,i=n.stateNode;if(n=n.tag,n!==5&&n!==26&&n!==27||i===null||(n=Fa(e,l),n!=null&&a.unshift(Dn(e,n,i)),n=Fa(e,t),n!=null&&a.push(Dn(e,n,i))),e.tag===3)return a;e=e.return}return[]}function ym(e){if(e===null)return null;do e=e.return;while(e&&e.tag!==5&&e.tag!==27);return e||null}function Qo(e,t,l,a,n){for(var i=t._reactName,u=[];l!==null&&l!==a;){var c=l,r=c.alternate,p=c.stateNode;if(c=c.tag,r!==null&&r===a)break;c!==5&&c!==26&&c!==27||p===null||(r=p,n?(p=Fa(l,i),p!=null&&u.unshift(Dn(l,p,r))):n||(p=Fa(l,i),p!=null&&u.push(Dn(l,p,r)))),l=l.return}u.length!==0&&e.push({event:t,listeners:u})}var bm=/\r\n?/g,jm=/\u0000|\uFFFD/g;function Vo(e){return(typeof e=="string"?e:""+e).replace(bm,`
`).replace(jm,"")}function Zo(e,t){return t=Vo(t),Vo(e)===t}function Ce(e,t,l,a,n,i){switch(l){case"children":typeof a=="string"?t==="body"||t==="textarea"&&a===""||ha(e,a):(typeof a=="number"||typeof a=="bigint")&&t!=="body"&&ha(e,""+a);break;case"className":Kn(e,"class",a);break;case"tabIndex":Kn(e,"tabindex",a);break;case"dir":case"role":case"viewBox":case"width":case"height":Kn(e,l,a);break;case"style":Qc(e,a,i);break;case"data":if(t!=="object"){Kn(e,"data",a);break}case"src":case"href":if(a===""&&(t!=="a"||l!=="href")){e.removeAttribute(l);break}if(a==null||typeof a=="function"||typeof a=="symbol"||typeof a=="boolean"){e.removeAttribute(l);break}a=kn(""+a),e.setAttribute(l,a);break;case"action":case"formAction":if(typeof a=="function"){e.setAttribute(l,"javascript:throw new Error('A React form was unexpectedly submitted. If you called form.submit() manually, consider using form.requestSubmit() instead. If you\\'re trying to use event.stopPropagation() in a submit event handler, consider also calling event.preventDefault().')");break}else typeof i=="function"&&(l==="formAction"?(t!=="input"&&Ce(e,t,"name",n.name,n,null),Ce(e,t,"formEncType",n.formEncType,n,null),Ce(e,t,"formMethod",n.formMethod,n,null),Ce(e,t,"formTarget",n.formTarget,n,null)):(Ce(e,t,"encType",n.encType,n,null),Ce(e,t,"method",n.method,n,null),Ce(e,t,"target",n.target,n,null)));if(a==null||typeof a=="symbol"||typeof a=="boolean"){e.removeAttribute(l);break}a=kn(""+a),e.setAttribute(l,a);break;case"onClick":a!=null&&(e.onclick=Pt);break;case"onScroll":a!=null&&me("scroll",e);break;case"onScrollEnd":a!=null&&me("scrollend",e);break;case"dangerouslySetInnerHTML":if(a!=null){if(typeof a!="object"||!("__html"in a))throw Error(o(61));if(l=a.__html,l!=null){if(n.children!=null)throw Error(o(60));e.innerHTML=l}}break;case"multiple":e.multiple=a&&typeof a!="function"&&typeof a!="symbol";break;case"muted":e.muted=a&&typeof a!="function"&&typeof a!="symbol";break;case"suppressContentEditableWarning":case"suppressHydrationWarning":case"defaultValue":case"defaultChecked":case"innerHTML":case"ref":break;case"autoFocus":break;case"xlinkHref":if(a==null||typeof a=="function"||typeof a=="boolean"||typeof a=="symbol"){e.removeAttribute("xlink:href");break}l=kn(""+a),e.setAttributeNS("http://www.w3.org/1999/xlink","xlink:href",l);break;case"contentEditable":case"spellCheck":case"draggable":case"value":case"autoReverse":case"externalResourcesRequired":case"focusable":case"preserveAlpha":a!=null&&typeof a!="function"&&typeof a!="symbol"?e.setAttribute(l,""+a):e.removeAttribute(l);break;case"inert":case"allowFullScreen":case"async":case"autoPlay":case"controls":case"default":case"defer":case"disabled":case"disablePictureInPicture":case"disableRemotePlayback":case"formNoValidate":case"hidden":case"loop":case"noModule":case"noValidate":case"open":case"playsInline":case"readOnly":case"required":case"reversed":case"scoped":case"seamless":case"itemScope":a&&typeof a!="function"&&typeof a!="symbol"?e.setAttribute(l,""):e.removeAttribute(l);break;case"capture":case"download":a===!0?e.setAttribute(l,""):a!==!1&&a!=null&&typeof a!="function"&&typeof a!="symbol"?e.setAttribute(l,a):e.removeAttribute(l);break;case"cols":case"rows":case"size":case"span":a!=null&&typeof a!="function"&&typeof a!="symbol"&&!isNaN(a)&&1<=a?e.setAttribute(l,a):e.removeAttribute(l);break;case"rowSpan":case"start":a==null||typeof a=="function"||typeof a=="symbol"||isNaN(a)?e.removeAttribute(l):e.setAttribute(l,a);break;case"popover":me("beforetoggle",e),me("toggle",e),Zn(e,"popover",a);break;case"xlinkActuate":Ft(e,"http://www.w3.org/1999/xlink","xlink:actuate",a);break;case"xlinkArcrole":Ft(e,"http://www.w3.org/1999/xlink","xlink:arcrole",a);break;case"xlinkRole":Ft(e,"http://www.w3.org/1999/xlink","xlink:role",a);break;case"xlinkShow":Ft(e,"http://www.w3.org/1999/xlink","xlink:show",a);break;case"xlinkTitle":Ft(e,"http://www.w3.org/1999/xlink","xlink:title",a);break;case"xlinkType":Ft(e,"http://www.w3.org/1999/xlink","xlink:type",a);break;case"xmlBase":Ft(e,"http://www.w3.org/XML/1998/namespace","xml:base",a);break;case"xmlLang":Ft(e,"http://www.w3.org/XML/1998/namespace","xml:lang",a);break;case"xmlSpace":Ft(e,"http://www.w3.org/XML/1998/namespace","xml:space",a);break;case"is":Zn(e,"is",a);break;case"innerText":case"textContent":break;default:(!(2<l.length)||l[0]!=="o"&&l[0]!=="O"||l[1]!=="n"&&l[1]!=="N")&&(l=$d.get(l)||l,Zn(e,l,a))}}function Pu(e,t,l,a,n,i){switch(l){case"style":Qc(e,a,i);break;case"dangerouslySetInnerHTML":if(a!=null){if(typeof a!="object"||!("__html"in a))throw Error(o(61));if(l=a.__html,l!=null){if(n.children!=null)throw Error(o(60));e.innerHTML=l}}break;case"children":typeof a=="string"?ha(e,a):(typeof a=="number"||typeof a=="bigint")&&ha(e,""+a);break;case"onScroll":a!=null&&me("scroll",e);break;case"onScrollEnd":a!=null&&me("scrollend",e);break;case"onClick":a!=null&&(e.onclick=Pt);break;case"suppressContentEditableWarning":case"suppressHydrationWarning":case"innerHTML":case"ref":break;case"innerText":case"textContent":break;default:if(!Uc.hasOwnProperty(l))e:{if(l[0]==="o"&&l[1]==="n"&&(n=l.endsWith("Capture"),t=l.slice(2,n?l.length-7:void 0),i=e[dt]||null,i=i!=null?i[l]:null,typeof i=="function"&&e.removeEventListener(t,i,n),typeof a=="function")){typeof i!="function"&&i!==null&&(l in e?e[l]=null:e.hasAttribute(l)&&e.removeAttribute(l)),e.addEventListener(t,a,n);break e}l in e?e[l]=a:a===!0?e.setAttribute(l,""):Zn(e,l,a)}}}function ct(e,t,l){switch(t){case"div":case"span":case"svg":case"path":case"a":case"g":case"p":case"li":break;case"img":me("error",e),me("load",e);var a=!1,n=!1,i;for(i in l)if(l.hasOwnProperty(i)){var u=l[i];if(u!=null)switch(i){case"src":a=!0;break;case"srcSet":n=!0;break;case"children":case"dangerouslySetInnerHTML":throw Error(o(137,t));default:Ce(e,t,i,u,l,null)}}n&&Ce(e,t,"srcSet",l.srcSet,l,null),a&&Ce(e,t,"src",l.src,l,null);return;case"input":me("invalid",e);var c=i=u=n=null,r=null,p=null;for(a in l)if(l.hasOwnProperty(a)){var S=l[a];if(S!=null)switch(a){case"name":n=S;break;case"type":u=S;break;case"checked":r=S;break;case"defaultChecked":p=S;break;case"value":i=S;break;case"defaultValue":c=S;break;case"children":case"dangerouslySetInnerHTML":if(S!=null)throw Error(o(137,t));break;default:Ce(e,t,a,S,l,null)}}qc(e,i,c,r,p,u,n,!1);return;case"select":me("invalid",e),a=u=i=null;for(n in l)if(l.hasOwnProperty(n)&&(c=l[n],c!=null))switch(n){case"value":i=c;break;case"defaultValue":u=c;break;case"multiple":a=c;default:Ce(e,t,n,c,l,null)}t=i,l=u,e.multiple=!!a,t!=null?ma(e,!!a,t,!1):l!=null&&ma(e,!!a,l,!0);return;case"textarea":me("invalid",e),i=n=a=null;for(u in l)if(l.hasOwnProperty(u)&&(c=l[u],c!=null))switch(u){case"value":a=c;break;case"defaultValue":n=c;break;case"children":i=c;break;case"dangerouslySetInnerHTML":if(c!=null)throw Error(o(91));break;default:Ce(e,t,u,c,l,null)}Gc(e,a,n,i);return;case"option":for(r in l)l.hasOwnProperty(r)&&(a=l[r],a!=null)&&(r==="selected"?e.selected=a&&typeof a!="function"&&typeof a!="symbol":Ce(e,t,r,a,l,null));return;case"dialog":me("beforetoggle",e),me("toggle",e),me("cancel",e),me("close",e);break;case"iframe":case"object":me("load",e);break;case"video":case"audio":for(a=0;a<Mn.length;a++)me(Mn[a],e);break;case"image":me("error",e),me("load",e);break;case"details":me("toggle",e);break;case"embed":case"source":case"link":me("error",e),me("load",e);case"area":case"base":case"br":case"col":case"hr":case"keygen":case"meta":case"param":case"track":case"wbr":case"menuitem":for(p in l)if(l.hasOwnProperty(p)&&(a=l[p],a!=null))switch(p){case"children":case"dangerouslySetInnerHTML":throw Error(o(137,t));default:Ce(e,t,p,a,l,null)}return;default:if(ds(t)){for(S in l)l.hasOwnProperty(S)&&(a=l[S],a!==void 0&&Pu(e,t,S,a,l,void 0));return}}for(c in l)l.hasOwnProperty(c)&&(a=l[c],a!=null&&Ce(e,t,c,a,l,null))}function Nm(e,t,l,a){switch(t){case"div":case"span":case"svg":case"path":case"a":case"g":case"p":case"li":break;case"input":var n=null,i=null,u=null,c=null,r=null,p=null,S=null;for(b in l){var T=l[b];if(l.hasOwnProperty(b)&&T!=null)switch(b){case"checked":break;case"value":break;case"defaultValue":r=T;default:a.hasOwnProperty(b)||Ce(e,t,b,null,a,T)}}for(var g in a){var b=a[g];if(T=l[g],a.hasOwnProperty(g)&&(b!=null||T!=null))switch(g){case"type":i=b;break;case"name":n=b;break;case"checked":p=b;break;case"defaultChecked":S=b;break;case"value":u=b;break;case"defaultValue":c=b;break;case"children":case"dangerouslySetInnerHTML":if(b!=null)throw Error(o(137,t));break;default:b!==T&&Ce(e,t,g,b,a,T)}}fs(e,u,c,r,p,S,i,n);return;case"select":b=u=c=g=null;for(i in l)if(r=l[i],l.hasOwnProperty(i)&&r!=null)switch(i){case"value":break;case"multiple":b=r;default:a.hasOwnProperty(i)||Ce(e,t,i,null,a,r)}for(n in a)if(i=a[n],r=l[n],a.hasOwnProperty(n)&&(i!=null||r!=null))switch(n){case"value":g=i;break;case"defaultValue":c=i;break;case"multiple":u=i;default:i!==r&&Ce(e,t,n,i,a,r)}t=c,l=u,a=b,g!=null?ma(e,!!l,g,!1):!!a!=!!l&&(t!=null?ma(e,!!l,t,!0):ma(e,!!l,l?[]:"",!1));return;case"textarea":b=g=null;for(c in l)if(n=l[c],l.hasOwnProperty(c)&&n!=null&&!a.hasOwnProperty(c))switch(c){case"value":break;case"children":break;default:Ce(e,t,c,null,a,n)}for(u in a)if(n=a[u],i=l[u],a.hasOwnProperty(u)&&(n!=null||i!=null))switch(u){case"value":g=n;break;case"defaultValue":b=n;break;case"children":break;case"dangerouslySetInnerHTML":if(n!=null)throw Error(o(91));break;default:n!==i&&Ce(e,t,u,n,a,i)}Yc(e,g,b);return;case"option":for(var q in l)g=l[q],l.hasOwnProperty(q)&&g!=null&&!a.hasOwnProperty(q)&&(q==="selected"?e.selected=!1:Ce(e,t,q,null,a,g));for(r in a)g=a[r],b=l[r],a.hasOwnProperty(r)&&g!==b&&(g!=null||b!=null)&&(r==="selected"?e.selected=g&&typeof g!="function"&&typeof g!="symbol":Ce(e,t,r,g,a,b));return;case"img":case"link":case"area":case"base":case"br":case"col":case"embed":case"hr":case"keygen":case"meta":case"param":case"source":case"track":case"wbr":case"menuitem":for(var I in l)g=l[I],l.hasOwnProperty(I)&&g!=null&&!a.hasOwnProperty(I)&&Ce(e,t,I,null,a,g);for(p in a)if(g=a[p],b=l[p],a.hasOwnProperty(p)&&g!==b&&(g!=null||b!=null))switch(p){case"children":case"dangerouslySetInnerHTML":if(g!=null)throw Error(o(137,t));break;default:Ce(e,t,p,g,a,b)}return;default:if(ds(t)){for(var Re in l)g=l[Re],l.hasOwnProperty(Re)&&g!==void 0&&!a.hasOwnProperty(Re)&&Pu(e,t,Re,void 0,a,g);for(S in a)g=a[S],b=l[S],!a.hasOwnProperty(S)||g===b||g===void 0&&b===void 0||Pu(e,t,S,g,a,b);return}}for(var m in l)g=l[m],l.hasOwnProperty(m)&&g!=null&&!a.hasOwnProperty(m)&&Ce(e,t,m,null,a,g);for(T in a)g=a[T],b=l[T],!a.hasOwnProperty(T)||g===b||g==null&&b==null||Ce(e,t,T,g,a,b)}function Ko(e){switch(e){case"css":case"script":case"font":case"img":case"image":case"input":case"link":return!0;default:return!1}}function Sm(){if(typeof performance.getEntriesByType=="function"){for(var e=0,t=0,l=performance.getEntriesByType("resource"),a=0;a<l.length;a++){var n=l[a],i=n.transferSize,u=n.initiatorType,c=n.duration;if(i&&c&&Ko(u)){for(u=0,c=n.responseEnd,a+=1;a<l.length;a++){var r=l[a],p=r.startTime;if(p>c)break;var S=r.transferSize,T=r.initiatorType;S&&Ko(T)&&(r=r.responseEnd,u+=S*(r<c?1:(c-p)/(r-p)))}if(--a,t+=8*(i+u)/(n.duration/1e3),e++,10<e)break}}if(0<e)return t/e/1e6}return navigator.connection&&(e=navigator.connection.downlink,typeof e=="number")?e:5}var Iu=null,ec=null;function Qi(e){return e.nodeType===9?e:e.ownerDocument}function Jo(e){switch(e){case"http://www.w3.org/2000/svg":return 1;case"http://www.w3.org/1998/Math/MathML":return 2;default:return 0}}function ko(e,t){if(e===0)switch(t){case"svg":return 1;case"math":return 2;default:return 0}return e===1&&t==="foreignObject"?0:e}function tc(e,t){return e==="textarea"||e==="noscript"||typeof t.children=="string"||typeof t.children=="number"||typeof t.children=="bigint"||typeof t.dangerouslySetInnerHTML=="object"&&t.dangerouslySetInnerHTML!==null&&t.dangerouslySetInnerHTML.__html!=null}var lc=null;function Em(){var e=window.event;return e&&e.type==="popstate"?e===lc?!1:(lc=e,!0):(lc=null,!1)}var $o=typeof setTimeout=="function"?setTimeout:void 0,Am=typeof clearTimeout=="function"?clearTimeout:void 0,Wo=typeof Promise=="function"?Promise:void 0,Tm=typeof queueMicrotask=="function"?queueMicrotask:typeof Wo<"u"?function(e){return Wo.resolve(null).then(e).catch(_m)}:$o;function _m(e){setTimeout(function(){throw e})}function Ul(e){return e==="head"}function Fo(e,t){var l=t,a=0;do{var n=l.nextSibling;if(e.removeChild(l),n&&n.nodeType===8)if(l=n.data,l==="/$"||l==="/&"){if(a===0){e.removeChild(n),Za(t);return}a--}else if(l==="$"||l==="$?"||l==="$~"||l==="$!"||l==="&")a++;else if(l==="html")Cn(e.ownerDocument.documentElement);else if(l==="head"){l=e.ownerDocument.head,Cn(l);for(var i=l.firstChild;i;){var u=i.nextSibling,c=i.nodeName;i[$a]||c==="SCRIPT"||c==="STYLE"||c==="LINK"&&i.rel.toLowerCase()==="stylesheet"||l.removeChild(i),i=u}}else l==="body"&&Cn(e.ownerDocument.body);l=n}while(l);Za(t)}function Po(e,t){var l=e;e=0;do{var a=l.nextSibling;if(l.nodeType===1?t?(l._stashedDisplay=l.style.display,l.style.display="none"):(l.style.display=l._stashedDisplay||"",l.getAttribute("style")===""&&l.removeAttribute("style")):l.nodeType===3&&(t?(l._stashedText=l.nodeValue,l.nodeValue=""):l.nodeValue=l._stashedText||""),a&&a.nodeType===8)if(l=a.data,l==="/$"){if(e===0)break;e--}else l!=="$"&&l!=="$?"&&l!=="$~"&&l!=="$!"||e++;l=a}while(l)}function ac(e){var t=e.firstChild;for(t&&t.nodeType===10&&(t=t.nextSibling);t;){var l=t;switch(t=t.nextSibling,l.nodeName){case"HTML":case"HEAD":case"BODY":ac(l),cs(l);continue;case"SCRIPT":case"STYLE":continue;case"LINK":if(l.rel.toLowerCase()==="stylesheet")continue}e.removeChild(l)}}function zm(e,t,l,a){for(;e.nodeType===1;){var n=l;if(e.nodeName.toLowerCase()!==t.toLowerCase()){if(!a&&(e.nodeName!=="INPUT"||e.type!=="hidden"))break}else if(a){if(!e[$a])switch(t){case"meta":if(!e.hasAttribute("itemprop"))break;return e;case"link":if(i=e.getAttribute("rel"),i==="stylesheet"&&e.hasAttribute("data-precedence"))break;if(i!==n.rel||e.getAttribute("href")!==(n.href==null||n.href===""?null:n.href)||e.getAttribute("crossorigin")!==(n.crossOrigin==null?null:n.crossOrigin)||e.getAttribute("title")!==(n.title==null?null:n.title))break;return e;case"style":if(e.hasAttribute("data-precedence"))break;return e;case"script":if(i=e.getAttribute("src"),(i!==(n.src==null?null:n.src)||e.getAttribute("type")!==(n.type==null?null:n.type)||e.getAttribute("crossorigin")!==(n.crossOrigin==null?null:n.crossOrigin))&&i&&e.hasAttribute("async")&&!e.hasAttribute("itemprop"))break;return e;default:return e}}else if(t==="input"&&e.type==="hidden"){var i=n.name==null?null:""+n.name;if(n.type==="hidden"&&e.getAttribute("name")===i)return e}else return e;if(e=Bt(e.nextSibling),e===null)break}return null}function Om(e,t,l){if(t==="")return null;for(;e.nodeType!==3;)if((e.nodeType!==1||e.nodeName!=="INPUT"||e.type!=="hidden")&&!l||(e=Bt(e.nextSibling),e===null))return null;return e}function Io(e,t){for(;e.nodeType!==8;)if((e.nodeType!==1||e.nodeName!=="INPUT"||e.type!=="hidden")&&!t||(e=Bt(e.nextSibling),e===null))return null;return e}function nc(e){return e.data==="$?"||e.data==="$~"}function ic(e){return e.data==="$!"||e.data==="$?"&&e.ownerDocument.readyState!=="loading"}function Mm(e,t){var l=e.ownerDocument;if(e.data==="$~")e._reactRetry=t;else if(e.data!=="$?"||l.readyState!=="loading")t();else{var a=function(){t(),l.removeEventListener("DOMContentLoaded",a)};l.addEventListener("DOMContentLoaded",a),e._reactRetry=a}}function Bt(e){for(;e!=null;e=e.nextSibling){var t=e.nodeType;if(t===1||t===3)break;if(t===8){if(t=e.data,t==="$"||t==="$!"||t==="$?"||t==="$~"||t==="&"||t==="F!"||t==="F")break;if(t==="/$"||t==="/&")return null}}return e}var sc=null;function ed(e){e=e.nextSibling;for(var t=0;e;){if(e.nodeType===8){var l=e.data;if(l==="/$"||l==="/&"){if(t===0)return Bt(e.nextSibling);t--}else l!=="$"&&l!=="$!"&&l!=="$?"&&l!=="$~"&&l!=="&"||t++}e=e.nextSibling}return null}function td(e){e=e.previousSibling;for(var t=0;e;){if(e.nodeType===8){var l=e.data;if(l==="$"||l==="$!"||l==="$?"||l==="$~"||l==="&"){if(t===0)return e;t--}else l!=="/$"&&l!=="/&"||t++}e=e.previousSibling}return null}function ld(e,t,l){switch(t=Qi(l),e){case"html":if(e=t.documentElement,!e)throw Error(o(452));return e;case"head":if(e=t.head,!e)throw Error(o(453));return e;case"body":if(e=t.body,!e)throw Error(o(454));return e;default:throw Error(o(451))}}function Cn(e){for(var t=e.attributes;t.length;)e.removeAttributeNode(t[0]);cs(e)}var Lt=new Map,ad=new Set;function Vi(e){return typeof e.getRootNode=="function"?e.getRootNode():e.nodeType===9?e:e.ownerDocument}var hl=O.d;O.d={f:Dm,r:Cm,D:Rm,C:Um,L:wm,m:Hm,X:Lm,S:Bm,M:qm};function Dm(){var e=hl.f(),t=wi();return e||t}function Cm(e){var t=fa(e);t!==null&&t.tag===5&&t.type==="form"?yf(t):hl.r(e)}var Xa=typeof document>"u"?null:document;function nd(e,t,l){var a=Xa;if(a&&typeof t=="string"&&t){var n=Mt(t);n='link[rel="'+e+'"][href="'+n+'"]',typeof l=="string"&&(n+='[crossorigin="'+l+'"]'),ad.has(n)||(ad.add(n),e={rel:e,crossOrigin:l,href:t},a.querySelector(n)===null&&(t=a.createElement("link"),ct(t,"link",e),tt(t),a.head.appendChild(t)))}}function Rm(e){hl.D(e),nd("dns-prefetch",e,null)}function Um(e,t){hl.C(e,t),nd("preconnect",e,t)}function wm(e,t,l){hl.L(e,t,l);var a=Xa;if(a&&e&&t){var n='link[rel="preload"][as="'+Mt(t)+'"]';t==="image"&&l&&l.imageSrcSet?(n+='[imagesrcset="'+Mt(l.imageSrcSet)+'"]',typeof l.imageSizes=="string"&&(n+='[imagesizes="'+Mt(l.imageSizes)+'"]')):n+='[href="'+Mt(e)+'"]';var i=n;switch(t){case"style":i=Qa(e);break;case"script":i=Va(e)}Lt.has(i)||(e=M({rel:"preload",href:t==="image"&&l&&l.imageSrcSet?void 0:e,as:t},l),Lt.set(i,e),a.querySelector(n)!==null||t==="style"&&a.querySelector(Rn(i))||t==="script"&&a.querySelector(Un(i))||(t=a.createElement("link"),ct(t,"link",e),tt(t),a.head.appendChild(t)))}}function Hm(e,t){hl.m(e,t);var l=Xa;if(l&&e){var a=t&&typeof t.as=="string"?t.as:"script",n='link[rel="modulepreload"][as="'+Mt(a)+'"][href="'+Mt(e)+'"]',i=n;switch(a){case"audioworklet":case"paintworklet":case"serviceworker":case"sharedworker":case"worker":case"script":i=Va(e)}if(!Lt.has(i)&&(e=M({rel:"modulepreload",href:e},t),Lt.set(i,e),l.querySelector(n)===null)){switch(a){case"audioworklet":case"paintworklet":case"serviceworker":case"sharedworker":case"worker":case"script":if(l.querySelector(Un(i)))return}a=l.createElement("link"),ct(a,"link",e),tt(a),l.head.appendChild(a)}}}function Bm(e,t,l){hl.S(e,t,l);var a=Xa;if(a&&e){var n=oa(a).hoistableStyles,i=Qa(e);t=t||"default";var u=n.get(i);if(!u){var c={loading:0,preload:null};if(u=a.querySelector(Rn(i)))c.loading=5;else{e=M({rel:"stylesheet",href:e,"data-precedence":t},l),(l=Lt.get(i))&&uc(e,l);var r=u=a.createElement("link");tt(r),ct(r,"link",e),r._p=new Promise(function(p,S){r.onload=p,r.onerror=S}),r.addEventListener("load",function(){c.loading|=1}),r.addEventListener("error",function(){c.loading|=2}),c.loading|=4,Zi(u,t,a)}u={type:"stylesheet",instance:u,count:1,state:c},n.set(i,u)}}}function Lm(e,t){hl.X(e,t);var l=Xa;if(l&&e){var a=oa(l).hoistableScripts,n=Va(e),i=a.get(n);i||(i=l.querySelector(Un(n)),i||(e=M({src:e,async:!0},t),(t=Lt.get(n))&&cc(e,t),i=l.createElement("script"),tt(i),ct(i,"link",e),l.head.appendChild(i)),i={type:"script",instance:i,count:1,state:null},a.set(n,i))}}function qm(e,t){hl.M(e,t);var l=Xa;if(l&&e){var a=oa(l).hoistableScripts,n=Va(e),i=a.get(n);i||(i=l.querySelector(Un(n)),i||(e=M({src:e,async:!0,type:"module"},t),(t=Lt.get(n))&&cc(e,t),i=l.createElement("script"),tt(i),ct(i,"link",e),l.head.appendChild(i)),i={type:"script",instance:i,count:1,state:null},a.set(n,i))}}function id(e,t,l,a){var n=(n=se.current)?Vi(n):null;if(!n)throw Error(o(446));switch(e){case"meta":case"title":return null;case"style":return typeof l.precedence=="string"&&typeof l.href=="string"?(t=Qa(l.href),l=oa(n).hoistableStyles,a=l.get(t),a||(a={type:"style",instance:null,count:0,state:null},l.set(t,a)),a):{type:"void",instance:null,count:0,state:null};case"link":if(l.rel==="stylesheet"&&typeof l.href=="string"&&typeof l.precedence=="string"){e=Qa(l.href);var i=oa(n).hoistableStyles,u=i.get(e);if(u||(n=n.ownerDocument||n,u={type:"stylesheet",instance:null,count:0,state:{loading:0,preload:null}},i.set(e,u),(i=n.querySelector(Rn(e)))&&!i._p&&(u.instance=i,u.state.loading=5),Lt.has(e)||(l={rel:"preload",as:"style",href:l.href,crossOrigin:l.crossOrigin,integrity:l.integrity,media:l.media,hrefLang:l.hrefLang,referrerPolicy:l.referrerPolicy},Lt.set(e,l),i||Ym(n,e,l,u.state))),t&&a===null)throw Error(o(528,""));return u}if(t&&a!==null)throw Error(o(529,""));return null;case"script":return t=l.async,l=l.src,typeof l=="string"&&t&&typeof t!="function"&&typeof t!="symbol"?(t=Va(l),l=oa(n).hoistableScripts,a=l.get(t),a||(a={type:"script",instance:null,count:0,state:null},l.set(t,a)),a):{type:"void",instance:null,count:0,state:null};default:throw Error(o(444,e))}}function Qa(e){return'href="'+Mt(e)+'"'}function Rn(e){return'link[rel="stylesheet"]['+e+"]"}function sd(e){return M({},e,{"data-precedence":e.precedence,precedence:null})}function Ym(e,t,l,a){e.querySelector('link[rel="preload"][as="style"]['+t+"]")?a.loading=1:(t=e.createElement("link"),a.preload=t,t.addEventListener("load",function(){return a.loading|=1}),t.addEventListener("error",function(){return a.loading|=2}),ct(t,"link",l),tt(t),e.head.appendChild(t))}function Va(e){return'[src="'+Mt(e)+'"]'}function Un(e){return"script[async]"+e}function ud(e,t,l){if(t.count++,t.instance===null)switch(t.type){case"style":var a=e.querySelector('style[data-href~="'+Mt(l.href)+'"]');if(a)return t.instance=a,tt(a),a;var n=M({},l,{"data-href":l.href,"data-precedence":l.precedence,href:null,precedence:null});return a=(e.ownerDocument||e).createElement("style"),tt(a),ct(a,"style",n),Zi(a,l.precedence,e),t.instance=a;case"stylesheet":n=Qa(l.href);var i=e.querySelector(Rn(n));if(i)return t.state.loading|=4,t.instance=i,tt(i),i;a=sd(l),(n=Lt.get(n))&&uc(a,n),i=(e.ownerDocument||e).createElement("link"),tt(i);var u=i;return u._p=new Promise(function(c,r){u.onload=c,u.onerror=r}),ct(i,"link",a),t.state.loading|=4,Zi(i,l.precedence,e),t.instance=i;case"script":return i=Va(l.src),(n=e.querySelector(Un(i)))?(t.instance=n,tt(n),n):(a=l,(n=Lt.get(i))&&(a=M({},l),cc(a,n)),e=e.ownerDocument||e,n=e.createElement("script"),tt(n),ct(n,"link",a),e.head.appendChild(n),t.instance=n);case"void":return null;default:throw Error(o(443,t.type))}else t.type==="stylesheet"&&(t.state.loading&4)===0&&(a=t.instance,t.state.loading|=4,Zi(a,l.precedence,e));return t.instance}function Zi(e,t,l){for(var a=l.querySelectorAll('link[rel="stylesheet"][data-precedence],style[data-precedence]'),n=a.length?a[a.length-1]:null,i=n,u=0;u<a.length;u++){var c=a[u];if(c.dataset.precedence===t)i=c;else if(i!==n)break}i?i.parentNode.insertBefore(e,i.nextSibling):(t=l.nodeType===9?l.head:l,t.insertBefore(e,t.firstChild))}function uc(e,t){e.crossOrigin==null&&(e.crossOrigin=t.crossOrigin),e.referrerPolicy==null&&(e.referrerPolicy=t.referrerPolicy),e.title==null&&(e.title=t.title)}function cc(e,t){e.crossOrigin==null&&(e.crossOrigin=t.crossOrigin),e.referrerPolicy==null&&(e.referrerPolicy=t.referrerPolicy),e.integrity==null&&(e.integrity=t.integrity)}var Ki=null;function cd(e,t,l){if(Ki===null){var a=new Map,n=Ki=new Map;n.set(l,a)}else n=Ki,a=n.get(l),a||(a=new Map,n.set(l,a));if(a.has(e))return a;for(a.set(e,null),l=l.getElementsByTagName(e),n=0;n<l.length;n++){var i=l[n];if(!(i[$a]||i[nt]||e==="link"&&i.getAttribute("rel")==="stylesheet")&&i.namespaceURI!=="http://www.w3.org/2000/svg"){var u=i.getAttribute(t)||"";u=e+u;var c=a.get(u);c?c.push(i):a.set(u,[i])}}return a}function rd(e,t,l){e=e.ownerDocument||e,e.head.insertBefore(l,t==="title"?e.querySelector("head > title"):null)}function Gm(e,t,l){if(l===1||t.itemProp!=null)return!1;switch(e){case"meta":case"title":return!0;case"style":if(typeof t.precedence!="string"||typeof t.href!="string"||t.href==="")break;return!0;case"link":if(typeof t.rel!="string"||typeof t.href!="string"||t.href===""||t.onLoad||t.onError)break;return t.rel==="stylesheet"?(e=t.disabled,typeof t.precedence=="string"&&e==null):!0;case"script":if(t.async&&typeof t.async!="function"&&typeof t.async!="symbol"&&!t.onLoad&&!t.onError&&t.src&&typeof t.src=="string")return!0}return!1}function fd(e){return!(e.type==="stylesheet"&&(e.state.loading&3)===0)}function Xm(e,t,l,a){if(l.type==="stylesheet"&&(typeof a.media!="string"||matchMedia(a.media).matches!==!1)&&(l.state.loading&4)===0){if(l.instance===null){var n=Qa(a.href),i=t.querySelector(Rn(n));if(i){t=i._p,t!==null&&typeof t=="object"&&typeof t.then=="function"&&(e.count++,e=Ji.bind(e),t.then(e,e)),l.state.loading|=4,l.instance=i,tt(i);return}i=t.ownerDocument||t,a=sd(a),(n=Lt.get(n))&&uc(a,n),i=i.createElement("link"),tt(i);var u=i;u._p=new Promise(function(c,r){u.onload=c,u.onerror=r}),ct(i,"link",a),l.instance=i}e.stylesheets===null&&(e.stylesheets=new Map),e.stylesheets.set(l,t),(t=l.state.preload)&&(l.state.loading&3)===0&&(e.count++,l=Ji.bind(e),t.addEventListener("load",l),t.addEventListener("error",l))}}var rc=0;function Qm(e,t){return e.stylesheets&&e.count===0&&$i(e,e.stylesheets),0<e.count||0<e.imgCount?function(l){var a=setTimeout(function(){if(e.stylesheets&&$i(e,e.stylesheets),e.unsuspend){var i=e.unsuspend;e.unsuspend=null,i()}},6e4+t);0<e.imgBytes&&rc===0&&(rc=62500*Sm());var n=setTimeout(function(){if(e.waitingForImages=!1,e.count===0&&(e.stylesheets&&$i(e,e.stylesheets),e.unsuspend)){var i=e.unsuspend;e.unsuspend=null,i()}},(e.imgBytes>rc?50:800)+t);return e.unsuspend=l,function(){e.unsuspend=null,clearTimeout(a),clearTimeout(n)}}:null}function Ji(){if(this.count--,this.count===0&&(this.imgCount===0||!this.waitingForImages)){if(this.stylesheets)$i(this,this.stylesheets);else if(this.unsuspend){var e=this.unsuspend;this.unsuspend=null,e()}}}var ki=null;function $i(e,t){e.stylesheets=null,e.unsuspend!==null&&(e.count++,ki=new Map,t.forEach(Vm,e),ki=null,Ji.call(e))}function Vm(e,t){if(!(t.state.loading&4)){var l=ki.get(e);if(l)var a=l.get(null);else{l=new Map,ki.set(e,l);for(var n=e.querySelectorAll("link[data-precedence],style[data-precedence]"),i=0;i<n.length;i++){var u=n[i];(u.nodeName==="LINK"||u.getAttribute("media")!=="not all")&&(l.set(u.dataset.precedence,u),a=u)}a&&l.set(null,a)}n=t.instance,u=n.getAttribute("data-precedence"),i=l.get(u)||a,i===a&&l.set(null,n),l.set(u,n),this.count++,a=Ji.bind(this),n.addEventListener("load",a),n.addEventListener("error",a),i?i.parentNode.insertBefore(n,i.nextSibling):(e=e.nodeType===9?e.head:e,e.insertBefore(n,e.firstChild)),t.state.loading|=4}}var wn={$$typeof:ne,Provider:null,Consumer:null,_currentValue:L,_currentValue2:L,_threadCount:0};function Zm(e,t,l,a,n,i,u,c,r){this.tag=1,this.containerInfo=e,this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.next=this.pendingContext=this.context=this.cancelPendingCommit=null,this.callbackPriority=0,this.expirationTimes=ns(-1),this.entangledLanes=this.shellSuspendCounter=this.errorRecoveryDisabledLanes=this.expiredLanes=this.warmLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=ns(0),this.hiddenUpdates=ns(null),this.identifierPrefix=a,this.onUncaughtError=n,this.onCaughtError=i,this.onRecoverableError=u,this.pooledCache=null,this.pooledCacheLanes=0,this.formState=r,this.incompleteTransitions=new Map}function od(e,t,l,a,n,i,u,c,r,p,S,T){return e=new Zm(e,t,l,u,r,p,S,T,c),t=1,i===!0&&(t|=24),i=jt(3,null,null,t),e.current=i,i.stateNode=e,t=Xs(),t.refCount++,e.pooledCache=t,t.refCount++,i.memoizedState={element:a,isDehydrated:l,cache:t},Ks(i),e}function dd(e){return e?(e=ja,e):ja}function md(e,t,l,a,n,i){n=dd(n),a.context===null?a.context=n:a.pendingContext=n,a=Sl(t),a.payload={element:l},i=i===void 0?null:i,i!==null&&(a.callback=i),l=El(e,a,t),l!==null&&(vt(l,e,t),mn(l,e,t))}function hd(e,t){if(e=e.memoizedState,e!==null&&e.dehydrated!==null){var l=e.retryLane;e.retryLane=l!==0&&l<t?l:t}}function fc(e,t){hd(e,t),(e=e.alternate)&&hd(e,t)}function xd(e){if(e.tag===13||e.tag===31){var t=Jl(e,67108864);t!==null&&vt(t,e,67108864),fc(e,67108864)}}function pd(e){if(e.tag===13||e.tag===31){var t=Tt();t=is(t);var l=Jl(e,t);l!==null&&vt(l,e,t),fc(e,t)}}var Wi=!0;function Km(e,t,l,a){var n=h.T;h.T=null;var i=O.p;try{O.p=2,oc(e,t,l,a)}finally{O.p=i,h.T=n}}function Jm(e,t,l,a){var n=h.T;h.T=null;var i=O.p;try{O.p=8,oc(e,t,l,a)}finally{O.p=i,h.T=n}}function oc(e,t,l,a){if(Wi){var n=dc(a);if(n===null)Fu(e,t,a,Fi,l),vd(e,a);else if($m(n,e,t,l,a))a.stopPropagation();else if(vd(e,a),t&4&&-1<km.indexOf(e)){for(;n!==null;){var i=fa(n);if(i!==null)switch(i.tag){case 3:if(i=i.stateNode,i.current.memoizedState.isDehydrated){var u=Xl(i.pendingLanes);if(u!==0){var c=i;for(c.pendingLanes|=2,c.entangledLanes|=2;u;){var r=1<<31-at(u);c.entanglements[1]|=r,u&=~r}Jt(i),(Te&6)===0&&(Ri=V()+500,On(0))}}break;case 31:case 13:c=Jl(i,2),c!==null&&vt(c,i,2),wi(),fc(i,2)}if(i=dc(a),i===null&&Fu(e,t,a,Fi,l),i===n)break;n=i}n!==null&&a.stopPropagation()}else Fu(e,t,a,null,l)}}function dc(e){return e=hs(e),mc(e)}var Fi=null;function mc(e){if(Fi=null,e=ra(e),e!==null){var t=U(e);if(t===null)e=null;else{var l=t.tag;if(l===13){if(e=w(t),e!==null)return e;e=null}else if(l===31){if(e=te(t),e!==null)return e;e=null}else if(l===3){if(t.stateNode.current.memoizedState.isDehydrated)return t.tag===3?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null)}}return Fi=e,null}function gd(e){switch(e){case"beforetoggle":case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"toggle":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 2;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 8;case"message":switch(W()){case re:return 2;case he:return 8;case Me:case Gl:return 32;case yt:return 268435456;default:return 32}default:return 32}}var hc=!1,wl=null,Hl=null,Bl=null,Hn=new Map,Bn=new Map,Ll=[],km="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset".split(" ");function vd(e,t){switch(e){case"focusin":case"focusout":wl=null;break;case"dragenter":case"dragleave":Hl=null;break;case"mouseover":case"mouseout":Bl=null;break;case"pointerover":case"pointerout":Hn.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":Bn.delete(t.pointerId)}}function Ln(e,t,l,a,n,i){return e===null||e.nativeEvent!==i?(e={blockedOn:t,domEventName:l,eventSystemFlags:a,nativeEvent:i,targetContainers:[n]},t!==null&&(t=fa(t),t!==null&&xd(t)),e):(e.eventSystemFlags|=a,t=e.targetContainers,n!==null&&t.indexOf(n)===-1&&t.push(n),e)}function $m(e,t,l,a,n){switch(t){case"focusin":return wl=Ln(wl,e,t,l,a,n),!0;case"dragenter":return Hl=Ln(Hl,e,t,l,a,n),!0;case"mouseover":return Bl=Ln(Bl,e,t,l,a,n),!0;case"pointerover":var i=n.pointerId;return Hn.set(i,Ln(Hn.get(i)||null,e,t,l,a,n)),!0;case"gotpointercapture":return i=n.pointerId,Bn.set(i,Ln(Bn.get(i)||null,e,t,l,a,n)),!0}return!1}function yd(e){var t=ra(e.target);if(t!==null){var l=U(t);if(l!==null){if(t=l.tag,t===13){if(t=w(l),t!==null){e.blockedOn=t,Dc(e.priority,function(){pd(l)});return}}else if(t===31){if(t=te(l),t!==null){e.blockedOn=t,Dc(e.priority,function(){pd(l)});return}}else if(t===3&&l.stateNode.current.memoizedState.isDehydrated){e.blockedOn=l.tag===3?l.stateNode.containerInfo:null;return}}}e.blockedOn=null}function Pi(e){if(e.blockedOn!==null)return!1;for(var t=e.targetContainers;0<t.length;){var l=dc(e.nativeEvent);if(l===null){l=e.nativeEvent;var a=new l.constructor(l.type,l);ms=a,l.target.dispatchEvent(a),ms=null}else return t=fa(l),t!==null&&xd(t),e.blockedOn=l,!1;t.shift()}return!0}function bd(e,t,l){Pi(e)&&l.delete(t)}function Wm(){hc=!1,wl!==null&&Pi(wl)&&(wl=null),Hl!==null&&Pi(Hl)&&(Hl=null),Bl!==null&&Pi(Bl)&&(Bl=null),Hn.forEach(bd),Bn.forEach(bd)}function Ii(e,t){e.blockedOn===t&&(e.blockedOn=null,hc||(hc=!0,j.unstable_scheduleCallback(j.unstable_NormalPriority,Wm)))}var es=null;function jd(e){es!==e&&(es=e,j.unstable_scheduleCallback(j.unstable_NormalPriority,function(){es===e&&(es=null);for(var t=0;t<e.length;t+=3){var l=e[t],a=e[t+1],n=e[t+2];if(typeof a!="function"){if(mc(a||l)===null)continue;break}var i=fa(l);i!==null&&(e.splice(t,3),t-=3,du(i,{pending:!0,data:n,method:l.method,action:a},a,n))}}))}function Za(e){function t(r){return Ii(r,e)}wl!==null&&Ii(wl,e),Hl!==null&&Ii(Hl,e),Bl!==null&&Ii(Bl,e),Hn.forEach(t),Bn.forEach(t);for(var l=0;l<Ll.length;l++){var a=Ll[l];a.blockedOn===e&&(a.blockedOn=null)}for(;0<Ll.length&&(l=Ll[0],l.blockedOn===null);)yd(l),l.blockedOn===null&&Ll.shift();if(l=(e.ownerDocument||e).$$reactFormReplay,l!=null)for(a=0;a<l.length;a+=3){var n=l[a],i=l[a+1],u=n[dt]||null;if(typeof i=="function")u||jd(l);else if(u){var c=null;if(i&&i.hasAttribute("formAction")){if(n=i,u=i[dt]||null)c=u.formAction;else if(mc(n)!==null)continue}else c=u.action;typeof c=="function"?l[a+1]=c:(l.splice(a,3),a-=3),jd(l)}}}function Nd(){function e(i){i.canIntercept&&i.info==="react-transition"&&i.intercept({handler:function(){return new Promise(function(u){return n=u})},focusReset:"manual",scroll:"manual"})}function t(){n!==null&&(n(),n=null),a||setTimeout(l,20)}function l(){if(!a&&!navigation.transition){var i=navigation.currentEntry;i&&i.url!=null&&navigation.navigate(i.url,{state:i.getState(),info:"react-transition",history:"replace"})}}if(typeof navigation=="object"){var a=!1,n=null;return navigation.addEventListener("navigate",e),navigation.addEventListener("navigatesuccess",t),navigation.addEventListener("navigateerror",t),setTimeout(l,100),function(){a=!0,navigation.removeEventListener("navigate",e),navigation.removeEventListener("navigatesuccess",t),navigation.removeEventListener("navigateerror",t),n!==null&&(n(),n=null)}}}function xc(e){this._internalRoot=e}ts.prototype.render=xc.prototype.render=function(e){var t=this._internalRoot;if(t===null)throw Error(o(409));var l=t.current,a=Tt();md(l,a,e,t,null,null)},ts.prototype.unmount=xc.prototype.unmount=function(){var e=this._internalRoot;if(e!==null){this._internalRoot=null;var t=e.containerInfo;md(e.current,2,null,e,null,null),wi(),t[ca]=null}};function ts(e){this._internalRoot=e}ts.prototype.unstable_scheduleHydration=function(e){if(e){var t=Mc();e={blockedOn:null,target:e,priority:t};for(var l=0;l<Ll.length&&t!==0&&t<Ll[l].priority;l++);Ll.splice(l,0,e),l===0&&yd(e)}};var Sd=J.version;if(Sd!=="19.2.3")throw Error(o(527,Sd,"19.2.3"));O.findDOMNode=function(e){var t=e._reactInternals;if(t===void 0)throw typeof e.render=="function"?Error(o(188)):(e=Object.keys(e).join(","),Error(o(268,e)));return e=v(t),e=e!==null?z(e):null,e=e===null?null:e.stateNode,e};var Fm={bundleType:0,version:"19.2.3",rendererPackageName:"react-dom",currentDispatcherRef:h,reconcilerVersion:"19.2.3"};if(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__<"u"){var ls=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!ls.isDisabled&&ls.supportsFiber)try{P=ls.inject(Fm),qe=ls}catch{}}return Yn.createRoot=function(e,t){if(!R(e))throw Error(o(299));var l=!1,a="",n=Of,i=Mf,u=Df;return t!=null&&(t.unstable_strictMode===!0&&(l=!0),t.identifierPrefix!==void 0&&(a=t.identifierPrefix),t.onUncaughtError!==void 0&&(n=t.onUncaughtError),t.onCaughtError!==void 0&&(i=t.onCaughtError),t.onRecoverableError!==void 0&&(u=t.onRecoverableError)),t=od(e,1,!1,null,null,l,a,null,n,i,u,Nd),e[ca]=t.current,Wu(e),new xc(t)},Yn.hydrateRoot=function(e,t,l){if(!R(e))throw Error(o(299));var a=!1,n="",i=Of,u=Mf,c=Df,r=null;return l!=null&&(l.unstable_strictMode===!0&&(a=!0),l.identifierPrefix!==void 0&&(n=l.identifierPrefix),l.onUncaughtError!==void 0&&(i=l.onUncaughtError),l.onCaughtError!==void 0&&(u=l.onCaughtError),l.onRecoverableError!==void 0&&(c=l.onRecoverableError),l.formState!==void 0&&(r=l.formState)),t=od(e,1,!0,t,l??null,a,n,r,i,u,c,Nd),t.context=dd(null),l=t.current,a=Tt(),a=is(a),n=Sl(a),n.callback=null,El(l,n,a),l=a,t.current.lanes=l,ka(t,l),Jt(t),e[ca]=t.current,Wu(e),new ts(t)},Yn.version="19.2.3",Yn}var Rd;function uh(){if(Rd)return vc.exports;Rd=1;function j(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(j)}catch(J){console.error(J)}}return j(),vc.exports=sh(),vc.exports}var ch=uh();const Ud="http://localhost:8000";function rh(){const j=N.useRef(null),J=N.useCallback((R,U,w="choreography")=>{j.current&&j.current.close();const te=`${Ud}/api/pnrs/${R}/evaluate?execution_mode=${w}`,_=new EventSource(te);return j.current=_,_.addEventListener("pipeline_start",v=>{const z=JSON.parse(v.data);U.onPipelineStart?.(z)}),_.addEventListener("planner_start",v=>{const z=JSON.parse(v.data);U.onPlannerStart?.(z)}),_.addEventListener("planner_decision",v=>{const z=JSON.parse(v.data);U.onPlannerDecision?.(z)}),_.addEventListener("agent_start",v=>{const z=JSON.parse(v.data);U.onAgentStart?.(z)}),_.addEventListener("agent_complete",v=>{const z=JSON.parse(v.data);U.onAgentComplete?.(z)}),_.addEventListener("agent_skip",v=>{const z=JSON.parse(v.data);U.onAgentSkip?.(z)}),_.addEventListener("rewoo_planner_complete",v=>{const z=JSON.parse(v.data);U.onReWOOPlannerComplete?.(z)}),_.addEventListener("rewoo_worker_step",v=>{const z=JSON.parse(v.data);U.onReWOOWorkerStep?.(z)}),_.addEventListener("rewoo_solver_complete",v=>{const z=JSON.parse(v.data);U.onReWOOSolverComplete?.(z)}),_.addEventListener("pipeline_complete",v=>{const z=JSON.parse(v.data);U.onPipelineComplete?.(z),_.close()}),_.addEventListener("error",v=>{const z=JSON.parse(v.data||"{}");U.onError?.(z.error||"Unknown error"),_.close()}),_.onerror=()=>{U.onError?.("Connection error"),_.close()},()=>{_.close()}},[]),D=N.useCallback(()=>{j.current&&(j.current.close(),j.current=null)},[]),o=N.useCallback(async(R,U=!1)=>{const w=`${Ud}/api/pnrs/${R}/evaluate-hitl?force_approval=${U}`,te=await fetch(w);if(!te.ok)throw new Error(`HITL evaluation failed: ${te.statusText}`);return te.json()},[]);return{startEvaluation:J,stopEvaluation:D,startEvaluationHITL:o}}function fh(j){if(!j.should_send_offer)return{offerType:"SUPPRESSED",offerName:`No Offer (${j.suppression_reason||"Criteria not met"})`,price:0,discount:0,expectedValue:0,confidence:"N/A",channel:"N/A",reasoning:j.suppression_reason||"Customer did not meet offer criteria"};const J={IU_BUSINESS:"Business Class Upgrade",IU_PREMIUM_ECONOMY:"Premium Economy Upgrade",MCE:"Main Cabin Extra"},D=j.offer_type||"UNKNOWN",o=j.price||0,R=j.discount_percent||0,te=.3*o*.85;return{offerType:D,offerName:J[D]||D,price:o,discount:R,expectedValue:te,confidence:R>0?"MEDIUM":"HIGH",channel:j.channel||"Push",reasoning:j.message_body||`Recommended ${J[D]||D} at $${o}`}}const Nc="http://localhost:8000";function oh({agentId:j,agentName:J,onPromptUpdated:D}){const[o,R]=N.useState(null),[U,w]=N.useState(""),[te,_]=N.useState(!1),[v,z]=N.useState(!1),[M,k]=N.useState(null),[Ne,je]=N.useState(!1);N.useEffect(()=>{ge()},[j]);const ge=async()=>{try{const ne=await(await fetch(`${Nc}/api/agents/${j}/prompt`)).json();R(ne),w(ne.system_prompt||""),k(null)}catch{k("Failed to load prompt")}},Q=async()=>{z(!0);try{(await fetch(`${Nc}/api/agents/${j}/prompt`,{method:"PUT",headers:{"Content-Type":"application/json"},body:JSON.stringify({system_prompt:U})})).ok?(await ge(),_(!1),D?.()):k("Failed to save prompt")}catch{k("Failed to save prompt")}finally{z(!1)}},oe=async()=>{z(!0);try{(await fetch(`${Nc}/api/agents/${j}/prompt`,{method:"DELETE"})).ok&&(await ge(),_(!1),D?.())}catch{k("Failed to reset prompt")}finally{z(!1)}};return o?o.type==="rules"?s.jsxs("div",{className:"bg-slate-50 border border-slate-200 rounded-lg p-4",children:[s.jsxs("div",{className:"flex items-center gap-2 mb-2",children:[s.jsx("span",{className:"text-lg",children:"‚ö°"}),s.jsx("span",{className:"font-medium text-slate-700",children:"Rules-Based Agent"}),s.jsx("span",{className:"text-xs bg-slate-200 text-slate-600 px-2 py-0.5 rounded",children:"Not Editable"})]}),s.jsxs("p",{className:"text-sm text-slate-500",children:[o.description,". This agent uses deterministic logic, not LLM prompts."]})]}):s.jsxs("div",{className:"bg-blue-50 border border-blue-200 rounded-lg p-4",children:[s.jsxs("div",{className:"flex items-center justify-between mb-3",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:"text-lg",children:"üß†"}),s.jsx("span",{className:"font-medium text-blue-700",children:"LLM System Prompt"}),o.is_custom&&s.jsx("span",{className:"text-xs bg-amber-100 text-amber-700 px-2 py-0.5 rounded",children:"Customized"})]}),s.jsxs("div",{className:"flex items-center gap-2 text-xs",children:[s.jsx("span",{className:"text-blue-500",children:o.llm_provider}),!te&&s.jsx("button",{onClick:()=>_(!0),className:"px-2 py-1 bg-blue-100 text-blue-600 rounded hover:bg-blue-200 transition-colors",children:"‚úèÔ∏è Edit Prompt"})]})]}),M&&s.jsx("div",{className:"mb-3 text-sm text-red-600 bg-red-50 p-2 rounded",children:M}),te?s.jsxs("div",{className:"space-y-3",children:[s.jsx("textarea",{value:U,onChange:K=>w(K.target.value),className:"w-full h-64 p-3 text-sm font-mono bg-slate-800 text-slate-100 rounded-lg border border-slate-600 focus:outline-none focus:ring-2 focus:ring-blue-500",placeholder:"Enter system prompt..."}),s.jsxs("div",{className:"flex items-center justify-between",children:[s.jsxs("div",{className:"text-xs text-slate-500",children:[U.length," characters"]}),s.jsxs("div",{className:"flex items-center gap-2",children:[o.is_custom&&s.jsx("button",{onClick:oe,disabled:v,className:"px-3 py-1.5 text-sm text-amber-600 hover:bg-amber-50 rounded transition-colors",children:"Reset to Default"}),s.jsx("button",{onClick:()=>{w(o.system_prompt||""),_(!1)},disabled:v,className:"px-3 py-1.5 text-sm text-slate-600 hover:bg-slate-100 rounded transition-colors",children:"Cancel"}),s.jsx("button",{onClick:Q,disabled:v,className:"px-3 py-1.5 text-sm bg-blue-600 text-white rounded hover:bg-blue-700 transition-colors disabled:opacity-50",children:v?"Saving...":"Save & Re-run"})]})]}),s.jsx("div",{className:"text-xs text-blue-600 bg-blue-100 p-2 rounded",children:"üí° Tip: After saving, run the evaluation again to see how the new prompt affects the agent's reasoning."})]}):s.jsxs("div",{children:[s.jsxs("div",{className:"relative",children:[s.jsx("pre",{className:`text-xs font-mono bg-slate-800 text-slate-100 p-3 rounded-lg overflow-x-auto ${Ne?"max-h-none":"max-h-32"} overflow-y-hidden`,children:o.system_prompt}),!Ne&&o.system_prompt&&o.system_prompt.length>500&&s.jsx("div",{className:"absolute bottom-0 left-0 right-0 h-12 bg-gradient-to-t from-slate-800 to-transparent rounded-b-lg"})]}),o.system_prompt&&o.system_prompt.length>500&&s.jsx("button",{onClick:()=>je(!Ne),className:"mt-2 text-xs text-blue-600 hover:underline",children:Ne?"‚ñ≤ Show less":"‚ñº Show full prompt"})]})]}):s.jsx("div",{className:"animate-pulse bg-slate-100 rounded-lg p-4 h-20"})}function dh(){return s.jsx("div",{className:"flex flex-col items-center justify-center h-full text-center",children:s.jsxs("div",{className:"animate-fadeInUp",children:[s.jsx("div",{className:"text-6xl mb-6",children:"ü§ñ"}),s.jsx("h1",{className:"text-5xl font-bold mb-4 bg-gradient-to-r from-cyan-400 to-blue-500 bg-clip-text text-transparent",children:"AI Agents"}),s.jsx("p",{className:"text-xl text-slate-300 mb-8",children:"The Future of Intelligent Automation"}),s.jsxs("div",{className:"flex items-center justify-center gap-2 text-slate-400",children:[s.jsx("span",{className:"w-12 h-px bg-slate-600"}),s.jsx("span",{className:"text-sm",children:"American Airlines"}),s.jsx("span",{className:"w-12 h-px bg-slate-600"})]})]})})}function mh(){const[j,J]=N.useState(0);return N.useEffect(()=>{const D=setInterval(()=>{J(o=>(o+1)%4)},1500);return()=>clearInterval(D)},[]),s.jsxs("div",{className:"flex flex-col items-center justify-center h-full",children:[s.jsx("h2",{className:"text-3xl font-bold mb-8 text-slate-200 animate-fadeInUp",children:"Traditional Automation"}),s.jsx("div",{className:"flex items-center gap-4 mb-8",children:["If A","Then B","Else C","End"].map((D,o)=>s.jsxs("div",{className:"flex items-center",children:[s.jsx("div",{className:`w-24 h-16 rounded-lg flex items-center justify-center text-sm font-mono transition-all duration-500 ${j===o?"bg-amber-500 text-black scale-110 shadow-lg shadow-amber-500/50":"bg-slate-700 text-slate-300"}`,children:D}),o<3&&s.jsx("div",{className:`w-8 h-0.5 transition-colors duration-500 ${j>o?"bg-amber-500":"bg-slate-600"}`})]},o))}),s.jsx("div",{className:"max-w-lg text-center animate-fadeInUp animation-delay-500",children:s.jsxs("p",{className:"text-slate-400 text-lg",children:[s.jsx("span",{className:"text-amber-400 font-semibold",children:"Rigid rules."})," Fixed paths.",s.jsx("br",{}),"Every scenario must be pre-programmed."]})}),s.jsx("div",{className:"mt-8 flex gap-4",children:["‚ùå Limited flexibility","‚ùå Maintenance nightmare","‚ùå Cannot adapt"].map((D,o)=>s.jsx("div",{className:"bg-red-900/30 border border-red-500/30 rounded-lg px-4 py-2 text-sm text-red-300 animate-fadeInUp",style:{animationDelay:`${o*200}ms`},children:D},o))})]})}function hh(){return s.jsxs("div",{className:"flex flex-col items-center justify-center h-full",children:[s.jsxs("h2",{className:"text-3xl font-bold mb-8 text-slate-200 animate-fadeInUp",children:["Enter: ",s.jsx("span",{className:"text-cyan-400",children:"AI Agents"})]}),s.jsxs("div",{className:"relative mb-8",children:[s.jsx("div",{className:"w-32 h-32 rounded-full bg-gradient-to-br from-cyan-500 to-blue-600 flex items-center justify-center animate-pulse-slow",children:s.jsx("span",{className:"text-6xl",children:"üß†"})}),s.jsx("div",{className:"absolute -top-2 -right-2 w-8 h-8 bg-emerald-500 rounded-full flex items-center justify-center animate-bounce",children:s.jsx("span",{className:"text-lg",children:"‚ú®"})})]}),s.jsx("div",{className:"max-w-2xl text-center mb-8 animate-fadeInUp animation-delay-300",children:s.jsxs("p",{className:"text-xl text-slate-300",children:["Agents are ",s.jsx("span",{className:"text-cyan-400 font-semibold",children:"autonomous systems"})," that can ",s.jsx("span",{className:"text-emerald-400 font-semibold",children:"reason"}),",",s.jsx("span",{className:"text-purple-400 font-semibold",children:" plan"}),", and",s.jsx("span",{className:"text-amber-400 font-semibold",children:" act"})," to achieve goals."]})}),s.jsx("div",{className:"grid grid-cols-3 gap-6 animate-fadeInUp animation-delay-500",children:[{icon:"üéØ",title:"Goal-Oriented",desc:"Give it objectives, not instructions"},{icon:"üîÑ",title:"Adaptive",desc:"Handles new situations gracefully"},{icon:"üí°",title:"Explainable",desc:"Shows its reasoning process"}].map((j,J)=>s.jsxs("div",{className:"bg-slate-800/50 border border-cyan-500/30 rounded-xl p-4 text-center",children:[s.jsx("div",{className:"text-3xl mb-2",children:j.icon}),s.jsx("div",{className:"font-semibold text-cyan-300 mb-1",children:j.title}),s.jsx("div",{className:"text-sm text-slate-400",children:j.desc})]},J))})]})}function xh(){return s.jsxs("div",{className:"flex flex-col items-center justify-center h-full",children:[s.jsx("h2",{className:"text-3xl font-bold mb-8 text-slate-200 animate-fadeInUp",children:"The Difference"}),s.jsxs("div",{className:"grid grid-cols-2 gap-8 max-w-4xl",children:[s.jsxs("div",{className:"bg-slate-800/50 border border-red-500/30 rounded-2xl p-6 animate-fadeInLeft",children:[s.jsxs("div",{className:"text-center mb-4",children:[s.jsx("span",{className:"text-4xl",children:"‚öôÔ∏è"}),s.jsx("h3",{className:"text-xl font-bold text-red-400 mt-2",children:"Traditional Workflow"})]}),s.jsxs("ul",{className:"space-y-3 text-slate-300",children:[s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-red-400",children:"‚Üí"}),s.jsx("span",{children:"Pre-defined decision trees"})]}),s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-red-400",children:"‚Üí"}),s.jsx("span",{children:"Developers write every rule"})]}),s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-red-400",children:"‚Üí"}),s.jsx("span",{children:"Fails on edge cases"})]}),s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-red-400",children:"‚Üí"}),s.jsx("span",{children:"Updates require code changes"})]})]}),s.jsx("div",{className:"mt-4 text-center text-sm text-red-300 bg-red-900/20 rounded-lg py-2",children:'"Computer, do exactly this..."'})]}),s.jsxs("div",{className:"bg-slate-800/50 border border-cyan-500/30 rounded-2xl p-6 animate-fadeInRight",children:[s.jsxs("div",{className:"text-center mb-4",children:[s.jsx("span",{className:"text-4xl",children:"ü§ñ"}),s.jsx("h3",{className:"text-xl font-bold text-cyan-400 mt-2",children:"AI Agent"})]}),s.jsxs("ul",{className:"space-y-3 text-slate-300",children:[s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-cyan-400",children:"‚Üí"}),s.jsx("span",{children:"Reasons about each situation"})]}),s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-cyan-400",children:"‚Üí"}),s.jsx("span",{children:"Business users define goals"})]}),s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-cyan-400",children:"‚Üí"}),s.jsx("span",{children:"Adapts to new scenarios"})]}),s.jsxs("li",{className:"flex items-start gap-2",children:[s.jsx("span",{className:"text-cyan-400",children:"‚Üí"}),s.jsx("span",{children:"Edit prompts in plain English"})]})]}),s.jsx("div",{className:"mt-4 text-center text-sm text-cyan-300 bg-cyan-900/20 rounded-lg py-2",children:'"Agent, achieve this goal..."'})]})]})]})}function ph(){const[j,J]=N.useState(0);N.useEffect(()=>{const o=setInterval(()=>{J(R=>(R+1)%4)},2e3);return()=>clearInterval(o)},[]);const D=[{icon:"üìã",name:"Planner",color:"cyan",desc:"Analyzes data & creates evaluation plan"},{icon:"‚öôÔ∏è",name:"Worker",color:"purple",desc:"Executes all evaluations in parallel"},{icon:"‚úÖ",name:"Solver",color:"emerald",desc:"Synthesizes evidence & decides"}];return s.jsxs("div",{className:"flex flex-col items-center justify-center h-full",children:[s.jsxs("h2",{className:"text-3xl font-bold mb-2 text-slate-200 animate-fadeInUp",children:["The ",s.jsx("span",{className:"text-cyan-400",children:"ReWOO"})," Pattern"]}),s.jsx("p",{className:"text-slate-400 mb-8 animate-fadeInUp animation-delay-200",children:"Reasoning Without Observation - Efficient & Transparent"}),s.jsx("div",{className:"flex items-center gap-4 mb-8",children:D.map((o,R)=>s.jsxs("div",{className:"flex items-center",children:[s.jsxs("div",{className:`w-40 rounded-2xl p-4 text-center transition-all duration-500 ${j===R?o.color==="cyan"?"bg-cyan-600 scale-110 shadow-lg shadow-cyan-500/50":o.color==="purple"?"bg-purple-600 scale-110 shadow-lg shadow-purple-500/50":"bg-emerald-600 scale-110 shadow-lg shadow-emerald-500/50":"bg-slate-700"}`,children:[s.jsx("div",{className:"text-3xl mb-2",children:o.icon}),s.jsx("div",{className:"font-bold text-white",children:o.name}),s.jsx("div",{className:`text-xs mt-1 ${j===R?"text-white/80":"text-slate-400"}`,children:o.desc})]}),R<2&&s.jsx("div",{className:`w-8 h-1 mx-2 rounded transition-colors duration-500 ${j>R?o.color==="cyan"?"bg-cyan-500":"bg-purple-500":"bg-slate-600"}`})]},R))}),s.jsx("div",{className:"bg-slate-800/50 border border-slate-600 rounded-xl p-4 max-w-xl text-center animate-fadeInUp animation-delay-500",children:s.jsxs("p",{className:"text-slate-300",children:["Only ",s.jsx("span",{className:"text-cyan-400 font-bold",children:"2-3 LLM calls"})," total, compared to ",s.jsx("span",{className:"text-red-400",children:"N calls"})," in older patterns.",s.jsx("br",{}),s.jsx("span",{className:"text-slate-400 text-sm",children:"Fast, efficient, and fully transparent!"})]})})]})}function gh(){return s.jsxs("div",{className:"flex flex-col items-center justify-center h-full",children:[s.jsx("h2",{className:"text-3xl font-bold mb-8 text-slate-200 animate-fadeInUp",children:"Demo Walkthrough"}),s.jsx("div",{className:"grid grid-cols-2 gap-6 max-w-4xl",children:[{step:"1",icon:"üéõÔ∏è",title:"Control Agent",desc:"Edit Planner, Worker, Solver prompts in plain English",color:"cyan"},{step:"2",icon:"üë§",title:"Select Customer",desc:"Choose a PNR to see different scenarios",color:"blue"},{step:"3",icon:"‚ñ∂Ô∏è",title:"Run Agent",desc:"Watch real-time reasoning from LangGraph",color:"emerald"},{step:"4",icon:"üéØ",title:"See Decision",desc:"Agent recommends personalized offer",color:"amber"}].map((j,J)=>s.jsxs("div",{className:`bg-slate-800/50 border rounded-xl p-4 flex items-start gap-4 animate-fadeInUp ${j.color==="cyan"?"border-cyan-500/30":j.color==="blue"?"border-blue-500/30":j.color==="emerald"?"border-emerald-500/30":"border-amber-500/30"}`,style:{animationDelay:`${J*150}ms`},children:[s.jsx("div",{className:`w-10 h-10 rounded-full flex items-center justify-center text-lg font-bold ${j.color==="cyan"?"bg-cyan-600":j.color==="blue"?"bg-blue-600":j.color==="emerald"?"bg-emerald-600":"bg-amber-600"}`,children:j.step}),s.jsxs("div",{children:[s.jsxs("div",{className:"flex items-center gap-2 mb-1",children:[s.jsx("span",{className:"text-xl",children:j.icon}),s.jsx("span",{className:"font-semibold text-white",children:j.title})]}),s.jsx("p",{className:"text-sm text-slate-400",children:j.desc})]})]},J))}),s.jsx("div",{className:"mt-8 text-center animate-fadeInUp animation-delay-700",children:s.jsx("p",{className:"text-slate-400",children:"Try editing prompts to see how agent behavior changes!"})})]})}function vh(){return s.jsx("div",{className:"flex flex-col items-center justify-center h-full text-center",children:s.jsxs("div",{className:"animate-fadeInUp",children:[s.jsx("div",{className:"text-6xl mb-6",children:"üöÄ"}),s.jsx("h2",{className:"text-4xl font-bold mb-4 text-white",children:"Ready to Explore?"}),s.jsx("p",{className:"text-xl text-slate-300 mb-8",children:"Click anywhere to close and start the demo"}),s.jsx("div",{className:"flex items-center justify-center gap-4",children:s.jsx("div",{className:"bg-cyan-600 rounded-full px-6 py-3 text-white font-semibold animate-pulse",children:"Let's Go!"})})]})})}const yh=[{id:"nova",label:"Nova",description:"Warm, engaging"},{id:"alloy",label:"Alloy",description:"Neutral, balanced"},{id:"echo",label:"Echo",description:"Deeper tone"},{id:"fable",label:"Fable",description:"Expressive"},{id:"onyx",label:"Onyx",description:"Deep, resonant"},{id:"shimmer",label:"Shimmer",description:"Clear, optimistic"}],bh={title:"Welcome to AI Agents. The future of intelligent automation for American Airlines.",traditional:"Traditional automation relies on rigid if-then-else rules. Every scenario must be pre-programmed. When edge cases appear, the system fails. Updates require code changes and lengthy deployment cycles.","agent-intro":"AI Agents are autonomous systems that can reason, plan, and act to achieve goals. They are goal-oriented, adaptive, and explainable.",comparison:"Traditional workflows use pre-defined decision trees. AI Agents reason about each situation dynamically. Business users define goals in plain English.",rewoo:"This demo uses the ReWOO pattern: Planner analyzes data, Worker executes evaluations in parallel, Solver synthesizes evidence and decides. Only 2-3 LLM calls total.",walkthrough:"Use the prompt editor to control agent behavior. Select a customer scenario. Click Run Agent to watch real-time reasoning. See the personalized offer recommendation.",outro:"You are ready to explore AI Agents. Click anywhere to close and start the demo."};function jh(){const[j,J]=N.useState(!1),[D,o]=N.useState(0),[R,U]=N.useState(!1),[w,te]=N.useState(!1),[_,v]=N.useState(!1),[z,M]=N.useState(null),[k,Ne]=N.useState("nova"),[je,ge]=N.useState(!1),[Q,oe]=N.useState(!0),[K,ne]=N.useState(!1),ee=N.useRef(null),$=N.useRef(new Map),H=N.useRef(null),Y=N.useRef(!1),ae=[{id:"title",duration:8,content:s.jsx(dh,{})},{id:"traditional",duration:25,title:"Traditional Automation",content:s.jsx(mh,{})},{id:"agent-intro",duration:22,title:"AI Agents",content:s.jsx(hh,{})},{id:"comparison",duration:28,title:"The Difference",content:s.jsx(xh,{})},{id:"rewoo",duration:30,title:"ReWOO Pattern",content:s.jsx(ph,{})},{id:"walkthrough",duration:25,title:"Demo Walkthrough",content:s.jsx(gh,{})},{id:"outro",duration:12,content:s.jsx(vh,{})}];N.useEffect(()=>{Y.current=R},[R]),N.useEffect(()=>{if(!j||!R||w)return;const h=ae[D].id,O=`${h}-${k}`;if(H.current===O)return;ee.current&&(ee.current.pause(),ee.current.currentTime=0),H.current=O,v(!0),M(null),(async()=>{try{let F=$.current.get(O);if(!F){try{const f=await fetch(`/audio/${h}.mp3`);if(f.ok){const E=await f.blob();F=URL.createObjectURL(E),$.current.set(O,F)}}catch{}if(!F){const f=await fetch(`/api/tts/narration/${h}?voice=${k}`);if(!f.ok){const C=await f.json();throw new Error(C.detail||"Failed to load audio")}const E=await f.blob();F=URL.createObjectURL(E),$.current.set(O,F)}}const le=new Audio(F);ee.current=le,le.onended=()=>{H.current=null,Y.current&&o(f=>f<ae.length-1?f+1:(U(!1),f))},le.onerror=()=>{H.current=null,M("Audio playback failed")},await le.play(),v(!1),ne(!1)}catch(F){H.current=null,v(!1),ne(!0),oe(!0);const le=F instanceof Error?F.message:"Audio failed";z||M(le.includes("API key")?"Voice unavailable - showing subtitles":le),console.log("Audio unavailable, using subtitles:",le);const f=ae[D].duration;setTimeout(()=>{Y.current&&D<ae.length-1&&o(E=>E+1)},f*1e3)}})()},[D,j,R,w,k,ae]),N.useEffect(()=>()=>{ee.current&&ee.current.pause(),$.current.forEach(h=>URL.revokeObjectURL(h))},[]);const Oe=N.useCallback(()=>{H.current=null,o(0),J(!0),U(!0),M(null)},[]),Qe=N.useCallback(()=>{ee.current&&ee.current.pause(),H.current=null,J(!1),U(!1),o(0)},[]),Ye=N.useCallback(()=>{D>0&&(ee.current&&ee.current.pause(),o(h=>h-1))},[D]),Se=N.useCallback(()=>{D<ae.length-1&&(ee.current&&ee.current.pause(),o(h=>h+1))},[D,ae.length]),Pe=N.useCallback(()=>{R?(ee.current&&ee.current.pause(),U(!1)):(U(!0),ee.current&&!w&&ee.current.play().catch(()=>{}))},[R,w]),Je=N.useCallback(()=>{te(h=>{const O=!h;return O?ee.current&&ee.current.pause():H.current=null,O})},[]),et=(D+1)/ae.length*100;return s.jsxs(s.Fragment,{children:[s.jsxs("button",{onClick:Oe,className:"fixed bottom-6 right-6 z-40 bg-gradient-to-r from-cyan-500 to-blue-600 hover:from-cyan-400 hover:to-blue-500 text-white rounded-full px-6 py-3 shadow-2xl flex items-center gap-3 transition-all hover:scale-105 group",children:[s.jsx("span",{className:"text-2xl group-hover:animate-bounce",children:"üé¨"}),s.jsx("span",{className:"font-semibold",children:"Watch Explainer"}),s.jsx("span",{className:"text-xs bg-white/20 px-2 py-0.5 rounded-full",children:"2 min"})]}),j&&s.jsx("div",{className:"fixed inset-0 z-50 bg-black/95 flex items-center justify-center",onClick:h=>{h.target===h.currentTarget&&D===ae.length-1&&Qe()},children:s.jsxs("div",{className:"relative w-full max-w-5xl h-[80vh] bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 rounded-2xl overflow-hidden shadow-2xl border border-slate-700",children:[s.jsx("button",{onClick:Qe,className:"absolute top-4 right-4 z-10 w-10 h-10 bg-slate-800/80 hover:bg-slate-700 rounded-full flex items-center justify-center text-slate-300 hover:text-white transition-colors",children:s.jsx("svg",{className:"w-6 h-6",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M6 18L18 6M6 6l12 12"})})}),s.jsx("div",{className:"h-full p-8 flex items-center justify-center",children:s.jsx("div",{className:"w-full h-full animate-fadeIn",children:ae[D].content},D)}),s.jsx("div",{className:"absolute bottom-0 left-0 right-0 h-1 bg-slate-700",children:s.jsx("div",{className:"h-full bg-gradient-to-r from-cyan-500 to-blue-500 transition-all duration-500",style:{width:`${et}%`}})}),_&&s.jsxs("div",{className:"absolute top-4 left-4 flex items-center gap-2 bg-slate-800/80 rounded-lg px-3 py-2",children:[s.jsx("div",{className:"w-4 h-4 border-2 border-cyan-400 border-t-transparent rounded-full animate-spin"}),s.jsx("span",{className:"text-xs text-slate-300",children:"Loading voice..."})]}),z&&!w&&s.jsxs("div",{className:"absolute top-4 left-4 flex items-center gap-2 bg-slate-800/90 rounded-lg px-3 py-2",children:[s.jsx("span",{className:"text-cyan-400",children:"üí¨"}),s.jsx("span",{className:"text-xs text-slate-300",children:"Subtitles enabled"})]}),Q&&s.jsx("div",{className:"absolute bottom-24 left-1/2 -translate-x-1/2 max-w-3xl w-full px-4",children:s.jsx("div",{className:"bg-black/80 rounded-lg px-6 py-3 text-center",children:s.jsx("p",{className:"text-white text-lg leading-relaxed",children:bh[ae[D].id]||""})})}),je&&s.jsxs("div",{className:"absolute bottom-20 left-1/2 -translate-x-1/2 bg-slate-800 rounded-xl p-4 shadow-xl border border-slate-600",children:[s.jsx("div",{className:"text-sm text-slate-300 mb-3 font-medium",children:"Select Voice"}),s.jsx("div",{className:"grid grid-cols-3 gap-2",children:yh.map(h=>s.jsxs("button",{onClick:()=>{ee.current&&ee.current.pause(),Ne(h.id),ge(!1),H.current=null},className:`px-3 py-2 rounded-lg text-sm transition-all ${k===h.id?"bg-cyan-600 text-white":"bg-slate-700 text-slate-300 hover:bg-slate-600"}`,children:[s.jsx("div",{className:"font-medium",children:h.label}),s.jsx("div",{className:"text-xs opacity-70",children:h.description})]},h.id))})]}),s.jsxs("div",{className:"absolute bottom-4 left-1/2 -translate-x-1/2 flex items-center gap-3 bg-slate-800/90 rounded-full px-4 py-2",children:[s.jsx("button",{onClick:Je,className:`w-8 h-8 flex items-center justify-center rounded-full transition-colors ${w?"text-red-400 hover:text-red-300":"text-slate-300 hover:text-white"}`,title:w?"Unmute":"Mute",children:w?s.jsxs("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:[s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z"}),s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M17 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2"})]}):s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z"})})}),s.jsx("button",{onClick:()=>oe(h=>!h),className:`w-8 h-8 flex items-center justify-center rounded-full transition-colors ${Q?"text-cyan-400 hover:text-cyan-300":"text-slate-300 hover:text-white"}`,title:Q?"Hide subtitles":"Show subtitles",children:s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"})})}),s.jsx("button",{onClick:()=>ge(h=>!h),disabled:K,className:`w-8 h-8 flex items-center justify-center transition-colors ${K?"text-slate-500 cursor-not-allowed":"text-slate-300 hover:text-white"}`,title:K?"Voice unavailable":"Change voice",children:s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"})})}),s.jsx("div",{className:"w-px h-6 bg-slate-600"}),s.jsx("button",{onClick:Ye,disabled:D===0,className:"w-8 h-8 flex items-center justify-center text-slate-300 hover:text-white disabled:opacity-30 disabled:cursor-not-allowed transition-colors",children:s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M15 19l-7-7 7-7"})})}),s.jsx("button",{onClick:Pe,className:"w-10 h-10 bg-cyan-600 hover:bg-cyan-500 rounded-full flex items-center justify-center text-white transition-colors",children:R?s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M10 9v6m4-6v6"})}):s.jsx("svg",{className:"w-5 h-5 ml-0.5",fill:"currentColor",viewBox:"0 0 24 24",children:s.jsx("path",{d:"M8 5v14l11-7z"})})}),s.jsx("button",{onClick:Se,disabled:D===ae.length-1,className:"w-8 h-8 flex items-center justify-center text-slate-300 hover:text-white disabled:opacity-30 disabled:cursor-not-allowed transition-colors",children:s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M9 5l7 7-7 7"})})}),s.jsx("div",{className:"w-px h-6 bg-slate-600"}),s.jsx("div",{className:"flex items-center gap-1",children:ae.map((h,O)=>s.jsx("button",{onClick:()=>{ee.current&&ee.current.pause(),o(O)},className:`w-2 h-2 rounded-full transition-all ${O===D?"bg-cyan-400 w-4":"bg-slate-600 hover:bg-slate-500"}`},O))}),s.jsxs("div",{className:"text-xs text-slate-400 ml-1",children:[D+1," / ",ae.length]})]})]})})]})}const Nh=["Be more friendly in messages","Focus on business travelers","Offer bigger discounts to loyal customers","Be more conservative with upgrade offers","Prioritize premium cabin upgrades","Add urgency to the messaging"];function Sh({onPromptUpdate:j,isOpen:J,onOpenChange:D}){const[o,R]=N.useState(!1),U=J!==void 0?J:o,w=Q=>{D?D(Q):R(Q)},[te,_]=N.useState([{id:"1",role:"assistant",content:`Hi! I'm your Prompt Assistant ü§ñ

Tell me how you'd like to change the agent's behavior in plain English, and I'll update the prompts for you safely.

For example:
‚Ä¢ "Be more friendly in messages"
‚Ä¢ "Focus on business travelers"
‚Ä¢ "Offer bigger discounts to loyal customers"`,timestamp:new Date}]),[v,z]=N.useState(""),[M,k]=N.useState(!1),Ne=N.useRef(null);N.useEffect(()=>{Ne.current?.scrollIntoView({behavior:"smooth"})},[te]);const je=async Q=>{if(Q.preventDefault(),!v.trim()||M)return;const oe={id:Date.now().toString(),role:"user",content:v.trim(),timestamp:new Date};_(K=>[...K,oe]),z(""),k(!0);try{const ne=await(await fetch("/api/prompt-assistant/instruct",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({instruction:oe.content})})).json(),ee={id:(Date.now()+1).toString(),role:"assistant",content:ne.message,timestamp:new Date,status:ne.status};if(_($=>[...$,ee]),ne.status==="success"&&ne.updated_prompts&&j)for(const $ of ne.updated_prompts)j($.agent_id,$.new_prompt)}catch{const ne={id:(Date.now()+1).toString(),role:"assistant",content:"Sorry, I couldn't process that request. Please try again.",timestamp:new Date,status:"error"};_(ee=>[...ee,ne])}finally{k(!1)}},ge=Q=>{z(Q)};return s.jsxs(s.Fragment,{children:[s.jsx("button",{onClick:()=>w(!0),className:`fixed bottom-6 left-6 z-40 bg-gradient-to-r from-purple-500 to-indigo-600 hover:from-purple-400 hover:to-indigo-500 text-white rounded-full p-4 shadow-2xl transition-all hover:scale-110 ${U?"hidden":""}`,title:"Prompt Assistant",children:s.jsxs("div",{className:"relative",children:[s.jsx("svg",{className:"w-8 h-8",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"})}),s.jsx("span",{className:"absolute -top-1 -right-1 w-4 h-4 bg-green-400 rounded-full border-2 border-white animate-pulse"})]})}),U&&s.jsxs("div",{className:"fixed bottom-6 left-6 z-50 w-96 h-[32rem] bg-slate-900 rounded-2xl shadow-2xl border border-slate-700 flex flex-col overflow-hidden animate-slideUp",children:[s.jsxs("div",{className:"bg-gradient-to-r from-purple-600 to-indigo-600 px-4 py-3 flex items-center justify-between",children:[s.jsxs("div",{className:"flex items-center gap-3",children:[s.jsx("div",{className:"w-10 h-10 bg-white/20 rounded-full flex items-center justify-center",children:s.jsx("span",{className:"text-2xl",children:"ü§ñ"})}),s.jsxs("div",{children:[s.jsx("h3",{className:"font-semibold text-white",children:"Prompt Assistant"}),s.jsx("p",{className:"text-xs text-purple-200",children:"Modify agent behavior safely"})]})]}),s.jsx("button",{onClick:()=>w(!1),className:"text-white/70 hover:text-white transition-colors",children:s.jsx("svg",{className:"w-6 h-6",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M6 18L18 6M6 6l12 12"})})})]}),s.jsxs("div",{className:"flex-1 overflow-y-auto p-4 space-y-4 custom-scrollbar",children:[te.map(Q=>s.jsx("div",{className:`flex ${Q.role==="user"?"justify-end":"justify-start"}`,children:s.jsx("div",{className:`max-w-[85%] rounded-2xl px-4 py-2 ${Q.role==="user"?"bg-purple-600 text-white":Q.status==="error"?"bg-red-900/50 border border-red-500/50 text-red-200":Q.status==="warning"?"bg-amber-900/50 border border-amber-500/50 text-amber-200":Q.status==="success"?"bg-emerald-900/50 border border-emerald-500/50 text-emerald-200":"bg-slate-800 text-slate-200"}`,children:s.jsx("p",{className:"text-sm whitespace-pre-wrap",children:Q.content})})},Q.id)),M&&s.jsx("div",{className:"flex justify-start",children:s.jsx("div",{className:"bg-slate-800 rounded-2xl px-4 py-3",children:s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("div",{className:"w-2 h-2 bg-purple-400 rounded-full animate-bounce"}),s.jsx("div",{className:"w-2 h-2 bg-purple-400 rounded-full animate-bounce",style:{animationDelay:"0.1s"}}),s.jsx("div",{className:"w-2 h-2 bg-purple-400 rounded-full animate-bounce",style:{animationDelay:"0.2s"}})]})})}),s.jsx("div",{ref:Ne})]}),te.length<=2&&s.jsxs("div",{className:"px-4 pb-2",children:[s.jsx("p",{className:"text-xs text-slate-500 mb-2",children:"Try these:"}),s.jsx("div",{className:"flex flex-wrap gap-1",children:Nh.slice(0,3).map((Q,oe)=>s.jsx("button",{onClick:()=>ge(Q),className:"text-xs bg-slate-800 hover:bg-slate-700 text-slate-300 rounded-full px-3 py-1 transition-colors",children:Q},oe))})]}),s.jsx("form",{onSubmit:je,className:"p-4 border-t border-slate-700",children:s.jsxs("div",{className:"flex gap-2",children:[s.jsx("input",{type:"text",value:v,onChange:Q=>z(Q.target.value),placeholder:"Describe how to change agent behavior...",className:"flex-1 bg-slate-800 border border-slate-600 rounded-xl px-4 py-2 text-sm text-white placeholder-slate-400 focus:outline-none focus:border-purple-500",disabled:M}),s.jsx("button",{type:"submit",disabled:!v.trim()||M,className:"bg-purple-600 hover:bg-purple-500 disabled:bg-slate-700 disabled:cursor-not-allowed text-white rounded-xl px-4 py-2 transition-colors",children:s.jsx("svg",{className:"w-5 h-5",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M12 19l9 2-9-18-9 18 9-2zm0 0v-8"})})})]})})]})]})}function Eh(){const[j,J]=N.useState({}),[D,o]=N.useState(!0),[R,U]=N.useState(null),[w,te]=N.useState(""),[_,v]=N.useState(!1),[z,M]=N.useState(null),k=N.useCallback(async()=>{try{const H=await(await fetch("/api/policies")).json();J(H.policies||{})}catch($){console.error("Failed to fetch policies:",$)}finally{o(!1)}},[]);N.useEffect(()=>{k();const $=setInterval(k,5e3);return()=>clearInterval($)},[k]);const Ne=($,H)=>{U($),te(H.value.toString()),M(null)},je=()=>{U(null),te("")},ge=async $=>{v(!0),M(null);try{const H=await fetch(`/api/policies/${$}`,{method:"PUT",headers:{"Content-Type":"application/json"},body:JSON.stringify({value:parseFloat(w)})}),Y=await H.json();H.ok?(M({type:"success",text:Y.message}),U(null),k()):M({type:"error",text:Y.detail||"Failed to save"})}catch{M({type:"error",text:"Network error"})}finally{v(!1)}},Q=async $=>{v(!0);try{const H=await fetch(`/api/policies/${$}`,{method:"DELETE"}),Y=await H.json();H.ok&&(M({type:"success",text:Y.message}),k())}catch{M({type:"error",text:"Failed to reset"})}finally{v(!1)}},oe=["goodwill_discount_percent","max_discount_percent","min_discount_percent","vip_discount_percent"],K=["min_confidence_threshold","high_confidence_threshold","vip_revenue_threshold"],ne=Object.keys(j).filter($=>!oe.includes($)&&!K.includes($)),ee=$=>{const H=j[$];if(!H)return null;const Y=R===$,ae=H.type==="decimal"?`${(H.value*100).toFixed(0)}%`:H.type==="currency"?`$${H.value.toLocaleString()}`:`${H.value}${H.unit}`;return s.jsx("div",{className:`p-3 rounded-lg border transition-all ${H.is_custom?"bg-cyan-900/30 border-cyan-500/50":"bg-slate-800/50 border-slate-700"}`,children:s.jsxs("div",{className:"flex items-start justify-between gap-2",children:[s.jsxs("div",{className:"flex-1 min-w-0",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:"font-medium text-sm text-slate-200",children:H.name}),H.is_custom&&s.jsx("span",{className:"text-xs bg-cyan-600 text-white px-1.5 py-0.5 rounded",children:"Modified"})]}),s.jsx("p",{className:"text-xs text-slate-400 mt-0.5 truncate",children:H.description})]}),Y?s.jsxs("div",{className:"flex items-center gap-1",children:[s.jsx("input",{type:"number",value:w,onChange:Oe=>te(Oe.target.value),step:H.type==="decimal"?"0.01":"1",min:H.min,max:H.max,className:"w-20 bg-slate-700 border border-slate-500 rounded px-2 py-1 text-sm text-white",autoFocus:!0}),s.jsx("button",{onClick:()=>ge($),disabled:_,className:"p-1 text-emerald-400 hover:text-emerald-300",children:"‚úì"}),s.jsx("button",{onClick:je,className:"p-1 text-slate-400 hover:text-slate-300",children:"‚úó"})]}):s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:`font-mono text-sm ${H.is_custom?"text-cyan-300":"text-slate-300"}`,children:ae}),s.jsx("button",{onClick:()=>Ne($,H),className:"p-1 text-slate-400 hover:text-white transition-colors",title:"Edit",children:s.jsx("svg",{className:"w-4 h-4",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M15.232 5.232l3.536 3.536m-2.036-5.036a2.5 2.5 0 113.536 3.536L6.5 21.036H3v-3.572L16.732 3.732z"})})}),H.is_custom&&s.jsx("button",{onClick:()=>Q($),className:"p-1 text-slate-400 hover:text-amber-400 transition-colors",title:"Reset to default",children:s.jsx("svg",{className:"w-4 h-4",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15"})})})]})]})},$)};return D?s.jsx("div",{className:"flex items-center justify-center p-8",children:s.jsx("div",{className:"w-6 h-6 border-2 border-cyan-400 border-t-transparent rounded-full animate-spin"})}):s.jsxs("div",{className:"space-y-4",children:[z&&s.jsx("div",{className:`p-3 rounded-lg text-sm ${z.type==="success"?"bg-emerald-900/50 border border-emerald-500/50 text-emerald-200":"bg-red-900/50 border border-red-500/50 text-red-200"}`,children:z.text}),s.jsxs("div",{children:[s.jsxs("h4",{className:"text-xs font-semibold text-slate-400 uppercase tracking-wider mb-2 flex items-center gap-2",children:[s.jsx("span",{children:"üí∞"})," Discount Policies"]}),s.jsx("div",{className:"space-y-2",children:oe.map(ee)})]}),s.jsxs("div",{children:[s.jsxs("h4",{className:"text-xs font-semibold text-slate-400 uppercase tracking-wider mb-2 flex items-center gap-2",children:[s.jsx("span",{children:"üìä"})," Thresholds"]}),s.jsx("div",{className:"space-y-2",children:K.map(ee)})]}),ne.length>0&&s.jsxs("div",{children:[s.jsxs("h4",{className:"text-xs font-semibold text-slate-400 uppercase tracking-wider mb-2 flex items-center gap-2",children:[s.jsx("span",{children:"‚öôÔ∏è"})," Other Settings"]}),s.jsx("div",{className:"space-y-2",children:ne.map(ee)})]}),s.jsx("div",{className:"bg-slate-800/30 rounded-lg p-3 text-xs text-slate-400",children:s.jsxs("p",{className:"flex items-center gap-1",children:[s.jsx("span",{children:"üí°"}),s.jsxs("span",{children:["Use the ",s.jsx("span",{className:"text-purple-400",children:"Prompt Assistant"})," with admin phrase to modify these values via natural language."]})]})})]})}const Sc="http://localhost:8000",Ah={E:"Executive Platinum",C:"Concierge Key",T:"Platinum Pro",P:"Platinum",G:"Gold",R:"AAdvantage",N:"General"};function Th({onSelectCustomer:j,onRunAgent:J,onToggleHITL:D,onExpandControlPanel:o,onToggleAdvancedMode:R,onOpenPromptAssistant:U,isAgentComplete:w,availablePNRs:te,customerInfo:_,plannerInfo:v,workerInfo:z,solverInfo:M}){const[k,Ne]=N.useState(!1),[je,ge]=N.useState(!1),[Q,oe]=N.useState(!1),[K,ne]=N.useState(0),[ee,$]=N.useState(null),[H,Y]=N.useState(""),[ae,Oe]=N.useState(""),[Qe,Ye]=N.useState(0),[Se,Pe]=N.useState(!1),[Je,et]=N.useState(!1),h=N.useRef(null),O=N.useRef(new Map),L=N.useRef(!1),F=N.useRef(!1),le=N.useRef(!1),f=N.useRef(0),E=N.useRef(!1),C=N.useRef(null),[B,X]=N.useState(!1),se=N.useCallback(()=>{if(!_||!v)return"See this? The Planner figured out, what factors matter, for this specific customer. Loyalty status. Recent history. Current context. Just like a human expert would.";const ce=Ah[_.loyalty_tier]||"General",V=_.flight_revenue_amt_history?.toLocaleString()||"0",W=v.plan.map(he=>he.evaluation_type).join(", "),re=v.offer_options.map(he=>he.cabin).join(" and ");return`Looking at ${_.name}, a ${ce} member, with $${V} annual revenue. Based on this profile, the Planner decides to evaluate: ${W}. The offer options being considered are: ${re}.`},[_,v]),ve=N.useCallback(()=>{if(!z||z.evaluations.length===0)return"Watch the Workers use MCP tools. Customer profile from AADV. Flight inventory from DCSID. ML scores from our models. The agent connects to existing systems, when it needs to.";const ce=["Worker executes each evaluation step via MCP tools."];for(const V of z.evaluations)V.type==="CONFIDENCE"&&V.recommendation?ce.push(`For confidence check: ${V.recommendation}.`):V.type==="PRICE_SENSITIVITY"&&V.recommendation?ce.push(`For price sensitivity: ${V.recommendation}.`):V.type==="INVENTORY"&&V.recommendation?ce.push(`For inventory: ${V.recommendation}.`):V.recommendation&&ce.push(`${V.type}: ${V.recommendation}.`);return ce.join(" ")},[z]),Ve=N.useCallback(()=>{if(!M||!M.selected_offer)return"Then, the Solver, reasons through all the evidence. Just like a human would reason it out. And you can read, exactly how it decided.";const ce=M.selected_offer,V=M.offer_price,W=M.expected_value?.toFixed(0)||"0",re=M.discount_applied||0;if(ce==="NONE"||!ce)return"The Solver analyzed all the evidence, and determined, no offer should be sent for this customer. You can see exactly why in the reasoning above.";let he="The Solver weighs all the evidence. ";return he+=`${ce} upgrade has the highest expected value at $${W}. `,re>0&&(he+=`A ${re}% discount is applied based on price sensitivity. `),he+=`Final recommendation: ${ce} upgrade at $${V}. `,he+="This is exactly how a human expert would reason through the same data.",he},[M]),we=N.useCallback(async ce=>{try{X(!0);const V=await fetch(`${Sc}/api/tts/speak`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({text:ce,voice:"nova"})});if(V.ok){const W=await V.blob();return URL.createObjectURL(W)}}catch(V){console.log("Failed to generate dynamic audio:",V)}finally{X(!1)}return null},[]);N.useEffect(()=>{L.current=je},[je]),N.useEffect(()=>{F.current=Q,!Q&&C.current&&(C.current(),C.current=null)},[Q]),N.useEffect(()=>{f.current=K},[K]);const _t=N.useCallback(ce=>new Promise(V=>{const W=document.querySelector(ce);W?(W.scrollIntoView({behavior:"smooth",block:"center",inline:"center"}),setTimeout(V,800)):V()}),[]),zt=N.useCallback(()=>[{id:"intro-1",narration:"Welcome. Let me show you, what makes Agentic AI, different.",pauseBefore:500,pauseAfter:1500},{id:"intro-2",narration:"With an Agent, you give it a goal. Not step by step instructions. The agent figures out, how to reach that goal, on its own.",pauseAfter:1500},{id:"intro-3",narration:"It plans, like a human would plan. It uses tools via MCP, when it needs data. And it reasons, like a human would reason.",pauseAfter:1500},{id:"intro-4",narration:"We've built this, around four pillars. Let me show you, each one.",scrollTo:'[data-tour="pillars-grid"]',highlight:'[data-tour="pillars-grid"]',pauseBefore:500,pauseAfter:2e3},{id:"pillars-overview",narration:"Here they are. Planning. Reasoning. Business Control. And, Human plus AI. Together, these give you, full transparency, into every decision.",highlight:'[data-tour="pillars-grid"]',pauseAfter:3e3},{id:"p1-intro",narration:"Pillar One. Planning. We give the agent a goal. Find the best offer, for this customer. The agent creates its own strategy, to achieve that goal.",pauseAfter:1500},{id:"p1-customer",narration:"Let me select a customer, and show you.",scrollTo:'[data-tour="customer-selector"]',highlight:'[data-tour="customer-selector"]',action:()=>{te.length>0&&j(te[0])},pauseBefore:500,pauseAfter:2e3},{id:"p1-run",narration:"Watch the Planner, in action.",scrollTo:'[data-tour="agent-reasoning"]',highlight:'[data-tour="agent-reasoning"]',action:()=>J(),waitForAgent:!0,pauseBefore:500},{id:"p1-planner",narration:"See this? The Planner figured out, what factors matter, for this specific customer. Loyalty status. Recent history. Current context. Just like a human expert would.",dynamicNarration:se,scrollTo:'[data-tour="planner-section"]',highlight:'[data-tour="planner-section"]',pauseBefore:500,pauseAfter:2500},{id:"p1-summary",narration:"This is Pillar One. Planning. The agent decides how to solve the problem. Not us.",pauseAfter:2e3},{id:"p2-intro",narration:"Pillar Two. Reasoning. Now the Workers execute the plan. When they need data, they use tools via MCP.",pauseAfter:1500},{id:"p2-worker",narration:"Watch the Workers use MCP tools. Customer profile from AADV. Flight inventory from DCSID. ML scores from our models. The agent connects to existing systems, when it needs to.",dynamicNarration:ve,scrollTo:'[data-tour="worker-section"]',highlight:'[data-tour="worker-section"]',pauseBefore:500,pauseAfter:2500},{id:"p2-solver",narration:"Then, the Solver, reasons through all the evidence. Just like a human would reason it out. And you can read, exactly how it decided.",dynamicNarration:Ve,scrollTo:'[data-tour="solver-section"]',highlight:'[data-tour="solver-section"]',pauseBefore:500,pauseAfter:2500},{id:"p2-transparency",narration:"Planning, plus Reasoning, equals Transparency. Every factor considered. Every decision explained. Full audit trail.",pauseAfter:2e3},{id:"p2-value",narration:"When a customer asks, why did I get this offer? You have a real answer. When regulators ask, how do you decide? You can show them.",pauseAfter:2500},{id:"p3-intro",narration:"Pillar Three. Business Control. Can you actually control this AI? Absolutely.",pauseAfter:1500},{id:"p3-panel",narration:"Let me open, the control panel.",scrollTo:'[data-tour="control-panel"]',action:()=>o(!0),pauseBefore:500,pauseAfter:1500},{id:"p3-highlight",narration:"This is your control center. No IT tickets. No waiting weeks. Changes take effect, immediately.",highlight:'[data-tour="control-panel"]',pauseAfter:2e3},{id:"p3-assistant",narration:"The Prompt Assistant, lets you give instructions, in plain English.",action:()=>U(),pauseBefore:500,pauseAfter:2e3},{id:"p3-example",narration:"Type, give extra discount, to customers with delays. That's it. The agent understands, and follows your instruction.",pauseAfter:3e3},{id:"p3-policy",narration:"For more direct control, there are policy values, you can adjust, in real time.",action:()=>R(!0),pauseBefore:500,pauseAfter:2e3},{id:"p3-values",narration:"Discount percentages. VIP thresholds. Maximum amounts. Change them here. The next decision, uses them instantly.",highlight:'[data-tour="control-panel"]',pauseAfter:2500},{id:"p3-summary",narration:"This is Pillar Three. Business Control. You drive the AI. Not IT. Not vendors. You.",action:()=>{R(!1),o(!1)},pauseAfter:2e3},{id:"p4-intro",narration:"Pillar Four. Human plus AI. For sensitive decisions, you might want, a human to approve.",pauseAfter:1500},{id:"p4-toggle",narration:"That's Human in the Loop. Let me turn it on.",scrollTo:'[data-tour="hitl-toggle"]',highlight:'[data-tour="hitl-toggle"]',action:()=>D(!0),pauseBefore:500,pauseAfter:2e3},{id:"p4-run",narration:"Now, watch what happens.",scrollTo:'[data-tour="agent-reasoning"]',action:()=>J(),waitForAgent:!0,pauseBefore:500},{id:"p4-pending",narration:"The agent analyzed everything, and made a recommendation. But look. It stopped. Awaiting approval.",scrollTo:'[data-tour="final-decision"]',highlight:'[data-tour="final-decision"]',pauseBefore:500,pauseAfter:2500},{id:"p4-approval",narration:"A human reviews. Then approves, or rejects. AI speed, for analysis. Human judgment, for the decision.",pauseAfter:2500},{id:"p4-summary",narration:"This is Pillar Four. Human plus AI. Best of both worlds.",action:()=>D(!1),pauseAfter:2e3},{id:"close-pattern",narration:"One more thing. What you saw, is a pattern, you can apply anywhere.",pauseAfter:1500},{id:"close-examples",narration:"Seat recommendations. Ancillary offers. Service routing. Loyalty decisions. Any complex decision, that needs transparency, and control.",pauseAfter:2500},{id:"close-recap",narration:"So, why Agentic AI? Four pillars.",pauseAfter:1500},{id:"close-four",narration:"One, Planning. The agent thinks first. Two, Reasoning. Full transparency. Three, Business control. You drive it. Four, Human plus AI. You stay in charge.",pauseAfter:3e3},{id:"close-end",narration:"That's Agentic AI. Planning. Reasoning. Control. Thank you, for watching.",pauseAfter:2e3}],[te,j,J,D,o,R,U,se,ve,Ve]),qt=N.useCallback(async(ce,V)=>{if(O.current.has(V))return!0;try{const W=await fetch(`${Sc}/static/audio/${V}.mp3`);if(W.ok){const re=await W.blob(),he=URL.createObjectURL(re);return O.current.set(V,he),!0}}catch{}try{const W=await fetch(`${Sc}/api/tts/speak`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({text:ce,voice:"nova"})});if(W.ok){const re=await W.blob(),he=URL.createObjectURL(re);return O.current.set(V,he),!0}}catch{console.log(`Failed to cache audio for ${V}`)}return!1},[]),Yl=N.useCallback(async()=>{if(E.current||Je)return;E.current=!0,Pe(!0),Ye(0);const ce=zt(),V=ce.length;let W=0;const re=4;for(let he=0;he<ce.length;he+=re){const Me=ce.slice(he,he+re);await Promise.all(Me.map(Gl=>qt(Gl.narration,Gl.id))),W+=Me.length,Ye(Math.min(100,Math.round(W/V*100)))}Pe(!1),et(!0),E.current=!1},[zt,qt,Je]);N.useEffect(()=>{k&&!Je&&!E.current&&Yl()},[k,Je,Yl]);const rt=N.useCallback(()=>new Promise(ce=>{F.current?C.current=ce:ce()}),[]),kt=N.useCallback(async(ce,V)=>new Promise(async W=>{if(Y(ce),F.current&&await rt(),O.current.has(V)){const Me=O.current.get(V);if(h.current){h.current.src=Me,h.current.onended=()=>W(),h.current.onerror=()=>W();try{await h.current.play();return}catch{}}}const re=ce.split(" ").length,he=Math.max(3e3,re*300);setTimeout(W,he)}),[rt]),Yt=N.useCallback(async ce=>{const V=zt();if(ce>=V.length||!L.current){ge(!1),ne(0),$(null),Y(""),Oe(""),le.current=!1;return}const W=V[ce];if(ne(ce),f.current=ce,W.id.startsWith("intro")?Oe("Introduction"):W.id.startsWith("pillars")?Oe("The 4 Pillars"):W.id.startsWith("p1")?Oe("Pillar 1: Planning"):W.id.startsWith("p2")?Oe("Pillar 2: Reasoning"):W.id.startsWith("p3")?Oe("Pillar 3: Business Control"):W.id.startsWith("p4")?Oe("Pillar 4: Human + AI"):W.id.startsWith("close")&&Oe("Summary"),W.pauseBefore&&await new Promise(Me=>setTimeout(Me,W.pauseBefore)),!L.current||(W.scrollTo&&await _t(W.scrollTo),!L.current)||($(W.highlight||null),W.highlight&&await new Promise(Me=>setTimeout(Me,500)),!L.current)||(W.action&&(W.action(),await new Promise(Me=>setTimeout(Me,500))),!L.current))return;if(W.waitForAgent){le.current=!0,await kt(W.narration,W.id);return}let re=W.narration,he=null;if(W.dynamicNarration)if(re=W.dynamicNarration(),Y(re),F.current&&await rt(),he=await we(re),he&&h.current)h.current.src=he,await new Promise(Me=>{h.current?(h.current.onended=()=>Me(),h.current.onerror=()=>Me(),h.current.play().catch(()=>Me())):Me()}),URL.revokeObjectURL(he);else{const Me=re.split(" ").length,Gl=Math.max(3e3,Me*300);await new Promise(yt=>setTimeout(yt,Gl))}else await kt(W.narration,W.id);L.current&&(W.pauseAfter&&await new Promise(Me=>setTimeout(Me,W.pauseAfter)),L.current&&(Y(""),Yt(ce+1)))},[zt,kt,_t,we,rt]);N.useEffect(()=>{le.current&&w&&L.current&&(le.current=!1,setTimeout(()=>{Y(""),Yt(f.current+1)},2e3))},[w,Yt]);const sa=N.useCallback(()=>{ge(!0),L.current=!0,ne(0),f.current=0,le.current=!1,Oe(""),Yt(0)},[Yt]),ua=N.useCallback(()=>{ge(!1),L.current=!1,oe(!1),F.current=!1,ne(0),$(null),Y(""),Oe(""),le.current=!1,h.current&&h.current.pause(),D(!1),o(!1),R(!1)},[D,o,R]),xl=N.useCallback(()=>{oe(!0),F.current=!0,h.current&&h.current.pause()},[]),$t=N.useCallback(()=>{oe(!1),F.current=!1,h.current&&h.current.src&&!h.current.ended&&h.current.play().catch(()=>{})},[]),Wt=zt(),Ka=(K+1)/Wt.length*100;return s.jsxs(s.Fragment,{children:[s.jsx("audio",{ref:h}),ee&&je&&s.jsxs("div",{className:"fixed inset-0 z-40 pointer-events-none",children:[s.jsx("div",{className:"absolute inset-0 bg-black/60 transition-opacity duration-500"}),s.jsx("style",{children:`
            ${ee} {
              position: relative;
              z-index: 50 !important;
              box-shadow: 0 0 0 4px rgba(34, 211, 238, 0.9), 0 0 40px rgba(34, 211, 238, 0.5), 0 0 80px rgba(34, 211, 238, 0.3) !important;
              border-radius: 12px;
              transition: box-shadow 0.3s ease;
            }
          `})]}),ae&&je&&s.jsx("div",{className:"fixed top-4 left-1/2 -translate-x-1/2 z-50",children:s.jsxs("div",{className:`text-white px-6 py-2 rounded-full shadow-lg flex items-center gap-2 ${Q?"bg-gradient-to-r from-amber-600 to-orange-600":"bg-gradient-to-r from-purple-600 to-indigo-600"}`,children:[Q&&s.jsx("span",{children:"‚è∏Ô∏è"}),s.jsx("span",{className:"font-semibold",children:ae}),Q&&s.jsx("span",{className:"text-sm opacity-80",children:"- Paused"})]})}),s.jsx("div",{className:"fixed bottom-6 left-24 z-50",children:s.jsx("button",{onClick:()=>Ne(!k),className:`w-14 h-14 rounded-full shadow-lg flex items-center justify-center transition-all hover:scale-110 ${Q?"bg-gradient-to-r from-amber-500 to-orange-500":je?"bg-gradient-to-r from-cyan-500 to-purple-500 animate-pulse":"bg-gradient-to-r from-emerald-600 to-cyan-600"}`,title:"Guided Demo",children:s.jsx("span",{className:"text-2xl",children:Q?"‚è∏Ô∏è":je?"üéôÔ∏è":"üé¨"})})}),k&&s.jsxs("div",{className:"fixed bottom-24 left-24 z-50 bg-slate-900/95 backdrop-blur border border-slate-700 rounded-2xl shadow-2xl w-96 overflow-hidden",children:[s.jsxs("div",{className:"bg-gradient-to-r from-emerald-600 to-cyan-600 px-4 py-3",children:[s.jsxs("div",{className:"flex items-center justify-between",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:"text-xl",children:"üé¨"}),s.jsx("span",{className:"font-bold text-white",children:"Guided Demo"})]}),s.jsx("button",{onClick:()=>Ne(!1),className:"text-white/70 hover:text-white",children:"‚úï"})]}),s.jsx("p",{className:"text-xs text-white/70 mt-1",children:"Voice-guided tour of the 4 Pillars"})]}),s.jsx("div",{className:"p-4 space-y-4",children:je?s.jsxs(s.Fragment,{children:[s.jsxs("div",{children:[s.jsxs("div",{className:"flex items-center justify-between text-xs text-slate-400 mb-1",children:[s.jsx("span",{children:ae||"Starting..."}),s.jsxs("span",{children:[K+1," / ",Wt.length]})]}),s.jsx("div",{className:"w-full bg-slate-700 rounded-full h-2",children:s.jsx("div",{className:"bg-gradient-to-r from-emerald-500 to-cyan-500 h-2 rounded-full transition-all duration-500",style:{width:`${Ka}%`}})})]}),s.jsxs("div",{className:`rounded-lg p-3 ${Q?"bg-amber-900/30 border border-amber-500/50":"bg-slate-800/50"}`,children:[s.jsx("div",{className:`text-xs mb-1 ${Q?"text-amber-400":"text-cyan-400"}`,children:Q?"‚è∏Ô∏è Paused":"Now Playing"}),s.jsx("div",{className:"text-sm text-white line-clamp-3",children:H||"Preparing..."})]}),s.jsxs("div",{className:"flex gap-2",children:[s.jsxs("button",{onClick:Q?$t:xl,className:`flex-1 py-3 rounded-xl font-medium flex items-center justify-center gap-2 transition-all ${Q?"bg-emerald-600 hover:bg-emerald-500 text-white":"bg-amber-600 hover:bg-amber-500 text-white"}`,children:[s.jsx("span",{children:Q?"‚ñ∂Ô∏è":"‚è∏Ô∏è"})," ",Q?"Resume":"Pause"]}),s.jsxs("button",{onClick:ua,className:"flex-1 py-3 rounded-xl font-medium bg-red-600 hover:bg-red-500 text-white flex items-center justify-center gap-2",children:[s.jsx("span",{children:"‚èπÔ∏è"})," Stop"]})]})]}):s.jsxs(s.Fragment,{children:[Se&&s.jsxs("div",{className:"bg-slate-800/50 rounded-lg p-4",children:[s.jsxs("div",{className:"flex items-center justify-between mb-2",children:[s.jsx("span",{className:"text-sm text-white",children:"Preparing audio..."}),s.jsxs("span",{className:"text-xs text-cyan-400",children:[Qe,"%"]})]}),s.jsx("div",{className:"w-full bg-slate-700 rounded-full h-2",children:s.jsx("div",{className:"bg-gradient-to-r from-cyan-500 to-emerald-500 h-2 rounded-full transition-all duration-300",style:{width:`${Qe}%`}})}),s.jsx("p",{className:"text-xs text-slate-500 mt-2",children:"Pre-loading voice narration..."})]}),Je&&s.jsx("div",{className:"bg-emerald-900/30 border border-emerald-500/30 rounded-lg p-3",children:s.jsxs("div",{className:"flex items-center gap-2 text-emerald-400",children:[s.jsx("span",{children:"‚úì"}),s.jsx("span",{className:"text-sm font-medium",children:"Audio ready!"})]})}),s.jsxs("div",{className:"text-sm text-slate-300 space-y-2",children:[s.jsx("p",{children:"This tour explains the 4 Pillars:"}),s.jsxs("ul",{className:"text-xs text-slate-400 space-y-1 ml-4",children:[s.jsx("li",{children:"‚Ä¢ Planning - Agent thinks first"}),s.jsx("li",{children:"‚Ä¢ Reasoning - Full transparency"}),s.jsx("li",{children:"‚Ä¢ Business Control - You drive it"}),s.jsx("li",{children:"‚Ä¢ Human + AI - You stay in charge"})]})]}),s.jsx("button",{onClick:sa,disabled:Se,className:`w-full py-4 rounded-xl font-medium text-white flex items-center justify-center gap-2 text-lg transition-all ${Se?"bg-slate-600 cursor-not-allowed":"bg-gradient-to-r from-emerald-600 to-cyan-600 hover:from-emerald-500 hover:to-cyan-500"}`,children:Se?s.jsxs(s.Fragment,{children:[s.jsx("span",{className:"animate-spin",children:"‚è≥"})," Preparing..."]}):s.jsxs(s.Fragment,{children:[s.jsx("span",{children:"‚ñ∂Ô∏è"})," Start Guided Demo"]})}),s.jsx("div",{className:"text-xs text-slate-500 text-center",children:"~4 minutes ‚Ä¢ Voice narration ‚Ä¢ Auto-scrolling"})]})}),!je&&s.jsxs("div",{className:"border-t border-slate-700 px-4 py-3",children:[s.jsx("div",{className:"text-xs text-slate-400 mb-2",children:"The 4 Pillars"}),s.jsx("div",{className:"grid grid-cols-4 gap-2 text-center",children:[{icon:"üìã",label:"Planning"},{icon:"üß†",label:"Reasoning"},{icon:"üéõÔ∏è",label:"Control"},{icon:"ü§ù",label:"Human+AI"}].map((ce,V)=>s.jsxs("div",{className:"flex flex-col items-center",children:[s.jsx("span",{className:"text-lg",children:ce.icon}),s.jsx("span",{className:"text-[10px] text-slate-500 mt-1",children:ce.label})]},V))})]})]})]})}const wd="http://localhost:8000",_h={E:"Executive Platinum",T:"Platinum Pro",P:"Platinum",G:"Gold",R:"Ruby",N:"General"},Hd={E:"text-slate-300",T:"text-purple-400",P:"text-purple-400",G:"text-yellow-400",R:"text-red-400",N:"text-slate-400"},Bd={E:"bg-slate-700/50 border-slate-400/50",T:"bg-purple-900/30 border-purple-500/50",P:"bg-purple-900/30 border-purple-500/50",G:"bg-yellow-900/30 border-yellow-500/50",R:"bg-red-900/30 border-red-500/50",N:"bg-slate-800/50 border-slate-600/50"};function zh(){const[j,J]=N.useState([]),[D,o]=N.useState(null),[R,U]=N.useState(!1),[w,te]=N.useState(null),[_,v]=N.useState(""),[z,M]=N.useState({phase:"idle"}),[k,Ne]=N.useState([]),[je,ge]=N.useState(""),[Q,oe]=N.useState(""),[K,ne]=N.useState(null),[ee,$]=N.useState(!1),[H,Y]=N.useState(0),[ae,Oe]=N.useState(!1),[Qe,Ye]=N.useState(!1),[Se,Pe]=N.useState(null),Je=N.useRef(ae);N.useEffect(()=>{Je.current=ae},[ae]);const[et,h]=N.useState([]),[,O]=N.useState([]),[,L]=N.useState([]),[F,le]=N.useState(!1),[f,E]=N.useState(!1),[C,B]=N.useState("policies"),[X,se]=N.useState("offer_orchestration.planner"),[ve,Ve]=N.useState(!1),[we,_t]=N.useState(null),[zt,qt]=N.useState(null),[Yl,rt]=N.useState(null),kt=H>=1,Yt=H>=3,sa=H>=4,ua=H>=5,{startEvaluation:xl,startEvaluationHITL:$t}=rh();N.useEffect(()=>{fetch(`${wd}/api/pnrs`).then(y=>{if(!y.ok)throw new Error("Failed to fetch PNRs");return y.json()}).then(y=>{J(y),y.length>0&&!_&&v(y[0].pnr)}).catch(y=>{te(`Failed to load PNRs: ${y.message}`)})},[]),N.useEffect(()=>{_&&(U(!0),te(null),fetch(`${wd}/api/pnrs/${_}`).then(y=>{if(!y.ok)throw new Error("Failed to fetch PNR details");return y.json()}).then(y=>{o(y),U(!1)}).catch(y=>{te(`Failed to load PNR: ${y.message}`),U(!1)}))},[_]),N.useEffect(()=>{M({phase:"idle"}),Ne([]),ge(""),oe(""),ne(null),$(!1),Y(0),Ye(!1),_t(null),qt(null),rt(null),Pe(null),h([]),O([]),L([])},[_]);const Wt=N.useCallback(async()=>{_&&(M({phase:"loading"}),Ne([]),ge(""),oe(""),ne(null),$(!1),Y(0),Ye(!1),_t(null),qt(null),rt(null),Pe(null),h([]),O([]),L([]),xl(_,{onPipelineStart:()=>{Y(1),setTimeout(()=>Y(2),200),setTimeout(()=>Y(3),400)},onPlannerStart:()=>{},onPlannerDecision:()=>{},onAgentStart:y=>{const P=y.step;P<=2&&Y(3+P),["customer_intelligence","flight_optimization"].includes(y.agent_id)&&M({phase:"loading"}),y.agent_id==="offer_orchestration"&&(M({phase:"planner"}),ge("üéØ ReWOO Planner analyzing customer and offers...")),y.agent_id},onReWOOPlannerComplete:y=>{O(y.plan),L(y.offer_options);const P=y.plan.map(ye=>`  ${ye.step_id}: [${ye.evaluation_type}] ${ye.description}`).join(`
`);ge(`üìã ReWOO Planner Complete

Reasoning: ${y.reasoning}

Plan has ${y.plan.length} evaluation steps:
${P}`);const qe=y.plan.map(ye=>({type:ye.evaluation_type,status:"pending",stepId:ye.step_id,result:ye.description}));Ne(qe),_t({reasoning:y.reasoning,plan:y.plan.map(ye=>({step_id:ye.step_id,evaluation_type:ye.evaluation_type,description:ye.description})),offer_options:(y.offer_options||[]).map(ye=>({offer_type:ye.offer_type||ye.type||"Unknown",cabin:ye.cabin||ye.name||"Unknown"}))}),qt({evaluations:[]}),M({phase:"worker"})},onReWOOWorkerStep:y=>{Ne(P=>P.map(qe=>qe.stepId===y.step_id?{...qe,status:"complete",recommendation:y.reasoning}:qe)),qt(P=>({evaluations:[...P?.evaluations||[],{type:y.evaluation_type,recommendation:y.recommendation||y.reasoning||"",reasoning:y.reasoning}]}))},onReWOOSolverComplete:y=>{M({phase:"solver"});const P=y.decision,ye={IU_BUSINESS:"Business Class",IU_PREMIUM_ECONOMY:"Premium Economy",MCE:"Main Cabin Extra"}[P.selected_offer]||P.selected_offer,at=P.discount_applied>0?`
   Discount: ${(P.discount_applied*100).toFixed(0)}%`:"",as=P.policies_applied?.length>0?`
   Policies: ${P.policies_applied.join(", ")}`:"";oe(`‚úÖ ReWOO Solver Complete

SYNTHESIS: ${P.reasoning}

FINAL DECISION: ${ye} @ $${P.offer_price?.toFixed(0)}`+at+as+`
   Expected Value: $${P.expected_value?.toFixed(2)}`),rt({selected_offer:ye,offer_price:P.offer_price||0,discount_applied:P.discount_applied?P.discount_applied*100:0,expected_value:P.expected_value||0,reasoning:P.reasoning||""})},onAgentComplete:y=>{Ka(y)},onAgentSkip:y=>{y.agent_id==="offer_orchestration"&&oe(`‚ùå Evaluation skipped

Reason: ${y.reason}`)},onPipelineComplete:y=>{ce(y)},onError:y=>{te(y),M({phase:"idle"})}},"planner-worker"))},[_,ae,xl,$t]),Ka=N.useCallback(y=>{if(["customer_intelligence","flight_optimization"].includes(y.agent_id)){h(P=>[...P,y]),y.agent_id==="customer_intelligence"&&y.outputs?.customer_eligible===!1&&(oe(`‚ùå Customer Not Eligible

Reason: ${y.outputs?.suppression_reason||"Customer criteria not met"}

No offer will be sent.`),M({phase:"complete"}),ne({offerType:"SUPPRESSED",offerName:`No Offer (${y.outputs?.suppression_reason||"Not Eligible"})`,price:0,discount:0,expectedValue:0,confidence:"N/A",channel:"N/A",reasoning:y.outputs?.suppression_reason||"Customer did not meet eligibility criteria"}),$(!0));return}y.agent_id!=="offer_orchestration"&&y.agent_id==="personalization"&&oe(P=>`${P}

üí¨ Personalized Message Generated:
"${y.outputs?.message_body||y.summary}"`)},[]),ce=N.useCallback(async y=>{Y(6);const P=fh(y.final_decision);if(Je.current&&_&&y.final_decision?.should_send_offer!==!1){Ye(!0),Pe(P),M({phase:"complete"});try{const ye=await $t(_,!0);if(ye.status==="pending_approval"){oe(at=>`${at}

‚è∏Ô∏è HUMAN-IN-THE-LOOP ENABLED

Agent recommendation is ready.
Awaiting human approval before sending offer...

Reason: ${ye.approval_reason_details||"Manual review requested"}`);return}}catch(ye){console.error("HITL check failed:",ye)}Ye(!1),Pe(null)}M({phase:"complete"}),ne(P),$(!0)},[_,$t]),V=N.useCallback(()=>{Se&&(ne(Se),Ye(!1),Pe(null),oe(y=>y+`

‚úÖ APPROVED by human reviewer`),$(!0))},[Se]),W=N.useCallback(()=>{ne({offerType:"REJECTED",offerName:"Offer Rejected by Reviewer",price:0,discount:0,expectedValue:0,confidence:"N/A",channel:"N/A",reasoning:"Human reviewer rejected this offer"}),Ye(!1),Pe(null),oe(y=>y+`

‚ùå REJECTED by human reviewer`),$(!0)},[]),re=D?.customer,he=D?.flight,Me=D?.reservation,yt=(()=>{if(!he?.cabins)return 75;const y=Object.values(he.cabins);if(y.length===0)return 75;const P=y.reduce((qe,ye)=>qe+(ye.expected_load_factor||75),0);return Math.round(P/y.length)})();return s.jsxs("div",{className:"min-h-screen bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 text-white p-6",children:[s.jsxs("div",{className:"max-w-7xl mx-auto",children:[s.jsxs("div",{className:"flex items-center justify-between mb-6",children:[s.jsxs("div",{children:[s.jsxs("h1",{className:"text-2xl font-bold flex items-center gap-3",children:[s.jsx("span",{className:"text-3xl",children:"üéØ"}),"Offer Agent Demo"]}),s.jsx("p",{className:"text-slate-400 mt-1",children:"Watch how the agent decides which upgrade offer to give each customer"}),s.jsx("p",{className:"text-slate-500 text-sm mt-1",children:"Connected to real LangGraph backend ‚Ä¢ ReWOO Pattern (Planner ‚Üí Worker ‚Üí Solver)"})]}),s.jsxs("div",{className:"flex items-center gap-4",children:[s.jsxs("div",{"data-tour":"hitl-toggle",className:"flex items-center gap-2 bg-slate-700 rounded-lg px-3 py-2",children:[s.jsx("div",{className:"flex flex-col items-start",children:s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:"text-sm text-slate-300",children:"Human + AI"}),s.jsx("span",{className:"text-[8px] bg-emerald-600 text-white px-1.5 py-0.5 rounded-full font-bold",children:"P5"})]})}),s.jsx("button",{onClick:()=>Oe(!ae),className:`relative w-12 h-6 rounded-full transition-all ${ae?"bg-amber-500":"bg-slate-600"}`,children:s.jsx("div",{className:`absolute top-1 w-4 h-4 bg-white rounded-full transition-all ${ae?"left-7":"left-1"}`})}),s.jsx("span",{className:`text-xs ${ae?"text-amber-400":"text-slate-500"}`,children:ae?"ON":"OFF"})]}),s.jsxs("div",{"data-tour":"customer-selector",className:"flex items-center gap-3",children:[s.jsx("select",{value:_,onChange:y=>v(y.target.value),className:"bg-slate-700 border border-slate-600 rounded-lg px-4 py-2 text-white",disabled:j.length===0,children:j.length===0?s.jsx("option",{children:"Loading PNRs..."}):j.map(y=>s.jsxs("option",{value:y.pnr,children:[y.pnr," - ",y.customer_name," (",y.scenario_tag,")"]},y.pnr))}),s.jsx("button",{onClick:Wt,disabled:z.phase!=="idle"&&z.phase!=="complete"||Qe||!_||R,className:`px-6 py-2 rounded-lg font-medium transition-all ${(z.phase==="idle"||z.phase==="complete")&&!Qe&&_&&!R?"bg-emerald-600 hover:bg-emerald-500 text-white":"bg-slate-600 text-slate-400 cursor-not-allowed"}`,children:R?"‚è≥ Loading...":z.phase==="idle"?"‚ñ∂ Run Agent":z.phase==="complete"&&!Qe?"‚Üª Run Again":"‚è≥ Running..."})]})]})]}),w&&s.jsx("div",{className:"bg-red-900/30 border border-red-500/50 rounded-lg p-4 mb-6",children:s.jsxs("div",{className:"flex items-center gap-2 text-red-400",children:[s.jsx("span",{children:"‚ö†Ô∏è"}),s.jsx("span",{children:w}),s.jsx("button",{onClick:()=>te(null),className:"ml-auto text-red-300 hover:text-white",children:"‚úï"})]})}),s.jsxs("div",{"data-tour":"control-panel",className:"bg-gradient-to-r from-cyan-900/30 via-slate-800/50 to-purple-900/30 rounded-2xl border border-cyan-500/30 mb-6 overflow-hidden",children:[s.jsxs("div",{className:"p-4 flex items-center justify-between cursor-pointer hover:bg-slate-700/20 transition-colors",onClick:()=>le(!F),children:[s.jsxs("div",{className:"flex items-center gap-4",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:"text-2xl",children:"üéõÔ∏è"}),s.jsxs("div",{children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("h2",{className:"text-lg font-bold",children:"Control Agent Behavior"}),s.jsx("span",{className:"text-[10px] bg-amber-600 text-white px-2 py-0.5 rounded-full font-bold",children:"PILLAR 3: BUSINESS CONTROL"})]}),s.jsx("p",{className:"text-xs text-slate-400",children:f?"Change policies & prompts instantly - no IT ticket":"Plain English instructions - no code required"})]})]}),f&&s.jsx("div",{className:"flex items-center gap-1 ml-4",children:[{id:"offer_orchestration.planner",icon:"üìã",label:"Planner"},{id:"offer_orchestration.worker",icon:"‚öôÔ∏è",label:"Worker"},{id:"offer_orchestration.solver",icon:"‚úÖ",label:"Solver"},{id:"personalization",icon:"üí¨",label:"Message"}].map(y=>s.jsxs("div",{className:`px-2 py-1 rounded text-xs flex items-center gap-1 ${X===y.id?"bg-cyan-600 text-white":"bg-slate-700/50 text-slate-400"}`,children:[s.jsx("span",{children:y.icon}),s.jsx("span",{className:"hidden sm:inline",children:y.label})]},y.id))})]}),s.jsxs("div",{className:"flex items-center gap-3",children:[s.jsx("button",{onClick:y=>{y.stopPropagation(),E(!f),f||le(!0)},className:`text-xs px-3 py-1 rounded-full transition-all ${f?"bg-amber-600 text-white":"bg-slate-700/50 text-slate-400 hover:bg-slate-700"}`,children:f?"üîß Advanced Mode":"üîß Advanced"}),s.jsx("span",{className:"text-xs text-purple-400 bg-purple-900/50 px-3 py-1 rounded-full",children:"ü§ñ Use Prompt Assistant"}),s.jsx("svg",{className:`w-6 h-6 text-slate-400 transition-transform ${F?"rotate-180":""}`,fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s.jsx("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M19 9l-7 7-7-7"})})]})]}),F&&s.jsxs("div",{className:"px-4 pb-4 space-y-4 border-t border-slate-700/50",children:[!f&&s.jsx("div",{className:"pt-4",children:s.jsxs("div",{className:"bg-gradient-to-r from-purple-900/30 to-indigo-900/30 border border-purple-500/30 rounded-xl p-6 text-center",children:[s.jsx("div",{className:"text-4xl mb-4",children:"ü§ñ"}),s.jsx("h3",{className:"text-xl font-bold text-white mb-2",children:"Use the Prompt Assistant"}),s.jsxs("p",{className:"text-slate-300 mb-4 max-w-md mx-auto",children:["Click the ",s.jsx("span",{className:"text-purple-400 font-semibold",children:"purple robot button"})," in the bottom-left corner to modify agent behavior using plain English instructions."]}),s.jsxs("div",{className:"flex flex-wrap justify-center gap-2 mb-4",children:[s.jsx("span",{className:"bg-purple-800/50 text-purple-200 px-3 py-1 rounded-full text-sm",children:'"Be more friendly"'}),s.jsx("span",{className:"bg-purple-800/50 text-purple-200 px-3 py-1 rounded-full text-sm",children:'"Focus on business travelers"'}),s.jsx("span",{className:"bg-purple-800/50 text-purple-200 px-3 py-1 rounded-full text-sm",children:'"Bigger discounts for VIPs"'})]}),s.jsx("p",{className:"text-xs text-slate-500",children:"The assistant validates all changes to keep the agent working correctly."})]})}),f&&s.jsxs(s.Fragment,{children:[s.jsxs("div",{className:"pt-4 flex gap-2",children:[s.jsxs("button",{onClick:()=>B("policies"),className:`flex-1 px-4 py-2 rounded-lg text-sm font-medium transition-all flex items-center justify-center gap-2 ${C==="policies"?"bg-cyan-600 text-white":"bg-slate-700/50 text-slate-300 hover:bg-slate-700"}`,children:[s.jsx("span",{children:"üìä"})," Policy Configuration"]}),s.jsxs("button",{onClick:()=>B("prompts"),className:`flex-1 px-4 py-2 rounded-lg text-sm font-medium transition-all flex items-center justify-center gap-2 ${C==="prompts"?"bg-amber-600 text-white":"bg-slate-700/50 text-slate-300 hover:bg-slate-700"}`,children:[s.jsx("span",{children:"üìù"})," Prompt Editor"]})]}),C==="policies"&&s.jsx("div",{className:"bg-slate-800/30 rounded-xl p-4 border border-slate-700",children:s.jsx(Eh,{})}),C==="prompts"&&s.jsxs(s.Fragment,{children:[s.jsxs("div",{className:"bg-amber-900/30 border border-amber-500/30 rounded-lg px-4 py-3 flex items-start gap-3",children:[s.jsx("span",{className:"text-xl",children:"‚ö†Ô∏è"}),s.jsxs("div",{children:[s.jsx("p",{className:"text-amber-200 font-medium text-sm",children:"Advanced Mode - For Prompt Engineers"}),s.jsx("p",{className:"text-amber-300/70 text-xs mt-1",children:"Direct editing can break agent behavior. Use with caution."})]})]}),s.jsx("div",{className:"flex gap-2",children:[{id:"offer_orchestration.planner",icon:"üìã",label:"Planner",color:"cyan",desc:"What to evaluate"},{id:"offer_orchestration.worker",icon:"‚öôÔ∏è",label:"Worker",color:"purple",desc:"How to evaluate"},{id:"offer_orchestration.solver",icon:"‚úÖ",label:"Solver",color:"emerald",desc:"How to decide"},{id:"personalization",icon:"üí¨",label:"Message",color:"amber",desc:"How to write"}].map(y=>s.jsxs("button",{onClick:()=>se(y.id),className:`flex-1 px-4 py-3 rounded-xl text-sm font-medium transition-all ${X===y.id?y.color==="cyan"?"bg-cyan-600 text-white shadow-lg shadow-cyan-500/30":y.color==="purple"?"bg-purple-600 text-white shadow-lg shadow-purple-500/30":y.color==="emerald"?"bg-emerald-600 text-white shadow-lg shadow-emerald-500/30":"bg-amber-600 text-white shadow-lg shadow-amber-500/30":"bg-slate-700/50 text-slate-300 hover:bg-slate-700"}`,children:[s.jsx("div",{className:"text-xl mb-1",children:y.icon}),s.jsx("div",{className:"font-semibold",children:y.label}),s.jsx("div",{className:`text-xs ${X===y.id?"text-white/70":"text-slate-500"}`,children:y.desc})]},y.id))}),s.jsxs("div",{className:"grid grid-cols-3 gap-4",children:[s.jsx("div",{className:"col-span-2",children:s.jsx(oh,{agentId:X,agentName:X==="offer_orchestration.planner"?"Planner":X==="offer_orchestration.worker"?"Worker":X==="offer_orchestration.solver"?"Solver":"Message Generator",onPromptUpdated:()=>{}})}),s.jsxs("div",{className:"space-y-3",children:[s.jsxs("div",{className:"bg-slate-800/50 rounded-xl p-4 border border-slate-700",children:[s.jsxs("div",{className:"text-sm font-semibold text-slate-300 mb-3 flex items-center gap-2",children:[s.jsx("span",{children:"üí°"})," Example Changes"]}),s.jsxs("ul",{className:"text-xs text-slate-400 space-y-2",children:[X==="offer_orchestration.planner"&&s.jsxs(s.Fragment,{children:[s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Always check inventory priority first"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Skip price sensitivity for Executive Platinum"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Add step to check recent purchase history"'})]}),X==="offer_orchestration.worker"&&s.jsxs(s.Fragment,{children:[s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Be more lenient with confidence thresholds"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Increase goodwill discount to 15%"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Prioritize high-inventory cabins aggressively"'})]}),X==="offer_orchestration.solver"&&s.jsxs(s.Fragment,{children:[s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Prioritize customer satisfaction over revenue"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Be aggressive with VIP discounts"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Consider inventory urgency heavily"'})]}),X==="personalization"&&s.jsxs(s.Fragment,{children:[s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Use a more casual, friendly tone"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Emphasize the upgrade benefits"'}),s.jsx("li",{className:"p-2 bg-slate-900/50 rounded",children:'"Keep messages shorter and direct"'})]})]})]}),s.jsxs("div",{className:"bg-amber-900/20 border border-amber-500/30 rounded-xl p-3 text-xs text-amber-200",children:[s.jsx("strong",{children:"‚ö†Ô∏è Careful:"}),s.jsxs("ul",{className:"mt-2 space-y-1 text-amber-300",children:[s.jsx("li",{children:"‚Ä¢ Test after every change"}),s.jsx("li",{children:"‚Ä¢ Keep backup of working prompts"}),s.jsx("li",{children:"‚Ä¢ Small changes are safer"})]})]})]})]})]})]})]})]}),s.jsx(Oh,{currentStep:H,isRunning:z.phase!=="idle"&&z.phase!=="complete",scoreThreshold:70,mlScore:.72}),s.jsxs("div",{className:"grid grid-cols-12 gap-6",children:[s.jsx("div",{className:"col-span-4 space-y-4",children:s.jsxs("div",{className:"bg-slate-800/50 rounded-2xl p-5 border border-slate-700",children:[s.jsxs("h2",{className:"text-lg font-semibold mb-4 flex items-center gap-2",children:[s.jsx("span",{className:"text-xl",children:"üì•"})," Input Data",R&&s.jsx("span",{className:"text-xs text-slate-400",children:"(Loading...)"}),H>0&&H<6&&s.jsx("span",{className:"text-xs text-cyan-400 animate-pulse",children:"(Loading from pipeline...)"})]}),Yt&&re?s.jsxs("div",{className:`rounded-xl p-4 mb-3 border transition-all duration-500 animate-fadeIn ${Bd[re.loyalty_tier]||Bd.N}`,children:[s.jsxs("div",{className:"flex items-center gap-3 mb-3",children:[s.jsx("div",{className:"w-12 h-12 bg-slate-600 rounded-full flex items-center justify-center text-xl",children:"üë§"}),s.jsxs("div",{children:[s.jsx("div",{className:"font-semibold",children:re.name}),s.jsxs("div",{className:`text-sm ${Hd[re.loyalty_tier]||Hd.N}`,children:[_h[re.loyalty_tier]||"General"," Member"]})]})]}),s.jsxs("div",{className:"grid grid-cols-2 gap-2 text-sm",children:[s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-2",children:[s.jsx("div",{className:"text-slate-400 text-xs",children:"Annual Revenue"}),s.jsxs("div",{className:"font-semibold",children:["$",re.flight_revenue_amt_history?.toLocaleString()||0]})]}),s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-2",children:[s.jsx("div",{className:"text-slate-400 text-xs",children:"Accept Rate"}),s.jsx("div",{className:"font-semibold",children:re.historical_upgrades?.acceptance_rate?`${(re.historical_upgrades.acceptance_rate*100).toFixed(0)}%`:"N/A"})]})]}),re.is_suppressed&&s.jsxs("div",{className:"mt-2 bg-red-900/30 border border-red-500/50 rounded-lg p-2 text-sm",children:[s.jsx("span",{className:"text-red-400",children:"‚ö†Ô∏è Suppressed:"})," ",s.jsx("span",{className:"text-red-200",children:re.complaint_reason||"Customer preference"})]})]}):s.jsx("div",{className:"rounded-xl p-4 mb-3 border border-slate-600 bg-slate-800/50",children:s.jsx("div",{className:"text-slate-400 text-center flex items-center justify-center gap-2",children:H>0&&H<3?s.jsxs(s.Fragment,{children:[s.jsx("span",{className:"animate-spin",children:"‚è≥"}),s.jsx("span",{children:"Waiting for passenger data (Step 3)..."})]}):s.jsx("span",{children:"üë§ Customer data appears at Step 3"})})}),kt&&he?s.jsxs("div",{className:"bg-blue-900/20 border border-blue-500/30 rounded-xl p-4 mb-3 transition-all duration-500 animate-fadeIn",children:[s.jsxs("div",{className:"flex items-center justify-between mb-3",children:[s.jsxs("div",{className:"flex items-center gap-3",children:[s.jsx("div",{className:"text-2xl",children:"‚úàÔ∏è"}),s.jsxs("div",{children:[s.jsxs("div",{className:"font-semibold",children:["AA",he.operat_flight_nbr]}),s.jsx("div",{className:"text-blue-300",children:he.route})]})]}),s.jsx("div",{className:`text-[10px] px-2 py-0.5 rounded ${yt<85?"bg-emerald-900/50 text-emerald-300":"bg-slate-700 text-slate-400"}`,children:yt<85?"‚úì Proactive OK":"‚úó High LDF"})]}),s.jsxs("div",{className:"grid grid-cols-2 gap-2 text-sm",children:[s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-2",children:[s.jsx("div",{className:"text-slate-400 text-xs",children:"Departure"}),s.jsxs("div",{className:"font-semibold",children:[Me?.hours_to_departure||0,"h away"]})]}),s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-2",children:[s.jsx("div",{className:"text-slate-400 text-xs",children:"Current Cabin"}),s.jsx("div",{className:"font-semibold",children:Me?.max_bkd_cabin_cd==="F"?"Business":Me?.max_bkd_cabin_cd==="W"?"Premium Economy":"Economy"})]})]}),s.jsxs("div",{className:"mt-2 bg-slate-900/50 rounded-lg p-2",children:[s.jsxs("div",{className:"flex items-center justify-between mb-1",children:[s.jsx("span",{className:"text-slate-400 text-xs",children:"Est. Load Factor (LDF)"}),s.jsxs("span",{className:`text-xs font-medium ${yt<70?"text-emerald-400":yt<85?"text-amber-400":"text-red-400"}`,children:[yt,"%"]})]}),s.jsx("div",{className:"w-full bg-slate-700 rounded-full h-1.5",children:s.jsx("div",{className:`h-1.5 rounded-full transition-all ${yt<70?"bg-emerald-500":yt<85?"bg-amber-500":"bg-red-500"}`,style:{width:`${yt}%`}})})]}),he.cabins&&s.jsx("div",{className:"mt-2 flex gap-2 flex-wrap",children:Object.entries(he.cabins).map(([y,P])=>s.jsxs("div",{className:"bg-slate-900/50 rounded px-2 py-1 text-xs",children:[s.jsxs("span",{className:"text-slate-400",children:[y,":"]})," ",s.jsxs("span",{className:"text-emerald-400",children:[P.cabin_available," seats"]})]},y))})]}):s.jsx("div",{className:"bg-blue-900/20 border border-blue-500/30 rounded-xl p-4 mb-3",children:s.jsx("div",{className:"text-slate-400 text-center flex items-center justify-center gap-2",children:s.jsx("span",{children:"‚úàÔ∏è Flight data appears at Step 1"})})}),sa&&D?.ml_scores?s.jsxs("div",{className:"bg-purple-900/20 border border-purple-500/30 rounded-xl p-4 mb-3 transition-all duration-500 animate-fadeIn",children:[s.jsxs("div",{className:"flex items-center gap-2 mb-3",children:[s.jsx("span",{className:"text-xl",children:"ü§ñ"}),s.jsx("span",{className:"font-semibold",children:"ML Scores"})]}),s.jsx("div",{className:"grid grid-cols-3 gap-2 text-sm",children:Object.entries(D.ml_scores.propensity_scores||{}).slice(0,3).map(([y,P])=>s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-2 text-center",children:[s.jsx("div",{className:"text-slate-400 text-[10px]",children:y.replace("IU_","")}),s.jsxs("div",{className:`text-lg font-bold ${P.confidence>.85?"text-emerald-400":P.confidence>.6?"text-amber-400":"text-red-400"}`,children:[(P.confidence*100).toFixed(0),"%"]}),s.jsx("div",{className:"text-[10px] text-slate-500",children:"confidence"})]},y))}),s.jsxs("div",{className:"mt-2 text-xs text-purple-300",children:["Price Sensitivity: ",s.jsx("span",{className:"font-semibold",children:String(D.ml_scores.price_sensitivity||"medium")})]})]}):sa?s.jsx("div",{className:"bg-purple-900/20 border border-purple-500/30 rounded-xl p-4 mb-3",children:s.jsxs("div",{className:"text-slate-400 text-center flex items-center justify-center gap-2",children:[s.jsx("span",{className:"animate-spin",children:"‚è≥"}),s.jsx("span",{children:"Loading ML scores..."})]})}):H>0?s.jsx("div",{className:"bg-purple-900/20 border border-purple-500/30 rounded-xl p-4 mb-3",children:s.jsx("div",{className:"text-slate-400 text-center",children:s.jsx("span",{children:"ü§ñ ML scores appear at Step 4"})})}):null,ua&&re?s.jsx("div",{className:`rounded-xl p-3 mb-3 border transition-all duration-500 animate-fadeIn ${re.is_suppressed?"bg-red-900/20 border-red-500/30":"bg-emerald-900/20 border-emerald-500/30"}`,children:s.jsxs("div",{className:"flex items-center justify-between",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{className:"text-lg",children:"üõ°Ô∏è"}),s.jsx("span",{className:"text-sm font-medium",children:"Eligibility Check"})]}),s.jsx("span",{className:`text-xs px-2 py-0.5 rounded ${re.is_suppressed?"bg-red-900/50 text-red-300":"bg-emerald-900/50 text-emerald-300"}`,children:re.is_suppressed?"‚ö†Ô∏è Suppressed":"‚úì Eligible"})]})}):H>0&&H<5?s.jsx("div",{className:"rounded-xl p-3 mb-3 border border-slate-600 bg-slate-800/50",children:s.jsx("div",{className:"text-slate-400 text-center",children:s.jsx("span",{children:"üõ°Ô∏è Eligibility check at Step 5"})})}):null,et.length>0&&s.jsxs("div",{className:"bg-cyan-900/20 border border-cyan-500/30 rounded-xl p-4",children:[s.jsxs("div",{className:"flex items-center gap-2 mb-3",children:[s.jsx("span",{className:"text-xl",children:"ü§ñ"}),s.jsx("span",{className:"font-semibold",children:"Pre-flight Analysis"})]}),s.jsx("div",{className:"space-y-2",children:et.map(y=>s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-2",children:[s.jsx("div",{className:"text-xs text-cyan-400",children:y.agent_name}),s.jsx("div",{className:"text-sm",children:y.summary})]},y.agent_id))})]})]})}),s.jsx("div",{className:"col-span-5 space-y-4",children:s.jsxs("div",{"data-tour":"agent-reasoning",className:"bg-slate-800/50 rounded-2xl p-5 border border-cyan-500/30 min-h-[500px]",children:[s.jsxs("div",{className:"flex items-center justify-between mb-4",children:[s.jsxs("h2",{className:"text-lg font-semibold flex items-center gap-2",children:[s.jsx("span",{className:"text-xl",children:"üß†"})," Agent Reasoning",s.jsx("span",{className:"text-[10px] bg-cyan-600 text-white px-2 py-0.5 rounded-full font-bold",children:"PILLARS 1-2: TRANSPARENCY"})]}),s.jsxs("span",{className:"text-xs text-cyan-400 bg-cyan-900/50 px-2 py-1 rounded flex items-center gap-1",children:[s.jsx("span",{className:"animate-pulse",children:"üí≠"})," See the WHY"]})]}),s.jsx("div",{className:"text-[10px] text-slate-400 mb-4 -mt-2",children:"Watch the agent THINK, not just score ‚Ä¢ Plan ‚Üí Execute ‚Üí Decide"}),s.jsx("div",{className:"flex items-center justify-between mb-6",children:[{id:"planner",label:"Planner",icon:"üìã",desc:"What to check?"},{id:"worker",label:"Worker",icon:"üîç",desc:"Execute checks"},{id:"solver",label:"Solver",icon:"‚úÖ",desc:"Final decision"}].map((y,P)=>s.jsxs("div",{className:"flex items-center",children:[s.jsxs("div",{className:`flex flex-col items-center transition-all duration-300 ${z.phase===y.id?"scale-110":""}`,children:[s.jsx("div",{className:`w-16 h-16 rounded-xl flex items-center justify-center text-2xl transition-all ${z.phase===y.id?"bg-cyan-600 shadow-lg shadow-cyan-500/30 animate-pulse":z.phase==="complete"||y.id==="planner"&&["worker","solver","complete"].includes(z.phase)||y.id==="worker"&&["solver","complete"].includes(z.phase)?"bg-emerald-600":"bg-slate-700"}`,children:y.icon}),s.jsx("div",{className:`text-xs mt-2 font-medium ${z.phase===y.id?"text-cyan-300":"text-slate-400"}`,children:y.label}),s.jsx("div",{className:"text-[10px] text-slate-500",children:y.desc})]}),P<2&&s.jsx("div",{className:`w-12 h-0.5 mx-2 transition-all ${P===0&&["worker","solver","complete"].includes(z.phase)||P===1&&["solver","complete"].includes(z.phase)?"bg-emerald-500":"bg-slate-600"}`})]},y.id))}),s.jsxs("div",{className:"space-y-4",children:[(z.phase==="planner"||["worker","solver","complete"].includes(z.phase))&&je&&s.jsxs("div",{"data-tour":"planner-section",className:"bg-slate-900/50 rounded-xl p-4 border border-cyan-500/30",children:[s.jsxs("div",{className:"text-xs text-cyan-400 mb-2 flex items-center justify-between",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{children:"üìã"})," PLANNER"]}),s.jsx("span",{className:"text-[10px] bg-cyan-600 text-white px-2 py-0.5 rounded-full font-bold",children:"PILLAR 1: PLANNING"})]}),s.jsx("pre",{className:"text-sm text-slate-300 whitespace-pre-wrap font-sans",children:je})]}),["worker","solver","complete"].includes(z.phase)&&k.length>0&&s.jsxs("div",{"data-tour":"worker-section",className:"bg-slate-900/50 rounded-xl p-4 border border-purple-500/30",children:[s.jsx("div",{className:"text-xs text-purple-400 mb-3 flex items-center justify-between",children:s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{children:"‚öôÔ∏è"})," WORKER EVALUATIONS"]})}),s.jsx("div",{className:"space-y-2",children:k.map((y,P)=>s.jsxs("div",{className:`flex items-start gap-3 p-2 rounded-lg transition-all ${y.status==="running"?"bg-purple-900/30 border border-purple-500/50":y.status==="complete"?"bg-emerald-900/20 border border-emerald-500/30":"bg-slate-800/50 border border-slate-600"}`,children:[s.jsx("div",{className:`w-6 h-6 rounded-full flex items-center justify-center text-xs flex-shrink-0 ${y.status==="running"?"bg-purple-600 animate-spin":y.status==="complete"?"bg-emerald-600":"bg-slate-600"}`,children:y.status==="complete"?"‚úì":y.status==="running"?"‚óå":P+1}),s.jsxs("div",{className:"flex-1 min-w-0",children:[s.jsx("div",{className:"text-sm font-medium",children:y.type}),y.recommendation&&s.jsx("div",{className:"text-xs text-emerald-300 mt-1",children:y.recommendation})]})]},P))})]}),["solver","complete"].includes(z.phase)&&Q&&s.jsxs("div",{"data-tour":"solver-section",className:"bg-slate-900/50 rounded-xl p-4 border border-emerald-500/30",children:[s.jsxs("div",{className:"text-xs text-emerald-400 mb-2 flex items-center justify-between",children:[s.jsxs("div",{className:"flex items-center gap-2",children:[s.jsx("span",{children:"‚úÖ"})," SOLVER"]}),s.jsx("span",{className:"text-[10px] bg-purple-600 text-white px-2 py-0.5 rounded-full font-bold",children:"PILLAR 2: REASONING"})]}),s.jsx("pre",{className:"text-sm text-slate-300 whitespace-pre-wrap font-sans",children:Q}),s.jsx("div",{className:"mt-2 pt-2 border-t border-slate-700 text-[10px] text-purple-300",children:"üëÅÔ∏è Full audit trail - every factor, every reason, every decision explained"})]}),z.phase==="idle"&&s.jsxs("div",{className:"space-y-4",children:[s.jsxs("div",{className:"text-center py-2",children:[s.jsx("h3",{className:"text-lg font-bold text-white mb-1",children:"Why Agentic AI?"}),s.jsx("p",{className:"text-xs text-slate-400",children:"What makes this different from traditional ML + Rules"})]}),s.jsx("div",{"data-tour":"pillars-grid",className:"grid grid-cols-4 gap-3",children:[{num:1,label:"PLANNING",desc:"Agent thinks first",color:"cyan",icon:"üìã"},{num:2,label:"REASONING",desc:"Full transparency",color:"purple",icon:"üß†"},{num:3,label:"BUSINESS CONTROL",desc:"You drive it",color:"amber",icon:"üéõÔ∏è"},{num:4,label:"HUMAN + AI",desc:"You stay in charge",color:"emerald",icon:"ü§ù"}].map(y=>s.jsxs("div",{className:`p-3 rounded-lg border text-center transition-all hover:scale-105 ${y.color==="cyan"?"bg-cyan-900/30 border-cyan-500/50":y.color==="purple"?"bg-purple-900/30 border-purple-500/50":y.color==="amber"?"bg-amber-900/30 border-amber-500/50":"bg-emerald-900/30 border-emerald-500/50"}`,children:[s.jsx("div",{className:"text-2xl mb-1",children:y.icon}),s.jsxs("div",{className:`text-[10px] font-bold ${y.color==="cyan"?"text-cyan-400":y.color==="purple"?"text-purple-400":y.color==="amber"?"text-amber-400":"text-emerald-400"}`,children:["P",y.num,": ",y.label]}),s.jsx("div",{className:"text-[9px] text-slate-500 mt-0.5",children:y.desc})]},y.num))}),s.jsxs("div",{className:"text-center pt-4 border-t border-slate-700",children:[s.jsx("div",{className:"text-2xl mb-2",children:"üéØ"}),s.jsxs("div",{className:"text-sm text-slate-300",children:["Click ",s.jsx("span",{className:"text-emerald-400 font-semibold",children:'"Run Agent"'})," to see pillars in action"]}),s.jsx("div",{className:"text-xs text-slate-500 mt-1",children:"Watch the agent THINK through a real decision"})]})]}),z.phase==="loading"&&s.jsxs("div",{className:"flex flex-col items-center justify-center h-64 text-slate-400",children:[s.jsx("div",{className:"text-4xl mb-4 animate-bounce",children:"‚è≥"}),s.jsx("div",{className:"text-lg",children:"Running pre-flight agents..."}),s.jsx("div",{className:"text-sm mt-2",children:"Customer Intelligence ‚Ä¢ Flight Optimization"})]})]})]})}),s.jsx("div",{className:"col-span-3 space-y-4",children:s.jsxs("div",{"data-tour":"final-decision",className:`bg-slate-800/50 rounded-2xl p-5 border transition-all duration-500 ${ee?K?.offerType==="REJECTED"||K?.offerType==="SUPPRESSED"?"border-red-500 shadow-lg shadow-red-500/20":"border-emerald-500 shadow-lg shadow-emerald-500/20":Qe?"border-amber-500 shadow-lg shadow-amber-500/20":"border-slate-700"}`,children:[s.jsxs("h2",{className:"text-lg font-semibold mb-4 flex items-center gap-2",children:[s.jsx("span",{className:"text-xl",children:"üéØ"})," Final Decision",Qe&&s.jsxs(s.Fragment,{children:[s.jsx("span",{className:"text-xs bg-amber-500 text-black px-2 py-0.5 rounded-full animate-pulse",children:"AWAITING APPROVAL"}),s.jsx("span",{className:"text-[10px] bg-emerald-600 text-white px-2 py-0.5 rounded-full font-bold",children:"PILLAR 4: HUMAN + AI"})]})]}),Qe&&Se&&s.jsxs("div",{className:"space-y-3",children:[s.jsxs("div",{className:"bg-amber-900/30 border border-amber-500/50 rounded-xl p-4 text-center",children:[s.jsx("div",{className:"text-amber-400 text-sm mb-1",children:"PENDING APPROVAL"}),s.jsx("div",{className:"text-2xl font-bold text-white",children:Se.offerName}),s.jsxs("div",{className:"text-3xl font-bold text-amber-400 mt-2",children:["$",Se.price.toFixed(0),Se.discount>0&&s.jsxs("span",{className:"text-sm text-amber-300 ml-2",children:["(-",Se.discount,"%)"]})]})]}),s.jsxs("div",{className:"grid grid-cols-2 gap-2",children:[s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-3 text-center",children:[s.jsx("div",{className:"text-xs text-slate-400",children:"Expected Value"}),s.jsxs("div",{className:"text-lg font-bold text-cyan-400",children:["$",Se.expectedValue.toFixed(2)]})]}),s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-3 text-center",children:[s.jsx("div",{className:"text-xs text-slate-400",children:"Confidence"}),s.jsx("div",{className:"text-lg font-bold text-emerald-400",children:Se.confidence})]})]}),s.jsxs("div",{className:"flex gap-2 mt-4",children:[s.jsxs("button",{onClick:V,className:"flex-1 bg-emerald-600 hover:bg-emerald-500 text-white font-medium py-3 rounded-lg transition-all flex items-center justify-center gap-2",children:[s.jsx("span",{children:"‚úÖ"})," Approve"]}),s.jsxs("button",{onClick:W,className:"flex-1 bg-red-600 hover:bg-red-500 text-white font-medium py-3 rounded-lg transition-all flex items-center justify-center gap-2",children:[s.jsx("span",{children:"‚ùå"})," Reject"]})]})]}),K&&ee&&s.jsxs("div",{className:"space-y-3",children:[s.jsxs("div",{className:`rounded-xl p-4 text-center ${K.offerType==="REJECTED"?"bg-red-900/30 border border-red-500/50":K.offerType==="SUPPRESSED"?"bg-slate-900/50 border border-slate-500/50":"bg-emerald-900/30 border border-emerald-500/50"}`,children:[s.jsx("div",{className:`text-sm mb-1 ${K.offerType==="REJECTED"?"text-red-400":K.offerType==="SUPPRESSED"?"text-slate-400":"text-emerald-400"}`,children:K.offerType==="REJECTED"?"REJECTED":K.offerType==="SUPPRESSED"?"NO OFFER":ae?"APPROVED":"RECOMMENDED"}),s.jsx("div",{className:"text-2xl font-bold text-white",children:K.offerName}),K.price>0&&s.jsxs("div",{className:"text-3xl font-bold text-emerald-400 mt-2",children:["$",K.price.toFixed(0),K.discount>0&&s.jsxs("span",{className:"text-sm text-amber-400 ml-2",children:["(-",K.discount,"%)"]})]})]}),K.price>0&&s.jsxs(s.Fragment,{children:[s.jsxs("div",{className:"grid grid-cols-2 gap-2",children:[s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-3 text-center",children:[s.jsx("div",{className:"text-xs text-slate-400",children:"Expected Value"}),s.jsxs("div",{className:"text-lg font-bold text-cyan-400",children:["$",K.expectedValue.toFixed(2)]})]}),s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-3 text-center",children:[s.jsx("div",{className:"text-xs text-slate-400",children:"Confidence"}),s.jsx("div",{className:`text-lg font-bold ${K.confidence==="HIGH"?"text-emerald-400":"text-amber-400"}`,children:K.confidence})]})]}),s.jsxs("div",{className:"bg-slate-900/50 rounded-lg p-3",children:[s.jsx("div",{className:"text-xs text-slate-400 mb-1",children:"Channel"}),s.jsxs("div",{className:"text-sm font-medium",children:[K.channel," Notification"]})]})]})]}),!K&&!Qe&&s.jsxs("div",{className:"flex flex-col items-center justify-center h-40 text-slate-500",children:[s.jsx("div",{className:"text-3xl mb-2",children:"‚è≥"}),s.jsx("div",{className:"text-sm",children:"Waiting for agent decision..."})]})]})})]})]}),s.jsx(jh,{}),s.jsx(Sh,{isOpen:ve,onOpenChange:Ve}),s.jsx(Th,{onSelectCustomer:y=>v(y),onRunAgent:Wt,onToggleHITL:Oe,onExpandControlPanel:le,onToggleAdvancedMode:E,onOpenPromptAssistant:()=>Ve(!0),isAgentComplete:z.phase==="complete"&&!Qe,availablePNRs:j.map(y=>y.pnr),customerInfo:re?{name:re.name,loyalty_tier:re.loyalty_tier,flight_revenue_amt_history:re.flight_revenue_amt_history,aadv_tenure_days:re.aadv_tenure_days}:void 0,plannerInfo:we||void 0,workerInfo:zt||void 0,solverInfo:Yl||void 0})]})}function Oh({currentStep:j,isRunning:J,scoreThreshold:D,mlScore:o}){const R=[{id:1,icon:"‚úàÔ∏è",label:"Eligible Flights",desc:"Flights with inventory"},{id:2,icon:"üìã",label:"PNRs",desc:"Reservation records"},{id:3,icon:"üë•",label:"Passengers",desc:"Individual travelers"},{id:4,icon:"ü§ñ",label:"ML Score",desc:"Propensity prediction",highlight:!0},{id:5,icon:"üìú",label:"Policy",desc:"Business rules",highlight:!0},{id:6,icon:"üéØ",label:"Decision",desc:"Send or suppress"}],U=o*100>=D;return s.jsxs("div",{className:"bg-slate-800/30 rounded-xl p-4 mb-6 border border-slate-700",children:[s.jsx("div",{className:"flex items-center justify-between mb-4",children:s.jsxs("div",{className:"flex items-center gap-3",children:[s.jsx("span",{className:"text-xs font-semibold text-slate-400 uppercase tracking-wider",children:"Decision Pipeline"}),s.jsx("span",{className:"text-xs px-2 py-0.5 rounded bg-cyan-900/50 text-cyan-300",children:"Real Backend"})]})}),s.jsx("div",{className:"flex items-center justify-between",children:R.map((w,te)=>s.jsxs("div",{className:"flex items-center flex-1",children:[s.jsxs("div",{className:`flex flex-col items-center transition-all duration-300 ${j>=w.id?"scale-105":""}`,children:[s.jsxs("div",{className:`w-14 h-14 rounded-xl flex items-center justify-center text-xl transition-all relative ${j===w.id&&J?w.id===4?"bg-purple-600 shadow-lg shadow-purple-500/30 animate-pulse":w.id===5?"bg-amber-600 shadow-lg shadow-amber-500/30 animate-pulse":"bg-cyan-600 shadow-lg shadow-cyan-500/30 animate-pulse":j>w.id?"bg-emerald-600/80":w.id===4?"bg-purple-900/50 border border-purple-500/30":w.id===5?"bg-amber-900/50 border border-amber-500/30":"bg-slate-700/50"}`,children:[w.icon,j>w.id&&s.jsx("div",{className:"absolute -bottom-1 -right-1 w-5 h-5 bg-emerald-500 rounded-full flex items-center justify-center text-xs",children:"‚úì"})]}),s.jsx("div",{className:`text-xs mt-2 font-medium text-center ${j>=w.id?"text-white":"text-slate-500"}`,children:w.label}),s.jsx("div",{className:"text-[10px] text-slate-500 text-center",children:w.desc}),w.id===4&&j>=4&&s.jsxs("div",{className:"mt-2 px-2 py-1 bg-purple-900/50 rounded text-xs",children:["Score: ",s.jsxs("span",{className:"text-purple-300 font-mono",children:[(o*100).toFixed(0),"%"]})]}),w.id===5&&j>=5&&s.jsxs("div",{className:"mt-2 px-2 py-1 bg-amber-900/50 rounded text-xs",children:["Threshold: ",s.jsxs("span",{className:"text-amber-300 font-mono",children:[D,"%"]})]}),w.id===6&&j>=6&&s.jsx("div",{className:`mt-2 px-2 py-1 rounded text-xs font-medium ${U?"bg-emerald-900/50 text-emerald-300":"bg-red-900/50 text-red-300"}`,children:U?"SEND":"SUPPRESS"})]}),te<R.length-1&&s.jsx("div",{className:`flex-1 h-0.5 mx-2 transition-all relative ${j>w.id?"bg-emerald-500":"bg-slate-600"}`,children:j>w.id&&s.jsx("div",{className:"absolute right-0 top-1/2 -translate-y-1/2 w-2 h-2 border-r-2 border-t-2 border-emerald-500 rotate-45"})})]},w.id))}),j===0&&s.jsx("div",{className:"mt-4 text-center text-sm text-slate-400",children:'Click "Run Agent" to see the decision pipeline in action'})]})}function Mh(){return s.jsx(zh,{})}ch.createRoot(document.getElementById("root")).render(s.jsx(N.StrictMode,{children:s.jsx(Mh,{})}));


================================================================================
FILE: frontend/dist/assets/index-DPvok_dg.css
================================================================================
@layer properties{@supports (((-webkit-hyphens:none)) and (not (margin-trim:inline))) or ((-moz-orient:inline) and (not (color:rgb(from red r g b)))){*,:before,:after,::backdrop{--tw-translate-x:0;--tw-translate-y:0;--tw-translate-z:0;--tw-scale-x:1;--tw-scale-y:1;--tw-scale-z:1;--tw-rotate-x:initial;--tw-rotate-y:initial;--tw-rotate-z:initial;--tw-skew-x:initial;--tw-skew-y:initial;--tw-space-y-reverse:0;--tw-space-x-reverse:0;--tw-border-style:solid;--tw-gradient-position:initial;--tw-gradient-from:#0000;--tw-gradient-via:#0000;--tw-gradient-to:#0000;--tw-gradient-stops:initial;--tw-gradient-via-stops:initial;--tw-gradient-from-position:0%;--tw-gradient-via-position:50%;--tw-gradient-to-position:100%;--tw-leading:initial;--tw-font-weight:initial;--tw-tracking:initial;--tw-shadow:0 0 #0000;--tw-shadow-color:initial;--tw-shadow-alpha:100%;--tw-inset-shadow:0 0 #0000;--tw-inset-shadow-color:initial;--tw-inset-shadow-alpha:100%;--tw-ring-color:initial;--tw-ring-shadow:0 0 #0000;--tw-inset-ring-color:initial;--tw-inset-ring-shadow:0 0 #0000;--tw-ring-inset:initial;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-offset-shadow:0 0 #0000;--tw-backdrop-blur:initial;--tw-backdrop-brightness:initial;--tw-backdrop-contrast:initial;--tw-backdrop-grayscale:initial;--tw-backdrop-hue-rotate:initial;--tw-backdrop-invert:initial;--tw-backdrop-opacity:initial;--tw-backdrop-saturate:initial;--tw-backdrop-sepia:initial;--tw-duration:initial;--tw-ease:initial}}}@layer theme{:root,:host{--font-sans:ui-sans-serif,system-ui,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--font-mono:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;--color-red-50:oklch(97.1% .013 17.38);--color-red-100:oklch(93.6% .032 17.717);--color-red-200:oklch(88.5% .062 18.334);--color-red-300:oklch(80.8% .114 19.571);--color-red-400:oklch(70.4% .191 22.216);--color-red-500:oklch(63.7% .237 25.331);--color-red-600:oklch(57.7% .245 27.325);--color-red-700:oklch(50.5% .213 27.518);--color-red-900:oklch(39.6% .141 25.723);--color-orange-500:oklch(70.5% .213 47.604);--color-orange-600:oklch(64.6% .222 41.116);--color-amber-50:oklch(98.7% .022 95.277);--color-amber-100:oklch(96.2% .059 95.617);--color-amber-200:oklch(92.4% .12 95.746);--color-amber-300:oklch(87.9% .169 91.605);--color-amber-400:oklch(82.8% .189 84.429);--color-amber-500:oklch(76.9% .188 70.08);--color-amber-600:oklch(66.6% .179 58.318);--color-amber-700:oklch(55.5% .163 48.998);--color-amber-800:oklch(47.3% .137 46.201);--color-amber-900:oklch(41.4% .112 45.904);--color-yellow-100:oklch(97.3% .071 103.193);--color-yellow-300:oklch(90.5% .182 98.111);--color-yellow-400:oklch(85.2% .199 91.936);--color-yellow-500:oklch(79.5% .184 86.047);--color-yellow-600:oklch(68.1% .162 75.834);--color-yellow-800:oklch(47.6% .114 61.907);--color-yellow-900:oklch(42.1% .095 57.708);--color-green-100:oklch(96.2% .044 156.743);--color-green-400:oklch(79.2% .209 151.711);--color-green-500:oklch(72.3% .219 149.579);--color-green-700:oklch(52.7% .154 150.069);--color-emerald-50:oklch(97.9% .021 166.113);--color-emerald-100:oklch(95% .052 163.051);--color-emerald-200:oklch(90.5% .093 164.15);--color-emerald-300:oklch(84.5% .143 164.978);--color-emerald-400:oklch(76.5% .177 163.223);--color-emerald-500:oklch(69.6% .17 162.48);--color-emerald-600:oklch(59.6% .145 163.225);--color-emerald-700:oklch(50.8% .118 165.612);--color-emerald-800:oklch(43.2% .095 166.913);--color-emerald-900:oklch(37.8% .077 168.94);--color-teal-400:oklch(77.7% .152 181.912);--color-teal-600:oklch(60% .118 184.704);--color-teal-900:oklch(38.6% .063 188.416);--color-cyan-100:oklch(95.6% .045 203.388);--color-cyan-300:oklch(86.5% .127 207.078);--color-cyan-400:oklch(78.9% .154 211.53);--color-cyan-500:oklch(71.5% .143 215.221);--color-cyan-600:oklch(60.9% .126 221.723);--color-cyan-900:oklch(39.8% .07 227.392);--color-blue-50:oklch(97% .014 254.604);--color-blue-100:oklch(93.2% .032 255.585);--color-blue-200:oklch(88.2% .059 254.128);--color-blue-300:oklch(80.9% .105 251.813);--color-blue-400:oklch(70.7% .165 254.624);--color-blue-500:oklch(62.3% .214 259.815);--color-blue-600:oklch(54.6% .245 262.881);--color-blue-700:oklch(48.8% .243 264.376);--color-blue-800:oklch(42.4% .199 265.638);--color-blue-900:oklch(37.9% .146 265.522);--color-indigo-50:oklch(96.2% .018 272.314);--color-indigo-100:oklch(93% .034 272.788);--color-indigo-300:oklch(78.5% .115 274.713);--color-indigo-500:oklch(58.5% .233 277.117);--color-indigo-600:oklch(51.1% .262 276.966);--color-indigo-700:oklch(45.7% .24 277.023);--color-indigo-800:oklch(39.8% .195 277.366);--color-indigo-900:oklch(35.9% .144 278.697);--color-purple-50:oklch(97.7% .014 308.299);--color-purple-100:oklch(94.6% .033 307.174);--color-purple-200:oklch(90.2% .063 306.703);--color-purple-300:oklch(82.7% .119 306.383);--color-purple-400:oklch(71.4% .203 305.504);--color-purple-500:oklch(62.7% .265 303.9);--color-purple-600:oklch(55.8% .288 302.321);--color-purple-700:oklch(49.6% .265 301.924);--color-purple-800:oklch(43.8% .218 303.724);--color-purple-900:oklch(38.1% .176 304.987);--color-pink-50:oklch(97.1% .014 343.198);--color-pink-100:oklch(94.8% .028 342.258);--color-pink-200:oklch(89.9% .061 343.231);--color-pink-300:oklch(82.3% .12 346.018);--color-pink-500:oklch(65.6% .241 354.308);--color-pink-900:oklch(40.8% .153 2.432);--color-slate-50:oklch(98.4% .003 247.858);--color-slate-100:oklch(96.8% .007 247.896);--color-slate-200:oklch(92.9% .013 255.508);--color-slate-300:oklch(86.9% .022 252.894);--color-slate-400:oklch(70.4% .04 256.788);--color-slate-500:oklch(55.4% .046 257.417);--color-slate-600:oklch(44.6% .043 257.281);--color-slate-700:oklch(37.2% .044 257.287);--color-slate-800:oklch(27.9% .041 260.031);--color-slate-900:oklch(20.8% .042 265.755);--color-slate-950:oklch(12.9% .042 264.695);--color-gray-50:oklch(98.5% .002 247.839);--color-gray-100:oklch(96.7% .003 264.542);--color-gray-200:oklch(92.8% .006 264.531);--color-gray-300:oklch(87.2% .01 258.338);--color-gray-400:oklch(70.7% .022 261.325);--color-gray-500:oklch(55.1% .027 264.364);--color-gray-600:oklch(44.6% .03 256.802);--color-gray-700:oklch(37.3% .034 259.733);--color-gray-800:oklch(27.8% .033 256.848);--color-gray-900:oklch(21% .034 264.665);--color-black:#000;--color-white:#fff;--spacing:.25rem;--container-md:28rem;--container-lg:32rem;--container-xl:36rem;--container-2xl:42rem;--container-3xl:48rem;--container-4xl:56rem;--container-5xl:64rem;--container-7xl:80rem;--text-xs:.75rem;--text-xs--line-height:calc(1/.75);--text-sm:.875rem;--text-sm--line-height:calc(1.25/.875);--text-lg:1.125rem;--text-lg--line-height:calc(1.75/1.125);--text-xl:1.25rem;--text-xl--line-height:calc(1.75/1.25);--text-2xl:1.5rem;--text-2xl--line-height:calc(2/1.5);--text-3xl:1.875rem;--text-3xl--line-height: 1.2 ;--text-4xl:2.25rem;--text-4xl--line-height:calc(2.5/2.25);--text-5xl:3rem;--text-5xl--line-height:1;--text-6xl:3.75rem;--text-6xl--line-height:1;--font-weight-normal:400;--font-weight-medium:500;--font-weight-semibold:600;--font-weight-bold:700;--tracking-tight:-.025em;--tracking-wide:.025em;--tracking-wider:.05em;--leading-relaxed:1.625;--radius-sm:.25rem;--radius-lg:.5rem;--radius-xl:.75rem;--radius-2xl:1rem;--ease-out:cubic-bezier(0,0,.2,1);--ease-in-out:cubic-bezier(.4,0,.2,1);--animate-spin:spin 1s linear infinite;--animate-pulse:pulse 2s cubic-bezier(.4,0,.6,1)infinite;--animate-bounce:bounce 1s infinite;--blur-md:12px;--default-transition-duration:.15s;--default-transition-timing-function:cubic-bezier(.4,0,.2,1);--default-font-family:var(--font-sans);--default-mono-font-family:var(--font-mono)}}@layer base{*,:after,:before,::backdrop{box-sizing:border-box;border:0 solid;margin:0;padding:0}::file-selector-button{box-sizing:border-box;border:0 solid;margin:0;padding:0}html,:host{-webkit-text-size-adjust:100%;tab-size:4;line-height:1.5;font-family:var(--default-font-family,ui-sans-serif,system-ui,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji");font-feature-settings:var(--default-font-feature-settings,normal);font-variation-settings:var(--default-font-variation-settings,normal);-webkit-tap-highlight-color:transparent}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,samp,pre{font-family:var(--default-mono-font-family,ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace);font-feature-settings:var(--default-mono-font-feature-settings,normal);font-variation-settings:var(--default-mono-font-variation-settings,normal);font-size:1em}small{font-size:80%}sub,sup{vertical-align:baseline;font-size:75%;line-height:0;position:relative}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}:-moz-focusring{outline:auto}progress{vertical-align:baseline}summary{display:list-item}ol,ul,menu{list-style:none}img,svg,video,canvas,audio,iframe,embed,object{vertical-align:middle;display:block}img,video{max-width:100%;height:auto}button,input,select,optgroup,textarea{font:inherit;font-feature-settings:inherit;font-variation-settings:inherit;letter-spacing:inherit;color:inherit;opacity:1;background-color:#0000;border-radius:0}::file-selector-button{font:inherit;font-feature-settings:inherit;font-variation-settings:inherit;letter-spacing:inherit;color:inherit;opacity:1;background-color:#0000;border-radius:0}:where(select:is([multiple],[size])) optgroup{font-weight:bolder}:where(select:is([multiple],[size])) optgroup option{padding-inline-start:20px}::file-selector-button{margin-inline-end:4px}::placeholder{opacity:1}@supports (not ((-webkit-appearance:-apple-pay-button))) or (contain-intrinsic-size:1px){::placeholder{color:currentColor}@supports (color:color-mix(in lab,red,red)){::placeholder{color:color-mix(in oklab,currentcolor 50%,transparent)}}}textarea{resize:vertical}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-date-and-time-value{min-height:1lh;text-align:inherit}::-webkit-datetime-edit{display:inline-flex}::-webkit-datetime-edit-fields-wrapper{padding:0}::-webkit-datetime-edit{padding-block:0}::-webkit-datetime-edit-year-field{padding-block:0}::-webkit-datetime-edit-month-field{padding-block:0}::-webkit-datetime-edit-day-field{padding-block:0}::-webkit-datetime-edit-hour-field{padding-block:0}::-webkit-datetime-edit-minute-field{padding-block:0}::-webkit-datetime-edit-second-field{padding-block:0}::-webkit-datetime-edit-millisecond-field{padding-block:0}::-webkit-datetime-edit-meridiem-field{padding-block:0}::-webkit-calendar-picker-indicator{line-height:1}:-moz-ui-invalid{box-shadow:none}button,input:where([type=button],[type=reset],[type=submit]){appearance:button}::file-selector-button{appearance:button}::-webkit-inner-spin-button{height:auto}::-webkit-outer-spin-button{height:auto}[hidden]:where(:not([hidden=until-found])){display:none!important}}@layer components;@layer utilities{.pointer-events-none{pointer-events:none}.absolute{position:absolute}.fixed{position:fixed}.relative{position:relative}.static{position:static}.inset-0{inset:calc(var(--spacing)*0)}.-top-1{top:calc(var(--spacing)*-1)}.-top-2{top:calc(var(--spacing)*-2)}.-top-3{top:calc(var(--spacing)*-3)}.-top-6{top:calc(var(--spacing)*-6)}.top-1{top:calc(var(--spacing)*1)}.top-1\/2{top:50%}.top-4{top:calc(var(--spacing)*4)}.top-12{top:calc(var(--spacing)*12)}.-right-1{right:calc(var(--spacing)*-1)}.-right-2{right:calc(var(--spacing)*-2)}.-right-12{right:calc(var(--spacing)*-12)}.-right-16{right:calc(var(--spacing)*-16)}.right-0{right:calc(var(--spacing)*0)}.right-4{right:calc(var(--spacing)*4)}.right-6{right:calc(var(--spacing)*6)}.right-8{right:calc(var(--spacing)*8)}.-bottom-1{bottom:calc(var(--spacing)*-1)}.-bottom-2{bottom:calc(var(--spacing)*-2)}.bottom-0{bottom:calc(var(--spacing)*0)}.bottom-4{bottom:calc(var(--spacing)*4)}.bottom-6{bottom:calc(var(--spacing)*6)}.bottom-20{bottom:calc(var(--spacing)*20)}.bottom-24{bottom:calc(var(--spacing)*24)}.bottom-full{bottom:100%}.-left-2{left:calc(var(--spacing)*-2)}.-left-20{left:calc(var(--spacing)*-20)}.left-0{left:calc(var(--spacing)*0)}.left-1{left:calc(var(--spacing)*1)}.left-1\/2{left:50%}.left-4{left:calc(var(--spacing)*4)}.left-6{left:calc(var(--spacing)*6)}.left-7{left:calc(var(--spacing)*7)}.left-24{left:calc(var(--spacing)*24)}.z-10{z-index:10}.z-40{z-index:40}.z-50{z-index:50}.col-span-2{grid-column:span 2/span 2}.col-span-3{grid-column:span 3/span 3}.col-span-4{grid-column:span 4/span 4}.col-span-5{grid-column:span 5/span 5}.mx-1{margin-inline:calc(var(--spacing)*1)}.mx-2{margin-inline:calc(var(--spacing)*2)}.mx-4{margin-inline:calc(var(--spacing)*4)}.mx-auto{margin-inline:auto}.-mt-2{margin-top:calc(var(--spacing)*-2)}.mt-0\.5{margin-top:calc(var(--spacing)*.5)}.mt-1{margin-top:calc(var(--spacing)*1)}.mt-2{margin-top:calc(var(--spacing)*2)}.mt-3{margin-top:calc(var(--spacing)*3)}.mt-4{margin-top:calc(var(--spacing)*4)}.mt-6{margin-top:calc(var(--spacing)*6)}.mt-8{margin-top:calc(var(--spacing)*8)}.mt-10{margin-top:calc(var(--spacing)*10)}.mt-12{margin-top:calc(var(--spacing)*12)}.mr-1{margin-right:calc(var(--spacing)*1)}.mr-2{margin-right:calc(var(--spacing)*2)}.mr-4{margin-right:calc(var(--spacing)*4)}.-mb-0\.5{margin-bottom:calc(var(--spacing)*-.5)}.mb-1{margin-bottom:calc(var(--spacing)*1)}.mb-2{margin-bottom:calc(var(--spacing)*2)}.mb-3{margin-bottom:calc(var(--spacing)*3)}.mb-4{margin-bottom:calc(var(--spacing)*4)}.mb-6{margin-bottom:calc(var(--spacing)*6)}.mb-8{margin-bottom:calc(var(--spacing)*8)}.ml-0\.5{margin-left:calc(var(--spacing)*.5)}.ml-1{margin-left:calc(var(--spacing)*1)}.ml-2{margin-left:calc(var(--spacing)*2)}.ml-4{margin-left:calc(var(--spacing)*4)}.ml-24{margin-left:calc(var(--spacing)*24)}.ml-auto{margin-left:auto}.line-clamp-3{-webkit-line-clamp:3;-webkit-box-orient:vertical;display:-webkit-box;overflow:hidden}.block{display:block}.flex{display:flex}.grid{display:grid}.hidden{display:none}.inline{display:inline}.inline-block{display:inline-block}.h-0\.5{height:calc(var(--spacing)*.5)}.h-1{height:calc(var(--spacing)*1)}.h-1\.5{height:calc(var(--spacing)*1.5)}.h-2{height:calc(var(--spacing)*2)}.h-3{height:calc(var(--spacing)*3)}.h-4{height:calc(var(--spacing)*4)}.h-5{height:calc(var(--spacing)*5)}.h-6{height:calc(var(--spacing)*6)}.h-8{height:calc(var(--spacing)*8)}.h-10{height:calc(var(--spacing)*10)}.h-12{height:calc(var(--spacing)*12)}.h-14{height:calc(var(--spacing)*14)}.h-16{height:calc(var(--spacing)*16)}.h-20{height:calc(var(--spacing)*20)}.h-24{height:calc(var(--spacing)*24)}.h-32{height:calc(var(--spacing)*32)}.h-40{height:calc(var(--spacing)*40)}.h-48{height:calc(var(--spacing)*48)}.h-64{height:calc(var(--spacing)*64)}.h-\[32rem\]{height:32rem}.h-\[80vh\]{height:80vh}.h-\[520px\]{height:520px}.h-full{height:100%}.h-px{height:1px}.max-h-24{max-height:calc(var(--spacing)*24)}.max-h-32{max-height:calc(var(--spacing)*32)}.max-h-64{max-height:calc(var(--spacing)*64)}.max-h-\[300px\]{max-height:300px}.max-h-\[500px\]{max-height:500px}.max-h-none{max-height:none}.min-h-\[200px\]{min-height:200px}.min-h-\[500px\]{min-height:500px}.min-h-screen{min-height:100vh}.w-2{width:calc(var(--spacing)*2)}.w-3{width:calc(var(--spacing)*3)}.w-4{width:calc(var(--spacing)*4)}.w-5{width:calc(var(--spacing)*5)}.w-6{width:calc(var(--spacing)*6)}.w-8{width:calc(var(--spacing)*8)}.w-10{width:calc(var(--spacing)*10)}.w-12{width:calc(var(--spacing)*12)}.w-14{width:calc(var(--spacing)*14)}.w-16{width:calc(var(--spacing)*16)}.w-20{width:calc(var(--spacing)*20)}.w-24{width:calc(var(--spacing)*24)}.w-32{width:calc(var(--spacing)*32)}.w-36{width:calc(var(--spacing)*36)}.w-40{width:calc(var(--spacing)*40)}.w-44{width:calc(var(--spacing)*44)}.w-48{width:calc(var(--spacing)*48)}.w-52{width:calc(var(--spacing)*52)}.w-56{width:calc(var(--spacing)*56)}.w-64{width:calc(var(--spacing)*64)}.w-72{width:calc(var(--spacing)*72)}.w-80{width:calc(var(--spacing)*80)}.w-96{width:calc(var(--spacing)*96)}.w-full{width:100%}.w-px{width:1px}.max-w-2xl{max-width:var(--container-2xl)}.max-w-3xl{max-width:var(--container-3xl)}.max-w-4xl{max-width:var(--container-4xl)}.max-w-5xl{max-width:var(--container-5xl)}.max-w-7xl{max-width:var(--container-7xl)}.max-w-\[80\%\]{max-width:80%}.max-w-\[85\%\]{max-width:85%}.max-w-\[120px\]{max-width:120px}.max-w-\[200px\]{max-width:200px}.max-w-lg{max-width:var(--container-lg)}.max-w-md{max-width:var(--container-md)}.max-w-xl{max-width:var(--container-xl)}.min-w-0{min-width:calc(var(--spacing)*0)}.flex-1{flex:1}.flex-shrink-0{flex-shrink:0}.-translate-x-1\/2{--tw-translate-x: -50% ;translate:var(--tw-translate-x)var(--tw-translate-y)}.-translate-y-1\/2{--tw-translate-y: -50% ;translate:var(--tw-translate-x)var(--tw-translate-y)}.translate-y-0{--tw-translate-y:calc(var(--spacing)*0);translate:var(--tw-translate-x)var(--tw-translate-y)}.translate-y-1\/2{--tw-translate-y: 50% ;translate:var(--tw-translate-x)var(--tw-translate-y)}.translate-y-8{--tw-translate-y:calc(var(--spacing)*8);translate:var(--tw-translate-x)var(--tw-translate-y)}.scale-50{--tw-scale-x:50%;--tw-scale-y:50%;--tw-scale-z:50%;scale:var(--tw-scale-x)var(--tw-scale-y)}.scale-90{--tw-scale-x:90%;--tw-scale-y:90%;--tw-scale-z:90%;scale:var(--tw-scale-x)var(--tw-scale-y)}.scale-100{--tw-scale-x:100%;--tw-scale-y:100%;--tw-scale-z:100%;scale:var(--tw-scale-x)var(--tw-scale-y)}.scale-105{--tw-scale-x:105%;--tw-scale-y:105%;--tw-scale-z:105%;scale:var(--tw-scale-x)var(--tw-scale-y)}.scale-110{--tw-scale-x:110%;--tw-scale-y:110%;--tw-scale-z:110%;scale:var(--tw-scale-x)var(--tw-scale-y)}.rotate-45{rotate:45deg}.rotate-180{rotate:180deg}.transform{transform:var(--tw-rotate-x,)var(--tw-rotate-y,)var(--tw-rotate-z,)var(--tw-skew-x,)var(--tw-skew-y,)}.animate-bounce{animation:var(--animate-bounce)}.animate-pulse{animation:var(--animate-pulse)}.animate-spin{animation:var(--animate-spin)}.cursor-not-allowed{cursor:not-allowed}.cursor-pointer{cursor:pointer}.grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.grid-cols-4{grid-template-columns:repeat(4,minmax(0,1fr))}.grid-cols-12{grid-template-columns:repeat(12,minmax(0,1fr))}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.items-center{align-items:center}.items-start{align-items:flex-start}.justify-between{justify-content:space-between}.justify-center{justify-content:center}.justify-end{justify-content:flex-end}.justify-start{justify-content:flex-start}.gap-1{gap:calc(var(--spacing)*1)}.gap-1\.5{gap:calc(var(--spacing)*1.5)}.gap-2{gap:calc(var(--spacing)*2)}.gap-3{gap:calc(var(--spacing)*3)}.gap-4{gap:calc(var(--spacing)*4)}.gap-6{gap:calc(var(--spacing)*6)}.gap-8{gap:calc(var(--spacing)*8)}:where(.space-y-1>:not(:last-child)){--tw-space-y-reverse:0;margin-block-start:calc(calc(var(--spacing)*1)*var(--tw-space-y-reverse));margin-block-end:calc(calc(var(--spacing)*1)*calc(1 - var(--tw-space-y-reverse)))}:where(.space-y-2>:not(:last-child)){--tw-space-y-reverse:0;margin-block-start:calc(calc(var(--spacing)*2)*var(--tw-space-y-reverse));margin-block-end:calc(calc(var(--spacing)*2)*calc(1 - var(--tw-space-y-reverse)))}:where(.space-y-3>:not(:last-child)){--tw-space-y-reverse:0;margin-block-start:calc(calc(var(--spacing)*3)*var(--tw-space-y-reverse));margin-block-end:calc(calc(var(--spacing)*3)*calc(1 - var(--tw-space-y-reverse)))}:where(.space-y-4>:not(:last-child)){--tw-space-y-reverse:0;margin-block-start:calc(calc(var(--spacing)*4)*var(--tw-space-y-reverse));margin-block-end:calc(calc(var(--spacing)*4)*calc(1 - var(--tw-space-y-reverse)))}.gap-x-6{column-gap:calc(var(--spacing)*6)}:where(.space-x-2>:not(:last-child)){--tw-space-x-reverse:0;margin-inline-start:calc(calc(var(--spacing)*2)*var(--tw-space-x-reverse));margin-inline-end:calc(calc(var(--spacing)*2)*calc(1 - var(--tw-space-x-reverse)))}:where(.space-x-4>:not(:last-child)){--tw-space-x-reverse:0;margin-inline-start:calc(calc(var(--spacing)*4)*var(--tw-space-x-reverse));margin-inline-end:calc(calc(var(--spacing)*4)*calc(1 - var(--tw-space-x-reverse)))}.gap-y-1{row-gap:calc(var(--spacing)*1)}.truncate{text-overflow:ellipsis;white-space:nowrap;overflow:hidden}.overflow-hidden{overflow:hidden}.overflow-x-auto{overflow-x:auto}.overflow-y-auto{overflow-y:auto}.overflow-y-hidden{overflow-y:hidden}.rounded{border-radius:.25rem}.rounded-2xl{border-radius:var(--radius-2xl)}.rounded-full{border-radius:3.40282e38px}.rounded-lg{border-radius:var(--radius-lg)}.rounded-xl{border-radius:var(--radius-xl)}.rounded-b-lg{border-bottom-right-radius:var(--radius-lg);border-bottom-left-radius:var(--radius-lg)}.rounded-br-sm{border-bottom-right-radius:var(--radius-sm)}.rounded-bl-sm{border-bottom-left-radius:var(--radius-sm)}.border{border-style:var(--tw-border-style);border-width:1px}.border-2{border-style:var(--tw-border-style);border-width:2px}.border-t{border-top-style:var(--tw-border-style);border-top-width:1px}.border-t-2{border-top-style:var(--tw-border-style);border-top-width:2px}.border-r-2{border-right-style:var(--tw-border-style);border-right-width:2px}.border-b{border-bottom-style:var(--tw-border-style);border-bottom-width:1px}.border-b-2{border-bottom-style:var(--tw-border-style);border-bottom-width:2px}.border-l{border-left-style:var(--tw-border-style);border-left-width:1px}.border-l-4{border-left-style:var(--tw-border-style);border-left-width:4px}.border-dashed{--tw-border-style:dashed;border-style:dashed}.border-amber-200{border-color:var(--color-amber-200)}.border-amber-400{border-color:var(--color-amber-400)}.border-amber-500{border-color:var(--color-amber-500)}.border-amber-500\/30{border-color:#f99c004d}@supports (color:color-mix(in lab,red,red)){.border-amber-500\/30{border-color:color-mix(in oklab,var(--color-amber-500)30%,transparent)}}.border-amber-500\/50{border-color:#f99c0080}@supports (color:color-mix(in lab,red,red)){.border-amber-500\/50{border-color:color-mix(in oklab,var(--color-amber-500)50%,transparent)}}.border-blue-200{border-color:var(--color-blue-200)}.border-blue-400{border-color:var(--color-blue-400)}.border-blue-500{border-color:var(--color-blue-500)}.border-blue-500\/30{border-color:#3080ff4d}@supports (color:color-mix(in lab,red,red)){.border-blue-500\/30{border-color:color-mix(in oklab,var(--color-blue-500)30%,transparent)}}.border-blue-500\/50{border-color:#3080ff80}@supports (color:color-mix(in lab,red,red)){.border-blue-500\/50{border-color:color-mix(in oklab,var(--color-blue-500)50%,transparent)}}.border-cyan-400{border-color:var(--color-cyan-400)}.border-cyan-500\/30{border-color:#00b7d74d}@supports (color:color-mix(in lab,red,red)){.border-cyan-500\/30{border-color:color-mix(in oklab,var(--color-cyan-500)30%,transparent)}}.border-cyan-500\/50{border-color:#00b7d780}@supports (color:color-mix(in lab,red,red)){.border-cyan-500\/50{border-color:color-mix(in oklab,var(--color-cyan-500)50%,transparent)}}.border-emerald-100{border-color:var(--color-emerald-100)}.border-emerald-200{border-color:var(--color-emerald-200)}.border-emerald-400{border-color:var(--color-emerald-400)}.border-emerald-500{border-color:var(--color-emerald-500)}.border-emerald-500\/30{border-color:#00bb7f4d}@supports (color:color-mix(in lab,red,red)){.border-emerald-500\/30{border-color:color-mix(in oklab,var(--color-emerald-500)30%,transparent)}}.border-emerald-500\/50{border-color:#00bb7f80}@supports (color:color-mix(in lab,red,red)){.border-emerald-500\/50{border-color:color-mix(in oklab,var(--color-emerald-500)50%,transparent)}}.border-gray-100{border-color:var(--color-gray-100)}.border-gray-200{border-color:var(--color-gray-200)}.border-gray-300{border-color:var(--color-gray-300)}.border-gray-400{border-color:var(--color-gray-400)}.border-indigo-500\/30{border-color:#625fff4d}@supports (color:color-mix(in lab,red,red)){.border-indigo-500\/30{border-color:color-mix(in oklab,var(--color-indigo-500)30%,transparent)}}.border-pink-500{border-color:var(--color-pink-500)}.border-pink-500\/30{border-color:#f6339a4d}@supports (color:color-mix(in lab,red,red)){.border-pink-500\/30{border-color:color-mix(in oklab,var(--color-pink-500)30%,transparent)}}.border-purple-200{border-color:var(--color-purple-200)}.border-purple-300{border-color:var(--color-purple-300)}.border-purple-400{border-color:var(--color-purple-400)}.border-purple-500{border-color:var(--color-purple-500)}.border-purple-500\/30{border-color:#ac4bff4d}@supports (color:color-mix(in lab,red,red)){.border-purple-500\/30{border-color:color-mix(in oklab,var(--color-purple-500)30%,transparent)}}.border-purple-500\/50{border-color:#ac4bff80}@supports (color:color-mix(in lab,red,red)){.border-purple-500\/50{border-color:color-mix(in oklab,var(--color-purple-500)50%,transparent)}}.border-red-400{border-color:var(--color-red-400)}.border-red-500{border-color:var(--color-red-500)}.border-red-500\/30{border-color:#fb2c364d}@supports (color:color-mix(in lab,red,red)){.border-red-500\/30{border-color:color-mix(in oklab,var(--color-red-500)30%,transparent)}}.border-red-500\/50{border-color:#fb2c3680}@supports (color:color-mix(in lab,red,red)){.border-red-500\/50{border-color:color-mix(in oklab,var(--color-red-500)50%,transparent)}}.border-slate-200{border-color:var(--color-slate-200)}.border-slate-300{border-color:var(--color-slate-300)}.border-slate-400{border-color:var(--color-slate-400)}.border-slate-400\/50{border-color:#90a1b980}@supports (color:color-mix(in lab,red,red)){.border-slate-400\/50{border-color:color-mix(in oklab,var(--color-slate-400)50%,transparent)}}.border-slate-500{border-color:var(--color-slate-500)}.border-slate-500\/50{border-color:#62748e80}@supports (color:color-mix(in lab,red,red)){.border-slate-500\/50{border-color:color-mix(in oklab,var(--color-slate-500)50%,transparent)}}.border-slate-600{border-color:var(--color-slate-600)}.border-slate-600\/30{border-color:#45556c4d}@supports (color:color-mix(in lab,red,red)){.border-slate-600\/30{border-color:color-mix(in oklab,var(--color-slate-600)30%,transparent)}}.border-slate-600\/50{border-color:#45556c80}@supports (color:color-mix(in lab,red,red)){.border-slate-600\/50{border-color:color-mix(in oklab,var(--color-slate-600)50%,transparent)}}.border-slate-700{border-color:var(--color-slate-700)}.border-slate-700\/50{border-color:#31415880}@supports (color:color-mix(in lab,red,red)){.border-slate-700\/50{border-color:color-mix(in oklab,var(--color-slate-700)50%,transparent)}}.border-slate-800{border-color:var(--color-slate-800)}.border-slate-800\/50{border-color:#1d293d80}@supports (color:color-mix(in lab,red,red)){.border-slate-800\/50{border-color:color-mix(in oklab,var(--color-slate-800)50%,transparent)}}.border-transparent{border-color:#0000}.border-white{border-color:var(--color-white)}.border-white\/30{border-color:#ffffff4d}@supports (color:color-mix(in lab,red,red)){.border-white\/30{border-color:color-mix(in oklab,var(--color-white)30%,transparent)}}.border-yellow-300{border-color:var(--color-yellow-300)}.border-yellow-500\/50{border-color:#edb20080}@supports (color:color-mix(in lab,red,red)){.border-yellow-500\/50{border-color:color-mix(in oklab,var(--color-yellow-500)50%,transparent)}}.border-yellow-600{border-color:var(--color-yellow-600)}.border-t-transparent{border-top-color:#0000}.bg-amber-50{background-color:var(--color-amber-50)}.bg-amber-100{background-color:var(--color-amber-100)}.bg-amber-200{background-color:var(--color-amber-200)}.bg-amber-500{background-color:var(--color-amber-500)}.bg-amber-500\/30{background-color:#f99c004d}@supports (color:color-mix(in lab,red,red)){.bg-amber-500\/30{background-color:color-mix(in oklab,var(--color-amber-500)30%,transparent)}}.bg-amber-600{background-color:var(--color-amber-600)}.bg-amber-800\/20{background-color:#953d0033}@supports (color:color-mix(in lab,red,red)){.bg-amber-800\/20{background-color:color-mix(in oklab,var(--color-amber-800)20%,transparent)}}.bg-amber-800\/30{background-color:#953d004d}@supports (color:color-mix(in lab,red,red)){.bg-amber-800\/30{background-color:color-mix(in oklab,var(--color-amber-800)30%,transparent)}}.bg-amber-800\/50{background-color:#953d0080}@supports (color:color-mix(in lab,red,red)){.bg-amber-800\/50{background-color:color-mix(in oklab,var(--color-amber-800)50%,transparent)}}.bg-amber-900\/10{background-color:#7b33061a}@supports (color:color-mix(in lab,red,red)){.bg-amber-900\/10{background-color:color-mix(in oklab,var(--color-amber-900)10%,transparent)}}.bg-amber-900\/20{background-color:#7b330633}@supports (color:color-mix(in lab,red,red)){.bg-amber-900\/20{background-color:color-mix(in oklab,var(--color-amber-900)20%,transparent)}}.bg-amber-900\/30{background-color:#7b33064d}@supports (color:color-mix(in lab,red,red)){.bg-amber-900\/30{background-color:color-mix(in oklab,var(--color-amber-900)30%,transparent)}}.bg-amber-900\/50{background-color:#7b330680}@supports (color:color-mix(in lab,red,red)){.bg-amber-900\/50{background-color:color-mix(in oklab,var(--color-amber-900)50%,transparent)}}.bg-black\/60{background-color:#0009}@supports (color:color-mix(in lab,red,red)){.bg-black\/60{background-color:color-mix(in oklab,var(--color-black)60%,transparent)}}.bg-black\/80{background-color:#000c}@supports (color:color-mix(in lab,red,red)){.bg-black\/80{background-color:color-mix(in oklab,var(--color-black)80%,transparent)}}.bg-black\/95{background-color:#000000f2}@supports (color:color-mix(in lab,red,red)){.bg-black\/95{background-color:color-mix(in oklab,var(--color-black)95%,transparent)}}.bg-blue-50{background-color:var(--color-blue-50)}.bg-blue-100{background-color:var(--color-blue-100)}.bg-blue-500{background-color:var(--color-blue-500)}.bg-blue-500\/30{background-color:#3080ff4d}@supports (color:color-mix(in lab,red,red)){.bg-blue-500\/30{background-color:color-mix(in oklab,var(--color-blue-500)30%,transparent)}}.bg-blue-500\/80{background-color:#3080ffcc}@supports (color:color-mix(in lab,red,red)){.bg-blue-500\/80{background-color:color-mix(in oklab,var(--color-blue-500)80%,transparent)}}.bg-blue-600{background-color:var(--color-blue-600)}.bg-blue-800\/30{background-color:#193cb84d}@supports (color:color-mix(in lab,red,red)){.bg-blue-800\/30{background-color:color-mix(in oklab,var(--color-blue-800)30%,transparent)}}.bg-blue-800\/50{background-color:#193cb880}@supports (color:color-mix(in lab,red,red)){.bg-blue-800\/50{background-color:color-mix(in oklab,var(--color-blue-800)50%,transparent)}}.bg-blue-900\/20{background-color:#1c398e33}@supports (color:color-mix(in lab,red,red)){.bg-blue-900\/20{background-color:color-mix(in oklab,var(--color-blue-900)20%,transparent)}}.bg-blue-900\/30{background-color:#1c398e4d}@supports (color:color-mix(in lab,red,red)){.bg-blue-900\/30{background-color:color-mix(in oklab,var(--color-blue-900)30%,transparent)}}.bg-blue-900\/50{background-color:#1c398e80}@supports (color:color-mix(in lab,red,red)){.bg-blue-900\/50{background-color:color-mix(in oklab,var(--color-blue-900)50%,transparent)}}.bg-cyan-400{background-color:var(--color-cyan-400)}.bg-cyan-500{background-color:var(--color-cyan-500)}.bg-cyan-600{background-color:var(--color-cyan-600)}.bg-cyan-600\/50{background-color:#0092b580}@supports (color:color-mix(in lab,red,red)){.bg-cyan-600\/50{background-color:color-mix(in oklab,var(--color-cyan-600)50%,transparent)}}.bg-cyan-900\/20{background-color:#104e6433}@supports (color:color-mix(in lab,red,red)){.bg-cyan-900\/20{background-color:color-mix(in oklab,var(--color-cyan-900)20%,transparent)}}.bg-cyan-900\/30{background-color:#104e644d}@supports (color:color-mix(in lab,red,red)){.bg-cyan-900\/30{background-color:color-mix(in oklab,var(--color-cyan-900)30%,transparent)}}.bg-cyan-900\/50{background-color:#104e6480}@supports (color:color-mix(in lab,red,red)){.bg-cyan-900\/50{background-color:color-mix(in oklab,var(--color-cyan-900)50%,transparent)}}.bg-emerald-50{background-color:var(--color-emerald-50)}.bg-emerald-100{background-color:var(--color-emerald-100)}.bg-emerald-200{background-color:var(--color-emerald-200)}.bg-emerald-500{background-color:var(--color-emerald-500)}.bg-emerald-500\/20{background-color:#00bb7f33}@supports (color:color-mix(in lab,red,red)){.bg-emerald-500\/20{background-color:color-mix(in oklab,var(--color-emerald-500)20%,transparent)}}.bg-emerald-500\/30{background-color:#00bb7f4d}@supports (color:color-mix(in lab,red,red)){.bg-emerald-500\/30{background-color:color-mix(in oklab,var(--color-emerald-500)30%,transparent)}}.bg-emerald-600{background-color:var(--color-emerald-600)}.bg-emerald-600\/80{background-color:#009767cc}@supports (color:color-mix(in lab,red,red)){.bg-emerald-600\/80{background-color:color-mix(in oklab,var(--color-emerald-600)80%,transparent)}}.bg-emerald-700{background-color:var(--color-emerald-700)}.bg-emerald-800\/20{background-color:#005f4633}@supports (color:color-mix(in lab,red,red)){.bg-emerald-800\/20{background-color:color-mix(in oklab,var(--color-emerald-800)20%,transparent)}}.bg-emerald-800\/30{background-color:#005f464d}@supports (color:color-mix(in lab,red,red)){.bg-emerald-800\/30{background-color:color-mix(in oklab,var(--color-emerald-800)30%,transparent)}}.bg-emerald-900\/10{background-color:#004e3b1a}@supports (color:color-mix(in lab,red,red)){.bg-emerald-900\/10{background-color:color-mix(in oklab,var(--color-emerald-900)10%,transparent)}}.bg-emerald-900\/20{background-color:#004e3b33}@supports (color:color-mix(in lab,red,red)){.bg-emerald-900\/20{background-color:color-mix(in oklab,var(--color-emerald-900)20%,transparent)}}.bg-emerald-900\/30{background-color:#004e3b4d}@supports (color:color-mix(in lab,red,red)){.bg-emerald-900\/30{background-color:color-mix(in oklab,var(--color-emerald-900)30%,transparent)}}.bg-emerald-900\/50{background-color:#004e3b80}@supports (color:color-mix(in lab,red,red)){.bg-emerald-900\/50{background-color:color-mix(in oklab,var(--color-emerald-900)50%,transparent)}}.bg-gray-50{background-color:var(--color-gray-50)}.bg-gray-100{background-color:var(--color-gray-100)}.bg-gray-200{background-color:var(--color-gray-200)}.bg-gray-300{background-color:var(--color-gray-300)}.bg-gray-400{background-color:var(--color-gray-400)}.bg-gray-700{background-color:var(--color-gray-700)}.bg-green-100{background-color:var(--color-green-100)}.bg-green-400{background-color:var(--color-green-400)}.bg-green-500{background-color:var(--color-green-500)}.bg-indigo-100{background-color:var(--color-indigo-100)}.bg-indigo-900\/30{background-color:#312c854d}@supports (color:color-mix(in lab,red,red)){.bg-indigo-900\/30{background-color:color-mix(in oklab,var(--color-indigo-900)30%,transparent)}}.bg-pink-900\/30{background-color:#8610434d}@supports (color:color-mix(in lab,red,red)){.bg-pink-900\/30{background-color:color-mix(in oklab,var(--color-pink-900)30%,transparent)}}.bg-pink-900\/50{background-color:#86104380}@supports (color:color-mix(in lab,red,red)){.bg-pink-900\/50{background-color:color-mix(in oklab,var(--color-pink-900)50%,transparent)}}.bg-purple-50{background-color:var(--color-purple-50)}.bg-purple-100{background-color:var(--color-purple-100)}.bg-purple-200{background-color:var(--color-purple-200)}.bg-purple-400{background-color:var(--color-purple-400)}.bg-purple-500{background-color:var(--color-purple-500)}.bg-purple-500\/30{background-color:#ac4bff4d}@supports (color:color-mix(in lab,red,red)){.bg-purple-500\/30{background-color:color-mix(in oklab,var(--color-purple-500)30%,transparent)}}.bg-purple-500\/80{background-color:#ac4bffcc}@supports (color:color-mix(in lab,red,red)){.bg-purple-500\/80{background-color:color-mix(in oklab,var(--color-purple-500)80%,transparent)}}.bg-purple-600{background-color:var(--color-purple-600)}.bg-purple-800\/20{background-color:#6e11b033}@supports (color:color-mix(in lab,red,red)){.bg-purple-800\/20{background-color:color-mix(in oklab,var(--color-purple-800)20%,transparent)}}.bg-purple-800\/50{background-color:#6e11b080}@supports (color:color-mix(in lab,red,red)){.bg-purple-800\/50{background-color:color-mix(in oklab,var(--color-purple-800)50%,transparent)}}.bg-purple-900\/10{background-color:#59168b1a}@supports (color:color-mix(in lab,red,red)){.bg-purple-900\/10{background-color:color-mix(in oklab,var(--color-purple-900)10%,transparent)}}.bg-purple-900\/20{background-color:#59168b33}@supports (color:color-mix(in lab,red,red)){.bg-purple-900\/20{background-color:color-mix(in oklab,var(--color-purple-900)20%,transparent)}}.bg-purple-900\/30{background-color:#59168b4d}@supports (color:color-mix(in lab,red,red)){.bg-purple-900\/30{background-color:color-mix(in oklab,var(--color-purple-900)30%,transparent)}}.bg-purple-900\/50{background-color:#59168b80}@supports (color:color-mix(in lab,red,red)){.bg-purple-900\/50{background-color:color-mix(in oklab,var(--color-purple-900)50%,transparent)}}.bg-red-50{background-color:var(--color-red-50)}.bg-red-100{background-color:var(--color-red-100)}.bg-red-400{background-color:var(--color-red-400)}.bg-red-500{background-color:var(--color-red-500)}.bg-red-500\/20{background-color:#fb2c3633}@supports (color:color-mix(in lab,red,red)){.bg-red-500\/20{background-color:color-mix(in oklab,var(--color-red-500)20%,transparent)}}.bg-red-600{background-color:var(--color-red-600)}.bg-red-900\/20{background-color:#82181a33}@supports (color:color-mix(in lab,red,red)){.bg-red-900\/20{background-color:color-mix(in oklab,var(--color-red-900)20%,transparent)}}.bg-red-900\/30{background-color:#82181a4d}@supports (color:color-mix(in lab,red,red)){.bg-red-900\/30{background-color:color-mix(in oklab,var(--color-red-900)30%,transparent)}}.bg-red-900\/50{background-color:#82181a80}@supports (color:color-mix(in lab,red,red)){.bg-red-900\/50{background-color:color-mix(in oklab,var(--color-red-900)50%,transparent)}}.bg-slate-50{background-color:var(--color-slate-50)}.bg-slate-100{background-color:var(--color-slate-100)}.bg-slate-200{background-color:var(--color-slate-200)}.bg-slate-500{background-color:var(--color-slate-500)}.bg-slate-500\/80{background-color:#62748ecc}@supports (color:color-mix(in lab,red,red)){.bg-slate-500\/80{background-color:color-mix(in oklab,var(--color-slate-500)80%,transparent)}}.bg-slate-600{background-color:var(--color-slate-600)}.bg-slate-700{background-color:var(--color-slate-700)}.bg-slate-700\/30{background-color:#3141584d}@supports (color:color-mix(in lab,red,red)){.bg-slate-700\/30{background-color:color-mix(in oklab,var(--color-slate-700)30%,transparent)}}.bg-slate-700\/50{background-color:#31415880}@supports (color:color-mix(in lab,red,red)){.bg-slate-700\/50{background-color:color-mix(in oklab,var(--color-slate-700)50%,transparent)}}.bg-slate-800{background-color:var(--color-slate-800)}.bg-slate-800\/30{background-color:#1d293d4d}@supports (color:color-mix(in lab,red,red)){.bg-slate-800\/30{background-color:color-mix(in oklab,var(--color-slate-800)30%,transparent)}}.bg-slate-800\/50{background-color:#1d293d80}@supports (color:color-mix(in lab,red,red)){.bg-slate-800\/50{background-color:color-mix(in oklab,var(--color-slate-800)50%,transparent)}}.bg-slate-800\/80{background-color:#1d293dcc}@supports (color:color-mix(in lab,red,red)){.bg-slate-800\/80{background-color:color-mix(in oklab,var(--color-slate-800)80%,transparent)}}.bg-slate-800\/90{background-color:#1d293de6}@supports (color:color-mix(in lab,red,red)){.bg-slate-800\/90{background-color:color-mix(in oklab,var(--color-slate-800)90%,transparent)}}.bg-slate-900{background-color:var(--color-slate-900)}.bg-slate-900\/50{background-color:#0f172b80}@supports (color:color-mix(in lab,red,red)){.bg-slate-900\/50{background-color:color-mix(in oklab,var(--color-slate-900)50%,transparent)}}.bg-slate-900\/95{background-color:#0f172bf2}@supports (color:color-mix(in lab,red,red)){.bg-slate-900\/95{background-color:color-mix(in oklab,var(--color-slate-900)95%,transparent)}}.bg-slate-950{background-color:var(--color-slate-950)}.bg-teal-600{background-color:var(--color-teal-600)}.bg-white{background-color:var(--color-white)}.bg-white\/20{background-color:#fff3}@supports (color:color-mix(in lab,red,red)){.bg-white\/20{background-color:color-mix(in oklab,var(--color-white)20%,transparent)}}.bg-yellow-100{background-color:var(--color-yellow-100)}.bg-yellow-900\/30{background-color:#733e0a4d}@supports (color:color-mix(in lab,red,red)){.bg-yellow-900\/30{background-color:color-mix(in oklab,var(--color-yellow-900)30%,transparent)}}.bg-gradient-to-b{--tw-gradient-position:to bottom in oklab;background-image:linear-gradient(var(--tw-gradient-stops))}.bg-gradient-to-br{--tw-gradient-position:to bottom right in oklab;background-image:linear-gradient(var(--tw-gradient-stops))}.bg-gradient-to-r{--tw-gradient-position:to right in oklab;background-image:linear-gradient(var(--tw-gradient-stops))}.bg-gradient-to-t{--tw-gradient-position:to top in oklab;background-image:linear-gradient(var(--tw-gradient-stops))}.from-amber-500{--tw-gradient-from:var(--color-amber-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-amber-600{--tw-gradient-from:var(--color-amber-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-blue-500{--tw-gradient-from:var(--color-blue-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-blue-600{--tw-gradient-from:var(--color-blue-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-blue-900\/20{--tw-gradient-from:#1c398e33}@supports (color:color-mix(in lab,red,red)){.from-blue-900\/20{--tw-gradient-from:color-mix(in oklab,var(--color-blue-900)20%,transparent)}}.from-blue-900\/20{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-cyan-400{--tw-gradient-from:var(--color-cyan-400);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-cyan-500{--tw-gradient-from:var(--color-cyan-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-cyan-600{--tw-gradient-from:var(--color-cyan-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-cyan-900\/30{--tw-gradient-from:#104e644d}@supports (color:color-mix(in lab,red,red)){.from-cyan-900\/30{--tw-gradient-from:color-mix(in oklab,var(--color-cyan-900)30%,transparent)}}.from-cyan-900\/30{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-emerald-500{--tw-gradient-from:var(--color-emerald-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-emerald-600{--tw-gradient-from:var(--color-emerald-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-emerald-600\/30{--tw-gradient-from:#0097674d}@supports (color:color-mix(in lab,red,red)){.from-emerald-600\/30{--tw-gradient-from:color-mix(in oklab,var(--color-emerald-600)30%,transparent)}}.from-emerald-600\/30{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-emerald-900\/20{--tw-gradient-from:#004e3b33}@supports (color:color-mix(in lab,red,red)){.from-emerald-900\/20{--tw-gradient-from:color-mix(in oklab,var(--color-emerald-900)20%,transparent)}}.from-emerald-900\/20{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-emerald-900\/50{--tw-gradient-from:#004e3b80}@supports (color:color-mix(in lab,red,red)){.from-emerald-900\/50{--tw-gradient-from:color-mix(in oklab,var(--color-emerald-900)50%,transparent)}}.from-emerald-900\/50{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-indigo-50{--tw-gradient-from:var(--color-indigo-50);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-purple-50{--tw-gradient-from:var(--color-purple-50);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-purple-50\/50{--tw-gradient-from:#faf5ff80}@supports (color:color-mix(in lab,red,red)){.from-purple-50\/50{--tw-gradient-from:color-mix(in oklab,var(--color-purple-50)50%,transparent)}}.from-purple-50\/50{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-purple-500{--tw-gradient-from:var(--color-purple-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-purple-600{--tw-gradient-from:var(--color-purple-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-purple-900\/30{--tw-gradient-from:#59168b4d}@supports (color:color-mix(in lab,red,red)){.from-purple-900\/30{--tw-gradient-from:color-mix(in oklab,var(--color-purple-900)30%,transparent)}}.from-purple-900\/30{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-red-700{--tw-gradient-from:var(--color-red-700);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-slate-50{--tw-gradient-from:var(--color-slate-50);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-slate-800{--tw-gradient-from:var(--color-slate-800);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.from-slate-900{--tw-gradient-from:var(--color-slate-900);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.via-slate-800{--tw-gradient-via:var(--color-slate-800);--tw-gradient-via-stops:var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-via)var(--tw-gradient-via-position),var(--tw-gradient-to)var(--tw-gradient-to-position);--tw-gradient-stops:var(--tw-gradient-via-stops)}.via-slate-800\/50{--tw-gradient-via:#1d293d80}@supports (color:color-mix(in lab,red,red)){.via-slate-800\/50{--tw-gradient-via:color-mix(in oklab,var(--color-slate-800)50%,transparent)}}.via-slate-800\/50{--tw-gradient-via-stops:var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-via)var(--tw-gradient-via-position),var(--tw-gradient-to)var(--tw-gradient-to-position);--tw-gradient-stops:var(--tw-gradient-via-stops)}.to-blue-500{--tw-gradient-to:var(--color-blue-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-blue-600{--tw-gradient-to:var(--color-blue-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-cyan-500{--tw-gradient-to:var(--color-cyan-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-cyan-600{--tw-gradient-to:var(--color-cyan-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-cyan-600\/30{--tw-gradient-to:#0092b54d}@supports (color:color-mix(in lab,red,red)){.to-cyan-600\/30{--tw-gradient-to:color-mix(in oklab,var(--color-cyan-600)30%,transparent)}}.to-cyan-600\/30{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-emerald-500{--tw-gradient-to:var(--color-emerald-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-emerald-600{--tw-gradient-to:var(--color-emerald-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-indigo-600{--tw-gradient-to:var(--color-indigo-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-indigo-900\/30{--tw-gradient-to:#312c854d}@supports (color:color-mix(in lab,red,red)){.to-indigo-900\/30{--tw-gradient-to:color-mix(in oklab,var(--color-indigo-900)30%,transparent)}}.to-indigo-900\/30{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-orange-500{--tw-gradient-to:var(--color-orange-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-orange-600{--tw-gradient-to:var(--color-orange-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-pink-50{--tw-gradient-to:var(--color-pink-50);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-purple-50{--tw-gradient-to:var(--color-purple-50);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-purple-500{--tw-gradient-to:var(--color-purple-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-purple-600{--tw-gradient-to:var(--color-purple-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-purple-900\/30{--tw-gradient-to:#59168b4d}@supports (color:color-mix(in lab,red,red)){.to-purple-900\/30{--tw-gradient-to:color-mix(in oklab,var(--color-purple-900)30%,transparent)}}.to-purple-900\/30{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-red-600{--tw-gradient-to:var(--color-red-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-slate-100{--tw-gradient-to:var(--color-slate-100);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-slate-700{--tw-gradient-to:var(--color-slate-700);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-slate-900{--tw-gradient-to:var(--color-slate-900);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-teal-600{--tw-gradient-to:var(--color-teal-600);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-teal-900\/50{--tw-gradient-to:#0b4f4a80}@supports (color:color-mix(in lab,red,red)){.to-teal-900\/50{--tw-gradient-to:color-mix(in oklab,var(--color-teal-900)50%,transparent)}}.to-teal-900\/50{--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-transparent{--tw-gradient-to:transparent;--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.to-white{--tw-gradient-to:var(--color-white);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.bg-clip-text{-webkit-background-clip:text;background-clip:text}.p-1{padding:calc(var(--spacing)*1)}.p-2{padding:calc(var(--spacing)*2)}.p-3{padding:calc(var(--spacing)*3)}.p-4{padding:calc(var(--spacing)*4)}.p-5{padding:calc(var(--spacing)*5)}.p-6{padding:calc(var(--spacing)*6)}.p-8{padding:calc(var(--spacing)*8)}.px-1{padding-inline:calc(var(--spacing)*1)}.px-1\.5{padding-inline:calc(var(--spacing)*1.5)}.px-2{padding-inline:calc(var(--spacing)*2)}.px-3{padding-inline:calc(var(--spacing)*3)}.px-4{padding-inline:calc(var(--spacing)*4)}.px-5{padding-inline:calc(var(--spacing)*5)}.px-6{padding-inline:calc(var(--spacing)*6)}.py-0\.5{padding-block:calc(var(--spacing)*.5)}.py-1{padding-block:calc(var(--spacing)*1)}.py-1\.5{padding-block:calc(var(--spacing)*1.5)}.py-2{padding-block:calc(var(--spacing)*2)}.py-2\.5{padding-block:calc(var(--spacing)*2.5)}.py-3{padding-block:calc(var(--spacing)*3)}.py-4{padding-block:calc(var(--spacing)*4)}.py-8{padding-block:calc(var(--spacing)*8)}.py-12{padding-block:calc(var(--spacing)*12)}.pt-2{padding-top:calc(var(--spacing)*2)}.pt-3{padding-top:calc(var(--spacing)*3)}.pt-4{padding-top:calc(var(--spacing)*4)}.pt-6{padding-top:calc(var(--spacing)*6)}.pb-2{padding-bottom:calc(var(--spacing)*2)}.pb-4{padding-bottom:calc(var(--spacing)*4)}.pb-6{padding-bottom:calc(var(--spacing)*6)}.pl-4{padding-left:calc(var(--spacing)*4)}.pl-8{padding-left:calc(var(--spacing)*8)}.text-center{text-align:center}.text-left{text-align:left}.text-right{text-align:right}.font-mono{font-family:var(--font-mono)}.font-sans{font-family:var(--font-sans)}.text-2xl{font-size:var(--text-2xl);line-height:var(--tw-leading,var(--text-2xl--line-height))}.text-3xl{font-size:var(--text-3xl);line-height:var(--tw-leading,var(--text-3xl--line-height))}.text-4xl{font-size:var(--text-4xl);line-height:var(--tw-leading,var(--text-4xl--line-height))}.text-5xl{font-size:var(--text-5xl);line-height:var(--tw-leading,var(--text-5xl--line-height))}.text-6xl{font-size:var(--text-6xl);line-height:var(--tw-leading,var(--text-6xl--line-height))}.text-lg{font-size:var(--text-lg);line-height:var(--tw-leading,var(--text-lg--line-height))}.text-sm{font-size:var(--text-sm);line-height:var(--tw-leading,var(--text-sm--line-height))}.text-xl{font-size:var(--text-xl);line-height:var(--tw-leading,var(--text-xl--line-height))}.text-xs{font-size:var(--text-xs);line-height:var(--tw-leading,var(--text-xs--line-height))}.text-\[8px\]{font-size:8px}.text-\[9px\]{font-size:9px}.text-\[10px\]{font-size:10px}.text-\[11px\]{font-size:11px}.leading-relaxed{--tw-leading:var(--leading-relaxed);line-height:var(--leading-relaxed)}.font-bold{--tw-font-weight:var(--font-weight-bold);font-weight:var(--font-weight-bold)}.font-medium{--tw-font-weight:var(--font-weight-medium);font-weight:var(--font-weight-medium)}.font-normal{--tw-font-weight:var(--font-weight-normal);font-weight:var(--font-weight-normal)}.font-semibold{--tw-font-weight:var(--font-weight-semibold);font-weight:var(--font-weight-semibold)}.tracking-tight{--tw-tracking:var(--tracking-tight);letter-spacing:var(--tracking-tight)}.tracking-wide{--tw-tracking:var(--tracking-wide);letter-spacing:var(--tracking-wide)}.tracking-wider{--tw-tracking:var(--tracking-wider);letter-spacing:var(--tracking-wider)}.break-all{word-break:break-all}.whitespace-nowrap{white-space:nowrap}.whitespace-pre-wrap{white-space:pre-wrap}.text-amber-200{color:var(--color-amber-200)}.text-amber-300{color:var(--color-amber-300)}.text-amber-300\/70{color:#ffd236b3}@supports (color:color-mix(in lab,red,red)){.text-amber-300\/70{color:color-mix(in oklab,var(--color-amber-300)70%,transparent)}}.text-amber-400{color:var(--color-amber-400)}.text-amber-500{color:var(--color-amber-500)}.text-amber-600{color:var(--color-amber-600)}.text-amber-700{color:var(--color-amber-700)}.text-amber-800{color:var(--color-amber-800)}.text-black{color:var(--color-black)}.text-blue-200{color:var(--color-blue-200)}.text-blue-300{color:var(--color-blue-300)}.text-blue-400{color:var(--color-blue-400)}.text-blue-500{color:var(--color-blue-500)}.text-blue-600{color:var(--color-blue-600)}.text-blue-700{color:var(--color-blue-700)}.text-blue-800{color:var(--color-blue-800)}.text-cyan-100{color:var(--color-cyan-100)}.text-cyan-300{color:var(--color-cyan-300)}.text-cyan-400{color:var(--color-cyan-400)}.text-emerald-200{color:var(--color-emerald-200)}.text-emerald-300{color:var(--color-emerald-300)}.text-emerald-400{color:var(--color-emerald-400)}.text-emerald-500{color:var(--color-emerald-500)}.text-emerald-600{color:var(--color-emerald-600)}.text-emerald-700{color:var(--color-emerald-700)}.text-emerald-800{color:var(--color-emerald-800)}.text-gray-400{color:var(--color-gray-400)}.text-gray-500{color:var(--color-gray-500)}.text-gray-600{color:var(--color-gray-600)}.text-gray-700{color:var(--color-gray-700)}.text-gray-800{color:var(--color-gray-800)}.text-gray-900{color:var(--color-gray-900)}.text-green-700{color:var(--color-green-700)}.text-indigo-300{color:var(--color-indigo-300)}.text-indigo-700{color:var(--color-indigo-700)}.text-indigo-800{color:var(--color-indigo-800)}.text-pink-200{color:var(--color-pink-200)}.text-pink-300{color:var(--color-pink-300)}.text-purple-200{color:var(--color-purple-200)}.text-purple-300{color:var(--color-purple-300)}.text-purple-400{color:var(--color-purple-400)}.text-purple-500{color:var(--color-purple-500)}.text-purple-600{color:var(--color-purple-600)}.text-purple-700{color:var(--color-purple-700)}.text-purple-800{color:var(--color-purple-800)}.text-red-200{color:var(--color-red-200)}.text-red-300{color:var(--color-red-300)}.text-red-400{color:var(--color-red-400)}.text-red-500{color:var(--color-red-500)}.text-red-600{color:var(--color-red-600)}.text-red-700{color:var(--color-red-700)}.text-slate-100{color:var(--color-slate-100)}.text-slate-200{color:var(--color-slate-200)}.text-slate-300{color:var(--color-slate-300)}.text-slate-400{color:var(--color-slate-400)}.text-slate-500{color:var(--color-slate-500)}.text-slate-600{color:var(--color-slate-600)}.text-slate-700{color:var(--color-slate-700)}.text-slate-800{color:var(--color-slate-800)}.text-teal-400{color:var(--color-teal-400)}.text-transparent{color:#0000}.text-white{color:var(--color-white)}.text-white\/70{color:#ffffffb3}@supports (color:color-mix(in lab,red,red)){.text-white\/70{color:color-mix(in oklab,var(--color-white)70%,transparent)}}.text-white\/80{color:#fffc}@supports (color:color-mix(in lab,red,red)){.text-white\/80{color:color-mix(in oklab,var(--color-white)80%,transparent)}}.text-yellow-400{color:var(--color-yellow-400)}.text-yellow-600{color:var(--color-yellow-600)}.text-yellow-800{color:var(--color-yellow-800)}.capitalize{text-transform:capitalize}.uppercase{text-transform:uppercase}.italic{font-style:italic}.placeholder-slate-400::placeholder{color:var(--color-slate-400)}.opacity-0{opacity:0}.opacity-25{opacity:.25}.opacity-70{opacity:.7}.opacity-75{opacity:.75}.opacity-80{opacity:.8}.opacity-100{opacity:1}.shadow-2xl{--tw-shadow:0 25px 50px -12px var(--tw-shadow-color,#00000040);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.shadow-lg{--tw-shadow:0 10px 15px -3px var(--tw-shadow-color,#0000001a),0 4px 6px -4px var(--tw-shadow-color,#0000001a);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.shadow-md{--tw-shadow:0 4px 6px -1px var(--tw-shadow-color,#0000001a),0 2px 4px -2px var(--tw-shadow-color,#0000001a);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.shadow-sm{--tw-shadow:0 1px 3px 0 var(--tw-shadow-color,#0000001a),0 1px 2px -1px var(--tw-shadow-color,#0000001a);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.shadow-xl{--tw-shadow:0 20px 25px -5px var(--tw-shadow-color,#0000001a),0 8px 10px -6px var(--tw-shadow-color,#0000001a);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.ring-1{--tw-ring-shadow:var(--tw-ring-inset,)0 0 0 calc(1px + var(--tw-ring-offset-width))var(--tw-ring-color,currentcolor);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.ring-2{--tw-ring-shadow:var(--tw-ring-inset,)0 0 0 calc(2px + var(--tw-ring-offset-width))var(--tw-ring-color,currentcolor);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.shadow-amber-500\/20{--tw-shadow-color:#f99c0033}@supports (color:color-mix(in lab,red,red)){.shadow-amber-500\/20{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-amber-500)20%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-amber-500\/30{--tw-shadow-color:#f99c004d}@supports (color:color-mix(in lab,red,red)){.shadow-amber-500\/30{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-amber-500)30%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-amber-500\/50{--tw-shadow-color:#f99c0080}@supports (color:color-mix(in lab,red,red)){.shadow-amber-500\/50{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-amber-500)50%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-blue-200{--tw-shadow-color:oklch(88.2% .059 254.128)}@supports (color:color-mix(in lab,red,red)){.shadow-blue-200{--tw-shadow-color:color-mix(in oklab,var(--color-blue-200)var(--tw-shadow-alpha),transparent)}}.shadow-blue-500\/30{--tw-shadow-color:#3080ff4d}@supports (color:color-mix(in lab,red,red)){.shadow-blue-500\/30{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-blue-500)30%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-cyan-500\/30{--tw-shadow-color:#00b7d74d}@supports (color:color-mix(in lab,red,red)){.shadow-cyan-500\/30{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-cyan-500)30%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-cyan-500\/50{--tw-shadow-color:#00b7d780}@supports (color:color-mix(in lab,red,red)){.shadow-cyan-500\/50{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-cyan-500)50%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-emerald-500\/20{--tw-shadow-color:#00bb7f33}@supports (color:color-mix(in lab,red,red)){.shadow-emerald-500\/20{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-emerald-500)20%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-emerald-500\/30{--tw-shadow-color:#00bb7f4d}@supports (color:color-mix(in lab,red,red)){.shadow-emerald-500\/30{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-emerald-500)30%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-emerald-500\/50{--tw-shadow-color:#00bb7f80}@supports (color:color-mix(in lab,red,red)){.shadow-emerald-500\/50{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-emerald-500)50%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-purple-500\/30{--tw-shadow-color:#ac4bff4d}@supports (color:color-mix(in lab,red,red)){.shadow-purple-500\/30{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-purple-500)30%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-purple-500\/50{--tw-shadow-color:#ac4bff80}@supports (color:color-mix(in lab,red,red)){.shadow-purple-500\/50{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-purple-500)50%,transparent)var(--tw-shadow-alpha),transparent)}}.shadow-red-500\/20{--tw-shadow-color:#fb2c3633}@supports (color:color-mix(in lab,red,red)){.shadow-red-500\/20{--tw-shadow-color:color-mix(in oklab,color-mix(in oklab,var(--color-red-500)20%,transparent)var(--tw-shadow-alpha),transparent)}}.ring-blue-500{--tw-ring-color:var(--color-blue-500)}.ring-current{--tw-ring-color:currentcolor}.ring-offset-1{--tw-ring-offset-width:1px;--tw-ring-offset-shadow:var(--tw-ring-inset,)0 0 0 var(--tw-ring-offset-width)var(--tw-ring-offset-color)}.ring-offset-2{--tw-ring-offset-width:2px;--tw-ring-offset-shadow:var(--tw-ring-inset,)0 0 0 var(--tw-ring-offset-width)var(--tw-ring-offset-color)}.ring-offset-slate-900{--tw-ring-offset-color:var(--color-slate-900)}.backdrop-blur{--tw-backdrop-blur:blur(8px);-webkit-backdrop-filter:var(--tw-backdrop-blur,)var(--tw-backdrop-brightness,)var(--tw-backdrop-contrast,)var(--tw-backdrop-grayscale,)var(--tw-backdrop-hue-rotate,)var(--tw-backdrop-invert,)var(--tw-backdrop-opacity,)var(--tw-backdrop-saturate,)var(--tw-backdrop-sepia,);backdrop-filter:var(--tw-backdrop-blur,)var(--tw-backdrop-brightness,)var(--tw-backdrop-contrast,)var(--tw-backdrop-grayscale,)var(--tw-backdrop-hue-rotate,)var(--tw-backdrop-invert,)var(--tw-backdrop-opacity,)var(--tw-backdrop-saturate,)var(--tw-backdrop-sepia,)}.backdrop-blur-md{--tw-backdrop-blur:blur(var(--blur-md));-webkit-backdrop-filter:var(--tw-backdrop-blur,)var(--tw-backdrop-brightness,)var(--tw-backdrop-contrast,)var(--tw-backdrop-grayscale,)var(--tw-backdrop-hue-rotate,)var(--tw-backdrop-invert,)var(--tw-backdrop-opacity,)var(--tw-backdrop-saturate,)var(--tw-backdrop-sepia,);backdrop-filter:var(--tw-backdrop-blur,)var(--tw-backdrop-brightness,)var(--tw-backdrop-contrast,)var(--tw-backdrop-grayscale,)var(--tw-backdrop-hue-rotate,)var(--tw-backdrop-invert,)var(--tw-backdrop-opacity,)var(--tw-backdrop-saturate,)var(--tw-backdrop-sepia,)}.transition{transition-property:color,background-color,border-color,outline-color,text-decoration-color,fill,stroke,--tw-gradient-from,--tw-gradient-via,--tw-gradient-to,opacity,box-shadow,transform,translate,scale,rotate,filter,-webkit-backdrop-filter,backdrop-filter,display,content-visibility,overlay,pointer-events;transition-timing-function:var(--tw-ease,var(--default-transition-timing-function));transition-duration:var(--tw-duration,var(--default-transition-duration))}.transition-all{transition-property:all;transition-timing-function:var(--tw-ease,var(--default-transition-timing-function));transition-duration:var(--tw-duration,var(--default-transition-duration))}.transition-colors{transition-property:color,background-color,border-color,outline-color,text-decoration-color,fill,stroke,--tw-gradient-from,--tw-gradient-via,--tw-gradient-to;transition-timing-function:var(--tw-ease,var(--default-transition-timing-function));transition-duration:var(--tw-duration,var(--default-transition-duration))}.transition-opacity{transition-property:opacity;transition-timing-function:var(--tw-ease,var(--default-transition-timing-function));transition-duration:var(--tw-duration,var(--default-transition-duration))}.transition-transform{transition-property:transform,translate,scale,rotate;transition-timing-function:var(--tw-ease,var(--default-transition-timing-function));transition-duration:var(--tw-duration,var(--default-transition-duration))}.delay-200{transition-delay:.2s}.delay-300{transition-delay:.3s}.delay-400{transition-delay:.4s}.delay-500{transition-delay:.5s}.delay-600{transition-delay:.6s}.delay-700{transition-delay:.7s}.duration-300{--tw-duration:.3s;transition-duration:.3s}.duration-500{--tw-duration:.5s;transition-duration:.5s}.duration-700{--tw-duration:.7s;transition-duration:.7s}.ease-in-out{--tw-ease:var(--ease-in-out);transition-timing-function:var(--ease-in-out)}.ease-out{--tw-ease:var(--ease-out);transition-timing-function:var(--ease-out)}@media(hover:hover){.group-hover\:animate-bounce:is(:where(.group):hover *){animation:var(--animate-bounce)}.hover\:scale-105:hover{--tw-scale-x:105%;--tw-scale-y:105%;--tw-scale-z:105%;scale:var(--tw-scale-x)var(--tw-scale-y)}.hover\:scale-110:hover{--tw-scale-x:110%;--tw-scale-y:110%;--tw-scale-z:110%;scale:var(--tw-scale-x)var(--tw-scale-y)}.hover\:animate-none:hover{animation:none}.hover\:border-amber-500:hover{border-color:var(--color-amber-500)}.hover\:border-emerald-500:hover{border-color:var(--color-emerald-500)}.hover\:border-emerald-500\/50:hover{border-color:#00bb7f80}@supports (color:color-mix(in lab,red,red)){.hover\:border-emerald-500\/50:hover{border-color:color-mix(in oklab,var(--color-emerald-500)50%,transparent)}}.hover\:border-gray-300:hover{border-color:var(--color-gray-300)}.hover\:border-red-500:hover{border-color:var(--color-red-500)}.hover\:bg-amber-50:hover{background-color:var(--color-amber-50)}.hover\:bg-amber-500:hover{background-color:var(--color-amber-500)}.hover\:bg-amber-600:hover{background-color:var(--color-amber-600)}.hover\:bg-blue-200:hover{background-color:var(--color-blue-200)}.hover\:bg-blue-700:hover{background-color:var(--color-blue-700)}.hover\:bg-cyan-500:hover{background-color:var(--color-cyan-500)}.hover\:bg-emerald-500:hover{background-color:var(--color-emerald-500)}.hover\:bg-emerald-600:hover{background-color:var(--color-emerald-600)}.hover\:bg-emerald-700:hover{background-color:var(--color-emerald-700)}.hover\:bg-gray-100:hover{background-color:var(--color-gray-100)}.hover\:bg-purple-100:hover{background-color:var(--color-purple-100)}.hover\:bg-purple-200:hover{background-color:var(--color-purple-200)}.hover\:bg-purple-500:hover{background-color:var(--color-purple-500)}.hover\:bg-red-500:hover{background-color:var(--color-red-500)}.hover\:bg-red-600:hover{background-color:var(--color-red-600)}.hover\:bg-slate-100:hover{background-color:var(--color-slate-100)}.hover\:bg-slate-200:hover{background-color:var(--color-slate-200)}.hover\:bg-slate-500:hover{background-color:var(--color-slate-500)}.hover\:bg-slate-600:hover{background-color:var(--color-slate-600)}.hover\:bg-slate-700:hover{background-color:var(--color-slate-700)}.hover\:bg-slate-700\/20:hover{background-color:#31415833}@supports (color:color-mix(in lab,red,red)){.hover\:bg-slate-700\/20:hover{background-color:color-mix(in oklab,var(--color-slate-700)20%,transparent)}}.hover\:bg-white\/5:hover{background-color:#ffffff0d}@supports (color:color-mix(in lab,red,red)){.hover\:bg-white\/5:hover{background-color:color-mix(in oklab,var(--color-white)5%,transparent)}}.hover\:from-blue-400:hover{--tw-gradient-from:var(--color-blue-400);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-blue-500:hover{--tw-gradient-from:var(--color-blue-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-cyan-400:hover{--tw-gradient-from:var(--color-cyan-400);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-emerald-400:hover{--tw-gradient-from:var(--color-emerald-400);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-emerald-500:hover{--tw-gradient-from:var(--color-emerald-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-indigo-100:hover{--tw-gradient-from:var(--color-indigo-100);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-purple-100:hover{--tw-gradient-from:var(--color-purple-100);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:from-purple-400:hover{--tw-gradient-from:var(--color-purple-400);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-blue-500:hover{--tw-gradient-to:var(--color-blue-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-cyan-500:hover{--tw-gradient-to:var(--color-cyan-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-emerald-500:hover{--tw-gradient-to:var(--color-emerald-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-indigo-500:hover{--tw-gradient-to:var(--color-indigo-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-pink-100:hover{--tw-gradient-to:var(--color-pink-100);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-purple-100:hover{--tw-gradient-to:var(--color-purple-100);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:to-purple-500:hover{--tw-gradient-to:var(--color-purple-500);--tw-gradient-stops:var(--tw-gradient-via-stops,var(--tw-gradient-position),var(--tw-gradient-from)var(--tw-gradient-from-position),var(--tw-gradient-to)var(--tw-gradient-to-position))}.hover\:stroke-blue-500:hover{stroke:var(--color-blue-500)}.hover\:stroke-purple-500:hover{stroke:var(--color-purple-500)}.hover\:stroke-yellow-500:hover{stroke:var(--color-yellow-500)}.hover\:text-amber-400:hover{color:var(--color-amber-400)}.hover\:text-cyan-300:hover{color:var(--color-cyan-300)}.hover\:text-emerald-300:hover{color:var(--color-emerald-300)}.hover\:text-gray-900:hover{color:var(--color-gray-900)}.hover\:text-purple-800:hover{color:var(--color-purple-800)}.hover\:text-red-300:hover{color:var(--color-red-300)}.hover\:text-slate-300:hover{color:var(--color-slate-300)}.hover\:text-white:hover{color:var(--color-white)}.hover\:underline:hover{text-decoration-line:underline}.hover\:shadow-lg:hover{--tw-shadow:0 10px 15px -3px var(--tw-shadow-color,#0000001a),0 4px 6px -4px var(--tw-shadow-color,#0000001a);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.hover\:shadow-xl:hover{--tw-shadow:0 20px 25px -5px var(--tw-shadow-color,#0000001a),0 8px 10px -6px var(--tw-shadow-color,#0000001a);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}}.focus\:border-blue-500:focus{border-color:var(--color-blue-500)}.focus\:border-purple-500:focus{border-color:var(--color-purple-500)}.focus\:ring-2:focus{--tw-ring-shadow:var(--tw-ring-inset,)0 0 0 calc(2px + var(--tw-ring-offset-width))var(--tw-ring-color,currentcolor);box-shadow:var(--tw-inset-shadow),var(--tw-inset-ring-shadow),var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow)}.focus\:ring-blue-500:focus{--tw-ring-color:var(--color-blue-500)}.focus\:ring-cyan-500:focus{--tw-ring-color:var(--color-cyan-500)}.focus\:outline-none:focus{--tw-outline-style:none;outline-style:none}.disabled\:cursor-not-allowed:disabled{cursor:not-allowed}.disabled\:bg-slate-700:disabled{background-color:var(--color-slate-700)}.disabled\:opacity-30:disabled{opacity:.3}.disabled\:opacity-50:disabled{opacity:.5}@media(min-width:40rem){.sm\:inline{display:inline}}@media(min-width:48rem){.md\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.md\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.md\:grid-cols-4{grid-template-columns:repeat(4,minmax(0,1fr))}}}body{background-color:#f8fafc;min-height:100vh;margin:0;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,sans-serif}#root{min-height:100vh}.reasoning-display{white-space:pre-wrap;word-break:break-word;font-family:JetBrains Mono,Fira Code,Monaco,monospace;font-size:.875rem;line-height:1.6}.agent-node{transition:all .3s}.agent-node:hover{transform:scale(1.05)}.agent-node.processing{animation:1.5s ease-in-out infinite pulseGlow}@keyframes pulseGlow{0%,to{box-shadow:0 0 #3b82f666}50%{box-shadow:0 0 0 12px #3b82f600}}.connection-line{stroke-dasharray:5 5;animation:1s linear infinite flowDash}.connection-line.active{stroke:#3b82f6;stroke-width:3px}@keyframes flowDash{to{stroke-dashoffset:-10px}}.custom-scrollbar::-webkit-scrollbar{width:8px}.custom-scrollbar::-webkit-scrollbar-track{background:#1e293b;border-radius:4px}.custom-scrollbar::-webkit-scrollbar-thumb{background:#475569;border-radius:4px}.custom-scrollbar::-webkit-scrollbar-thumb:hover{background:#64748b}.animate-slide-up{animation:.4s ease-out forwards slideUp}@keyframes slideUp{0%{opacity:0;transform:translateY(20px)}to{opacity:1;transform:translateY(0)}}.animate-fadeIn{animation:.5s ease-out forwards fadeIn}@keyframes fadeIn{0%{opacity:0;transform:translateY(-10px)}to{opacity:1;transform:translateY(0)}}.animate-slideUp{animation:.3s ease-out forwards slideUpChat}@keyframes slideUpChat{0%{opacity:0;transform:translateY(20px)scale(.95)}to{opacity:1;transform:translateY(0)scale(1)}}.animate-fadeInUp{animation:.8s ease-out forwards fadeInUp}.animate-fadeInLeft{animation:.8s ease-out forwards fadeInLeft}.animate-fadeInRight{animation:.8s ease-out forwards fadeInRight}.animate-pulse-slow{animation:2s ease-in-out infinite pulseSlow}.animation-delay-200{animation-delay:.2s}.animation-delay-300{animation-delay:.3s}.animation-delay-500{animation-delay:.5s}.animation-delay-700{animation-delay:.7s}@keyframes fadeInUp{0%{opacity:0;transform:translateY(30px)}to{opacity:1;transform:translateY(0)}}@keyframes fadeInLeft{0%{opacity:0;transform:translate(-30px)}to{opacity:1;transform:translate(0)}}@keyframes fadeInRight{0%{opacity:0;transform:translate(30px)}to{opacity:1;transform:translate(0)}}@keyframes pulseSlow{0%,to{transform:scale(1);box-shadow:0 0 #06b6d466}50%{transform:scale(1.05);box-shadow:0 0 30px 10px #06b6d433}}@property --tw-translate-x{syntax:"*";inherits:false;initial-value:0}@property --tw-translate-y{syntax:"*";inherits:false;initial-value:0}@property --tw-translate-z{syntax:"*";inherits:false;initial-value:0}@property --tw-scale-x{syntax:"*";inherits:false;initial-value:1}@property --tw-scale-y{syntax:"*";inherits:false;initial-value:1}@property --tw-scale-z{syntax:"*";inherits:false;initial-value:1}@property --tw-rotate-x{syntax:"*";inherits:false}@property --tw-rotate-y{syntax:"*";inherits:false}@property --tw-rotate-z{syntax:"*";inherits:false}@property --tw-skew-x{syntax:"*";inherits:false}@property --tw-skew-y{syntax:"*";inherits:false}@property --tw-space-y-reverse{syntax:"*";inherits:false;initial-value:0}@property --tw-space-x-reverse{syntax:"*";inherits:false;initial-value:0}@property --tw-border-style{syntax:"*";inherits:false;initial-value:solid}@property --tw-gradient-position{syntax:"*";inherits:false}@property --tw-gradient-from{syntax:"<color>";inherits:false;initial-value:#0000}@property --tw-gradient-via{syntax:"<color>";inherits:false;initial-value:#0000}@property --tw-gradient-to{syntax:"<color>";inherits:false;initial-value:#0000}@property --tw-gradient-stops{syntax:"*";inherits:false}@property --tw-gradient-via-stops{syntax:"*";inherits:false}@property --tw-gradient-from-position{syntax:"<length-percentage>";inherits:false;initial-value:0%}@property --tw-gradient-via-position{syntax:"<length-percentage>";inherits:false;initial-value:50%}@property --tw-gradient-to-position{syntax:"<length-percentage>";inherits:false;initial-value:100%}@property --tw-leading{syntax:"*";inherits:false}@property --tw-font-weight{syntax:"*";inherits:false}@property --tw-tracking{syntax:"*";inherits:false}@property --tw-shadow{syntax:"*";inherits:false;initial-value:0 0 #0000}@property --tw-shadow-color{syntax:"*";inherits:false}@property --tw-shadow-alpha{syntax:"<percentage>";inherits:false;initial-value:100%}@property --tw-inset-shadow{syntax:"*";inherits:false;initial-value:0 0 #0000}@property --tw-inset-shadow-color{syntax:"*";inherits:false}@property --tw-inset-shadow-alpha{syntax:"<percentage>";inherits:false;initial-value:100%}@property --tw-ring-color{syntax:"*";inherits:false}@property --tw-ring-shadow{syntax:"*";inherits:false;initial-value:0 0 #0000}@property --tw-inset-ring-color{syntax:"*";inherits:false}@property --tw-inset-ring-shadow{syntax:"*";inherits:false;initial-value:0 0 #0000}@property --tw-ring-inset{syntax:"*";inherits:false}@property --tw-ring-offset-width{syntax:"<length>";inherits:false;initial-value:0}@property --tw-ring-offset-color{syntax:"*";inherits:false;initial-value:#fff}@property --tw-ring-offset-shadow{syntax:"*";inherits:false;initial-value:0 0 #0000}@property --tw-backdrop-blur{syntax:"*";inherits:false}@property --tw-backdrop-brightness{syntax:"*";inherits:false}@property --tw-backdrop-contrast{syntax:"*";inherits:false}@property --tw-backdrop-grayscale{syntax:"*";inherits:false}@property --tw-backdrop-hue-rotate{syntax:"*";inherits:false}@property --tw-backdrop-invert{syntax:"*";inherits:false}@property --tw-backdrop-opacity{syntax:"*";inherits:false}@property --tw-backdrop-saturate{syntax:"*";inherits:false}@property --tw-backdrop-sepia{syntax:"*";inherits:false}@property --tw-duration{syntax:"*";inherits:false}@property --tw-ease{syntax:"*";inherits:false}@keyframes spin{to{transform:rotate(360deg)}}@keyframes pulse{50%{opacity:.5}}@keyframes bounce{0%,to{animation-timing-function:cubic-bezier(.8,0,1,1);transform:translateY(-25%)}50%{animation-timing-function:cubic-bezier(0,0,.2,1);transform:none}}


================================================================================
FILE: frontend/dist/index.html
================================================================================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>frontend</title>
    <script type="module" crossorigin src="/assets/index-CF3sXGZT.js"></script>
    <link rel="stylesheet" crossorigin href="/assets/index-DPvok_dg.css">
  </head>
  <body>
    <div id="root"></div>
  </body>
</html>


================================================================================
FILE: frontend/eslint.config.js
================================================================================
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import tseslint from 'typescript-eslint'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      js.configs.recommended,
      tseslint.configs.recommended,
      reactHooks.configs.flat.recommended,
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
  },
])


================================================================================
FILE: frontend/index.html
================================================================================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>frontend</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>


